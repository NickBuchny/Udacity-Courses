<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_image_classification2</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Image-Classification">Image Classification<a class="anchor-link" href="#Image-Classification">&#182;</a></h1><p>In this project, you'll classify images from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>.  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Run the following cell to download the <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">isdir</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="n">cifar10_dataset_folder_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-batches-py&#39;</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;CIFAR-10 Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isdir</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;cifar-10-python.tar.gz&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="n">tests</span><span class="o">.</span><span class="n">test_folder_path</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>All files found!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named <code>data_batch_1</code>, <code>data_batch_2</code>, etc.. Each batch contains the labels and images that are one of the following:</p>
<ul>
<li>airplane</li>
<li>automobile</li>
<li>bird</li>
<li>cat</li>
<li>deer</li>
<li>dog</li>
<li>frog</li>
<li>horse</li>
<li>ship</li>
<li>truck</li>
</ul>
<p>Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the <code>batch_id</code> and <code>sample_id</code>. The <code>batch_id</code> is the id for a batch (1-5). The <code>sample_id</code> is the id for a image and label pair in the batch.</p>
<p>Ask yourself "What are all possible labels?", "What is the range of values for the image data?", "Are the labels in order or random?".  Answers to questions like these will help you preprocess the data and end up with better predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Explore the dataset</span>
<span class="n">batch_id</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sample_id</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">helper</span><span class="o">.</span><span class="n">display_stats</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Stats of batch 1:
Samples: 10000
Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}
First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]

Example of Image 5:
Image - Min Value: 0 Max Value: 252
Image - Shape: (32, 32, 3)
Label - Label Id: 1 Name: automobile
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=253
height=250
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocess-Functions">Implement Preprocess Functions<a class="anchor-link" href="#Implement-Preprocess-Functions">&#182;</a></h2><h3 id="Normalize">Normalize<a class="anchor-link" href="#Normalize">&#182;</a></h3><p>In the cell below, implement the <code>normalize</code> function to take in image data, <code>x</code>, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as <code>x</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize a list of sample image data in the range of 0 to 1</span>
<span class="sd">    : x: List of image data.  The image shape is (32, 32, 3)</span>
<span class="sd">    : return: Numpy array of normalize data</span>
<span class="sd">    &quot;&quot;&quot;</span>
   
    <span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span> 
    <span class="n">normer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span>
    <span class="n">normed</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">pixel_data</span> <span class="ow">in</span> <span class="n">image</span><span class="p">:</span>
            <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">normer</span><span class="p">(</span><span class="n">pixel_data</span><span class="p">))</span>
        <span class="n">normed</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">normed</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_normalize</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/tom/anaconda2/envs/tflearn/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.
  warnings.warn(msg, _DataConversionWarning)
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-hot-encode">One-hot encode<a class="anchor-link" href="#One-hot-encode">&#182;</a></h3><p>Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the <code>one_hot_encode</code> function. The input, <code>x</code>, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to <code>one_hot_encode</code>.  Make sure to save the map of encodings outside the function.</p>
<p>Hint: Don't reinvent the wheel.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mapping</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">stuff</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mapping</span><span class="p">):</span>
    <span class="n">stuff</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.</span>
<span class="sd">    : x: List of sample Labels</span>
<span class="sd">    : return: Numpy array of one-hot encoded labels</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_copy</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">whatever</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">x_copy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">mapping</span><span class="p">[:,</span> <span class="n">whatever</span><span class="p">]</span>
    

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_copy</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_one_hot_encode</span><span class="p">(</span><span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Randomize-Data">Randomize Data<a class="anchor-link" href="#Randomize-Data">&#182;</a></h3><p>As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/tom/anaconda2/envs/tflearn/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the normalize function.
  warnings.warn(msg, _DataConversionWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="c1"># Load the Preprocessed Validation data</span>
<span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_validation.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h2><p>For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.</p>
<blockquote><p><strong>Note:</strong> If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages to build each layer, except the layers you build in the "Convolutional and Max Pooling Layer" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.</p>
<p>However, if you would like to get the most out of this course, try to solve all the problems <em>without</em> using anything from the TF Layers packages. You <strong>can</strong> still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the <code>conv2d</code> class, <a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d">tf.layers.conv2d</a>, you would want to use the TF Neural Network version of <code>conv2d</code>, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">tf.nn.conv2d</a>.</p>
</blockquote>
<p>Let's begin!</p>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions</p>
<ul>
<li>Implement <code>neural_net_image_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>image_shape</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "x" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_label_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>n_classes</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "y" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_keep_prob_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> for dropout keep probability.</li>
<li>Name the TensorFlow placeholder "keep_prob" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
</ul>
<p>These names will be used at the end of the project to load your saved model.</p>
<p>Note: <code>None</code> for shapes in TensorFlow allow for a dynamic size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">neural_net_image_input</span><span class="p">(</span><span class="n">image_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of image input</span>
<span class="sd">    : image_shape: Shape of the images</span>
<span class="sd">    : return: Tensor for image input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>    
    
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">neural_net_label_input</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of label input</span>
<span class="sd">    : n_classes: Number of classes</span>
<span class="sd">    : return: Tensor for label input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;y&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y</span>


<span class="k">def</span> <span class="nf">neural_net_keep_prob_input</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for keep probability</span>
<span class="sd">    : return: Tensor for keep probability.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">keep_prob</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_image_inputs</span><span class="p">(</span><span class="n">neural_net_image_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_label_inputs</span><span class="p">(</span><span class="n">neural_net_label_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_keep_prob_inputs</span><span class="p">(</span><span class="n">neural_net_keep_prob_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Image Input Tests Passed.
Label Input Tests Passed.
Keep Prob Tests Passed.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolution-and-Max-Pooling-Layer">Convolution and Max Pooling Layer<a class="anchor-link" href="#Convolution-and-Max-Pooling-Layer">&#182;</a></h3><p>Convolution layers have a lot of success with images. For this code cell, you should implement the function <code>conv2d_maxpool</code> to apply convolution then max pooling:</p>
<ul>
<li>Create the weight and bias using <code>conv_ksize</code>, <code>conv_num_outputs</code> and the shape of <code>x_tensor</code>.</li>
<li>Apply a convolution to <code>x_tensor</code> using weight and <code>conv_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
<li>Add bias</li>
<li>Add a nonlinear activation to the convolution.</li>
<li>Apply Max Pooling using <code>pool_ksize</code> and <code>pool_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
</ul>
<p><strong>Note:</strong> You <strong>can't</strong> use <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> for <strong>this</strong> layer, but you can still use TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/nn">Neural Network</a> package. You may still use the shortcut option for all the <strong>other</strong> layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv2d_maxpool</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">conv_num_outputs</span><span class="p">,</span> <span class="n">conv_ksize</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">,</span>
                   <span class="n">pool_ksize</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">):</span>
    
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply convolution then max pooling to x_tensor</span>
<span class="sd">    :param x_tensor: TensorFlow Tensor</span>
<span class="sd">    :param conv_num_outputs: Number of outputs for the convolutional layer</span>
<span class="sd">    :param conv_strides: Stride 2-D Tuple for convolution</span>
<span class="sd">    :param pool_ksize: kernal size 2-D Tuple for pool</span>
<span class="sd">    :param pool_strides: Stride 2-D Tuple for pool</span>
<span class="sd">    : return: A tensor that represents convolution and max pooling of x_tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># weights + bias</span>
    <span class="n">filter_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">conv_ksize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conv_ksize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                                                              <span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">3</span><span class="p">],</span>
                                                              <span class="n">conv_num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=.</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">filter_bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">conv_num_outputs</span><span class="p">))</span>
    
    <span class="c1"># vals</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">conv_strides</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="s2">&quot;SAME&quot;</span>
    
    
    <span class="c1"># conv layer</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">x_tensor</span><span class="p">,</span> <span class="nb">filter</span><span class="o">=</span><span class="n">filter_weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">conv_strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span>
                        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span> 
    <span class="c1"># add bias</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">filter_bias</span><span class="p">)</span>
    
    <span class="c1"># pass through relu activation</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>
    
    <span class="c1"># max pool</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">conv</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">pool_ksize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pool_ksize</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span>
                          <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pool_strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">conv</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_con_pool</span><span class="p">(</span><span class="n">conv2d_maxpool</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Flatten-Layer">Flatten Layer<a class="anchor-link" href="#Flatten-Layer">&#182;</a></h3><p>Implement the <code>flatten</code> function to change the dimension of <code>x_tensor</code> from a 4-D tensor to a 2-D tensor.  The output should be the shape (<em>Batch Size</em>, <em>Flattened Image Size</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flatten x_tensor to (Batch Size, Flattened Image Size)</span>
<span class="sd">    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.</span>
<span class="sd">    : return: A tensor of size (Batch Size, Flattened Image Size).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">flat_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_tensor</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">flat_tensor</span>




<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_flatten</span><span class="p">(</span><span class="n">flatten</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Connected-Layer">Fully-Connected Layer<a class="anchor-link" href="#Fully-Connected-Layer">&#182;</a></h3><p>Implement the <code>fully_conn</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a fully connected layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="p">,</span> 
                                             <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">layer</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_fully_conn</span><span class="p">(</span><span class="n">fully_conn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-Layer">Output Layer<a class="anchor-link" href="#Output-Layer">&#182;</a></h3><p>Implement the <code>output</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>
<p><strong>Note:</strong> Activation, softmax, or cross entropy should <strong>not</strong> be applied to this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a output layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="p">,</span> 
                                             <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">layer</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Convolutional-Model">Create Convolutional Model<a class="anchor-link" href="#Create-Convolutional-Model">&#182;</a></h3><p>Implement the function <code>conv_net</code> to create a convolutional neural network model. The function takes in a batch of images, <code>x</code>, and outputs logits.  Use the layers you created above to create this model:</p>
<ul>
<li>Apply 1, 2, or 3 Convolution and Max Pool layers</li>
<li>Apply a Flatten Layer</li>
<li>Apply 1, 2, or 3 Fully Connected Layers</li>
<li>Apply an Output Layer</li>
<li>Return the output</li>
<li>Apply <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout">TensorFlow's Dropout</a> to one or more layers in the model using <code>keep_prob</code>. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a convolutional neural network model</span>
<span class="sd">    : x: Placeholder tensor that holds image data.</span>
<span class="sd">    : keep_prob: Placeholder tensor that hold dropout keep probability.</span>
<span class="sd">    : return: Tensor that represents logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Apply 1, 2, or 3 Convolution and Max Pool layers</span>
    <span class="c1">#    Play around with different number of outputs, </span>
    <span class="c1"># kernel size and stride</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#    conv2d_maxpool(x_tensor, conv_num_outputs, </span>
    <span class="c1"># conv_ksize, conv_strides, pool_ksize, pool_strides)</span>
    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    param x_tensor: TensorFlow Tensor</span>
<span class="sd">    :param conv_num_outputs: Number of outputs for the convolutional layer</span>
<span class="sd">    :param conv_strides: Stride 2-D Tuple for convolution</span>
<span class="sd">    :param pool_ksize: kernal size 2-D Tuple for pool</span>
<span class="sd">    :param pool_strides: Stride 2-D Tuple for pool</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">num_outputs3</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">conv_num_outputs1</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">conv_ksize1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">conv_strides1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pool_ksize1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">pool_strides1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_num_outputs1</span><span class="p">,</span> <span class="n">conv_ksize1</span><span class="p">,</span> <span class="n">conv_strides1</span><span class="p">,</span>
                   <span class="n">pool_ksize1</span><span class="p">,</span> <span class="n">pool_strides1</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">conv_num_outputs2</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">conv_ksize2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">conv_strides2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pool_ksize2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">pool_strides2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">num_outputs3</span> <span class="o">=</span> <span class="mi">1024</span>
    

    <span class="n">layer</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_num_outputs2</span><span class="p">,</span> <span class="n">conv_ksize2</span><span class="p">,</span> <span class="n">conv_strides2</span><span class="p">,</span>
                   <span class="n">pool_ksize2</span><span class="p">,</span> <span class="n">pool_strides2</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_num_outputs2</span><span class="p">,</span> <span class="n">conv_ksize2</span><span class="p">,</span> <span class="n">conv_strides2</span><span class="p">,</span>
                   <span class="n">pool_ksize2</span><span class="p">,</span> <span class="n">pool_strides2</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">conv_num_outputs3</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">conv_ksize3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">conv_strides3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">pool_ksize3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">pool_strides3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">num_outputs3</span> <span class="o">=</span> <span class="mi">128</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_num_outputs3</span><span class="p">,</span> <span class="n">conv_ksize3</span><span class="p">,</span> <span class="n">conv_strides3</span><span class="p">,</span>
                   <span class="n">pool_ksize3</span><span class="p">,</span> <span class="n">pool_strides3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">conv_num_outputs3</span><span class="p">,</span> <span class="n">conv_ksize3</span><span class="p">,</span> <span class="n">conv_strides3</span><span class="p">,</span>
                   <span class="n">pool_ksize3</span><span class="p">,</span> <span class="n">pool_strides3</span><span class="p">)</span>
        
    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    
    <span class="n">num_outputs3</span> <span class="o">=</span> <span class="mi">32</span>    
    
    <span class="n">layer</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">num_outputs3</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">output</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># TODO: return output</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">##############################</span>
<span class="c1">## Build the Neural Network ##</span>
<span class="c1">##############################</span>

<span class="c1"># Remove previous weights, bias, inputs, etc..</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># Inputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">neural_net_image_input</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">neural_net_label_input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">neural_net_keep_prob_input</span><span class="p">()</span>

<span class="c1"># Model</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

<span class="c1"># Name logits Tensor, so that is can be loaded from disk after training</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="c1"># Accuracy</span>
<span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_conv_net</span><span class="p">(</span><span class="n">conv_net</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Neural Network Built!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-the-Neural-Network">Train the Neural Network<a class="anchor-link" href="#Train-the-Neural-Network">&#182;</a></h2><h3 id="Single-Optimization">Single Optimization<a class="anchor-link" href="#Single-Optimization">&#182;</a></h3><p>Implement the function <code>train_neural_network</code> to do a single optimization.  The optimization should use <code>optimizer</code> to optimize in <code>session</code> with a <code>feed_dict</code> of the following:</p>
<ul>
<li><code>x</code> for image input</li>
<li><code>y</code> for labels</li>
<li><code>keep_prob</code> for keep probability for dropout</li>
</ul>
<p>This function will be called for each batch, so <code>tf.global_variables_initializer()</code> has already been called.</p>
<p>Note: Nothing needs to be returned. This function is only optimizing the neural network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Optimize the session on a batch of images and labels</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : optimizer: TensorFlow optimizer function</span>
<span class="sd">    : keep_probability: keep probability</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function&#39;</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> 
               <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">label_batch</span><span class="p">,</span> 
                           <span class="n">keep_prob</span><span class="p">:</span><span class="n">keep_probability</span><span class="p">})</span>
    <span class="k">pass</span>

    
    


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_train_nn</span><span class="p">(</span><span class="n">train_neural_network</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-Stats">Show Stats<a class="anchor-link" href="#Show-Stats">&#182;</a></h3><p>Implement the function <code>print_stats</code> to print loss and validation accuracy.  Use the global variables <code>valid_features</code> and <code>valid_labels</code> to calculate validation accuracy.  Use a keep probability of <code>1.0</code> to calculate the loss and validation accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information about loss and validation accuracy</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    : cost: TensorFlow cost function</span>
<span class="sd">    : accuracy: TensorFlow accuracy function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> 
                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">feature_batch</span><span class="p">,</span> 
                                        <span class="n">y</span><span class="p">:</span><span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> 
                             <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">valid_features</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">valid_labels</span><span class="p">,</span>
                                        <span class="n">keep_prob</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>
    <span class="n">validation_accuracy</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> 
                                      <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span><span class="n">valid_features</span><span class="p">,</span> 
                                                 <span class="n">y</span><span class="p">:</span><span class="n">valid_labels</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train_Loss:</span><span class="si">{0}</span><span class="s2">, Valid_Loss:</span><span class="si">{1}</span><span class="s2">, Valid_ACC:</span><span class="si">{2}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> 
                                                                <span class="n">valid_loss</span><span class="p">,</span> 
                                                                <span class="n">validation_accuracy</span><span class="p">))</span>
    <span class="k">pass</span>
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of iterations until the network stops learning or start overfitting</li>
<li>Set <code>batch_size</code> to the highest number that your machine has memory for.  Most people set them to common sizes of memory:<ul>
<li>64</li>
<li>128</li>
<li>256</li>
<li>...</li>
</ul>
</li>
<li>Set <code>keep_probability</code> to the probability of keeping a node using dropout</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: Tune Parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-on-a-Single-CIFAR-10-Batch">Train on a Single CIFAR-10 Batch<a class="anchor-link" href="#Train-on-a-Single-CIFAR-10-Batch">&#182;</a></h3><p>Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking the Training on a Single Batch...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking the Training on a Single Batch...
Epoch  1, CIFAR-10 Batch 1:  Train_Loss:2.30214524269104, Valid_Loss:2.3021209239959717, Valid_ACC:0.11779998987913132
Epoch  2, CIFAR-10 Batch 1:  Train_Loss:2.2998428344726562, Valid_Loss:2.2988333702087402, Valid_ACC:0.11979997903108597
Epoch  3, CIFAR-10 Batch 1:  Train_Loss:2.2896595001220703, Valid_Loss:2.288846969604492, Valid_ACC:0.13779999315738678
Epoch  4, CIFAR-10 Batch 1:  Train_Loss:2.272956132888794, Valid_Loss:2.275080680847168, Valid_ACC:0.14240001142024994
Epoch  5, CIFAR-10 Batch 1:  Train_Loss:2.256415367126465, Valid_Loss:2.262195587158203, Valid_ACC:0.1743999868631363
Epoch  6, CIFAR-10 Batch 1:  Train_Loss:2.2417240142822266, Valid_Loss:2.2411956787109375, Valid_ACC:0.17960000038146973
Epoch  7, CIFAR-10 Batch 1:  Train_Loss:2.2316083908081055, Valid_Loss:2.2205770015716553, Valid_ACC:0.19019998610019684
Epoch  8, CIFAR-10 Batch 1:  Train_Loss:2.2221670150756836, Valid_Loss:2.2154226303100586, Valid_ACC:0.19339999556541443
Epoch  9, CIFAR-10 Batch 1:  Train_Loss:2.1909139156341553, Valid_Loss:2.191025495529175, Valid_ACC:0.22579999268054962
Epoch 10, CIFAR-10 Batch 1:  Train_Loss:2.1634836196899414, Valid_Loss:2.1692168712615967, Valid_ACC:0.2337999939918518
Epoch 11, CIFAR-10 Batch 1:  Train_Loss:2.1473500728607178, Valid_Loss:2.157089948654175, Valid_ACC:0.2361999750137329
Epoch 12, CIFAR-10 Batch 1:  Train_Loss:2.1341147422790527, Valid_Loss:2.142099618911743, Valid_ACC:0.24199999868869781
Epoch 13, CIFAR-10 Batch 1:  Train_Loss:2.1258721351623535, Valid_Loss:2.1374549865722656, Valid_ACC:0.24300000071525574
Epoch 14, CIFAR-10 Batch 1:  Train_Loss:2.114652156829834, Valid_Loss:2.133434772491455, Valid_ACC:0.24399997293949127
Epoch 15, CIFAR-10 Batch 1:  Train_Loss:2.107755422592163, Valid_Loss:2.128674268722534, Valid_ACC:0.2441999912261963
Epoch 16, CIFAR-10 Batch 1:  Train_Loss:2.1050643920898438, Valid_Loss:2.126866579055786, Valid_ACC:0.24599997699260712
Epoch 17, CIFAR-10 Batch 1:  Train_Loss:2.096379041671753, Valid_Loss:2.118593692779541, Valid_ACC:0.24899998307228088
Epoch 18, CIFAR-10 Batch 1:  Train_Loss:2.08971905708313, Valid_Loss:2.1133956909179688, Valid_ACC:0.2521999776363373
Epoch 19, CIFAR-10 Batch 1:  Train_Loss:2.087193489074707, Valid_Loss:2.109595775604248, Valid_ACC:0.2541999816894531
Epoch 20, CIFAR-10 Batch 1:  Train_Loss:2.078338146209717, Valid_Loss:2.1051249504089355, Valid_ACC:0.25599998235702515
Epoch 21, CIFAR-10 Batch 1:  Train_Loss:2.076728343963623, Valid_Loss:2.1030936241149902, Valid_ACC:0.25939998030662537
Epoch 22, CIFAR-10 Batch 1:  Train_Loss:2.0679755210876465, Valid_Loss:2.0996217727661133, Valid_ACC:0.2556000053882599
Epoch 23, CIFAR-10 Batch 1:  Train_Loss:2.063476085662842, Valid_Loss:2.0961997509002686, Valid_ACC:0.2563999891281128
Epoch 24, CIFAR-10 Batch 1:  Train_Loss:2.059217929840088, Valid_Loss:2.0920050144195557, Valid_ACC:0.26019999384880066
Epoch 25, CIFAR-10 Batch 1:  Train_Loss:2.056727409362793, Valid_Loss:2.090247631072998, Valid_ACC:0.26099997758865356
Epoch 26, CIFAR-10 Batch 1:  Train_Loss:2.052138566970825, Valid_Loss:2.091019630432129, Valid_ACC:0.25779998302459717
Epoch 27, CIFAR-10 Batch 1:  Train_Loss:2.05102801322937, Valid_Loss:2.092216968536377, Valid_ACC:0.26019999384880066
Epoch 28, CIFAR-10 Batch 1:  Train_Loss:2.0486645698547363, Valid_Loss:2.086559295654297, Valid_ACC:0.2639999985694885
Epoch 29, CIFAR-10 Batch 1:  Train_Loss:2.042583465576172, Valid_Loss:2.083907127380371, Valid_ACC:0.26639997959136963
Epoch 30, CIFAR-10 Batch 1:  Train_Loss:2.036968946456909, Valid_Loss:2.080988883972168, Valid_ACC:0.2643999755382538
Epoch 31, CIFAR-10 Batch 1:  Train_Loss:2.033677101135254, Valid_Loss:2.0774524211883545, Valid_ACC:0.26759999990463257
Epoch 32, CIFAR-10 Batch 1:  Train_Loss:2.0317611694335938, Valid_Loss:2.080916404724121, Valid_ACC:0.2675999701023102
Epoch 33, CIFAR-10 Batch 1:  Train_Loss:2.0264816284179688, Valid_Loss:2.078937292098999, Valid_ACC:0.2655999958515167
Epoch 34, CIFAR-10 Batch 1:  Train_Loss:2.0223193168640137, Valid_Loss:2.0747714042663574, Valid_ACC:0.266400009393692
Epoch 35, CIFAR-10 Batch 1:  Train_Loss:2.0284900665283203, Valid_Loss:2.077507257461548, Valid_ACC:0.26819998025894165
Epoch 36, CIFAR-10 Batch 1:  Train_Loss:2.020766258239746, Valid_Loss:2.0751900672912598, Valid_ACC:0.266400009393692
Epoch 37, CIFAR-10 Batch 1:  Train_Loss:2.015596628189087, Valid_Loss:2.0742058753967285, Valid_ACC:0.26579996943473816
Epoch 38, CIFAR-10 Batch 1:  Train_Loss:2.019345760345459, Valid_Loss:2.0794131755828857, Valid_ACC:0.26179999113082886
Epoch 39, CIFAR-10 Batch 1:  Train_Loss:2.008472204208374, Valid_Loss:2.0705323219299316, Valid_ACC:0.2669999897480011
Epoch 40, CIFAR-10 Batch 1:  Train_Loss:2.0114426612854004, Valid_Loss:2.0714333057403564, Valid_ACC:0.2683999836444855
Epoch 41, CIFAR-10 Batch 1:  Train_Loss:2.009284257888794, Valid_Loss:2.0689306259155273, Valid_ACC:0.26899996399879456
Epoch 42, CIFAR-10 Batch 1:  Train_Loss:2.0045197010040283, Valid_Loss:2.0679850578308105, Valid_ACC:0.2685999870300293
Epoch 43, CIFAR-10 Batch 1:  Train_Loss:2.0020813941955566, Valid_Loss:2.068330764770508, Valid_ACC:0.26739999651908875
Epoch 44, CIFAR-10 Batch 1:  Train_Loss:2.0021286010742188, Valid_Loss:2.067033052444458, Valid_ACC:0.2678000032901764
Epoch 45, CIFAR-10 Batch 1:  Train_Loss:1.9986720085144043, Valid_Loss:2.0671303272247314, Valid_ACC:0.26979997754096985
Epoch 46, CIFAR-10 Batch 1:  Train_Loss:1.9932929277420044, Valid_Loss:2.0633888244628906, Valid_ACC:0.2687999904155731
Epoch 47, CIFAR-10 Batch 1:  Train_Loss:1.9899674654006958, Valid_Loss:2.063274383544922, Valid_ACC:0.2699999511241913
Epoch 48, CIFAR-10 Batch 1:  Train_Loss:1.9884685277938843, Valid_Loss:2.0609846115112305, Valid_ACC:0.27139997482299805
Epoch 49, CIFAR-10 Batch 1:  Train_Loss:1.9871726036071777, Valid_Loss:2.0607211589813232, Valid_ACC:0.26919999718666077
Epoch 50, CIFAR-10 Batch 1:  Train_Loss:1.9834281206130981, Valid_Loss:2.058720350265503, Valid_ACC:0.272599995136261
Epoch 51, CIFAR-10 Batch 1:  Train_Loss:1.9885971546173096, Valid_Loss:2.0624876022338867, Valid_ACC:0.2675999701023102
Epoch 52, CIFAR-10 Batch 1:  Train_Loss:1.9806958436965942, Valid_Loss:2.0579872131347656, Valid_ACC:0.2709999680519104
Epoch 53, CIFAR-10 Batch 1:  Train_Loss:1.9839493036270142, Valid_Loss:2.0622498989105225, Valid_ACC:0.2671999931335449
Epoch 54, CIFAR-10 Batch 1:  Train_Loss:1.9788084030151367, Valid_Loss:2.0584397315979004, Valid_ACC:0.27000001072883606
Epoch 55, CIFAR-10 Batch 1:  Train_Loss:1.9763492345809937, Valid_Loss:2.057194948196411, Valid_ACC:0.26919999718666077
Epoch 56, CIFAR-10 Batch 1:  Train_Loss:1.9748808145523071, Valid_Loss:2.060675859451294, Valid_ACC:0.26460000872612
Epoch 57, CIFAR-10 Batch 1:  Train_Loss:1.975042700767517, Valid_Loss:2.060093641281128, Valid_ACC:0.26600000262260437
Epoch 58, CIFAR-10 Batch 1:  Train_Loss:1.9708229303359985, Valid_Loss:2.060917854309082, Valid_ACC:0.267799973487854
Epoch 59, CIFAR-10 Batch 1:  Train_Loss:1.9706631898880005, Valid_Loss:2.0590579509735107, Valid_ACC:0.2651999890804291
Epoch 60, CIFAR-10 Batch 1:  Train_Loss:1.9625930786132812, Valid_Loss:2.053778648376465, Valid_ACC:0.27159997820854187
Epoch 61, CIFAR-10 Batch 1:  Train_Loss:1.9750449657440186, Valid_Loss:2.065690517425537, Valid_ACC:0.26319998502731323
Epoch 62, CIFAR-10 Batch 1:  Train_Loss:1.972608208656311, Valid_Loss:2.0654892921447754, Valid_ACC:0.26179999113082886
Epoch 63, CIFAR-10 Batch 1:  Train_Loss:1.9667185544967651, Valid_Loss:2.0625967979431152, Valid_ACC:0.26440000534057617
Epoch 64, CIFAR-10 Batch 1:  Train_Loss:1.9681607484817505, Valid_Loss:2.061742067337036, Valid_ACC:0.2679999768733978
Epoch 65, CIFAR-10 Batch 1:  Train_Loss:1.9651050567626953, Valid_Loss:2.059905767440796, Valid_ACC:0.2679999768733978
Epoch 66, CIFAR-10 Batch 1:  Train_Loss:1.9574005603790283, Valid_Loss:2.0548388957977295, Valid_ACC:0.2687999904155731
Epoch 67, CIFAR-10 Batch 1:  Train_Loss:1.962502121925354, Valid_Loss:2.0590341091156006, Valid_ACC:0.2635999917984009
Epoch 68, CIFAR-10 Batch 1:  Train_Loss:1.9557523727416992, Valid_Loss:2.0553438663482666, Valid_ACC:0.2694000005722046
Epoch 69, CIFAR-10 Batch 1:  Train_Loss:1.9598309993743896, Valid_Loss:2.05747389793396, Valid_ACC:0.26759999990463257
Epoch 70, CIFAR-10 Batch 1:  Train_Loss:1.953687071800232, Valid_Loss:2.053832530975342, Valid_ACC:0.269599974155426
Epoch 71, CIFAR-10 Batch 1:  Train_Loss:1.9546549320220947, Valid_Loss:2.053800582885742, Valid_ACC:0.26999998092651367
Epoch 72, CIFAR-10 Batch 1:  Train_Loss:1.9587442874908447, Valid_Loss:2.058473825454712, Valid_ACC:0.2662000060081482
Epoch 73, CIFAR-10 Batch 1:  Train_Loss:1.9615719318389893, Valid_Loss:2.0595920085906982, Valid_ACC:0.26739999651908875
Epoch 74, CIFAR-10 Batch 1:  Train_Loss:1.965878963470459, Valid_Loss:2.0634100437164307, Valid_ACC:0.26579999923706055
Epoch 75, CIFAR-10 Batch 1:  Train_Loss:1.9552819728851318, Valid_Loss:2.0586459636688232, Valid_ACC:0.2651999890804291
Epoch 76, CIFAR-10 Batch 1:  Train_Loss:1.9544312953948975, Valid_Loss:2.0580503940582275, Valid_ACC:0.26660001277923584
Epoch 77, CIFAR-10 Batch 1:  Train_Loss:1.94465970993042, Valid_Loss:2.0527663230895996, Valid_ACC:0.2696000039577484
Epoch 78, CIFAR-10 Batch 1:  Train_Loss:1.9466971158981323, Valid_Loss:2.057532548904419, Valid_ACC:0.26639997959136963
Epoch 79, CIFAR-10 Batch 1:  Train_Loss:1.959669828414917, Valid_Loss:2.077685832977295, Valid_ACC:0.2603999972343445
Epoch 80, CIFAR-10 Batch 1:  Train_Loss:1.9589155912399292, Valid_Loss:2.0749382972717285, Valid_ACC:0.2645999789237976
Epoch 81, CIFAR-10 Batch 1:  Train_Loss:1.9526922702789307, Valid_Loss:2.070826768875122, Valid_ACC:0.2683999836444855
Epoch 82, CIFAR-10 Batch 1:  Train_Loss:1.9367338418960571, Valid_Loss:2.0555002689361572, Valid_ACC:0.27139997482299805
Epoch 83, CIFAR-10 Batch 1:  Train_Loss:1.9397029876708984, Valid_Loss:2.058950662612915, Valid_ACC:0.2727999985218048
Epoch 84, CIFAR-10 Batch 1:  Train_Loss:1.932593822479248, Valid_Loss:2.0534462928771973, Valid_ACC:0.2759999632835388
Epoch 85, CIFAR-10 Batch 1:  Train_Loss:1.9421712160110474, Valid_Loss:2.060725212097168, Valid_ACC:0.2723999619483948
Epoch 86, CIFAR-10 Batch 1:  Train_Loss:1.9370827674865723, Valid_Loss:2.0628902912139893, Valid_ACC:0.27399998903274536
Epoch 87, CIFAR-10 Batch 1:  Train_Loss:1.9404690265655518, Valid_Loss:2.0653345584869385, Valid_ACC:0.27399998903274536
Epoch 88, CIFAR-10 Batch 1:  Train_Loss:1.9330463409423828, Valid_Loss:2.062242031097412, Valid_ACC:0.2723999619483948
Epoch 89, CIFAR-10 Batch 1:  Train_Loss:1.929228663444519, Valid_Loss:2.0616037845611572, Valid_ACC:0.2720000147819519
Epoch 90, CIFAR-10 Batch 1:  Train_Loss:1.9249567985534668, Valid_Loss:2.055724859237671, Valid_ACC:0.2734000086784363
Epoch 91, CIFAR-10 Batch 1:  Train_Loss:1.9289255142211914, Valid_Loss:2.05979585647583, Valid_ACC:0.2712000012397766
Epoch 92, CIFAR-10 Batch 1:  Train_Loss:1.9233251810073853, Valid_Loss:2.0600900650024414, Valid_ACC:0.27399998903274536
Epoch 93, CIFAR-10 Batch 1:  Train_Loss:1.9171717166900635, Valid_Loss:2.058431625366211, Valid_ACC:0.27239999175071716
Epoch 94, CIFAR-10 Batch 1:  Train_Loss:1.9220082759857178, Valid_Loss:2.0604352951049805, Valid_ACC:0.2735999822616577
Epoch 95, CIFAR-10 Batch 1:  Train_Loss:1.9216197729110718, Valid_Loss:2.0619680881500244, Valid_ACC:0.27219998836517334
Epoch 96, CIFAR-10 Batch 1:  Train_Loss:1.923611044883728, Valid_Loss:2.068800449371338, Valid_ACC:0.2752000093460083
Epoch 97, CIFAR-10 Batch 1:  Train_Loss:1.9159677028656006, Valid_Loss:2.0625271797180176, Valid_ACC:0.27379998564720154
Epoch 98, CIFAR-10 Batch 1:  Train_Loss:1.9084527492523193, Valid_Loss:2.056135654449463, Valid_ACC:0.27140000462532043
Epoch 99, CIFAR-10 Batch 1:  Train_Loss:1.9068677425384521, Valid_Loss:2.0571398735046387, Valid_ACC:0.2709999680519104
Epoch 100, CIFAR-10 Batch 1:  Train_Loss:1.9046427011489868, Valid_Loss:2.053569793701172, Valid_ACC:0.27160000801086426
Epoch 101, CIFAR-10 Batch 1:  Train_Loss:1.907271146774292, Valid_Loss:2.059342384338379, Valid_ACC:0.27399998903274536
Epoch 102, CIFAR-10 Batch 1:  Train_Loss:1.9032502174377441, Valid_Loss:2.054387092590332, Valid_ACC:0.2703999876976013
Epoch 103, CIFAR-10 Batch 1:  Train_Loss:1.9084951877593994, Valid_Loss:2.063263416290283, Valid_ACC:0.26899999380111694
Epoch 104, CIFAR-10 Batch 1:  Train_Loss:1.8987265825271606, Valid_Loss:2.0543198585510254, Valid_ACC:0.2696000039577484
Epoch 105, CIFAR-10 Batch 1:  Train_Loss:1.8958832025527954, Valid_Loss:2.053055763244629, Valid_ACC:0.269599974155426
Epoch 106, CIFAR-10 Batch 1:  Train_Loss:1.9061400890350342, Valid_Loss:2.0651674270629883, Valid_ACC:0.26179999113082886
Epoch 107, CIFAR-10 Batch 1:  Train_Loss:1.897200584411621, Valid_Loss:2.054659843444824, Valid_ACC:0.26919999718666077
Epoch 108, CIFAR-10 Batch 1:  Train_Loss:1.8944166898727417, Valid_Loss:2.0582239627838135, Valid_ACC:0.27399998903274536
Epoch 109, CIFAR-10 Batch 1:  Train_Loss:1.8972736597061157, Valid_Loss:2.0589990615844727, Valid_ACC:0.274399995803833
Epoch 110, CIFAR-10 Batch 1:  Train_Loss:1.9004476070404053, Valid_Loss:2.0609793663024902, Valid_ACC:0.26999998092651367
Epoch 111, CIFAR-10 Batch 1:  Train_Loss:1.911267638206482, Valid_Loss:2.0702452659606934, Valid_ACC:0.26179999113082886
Epoch 112, CIFAR-10 Batch 1:  Train_Loss:1.8913099765777588, Valid_Loss:2.0538878440856934, Valid_ACC:0.27059999108314514
Epoch 113, CIFAR-10 Batch 1:  Train_Loss:1.8922977447509766, Valid_Loss:2.0618698596954346, Valid_ACC:0.273999959230423
Epoch 114, CIFAR-10 Batch 1:  Train_Loss:1.8866908550262451, Valid_Loss:2.055216073989868, Valid_ACC:0.2709999680519104
Epoch 115, CIFAR-10 Batch 1:  Train_Loss:1.8896355628967285, Valid_Loss:2.057814836502075, Valid_ACC:0.26659998297691345
Epoch 116, CIFAR-10 Batch 1:  Train_Loss:1.8877536058425903, Valid_Loss:2.0621445178985596, Valid_ACC:0.27059999108314514
Epoch 117, CIFAR-10 Batch 1:  Train_Loss:1.890764594078064, Valid_Loss:2.0622150897979736, Valid_ACC:0.27139997482299805
Epoch 118, CIFAR-10 Batch 1:  Train_Loss:1.886039137840271, Valid_Loss:2.0589046478271484, Valid_ACC:0.2717999815940857
Epoch 119, CIFAR-10 Batch 1:  Train_Loss:1.8900372982025146, Valid_Loss:2.063204526901245, Valid_ACC:0.2712000012397766
Epoch 120, CIFAR-10 Batch 1:  Train_Loss:1.8794405460357666, Valid_Loss:2.0553760528564453, Valid_ACC:0.27399998903274536
Epoch 121, CIFAR-10 Batch 1:  Train_Loss:1.876842737197876, Valid_Loss:2.0515940189361572, Valid_ACC:0.27319997549057007
Epoch 122, CIFAR-10 Batch 1:  Train_Loss:1.874638557434082, Valid_Loss:2.0548715591430664, Valid_ACC:0.27139997482299805
Epoch 123, CIFAR-10 Batch 1:  Train_Loss:1.8761234283447266, Valid_Loss:2.056910991668701, Valid_ACC:0.2734000086784363
Epoch 124, CIFAR-10 Batch 1:  Train_Loss:1.8803203105926514, Valid_Loss:2.066493034362793, Valid_ACC:0.27459999918937683
Epoch 125, CIFAR-10 Batch 1:  Train_Loss:1.8771570920944214, Valid_Loss:2.0663046836853027, Valid_ACC:0.27479997277259827
Epoch 126, CIFAR-10 Batch 1:  Train_Loss:1.8736876249313354, Valid_Loss:2.069277763366699, Valid_ACC:0.27399998903274536
Epoch 127, CIFAR-10 Batch 1:  Train_Loss:1.8719980716705322, Valid_Loss:2.06839656829834, Valid_ACC:0.2759999930858612
Epoch 128, CIFAR-10 Batch 1:  Train_Loss:1.8690638542175293, Valid_Loss:2.0605766773223877, Valid_ACC:0.2727999985218048
Epoch 129, CIFAR-10 Batch 1:  Train_Loss:1.8679708242416382, Valid_Loss:2.059596061706543, Valid_ACC:0.26919999718666077
Epoch 130, CIFAR-10 Batch 1:  Train_Loss:1.8690978288650513, Valid_Loss:2.065450668334961, Valid_ACC:0.26600000262260437
Epoch 131, CIFAR-10 Batch 1:  Train_Loss:1.8600189685821533, Valid_Loss:2.054551124572754, Valid_ACC:0.27319997549057007
Epoch 132, CIFAR-10 Batch 1:  Train_Loss:1.8662580251693726, Valid_Loss:2.0620017051696777, Valid_ACC:0.27639999985694885
Epoch 133, CIFAR-10 Batch 1:  Train_Loss:1.8625398874282837, Valid_Loss:2.0645642280578613, Valid_ACC:0.2701999843120575
Epoch 134, CIFAR-10 Batch 1:  Train_Loss:1.8591763973236084, Valid_Loss:2.055403709411621, Valid_ACC:0.27139997482299805
Epoch 135, CIFAR-10 Batch 1:  Train_Loss:1.857850432395935, Valid_Loss:2.060103178024292, Valid_ACC:0.2727999687194824
Epoch 136, CIFAR-10 Batch 1:  Train_Loss:1.8491473197937012, Valid_Loss:2.052983045578003, Valid_ACC:0.27320000529289246
Epoch 137, CIFAR-10 Batch 1:  Train_Loss:1.8534650802612305, Valid_Loss:2.0630483627319336, Valid_ACC:0.274399995803833
Epoch 138, CIFAR-10 Batch 1:  Train_Loss:1.8492497205734253, Valid_Loss:2.0552597045898438, Valid_ACC:0.274399995803833
Epoch 139, CIFAR-10 Batch 1:  Train_Loss:1.8575973510742188, Valid_Loss:2.056057929992676, Valid_ACC:0.2685999870300293
Epoch 140, CIFAR-10 Batch 1:  Train_Loss:1.8486590385437012, Valid_Loss:2.055312156677246, Valid_ACC:0.2717999815940857
Epoch 141, CIFAR-10 Batch 1:  Train_Loss:1.8469434976577759, Valid_Loss:2.0538339614868164, Valid_ACC:0.27219998836517334
Epoch 142, CIFAR-10 Batch 1:  Train_Loss:1.845320463180542, Valid_Loss:2.0505025386810303, Valid_ACC:0.27319997549057007
Epoch 143, CIFAR-10 Batch 1:  Train_Loss:1.844994306564331, Valid_Loss:2.053199529647827, Valid_ACC:0.2687999904155731
Epoch 144, CIFAR-10 Batch 1:  Train_Loss:1.843939185142517, Valid_Loss:2.057356119155884, Valid_ACC:0.2669999897480011
Epoch 145, CIFAR-10 Batch 1:  Train_Loss:1.8415188789367676, Valid_Loss:2.053675413131714, Valid_ACC:0.2678000032901764
Epoch 146, CIFAR-10 Batch 1:  Train_Loss:1.849006175994873, Valid_Loss:2.0587501525878906, Valid_ACC:0.2635999917984009
Epoch 147, CIFAR-10 Batch 1:  Train_Loss:1.8477336168289185, Valid_Loss:2.0609138011932373, Valid_ACC:0.26579999923706055
Epoch 148, CIFAR-10 Batch 1:  Train_Loss:1.8452749252319336, Valid_Loss:2.056218385696411, Valid_ACC:0.2701999843120575
Epoch 149, CIFAR-10 Batch 1:  Train_Loss:1.8434325456619263, Valid_Loss:2.053201675415039, Valid_ACC:0.26739999651908875
Epoch 150, CIFAR-10 Batch 1:  Train_Loss:1.8443607091903687, Valid_Loss:2.056227684020996, Valid_ACC:0.2662000060081482
Epoch 151, CIFAR-10 Batch 1:  Train_Loss:1.8493707180023193, Valid_Loss:2.0608396530151367, Valid_ACC:0.26479998230934143
Epoch 152, CIFAR-10 Batch 1:  Train_Loss:1.8408278226852417, Valid_Loss:2.0525364875793457, Valid_ACC:0.2669999897480011
Epoch 153, CIFAR-10 Batch 1:  Train_Loss:1.8500776290893555, Valid_Loss:2.0569186210632324, Valid_ACC:0.26420000195503235
Epoch 154, CIFAR-10 Batch 1:  Train_Loss:1.8476049900054932, Valid_Loss:2.0548272132873535, Valid_ACC:0.26260000467300415
Epoch 155, CIFAR-10 Batch 1:  Train_Loss:1.8385542631149292, Valid_Loss:2.0527563095092773, Valid_ACC:0.26759999990463257
Epoch 156, CIFAR-10 Batch 1:  Train_Loss:1.8309452533721924, Valid_Loss:2.052699565887451, Valid_ACC:0.2683999836444855
Epoch 157, CIFAR-10 Batch 1:  Train_Loss:1.839727520942688, Valid_Loss:2.0574443340301514, Valid_ACC:0.2667999863624573
Epoch 158, CIFAR-10 Batch 1:  Train_Loss:1.8359875679016113, Valid_Loss:2.053715467453003, Valid_ACC:0.27059999108314514
Epoch 159, CIFAR-10 Batch 1:  Train_Loss:1.8348249197006226, Valid_Loss:2.0567924976348877, Valid_ACC:0.27000001072883606
Epoch 160, CIFAR-10 Batch 1:  Train_Loss:1.8277604579925537, Valid_Loss:2.0613062381744385, Valid_ACC:0.26899999380111694
Epoch 161, CIFAR-10 Batch 1:  Train_Loss:1.8281341791152954, Valid_Loss:2.0571017265319824, Valid_ACC:0.26919999718666077
Epoch 162, CIFAR-10 Batch 1:  Train_Loss:1.825991153717041, Valid_Loss:2.056593418121338, Valid_ACC:0.2683999836444855
Epoch 163, CIFAR-10 Batch 1:  Train_Loss:1.8168063163757324, Valid_Loss:2.0480358600616455, Valid_ACC:0.2671999931335449
Epoch 164, CIFAR-10 Batch 1:  Train_Loss:1.8222731351852417, Valid_Loss:2.056572198867798, Valid_ACC:0.26659998297691345
Epoch 165, CIFAR-10 Batch 1:  Train_Loss:1.8140244483947754, Valid_Loss:2.051490068435669, Valid_ACC:0.2709999978542328
Epoch 166, CIFAR-10 Batch 1:  Train_Loss:1.8098585605621338, Valid_Loss:2.0620713233947754, Valid_ACC:0.27159997820854187
Epoch 167, CIFAR-10 Batch 1:  Train_Loss:1.808652639389038, Valid_Loss:2.0593724250793457, Valid_ACC:0.2687999904155731
Epoch 168, CIFAR-10 Batch 1:  Train_Loss:1.8100624084472656, Valid_Loss:2.056983470916748, Valid_ACC:0.26820001006126404
Epoch 169, CIFAR-10 Batch 1:  Train_Loss:1.8106365203857422, Valid_Loss:2.057077169418335, Valid_ACC:0.2685999870300293
Epoch 170, CIFAR-10 Batch 1:  Train_Loss:1.8192939758300781, Valid_Loss:2.065340995788574, Valid_ACC:0.26579996943473816
Epoch 171, CIFAR-10 Batch 1:  Train_Loss:1.8078348636627197, Valid_Loss:2.057101011276245, Valid_ACC:0.27079999446868896
Epoch 172, CIFAR-10 Batch 1:  Train_Loss:1.8050161600112915, Valid_Loss:2.060436248779297, Valid_ACC:0.27140000462532043
Epoch 173, CIFAR-10 Batch 1:  Train_Loss:1.804218053817749, Valid_Loss:2.0610907077789307, Valid_ACC:0.2675999701023102
Epoch 174, CIFAR-10 Batch 1:  Train_Loss:1.8048901557922363, Valid_Loss:2.0603771209716797, Valid_ACC:0.2685999870300293
Epoch 175, CIFAR-10 Batch 1:  Train_Loss:1.8010658025741577, Valid_Loss:2.0552806854248047, Valid_ACC:0.2701999843120575
Epoch 176, CIFAR-10 Batch 1:  Train_Loss:1.800277590751648, Valid_Loss:2.056607246398926, Valid_ACC:0.2671999931335449
Epoch 177, CIFAR-10 Batch 1:  Train_Loss:1.8027149438858032, Valid_Loss:2.0622448921203613, Valid_ACC:0.2694000005722046
Epoch 178, CIFAR-10 Batch 1:  Train_Loss:1.8000001907348633, Valid_Loss:2.067195177078247, Valid_ACC:0.27139997482299805
Epoch 179, CIFAR-10 Batch 1:  Train_Loss:1.8077064752578735, Valid_Loss:2.068638324737549, Valid_ACC:0.2661999762058258
Epoch 180, CIFAR-10 Batch 1:  Train_Loss:1.7965710163116455, Valid_Loss:2.0578174591064453, Valid_ACC:0.2671999931335449
Epoch 181, CIFAR-10 Batch 1:  Train_Loss:1.792353630065918, Valid_Loss:2.0596728324890137, Valid_ACC:0.27320000529289246
Epoch 182, CIFAR-10 Batch 1:  Train_Loss:1.796167254447937, Valid_Loss:2.0615639686584473, Valid_ACC:0.26899996399879456
Epoch 183, CIFAR-10 Batch 1:  Train_Loss:1.7970407009124756, Valid_Loss:2.054720401763916, Valid_ACC:0.26980000734329224
Epoch 184, CIFAR-10 Batch 1:  Train_Loss:1.7961148023605347, Valid_Loss:2.056349039077759, Valid_ACC:0.26739999651908875
Epoch 185, CIFAR-10 Batch 1:  Train_Loss:1.793216586112976, Valid_Loss:2.0533642768859863, Valid_ACC:0.2694000005722046
Epoch 186, CIFAR-10 Batch 1:  Train_Loss:1.7950878143310547, Valid_Loss:2.0562093257904053, Valid_ACC:0.2675999701023102
Epoch 187, CIFAR-10 Batch 1:  Train_Loss:1.7977603673934937, Valid_Loss:2.060304880142212, Valid_ACC:0.2643999755382538
Epoch 188, CIFAR-10 Batch 1:  Train_Loss:1.7850419282913208, Valid_Loss:2.0578858852386475, Valid_ACC:0.26999998092651367
Epoch 189, CIFAR-10 Batch 1:  Train_Loss:1.7839105129241943, Valid_Loss:2.063066005706787, Valid_ACC:0.2671999931335449
Epoch 190, CIFAR-10 Batch 1:  Train_Loss:1.7904038429260254, Valid_Loss:2.0646755695343018, Valid_ACC:0.2703999876976013
Epoch 191, CIFAR-10 Batch 1:  Train_Loss:1.7791467905044556, Valid_Loss:2.0564212799072266, Valid_ACC:0.2694000005722046
Epoch 192, CIFAR-10 Batch 1:  Train_Loss:1.7879700660705566, Valid_Loss:2.0616374015808105, Valid_ACC:0.26579996943473816
Epoch 193, CIFAR-10 Batch 1:  Train_Loss:1.7762037515640259, Valid_Loss:2.0588598251342773, Valid_ACC:0.2662000060081482
Epoch 194, CIFAR-10 Batch 1:  Train_Loss:1.7778751850128174, Valid_Loss:2.0581679344177246, Valid_ACC:0.26899999380111694
Epoch 195, CIFAR-10 Batch 1:  Train_Loss:1.7745258808135986, Valid_Loss:2.0540244579315186, Valid_ACC:0.26759999990463257
Epoch 196, CIFAR-10 Batch 1:  Train_Loss:1.7796247005462646, Valid_Loss:2.068340301513672, Valid_ACC:0.27140000462532043
Epoch 197, CIFAR-10 Batch 1:  Train_Loss:1.7775005102157593, Valid_Loss:2.064202070236206, Valid_ACC:0.2680000066757202
Epoch 198, CIFAR-10 Batch 1:  Train_Loss:1.7745002508163452, Valid_Loss:2.058652400970459, Valid_ACC:0.26840001344680786
Epoch 199, CIFAR-10 Batch 1:  Train_Loss:1.7733187675476074, Valid_Loss:2.0653138160705566, Valid_ACC:0.26919999718666077
Epoch 200, CIFAR-10 Batch 1:  Train_Loss:1.777752161026001, Valid_Loss:2.060802459716797, Valid_ACC:0.2671999931335449
Epoch 201, CIFAR-10 Batch 1:  Train_Loss:1.7849456071853638, Valid_Loss:2.057037830352783, Valid_ACC:0.26340001821517944
Epoch 202, CIFAR-10 Batch 1:  Train_Loss:1.7740541696548462, Valid_Loss:2.0599827766418457, Valid_ACC:0.2661999762058258
Epoch 203, CIFAR-10 Batch 1:  Train_Loss:1.7669026851654053, Valid_Loss:2.059349298477173, Valid_ACC:0.26739999651908875
Epoch 204, CIFAR-10 Batch 1:  Train_Loss:1.7630863189697266, Valid_Loss:2.0632662773132324, Valid_ACC:0.2709999680519104
Epoch 205, CIFAR-10 Batch 1:  Train_Loss:1.7723932266235352, Valid_Loss:2.0580925941467285, Valid_ACC:0.26600000262260437
Epoch 206, CIFAR-10 Batch 1:  Train_Loss:1.7648184299468994, Valid_Loss:2.0595366954803467, Valid_ACC:0.2671999931335449
Epoch 207, CIFAR-10 Batch 1:  Train_Loss:1.7597600221633911, Valid_Loss:2.0679280757904053, Valid_ACC:0.2691999673843384
Epoch 208, CIFAR-10 Batch 1:  Train_Loss:1.7763912677764893, Valid_Loss:2.06685471534729, Valid_ACC:0.2639999985694885
Epoch 209, CIFAR-10 Batch 1:  Train_Loss:1.7675423622131348, Valid_Loss:2.0664479732513428, Valid_ACC:0.26759999990463257
Epoch 210, CIFAR-10 Batch 1:  Train_Loss:1.7602896690368652, Valid_Loss:2.063032627105713, Valid_ACC:0.2661999762058258
Epoch 211, CIFAR-10 Batch 1:  Train_Loss:1.763451337814331, Valid_Loss:2.0639140605926514, Valid_ACC:0.2678000032901764
Epoch 212, CIFAR-10 Batch 1:  Train_Loss:1.7646887302398682, Valid_Loss:2.06247878074646, Valid_ACC:0.26520001888275146
Epoch 213, CIFAR-10 Batch 1:  Train_Loss:1.7586199045181274, Valid_Loss:2.0622687339782715, Valid_ACC:0.2679999768733978
Epoch 214, CIFAR-10 Batch 1:  Train_Loss:1.7614978551864624, Valid_Loss:2.0637474060058594, Valid_ACC:0.2669999897480011
Epoch 215, CIFAR-10 Batch 1:  Train_Loss:1.7550852298736572, Valid_Loss:2.060791254043579, Valid_ACC:0.26579996943473816
Epoch 216, CIFAR-10 Batch 1:  Train_Loss:1.7632216215133667, Valid_Loss:2.054328680038452, Valid_ACC:0.265999972820282
Epoch 217, CIFAR-10 Batch 1:  Train_Loss:1.753110408782959, Valid_Loss:2.0591986179351807, Valid_ACC:0.26579999923706055
Epoch 218, CIFAR-10 Batch 1:  Train_Loss:1.760392665863037, Valid_Loss:2.0627613067626953, Valid_ACC:0.2643999755382538
Epoch 219, CIFAR-10 Batch 1:  Train_Loss:1.7618201971054077, Valid_Loss:2.0610854625701904, Valid_ACC:0.2651999890804291
Epoch 220, CIFAR-10 Batch 1:  Train_Loss:1.760926604270935, Valid_Loss:2.058318614959717, Valid_ACC:0.2662000060081482
Epoch 221, CIFAR-10 Batch 1:  Train_Loss:1.7540277242660522, Valid_Loss:2.0705578327178955, Valid_ACC:0.27059996128082275
Epoch 222, CIFAR-10 Batch 1:  Train_Loss:1.7506561279296875, Valid_Loss:2.0676372051239014, Valid_ACC:0.2675999701023102
Epoch 223, CIFAR-10 Batch 1:  Train_Loss:1.7479043006896973, Valid_Loss:2.0567915439605713, Valid_ACC:0.2653999924659729
Epoch 224, CIFAR-10 Batch 1:  Train_Loss:1.7518655061721802, Valid_Loss:2.0645227432250977, Valid_ACC:0.26440000534057617
Epoch 225, CIFAR-10 Batch 1:  Train_Loss:1.7458449602127075, Valid_Loss:2.061321258544922, Valid_ACC:0.2662000060081482
Epoch 226, CIFAR-10 Batch 1:  Train_Loss:1.7479281425476074, Valid_Loss:2.0662999153137207, Valid_ACC:0.26739999651908875
Epoch 227, CIFAR-10 Batch 1:  Train_Loss:1.743797779083252, Valid_Loss:2.075535774230957, Valid_ACC:0.26579999923706055
Epoch 228, CIFAR-10 Batch 1:  Train_Loss:1.7480236291885376, Valid_Loss:2.0705058574676514, Valid_ACC:0.2651999890804291
Epoch 229, CIFAR-10 Batch 1:  Train_Loss:1.7542455196380615, Valid_Loss:2.0747172832489014, Valid_ACC:0.26179999113082886
Epoch 230, CIFAR-10 Batch 1:  Train_Loss:1.746040940284729, Valid_Loss:2.073709011077881, Valid_ACC:0.2662000060081482
Epoch 231, CIFAR-10 Batch 1:  Train_Loss:1.7432122230529785, Valid_Loss:2.075009822845459, Valid_ACC:0.26420000195503235
Epoch 232, CIFAR-10 Batch 1:  Train_Loss:1.7496609687805176, Valid_Loss:2.0834922790527344, Valid_ACC:0.2655999958515167
Epoch 233, CIFAR-10 Batch 1:  Train_Loss:1.7456403970718384, Valid_Loss:2.0820388793945312, Valid_ACC:0.2637999951839447
Epoch 234, CIFAR-10 Batch 1:  Train_Loss:1.736607313156128, Valid_Loss:2.0654735565185547, Valid_ACC:0.26260000467300415
Epoch 235, CIFAR-10 Batch 1:  Train_Loss:1.7418972253799438, Valid_Loss:2.063429832458496, Valid_ACC:0.2613999843597412
Epoch 236, CIFAR-10 Batch 1:  Train_Loss:1.7471425533294678, Valid_Loss:2.064300537109375, Valid_ACC:0.26080000400543213
Epoch 237, CIFAR-10 Batch 1:  Train_Loss:1.7323247194290161, Valid_Loss:2.0625076293945312, Valid_ACC:0.265999972820282
Epoch 238, CIFAR-10 Batch 1:  Train_Loss:1.7386982440948486, Valid_Loss:2.075807571411133, Valid_ACC:0.2662000060081482
Epoch 239, CIFAR-10 Batch 1:  Train_Loss:1.745512843132019, Valid_Loss:2.074197769165039, Valid_ACC:0.25939998030662537
Epoch 240, CIFAR-10 Batch 1:  Train_Loss:1.744556188583374, Valid_Loss:2.072836399078369, Valid_ACC:0.2581999897956848
Epoch 241, CIFAR-10 Batch 1:  Train_Loss:1.7406030893325806, Valid_Loss:2.076894521713257, Valid_ACC:0.26399996876716614
Epoch 242, CIFAR-10 Batch 1:  Train_Loss:1.7308595180511475, Valid_Loss:2.086864948272705, Valid_ACC:0.26659998297691345
Epoch 243, CIFAR-10 Batch 1:  Train_Loss:1.739190936088562, Valid_Loss:2.0760443210601807, Valid_ACC:0.26099997758865356
Epoch 244, CIFAR-10 Batch 1:  Train_Loss:1.7369723320007324, Valid_Loss:2.0648701190948486, Valid_ACC:0.2643999755382538
Epoch 245, CIFAR-10 Batch 1:  Train_Loss:1.7416820526123047, Valid_Loss:2.0702133178710938, Valid_ACC:0.26339998841285706
Epoch 246, CIFAR-10 Batch 1:  Train_Loss:1.7379429340362549, Valid_Loss:2.080007791519165, Valid_ACC:0.26840001344680786
Epoch 247, CIFAR-10 Batch 1:  Train_Loss:1.763238549232483, Valid_Loss:2.0883779525756836, Valid_ACC:0.2653999924659729
Epoch 248, CIFAR-10 Batch 1:  Train_Loss:1.7646610736846924, Valid_Loss:2.088467836380005, Valid_ACC:0.2637999653816223
Epoch 249, CIFAR-10 Batch 1:  Train_Loss:1.7457971572875977, Valid_Loss:2.080913782119751, Valid_ACC:0.2694000005722046
Epoch 250, CIFAR-10 Batch 1:  Train_Loss:1.72296142578125, Valid_Loss:2.0751073360443115, Valid_ACC:0.2685999870300293
Epoch 251, CIFAR-10 Batch 1:  Train_Loss:1.7358043193817139, Valid_Loss:2.089350700378418, Valid_ACC:0.2667999863624573
Epoch 252, CIFAR-10 Batch 1:  Train_Loss:1.73160719871521, Valid_Loss:2.0807290077209473, Valid_ACC:0.26659998297691345
Epoch 253, CIFAR-10 Batch 1:  Train_Loss:1.7258057594299316, Valid_Loss:2.085222005844116, Valid_ACC:0.26919999718666077
Epoch 254, CIFAR-10 Batch 1:  Train_Loss:1.7517657279968262, Valid_Loss:2.094405174255371, Valid_ACC:0.2648000121116638
Epoch 255, CIFAR-10 Batch 1:  Train_Loss:1.726128101348877, Valid_Loss:2.0908241271972656, Valid_ACC:0.2687999904155731
Epoch 256, CIFAR-10 Batch 1:  Train_Loss:1.7341043949127197, Valid_Loss:2.0886497497558594, Valid_ACC:0.26600000262260437
Epoch 257, CIFAR-10 Batch 1:  Train_Loss:1.728405475616455, Valid_Loss:2.0861587524414062, Valid_ACC:0.26739999651908875
Epoch 258, CIFAR-10 Batch 1:  Train_Loss:1.7243245840072632, Valid_Loss:2.0838088989257812, Valid_ACC:0.26999998092651367
Epoch 259, CIFAR-10 Batch 1:  Train_Loss:1.715924859046936, Valid_Loss:2.078171491622925, Valid_ACC:0.269599974155426
Epoch 260, CIFAR-10 Batch 1:  Train_Loss:1.7196909189224243, Valid_Loss:2.0859456062316895, Valid_ACC:0.26899996399879456
Epoch 261, CIFAR-10 Batch 1:  Train_Loss:1.7221852540969849, Valid_Loss:2.0784363746643066, Valid_ACC:0.26759999990463257
Epoch 262, CIFAR-10 Batch 1:  Train_Loss:1.7133235931396484, Valid_Loss:2.079108953475952, Valid_ACC:0.26499998569488525
Epoch 263, CIFAR-10 Batch 1:  Train_Loss:1.7072569131851196, Valid_Loss:2.0824825763702393, Valid_ACC:0.26499998569488525
Epoch 264, CIFAR-10 Batch 1:  Train_Loss:1.7030887603759766, Valid_Loss:2.091876983642578, Valid_ACC:0.26739999651908875
Epoch 265, CIFAR-10 Batch 1:  Train_Loss:1.7102075815200806, Valid_Loss:2.0951905250549316, Valid_ACC:0.26999998092651367
Epoch 266, CIFAR-10 Batch 1:  Train_Loss:1.706164836883545, Valid_Loss:2.095057487487793, Valid_ACC:0.2696000039577484
Epoch 267, CIFAR-10 Batch 1:  Train_Loss:1.7071855068206787, Valid_Loss:2.091649055480957, Valid_ACC:0.2709999680519104
Epoch 268, CIFAR-10 Batch 1:  Train_Loss:1.71085524559021, Valid_Loss:2.0863842964172363, Valid_ACC:0.26600000262260437
Epoch 269, CIFAR-10 Batch 1:  Train_Loss:1.7194247245788574, Valid_Loss:2.0880773067474365, Valid_ACC:0.2678000032901764
Epoch 270, CIFAR-10 Batch 1:  Train_Loss:1.7095731496810913, Valid_Loss:2.0839362144470215, Valid_ACC:0.2661999762058258
Epoch 271, CIFAR-10 Batch 1:  Train_Loss:1.7027825117111206, Valid_Loss:2.084713935852051, Valid_ACC:0.2685999870300293
Epoch 272, CIFAR-10 Batch 1:  Train_Loss:1.7017624378204346, Valid_Loss:2.098491907119751, Valid_ACC:0.2671999931335449
Epoch 273, CIFAR-10 Batch 1:  Train_Loss:1.7000361680984497, Valid_Loss:2.0984861850738525, Valid_ACC:0.2679999768733978
Epoch 274, CIFAR-10 Batch 1:  Train_Loss:1.7164082527160645, Valid_Loss:2.097376823425293, Valid_ACC:0.2667999863624573
Epoch 275, CIFAR-10 Batch 1:  Train_Loss:1.6970088481903076, Valid_Loss:2.0938189029693604, Valid_ACC:0.2669999897480011
Epoch 276, CIFAR-10 Batch 1:  Train_Loss:1.7065114974975586, Valid_Loss:2.095555067062378, Valid_ACC:0.2639999985694885
Epoch 277, CIFAR-10 Batch 1:  Train_Loss:1.7076536417007446, Valid_Loss:2.0999503135681152, Valid_ACC:0.2645999789237976
Epoch 278, CIFAR-10 Batch 1:  Train_Loss:1.6993902921676636, Valid_Loss:2.0964114665985107, Valid_ACC:0.26600000262260437
Epoch 279, CIFAR-10 Batch 1:  Train_Loss:1.6929479837417603, Valid_Loss:2.096203088760376, Valid_ACC:0.2653999924659729
Epoch 280, CIFAR-10 Batch 1:  Train_Loss:1.6951416730880737, Valid_Loss:2.105227470397949, Valid_ACC:0.265999972820282
Epoch 281, CIFAR-10 Batch 1:  Train_Loss:1.7022844552993774, Valid_Loss:2.0931034088134766, Valid_ACC:0.26339998841285706
Epoch 282, CIFAR-10 Batch 1:  Train_Loss:1.6989948749542236, Valid_Loss:2.0925633907318115, Valid_ACC:0.2630000114440918
Epoch 283, CIFAR-10 Batch 1:  Train_Loss:1.6906219720840454, Valid_Loss:2.088158369064331, Valid_ACC:0.2655999958515167
Epoch 284, CIFAR-10 Batch 1:  Train_Loss:1.6968815326690674, Valid_Loss:2.0864012241363525, Valid_ACC:0.265999972820282
Epoch 285, CIFAR-10 Batch 1:  Train_Loss:1.692674160003662, Valid_Loss:2.0819592475891113, Valid_ACC:0.26680001616477966
Epoch 286, CIFAR-10 Batch 1:  Train_Loss:1.6801444292068481, Valid_Loss:2.092123508453369, Valid_ACC:0.26579999923706055
Epoch 287, CIFAR-10 Batch 1:  Train_Loss:1.6869988441467285, Valid_Loss:2.092653512954712, Valid_ACC:0.26600000262260437
Epoch 288, CIFAR-10 Batch 1:  Train_Loss:1.7024486064910889, Valid_Loss:2.0960421562194824, Valid_ACC:0.2613999843597412
Epoch 289, CIFAR-10 Batch 1:  Train_Loss:1.688232660293579, Valid_Loss:2.087244987487793, Valid_ACC:0.2651999890804291
Epoch 290, CIFAR-10 Batch 1:  Train_Loss:1.6820687055587769, Valid_Loss:2.0841875076293945, Valid_ACC:0.26159998774528503
Epoch 291, CIFAR-10 Batch 1:  Train_Loss:1.6825988292694092, Valid_Loss:2.0847606658935547, Valid_ACC:0.26479998230934143
Epoch 292, CIFAR-10 Batch 1:  Train_Loss:1.687145709991455, Valid_Loss:2.082627296447754, Valid_ACC:0.26479998230934143
Epoch 293, CIFAR-10 Batch 1:  Train_Loss:1.6874642372131348, Valid_Loss:2.081245183944702, Valid_ACC:0.26159998774528503
Epoch 294, CIFAR-10 Batch 1:  Train_Loss:1.6872152090072632, Valid_Loss:2.082099676132202, Valid_ACC:0.2671999931335449
Epoch 295, CIFAR-10 Batch 1:  Train_Loss:1.6892428398132324, Valid_Loss:2.07999324798584, Valid_ACC:0.2643999755382538
Epoch 296, CIFAR-10 Batch 1:  Train_Loss:1.6786220073699951, Valid_Loss:2.0846526622772217, Valid_ACC:0.26260000467300415
Epoch 297, CIFAR-10 Batch 1:  Train_Loss:1.6832419633865356, Valid_Loss:2.087540864944458, Valid_ACC:0.26159998774528503
Epoch 298, CIFAR-10 Batch 1:  Train_Loss:1.6774159669876099, Valid_Loss:2.0874826908111572, Valid_ACC:0.2635999917984009
Epoch 299, CIFAR-10 Batch 1:  Train_Loss:1.6882727146148682, Valid_Loss:2.0886764526367188, Valid_ACC:0.2643999755382538
Epoch 300, CIFAR-10 Batch 1:  Train_Loss:1.679735541343689, Valid_Loss:2.083899974822998, Valid_ACC:0.2639999985694885
Epoch 301, CIFAR-10 Batch 1:  Train_Loss:1.681731104850769, Valid_Loss:2.0855724811553955, Valid_ACC:0.2629999816417694
Epoch 302, CIFAR-10 Batch 1:  Train_Loss:1.682047963142395, Valid_Loss:2.0858561992645264, Valid_ACC:0.26319998502731323
Epoch 303, CIFAR-10 Batch 1:  Train_Loss:1.681152582168579, Valid_Loss:2.0828871726989746, Valid_ACC:0.2639999985694885
Epoch 304, CIFAR-10 Batch 1:  Train_Loss:1.6809120178222656, Valid_Loss:2.084474563598633, Valid_ACC:0.2629999816417694
Epoch 305, CIFAR-10 Batch 1:  Train_Loss:1.6743041276931763, Valid_Loss:2.0804879665374756, Valid_ACC:0.26319998502731323
Epoch 306, CIFAR-10 Batch 1:  Train_Loss:1.6801691055297852, Valid_Loss:2.079230308532715, Valid_ACC:0.26179996132850647
Epoch 307, CIFAR-10 Batch 1:  Train_Loss:1.6748206615447998, Valid_Loss:2.0847582817077637, Valid_ACC:0.26499998569488525
Epoch 308, CIFAR-10 Batch 1:  Train_Loss:1.6731948852539062, Valid_Loss:2.0882797241210938, Valid_ACC:0.26159998774528503
Epoch 309, CIFAR-10 Batch 1:  Train_Loss:1.6771340370178223, Valid_Loss:2.109663963317871, Valid_ACC:0.26159998774528503
Epoch 310, CIFAR-10 Batch 1:  Train_Loss:1.6719714403152466, Valid_Loss:2.100282907485962, Valid_ACC:0.2619999945163727
Epoch 311, CIFAR-10 Batch 1:  Train_Loss:1.6681649684906006, Valid_Loss:2.0917811393737793, Valid_ACC:0.26440000534057617
Epoch 312, CIFAR-10 Batch 1:  Train_Loss:1.6708959341049194, Valid_Loss:2.0887951850891113, Valid_ACC:0.26319998502731323
Epoch 313, CIFAR-10 Batch 1:  Train_Loss:1.6743791103363037, Valid_Loss:2.0861501693725586, Valid_ACC:0.26080000400543213
Epoch 314, CIFAR-10 Batch 1:  Train_Loss:1.672878623008728, Valid_Loss:2.095454216003418, Valid_ACC:0.26259997487068176
Epoch 315, CIFAR-10 Batch 1:  Train_Loss:1.6770931482315063, Valid_Loss:2.097867250442505, Valid_ACC:0.25760000944137573
Epoch 316, CIFAR-10 Batch 1:  Train_Loss:1.6751590967178345, Valid_Loss:2.0991454124450684, Valid_ACC:0.2616000175476074
Epoch 317, CIFAR-10 Batch 1:  Train_Loss:1.6665475368499756, Valid_Loss:2.099857807159424, Valid_ACC:0.26079997420310974
Epoch 318, CIFAR-10 Batch 1:  Train_Loss:1.669359564781189, Valid_Loss:2.085599899291992, Valid_ACC:0.25939998030662537
Epoch 319, CIFAR-10 Batch 1:  Train_Loss:1.6723034381866455, Valid_Loss:2.1032962799072266, Valid_ACC:0.2627999782562256
Epoch 320, CIFAR-10 Batch 1:  Train_Loss:1.6646419763565063, Valid_Loss:2.0990874767303467, Valid_ACC:0.2655999958515167
Epoch 321, CIFAR-10 Batch 1:  Train_Loss:1.6591317653656006, Valid_Loss:2.1077990531921387, Valid_ACC:0.2632000148296356
Epoch 322, CIFAR-10 Batch 1:  Train_Loss:1.6769826412200928, Valid_Loss:2.1210567951202393, Valid_ACC:0.2627999782562256
Epoch 323, CIFAR-10 Batch 1:  Train_Loss:1.6618115901947021, Valid_Loss:2.110055685043335, Valid_ACC:0.2643999755382538
Epoch 324, CIFAR-10 Batch 1:  Train_Loss:1.6601969003677368, Valid_Loss:2.1102731227874756, Valid_ACC:0.26840001344680786
Epoch 325, CIFAR-10 Batch 1:  Train_Loss:1.6714462041854858, Valid_Loss:2.099384069442749, Valid_ACC:0.266400009393692
Epoch 326, CIFAR-10 Batch 1:  Train_Loss:1.6605424880981445, Valid_Loss:2.1010959148406982, Valid_ACC:0.2635999917984009
Epoch 327, CIFAR-10 Batch 1:  Train_Loss:1.6588274240493774, Valid_Loss:2.0964670181274414, Valid_ACC:0.2635999917984009
Epoch 328, CIFAR-10 Batch 1:  Train_Loss:1.6541414260864258, Valid_Loss:2.1034576892852783, Valid_ACC:0.26499998569488525
Epoch 329, CIFAR-10 Batch 1:  Train_Loss:1.660753607749939, Valid_Loss:2.1010942459106445, Valid_ACC:0.2632000148296356
Epoch 330, CIFAR-10 Batch 1:  Train_Loss:1.662081241607666, Valid_Loss:2.116659164428711, Valid_ACC:0.26479998230934143
Epoch 331, CIFAR-10 Batch 1:  Train_Loss:1.6632280349731445, Valid_Loss:2.1058542728424072, Valid_ACC:0.25839999318122864
Epoch 332, CIFAR-10 Batch 1:  Train_Loss:1.6540166139602661, Valid_Loss:2.107395648956299, Valid_ACC:0.26479998230934143
Epoch 333, CIFAR-10 Batch 1:  Train_Loss:1.655029058456421, Valid_Loss:2.1138033866882324, Valid_ACC:0.25999999046325684
Epoch 334, CIFAR-10 Batch 1:  Train_Loss:1.6514453887939453, Valid_Loss:2.1205101013183594, Valid_ACC:0.26460000872612
Epoch 335, CIFAR-10 Batch 1:  Train_Loss:1.6501109600067139, Valid_Loss:2.1112537384033203, Valid_ACC:0.2680000066757202
Epoch 336, CIFAR-10 Batch 1:  Train_Loss:1.6602756977081299, Valid_Loss:2.136392593383789, Valid_ACC:0.2662000060081482
Epoch 337, CIFAR-10 Batch 1:  Train_Loss:1.6591627597808838, Valid_Loss:2.128182888031006, Valid_ACC:0.2637999951839447
Epoch 338, CIFAR-10 Batch 1:  Train_Loss:1.6718477010726929, Valid_Loss:2.1333231925964355, Valid_ACC:0.2606000006198883
Epoch 339, CIFAR-10 Batch 1:  Train_Loss:1.6546845436096191, Valid_Loss:2.1433069705963135, Valid_ACC:0.26739999651908875
Epoch 340, CIFAR-10 Batch 1:  Train_Loss:1.6579605340957642, Valid_Loss:2.137479543685913, Valid_ACC:0.26579996943473816
Epoch 341, CIFAR-10 Batch 1:  Train_Loss:1.6557328701019287, Valid_Loss:2.1145246028900146, Valid_ACC:0.2655999958515167
Epoch 342, CIFAR-10 Batch 1:  Train_Loss:1.65926194190979, Valid_Loss:2.0976333618164062, Valid_ACC:0.2624000012874603
Epoch 343, CIFAR-10 Batch 1:  Train_Loss:1.6605615615844727, Valid_Loss:2.1034510135650635, Valid_ACC:0.26680001616477966
Epoch 344, CIFAR-10 Batch 1:  Train_Loss:1.655458927154541, Valid_Loss:2.100111722946167, Valid_ACC:0.26440000534057617
Epoch 345, CIFAR-10 Batch 1:  Train_Loss:1.6521459817886353, Valid_Loss:2.098202705383301, Valid_ACC:0.2637999951839447
Epoch 346, CIFAR-10 Batch 1:  Train_Loss:1.6594946384429932, Valid_Loss:2.1078267097473145, Valid_ACC:0.266400009393692
Epoch 347, CIFAR-10 Batch 1:  Train_Loss:1.6556968688964844, Valid_Loss:2.1185295581817627, Valid_ACC:0.2653999924659729
Epoch 348, CIFAR-10 Batch 1:  Train_Loss:1.6495981216430664, Valid_Loss:2.136201858520508, Valid_ACC:0.26759999990463257
Epoch 349, CIFAR-10 Batch 1:  Train_Loss:1.6535001993179321, Valid_Loss:2.121798038482666, Valid_ACC:0.26440000534057617
Epoch 350, CIFAR-10 Batch 1:  Train_Loss:1.6459405422210693, Valid_Loss:2.115999698638916, Valid_ACC:0.2632000148296356
Epoch 351, CIFAR-10 Batch 1:  Train_Loss:1.6492512226104736, Valid_Loss:2.099750280380249, Valid_ACC:0.25940001010894775
Epoch 352, CIFAR-10 Batch 1:  Train_Loss:1.6484429836273193, Valid_Loss:2.1170430183410645, Valid_ACC:0.265999972820282
Epoch 353, CIFAR-10 Batch 1:  Train_Loss:1.6462392807006836, Valid_Loss:2.1106348037719727, Valid_ACC:0.2651999890804291
Epoch 354, CIFAR-10 Batch 1:  Train_Loss:1.6421585083007812, Valid_Loss:2.1062159538269043, Valid_ACC:0.2679999768733978
Epoch 355, CIFAR-10 Batch 1:  Train_Loss:1.6416206359863281, Valid_Loss:2.081568956375122, Valid_ACC:0.27219998836517334
Epoch 356, CIFAR-10 Batch 1:  Train_Loss:1.6343755722045898, Valid_Loss:2.086282253265381, Valid_ACC:0.27699998021125793
Epoch 357, CIFAR-10 Batch 1:  Train_Loss:1.6030014753341675, Valid_Loss:2.0765573978424072, Valid_ACC:0.280599981546402
Epoch 358, CIFAR-10 Batch 1:  Train_Loss:1.5945792198181152, Valid_Loss:2.073336124420166, Valid_ACC:0.28279995918273926
Epoch 359, CIFAR-10 Batch 1:  Train_Loss:1.5908277034759521, Valid_Loss:2.075192451477051, Valid_ACC:0.284199982881546
Epoch 360, CIFAR-10 Batch 1:  Train_Loss:1.588094711303711, Valid_Loss:2.071479320526123, Valid_ACC:0.2895999848842621
Epoch 361, CIFAR-10 Batch 1:  Train_Loss:1.576238751411438, Valid_Loss:2.06693172454834, Valid_ACC:0.2935999929904938
Epoch 362, CIFAR-10 Batch 1:  Train_Loss:1.5681883096694946, Valid_Loss:2.0716230869293213, Valid_ACC:0.29159995913505554
Epoch 363, CIFAR-10 Batch 1:  Train_Loss:1.567556619644165, Valid_Loss:2.055206060409546, Valid_ACC:0.28999999165534973
Epoch 364, CIFAR-10 Batch 1:  Train_Loss:1.5608631372451782, Valid_Loss:2.054166793823242, Valid_ACC:0.28779998421669006
Epoch 365, CIFAR-10 Batch 1:  Train_Loss:1.5478181838989258, Valid_Loss:2.0438451766967773, Valid_ACC:0.29100000858306885
Epoch 366, CIFAR-10 Batch 1:  Train_Loss:1.5466630458831787, Valid_Loss:2.0400774478912354, Valid_ACC:0.2897999882698059
Epoch 367, CIFAR-10 Batch 1:  Train_Loss:1.5475398302078247, Valid_Loss:2.0452611446380615, Valid_ACC:0.2903999984264374
Epoch 368, CIFAR-10 Batch 1:  Train_Loss:1.5509657859802246, Valid_Loss:2.038844347000122, Valid_ACC:0.289000004529953
Epoch 369, CIFAR-10 Batch 1:  Train_Loss:1.5422894954681396, Valid_Loss:2.0406529903411865, Valid_ACC:0.2897999882698059
Epoch 370, CIFAR-10 Batch 1:  Train_Loss:1.5415209531784058, Valid_Loss:2.0446619987487793, Valid_ACC:0.2900000214576721
Epoch 371, CIFAR-10 Batch 1:  Train_Loss:1.5511723756790161, Valid_Loss:2.033466339111328, Valid_ACC:0.28779998421669006
Epoch 372, CIFAR-10 Batch 1:  Train_Loss:1.5575191974639893, Valid_Loss:2.0447194576263428, Valid_ACC:0.2881999611854553
Epoch 373, CIFAR-10 Batch 1:  Train_Loss:1.531063199043274, Valid_Loss:2.0338618755340576, Valid_ACC:0.28939998149871826
Epoch 374, CIFAR-10 Batch 1:  Train_Loss:1.5329827070236206, Valid_Loss:2.051635265350342, Valid_ACC:0.2865999937057495
Epoch 375, CIFAR-10 Batch 1:  Train_Loss:1.5422955751419067, Valid_Loss:2.0431199073791504, Valid_ACC:0.28679999709129333
Epoch 376, CIFAR-10 Batch 1:  Train_Loss:1.5324395895004272, Valid_Loss:2.029796838760376, Valid_ACC:0.296999990940094
Epoch 377, CIFAR-10 Batch 1:  Train_Loss:1.5148520469665527, Valid_Loss:2.009028673171997, Valid_ACC:0.311599999666214
Epoch 378, CIFAR-10 Batch 1:  Train_Loss:1.502793788909912, Valid_Loss:2.002746105194092, Valid_ACC:0.3155999779701233
Epoch 379, CIFAR-10 Batch 1:  Train_Loss:1.4908463954925537, Valid_Loss:1.972970962524414, Valid_ACC:0.3245999813079834
Epoch 380, CIFAR-10 Batch 1:  Train_Loss:1.4743837118148804, Valid_Loss:1.972224235534668, Valid_ACC:0.33299997448921204
Epoch 381, CIFAR-10 Batch 1:  Train_Loss:1.466672420501709, Valid_Loss:1.9623467922210693, Valid_ACC:0.3317999839782715
Epoch 382, CIFAR-10 Batch 1:  Train_Loss:1.4651598930358887, Valid_Loss:1.9539529085159302, Valid_ACC:0.3319999873638153
Epoch 383, CIFAR-10 Batch 1:  Train_Loss:1.46055269241333, Valid_Loss:1.9713841676712036, Valid_ACC:0.3333999812602997
Epoch 384, CIFAR-10 Batch 1:  Train_Loss:1.4749093055725098, Valid_Loss:1.9804176092147827, Valid_ACC:0.3317999839782715
Epoch 385, CIFAR-10 Batch 1:  Train_Loss:1.4395450353622437, Valid_Loss:1.9603687524795532, Valid_ACC:0.3343999981880188
Epoch 386, CIFAR-10 Batch 1:  Train_Loss:1.4312083721160889, Valid_Loss:1.9705946445465088, Valid_ACC:0.3361999988555908
Epoch 387, CIFAR-10 Batch 1:  Train_Loss:1.4302210807800293, Valid_Loss:1.9449173212051392, Valid_ACC:0.3391999900341034
Epoch 388, CIFAR-10 Batch 1:  Train_Loss:1.4190731048583984, Valid_Loss:1.9400315284729004, Valid_ACC:0.33560001850128174
Epoch 389, CIFAR-10 Batch 1:  Train_Loss:1.414549469947815, Valid_Loss:1.9404287338256836, Valid_ACC:0.3370000123977661
Epoch 390, CIFAR-10 Batch 1:  Train_Loss:1.4056059122085571, Valid_Loss:1.9555033445358276, Valid_ACC:0.3409999907016754
Epoch 391, CIFAR-10 Batch 1:  Train_Loss:1.4049487113952637, Valid_Loss:1.9503684043884277, Valid_ACC:0.33959996700286865
Epoch 392, CIFAR-10 Batch 1:  Train_Loss:1.3978633880615234, Valid_Loss:1.943253993988037, Valid_ACC:0.3368000090122223
Epoch 393, CIFAR-10 Batch 1:  Train_Loss:1.395446538925171, Valid_Loss:1.947243571281433, Valid_ACC:0.3431999981403351
Epoch 394, CIFAR-10 Batch 1:  Train_Loss:1.3859387636184692, Valid_Loss:1.9500219821929932, Valid_ACC:0.3394000232219696
Epoch 395, CIFAR-10 Batch 1:  Train_Loss:1.3877736330032349, Valid_Loss:1.9545068740844727, Valid_ACC:0.3409999907016754
Epoch 396, CIFAR-10 Batch 1:  Train_Loss:1.386338472366333, Valid_Loss:1.9705429077148438, Valid_ACC:0.34679996967315674
Epoch 397, CIFAR-10 Batch 1:  Train_Loss:1.396484613418579, Valid_Loss:1.9722559452056885, Valid_ACC:0.3400000035762787
Epoch 398, CIFAR-10 Batch 1:  Train_Loss:1.366013526916504, Valid_Loss:1.9325509071350098, Valid_ACC:0.3497999906539917
Epoch 399, CIFAR-10 Batch 1:  Train_Loss:1.361283779144287, Valid_Loss:1.9130111932754517, Valid_ACC:0.35819998383522034
Epoch 400, CIFAR-10 Batch 1:  Train_Loss:1.3424623012542725, Valid_Loss:1.90886390209198, Valid_ACC:0.3637999892234802
Epoch 401, CIFAR-10 Batch 1:  Train_Loss:1.3293027877807617, Valid_Loss:1.9006187915802002, Valid_ACC:0.36039999127388
Epoch 402, CIFAR-10 Batch 1:  Train_Loss:1.3180807828903198, Valid_Loss:1.9074788093566895, Valid_ACC:0.3625999689102173
Epoch 403, CIFAR-10 Batch 1:  Train_Loss:1.3061423301696777, Valid_Loss:1.912702202796936, Valid_ACC:0.3677999675273895
Epoch 404, CIFAR-10 Batch 1:  Train_Loss:1.3180856704711914, Valid_Loss:1.9227062463760376, Valid_ACC:0.36979997158050537
Epoch 405, CIFAR-10 Batch 1:  Train_Loss:1.3235770463943481, Valid_Loss:1.9224767684936523, Valid_ACC:0.3684000074863434
Epoch 406, CIFAR-10 Batch 1:  Train_Loss:1.281092882156372, Valid_Loss:1.9063117504119873, Valid_ACC:0.37700000405311584
Epoch 407, CIFAR-10 Batch 1:  Train_Loss:1.2836787700653076, Valid_Loss:1.890616774559021, Valid_ACC:0.37519997358322144
Epoch 408, CIFAR-10 Batch 1:  Train_Loss:1.2821714878082275, Valid_Loss:1.8959763050079346, Valid_ACC:0.3755999803543091
Epoch 409, CIFAR-10 Batch 1:  Train_Loss:1.274840235710144, Valid_Loss:1.8930163383483887, Valid_ACC:0.38419997692108154
Epoch 410, CIFAR-10 Batch 1:  Train_Loss:1.270717978477478, Valid_Loss:1.8971116542816162, Valid_ACC:0.3824000060558319
Epoch 411, CIFAR-10 Batch 1:  Train_Loss:1.2730181217193604, Valid_Loss:1.888158917427063, Valid_ACC:0.3807999789714813
Epoch 412, CIFAR-10 Batch 1:  Train_Loss:1.2741053104400635, Valid_Loss:1.897875189781189, Valid_ACC:0.3811999559402466
Epoch 413, CIFAR-10 Batch 1:  Train_Loss:1.2790300846099854, Valid_Loss:1.9143092632293701, Valid_ACC:0.38499999046325684
Epoch 414, CIFAR-10 Batch 1:  Train_Loss:1.2694422006607056, Valid_Loss:1.9173680543899536, Valid_ACC:0.38439998030662537
Epoch 415, CIFAR-10 Batch 1:  Train_Loss:1.2570579051971436, Valid_Loss:1.895455002784729, Valid_ACC:0.3830000162124634
Epoch 416, CIFAR-10 Batch 1:  Train_Loss:1.2429693937301636, Valid_Loss:1.899681806564331, Valid_ACC:0.3869999945163727
Epoch 417, CIFAR-10 Batch 1:  Train_Loss:1.2407701015472412, Valid_Loss:1.903379201889038, Valid_ACC:0.38179996609687805
Epoch 418, CIFAR-10 Batch 1:  Train_Loss:1.2347691059112549, Valid_Loss:1.879116415977478, Valid_ACC:0.38899993896484375
Epoch 419, CIFAR-10 Batch 1:  Train_Loss:1.232558012008667, Valid_Loss:1.891528606414795, Valid_ACC:0.3805999755859375
Epoch 420, CIFAR-10 Batch 1:  Train_Loss:1.225353717803955, Valid_Loss:1.8939119577407837, Valid_ACC:0.38839998841285706
Epoch 421, CIFAR-10 Batch 1:  Train_Loss:1.2190812826156616, Valid_Loss:1.891503095626831, Valid_ACC:0.3887999653816223
Epoch 422, CIFAR-10 Batch 1:  Train_Loss:1.2167766094207764, Valid_Loss:1.8969669342041016, Valid_ACC:0.3861999809741974
Epoch 423, CIFAR-10 Batch 1:  Train_Loss:1.2168736457824707, Valid_Loss:1.8965444564819336, Valid_ACC:0.3840000033378601
Epoch 424, CIFAR-10 Batch 1:  Train_Loss:1.2117948532104492, Valid_Loss:1.8947259187698364, Valid_ACC:0.3837999701499939
Epoch 425, CIFAR-10 Batch 1:  Train_Loss:1.2155119180679321, Valid_Loss:1.8913004398345947, Valid_ACC:0.3790000081062317
Epoch 426, CIFAR-10 Batch 1:  Train_Loss:1.2226741313934326, Valid_Loss:1.9054346084594727, Valid_ACC:0.38119998574256897
Epoch 427, CIFAR-10 Batch 1:  Train_Loss:1.2159048318862915, Valid_Loss:1.8947877883911133, Valid_ACC:0.3797999620437622
Epoch 428, CIFAR-10 Batch 1:  Train_Loss:1.2164791822433472, Valid_Loss:1.9043959379196167, Valid_ACC:0.3837999701499939
Epoch 429, CIFAR-10 Batch 1:  Train_Loss:1.204344391822815, Valid_Loss:1.9031190872192383, Valid_ACC:0.3871999680995941
Epoch 430, CIFAR-10 Batch 1:  Train_Loss:1.2129602432250977, Valid_Loss:1.910497784614563, Valid_ACC:0.3871999680995941
Epoch 431, CIFAR-10 Batch 1:  Train_Loss:1.204939842224121, Valid_Loss:1.9107420444488525, Valid_ACC:0.37959998846054077
Epoch 432, CIFAR-10 Batch 1:  Train_Loss:1.1996108293533325, Valid_Loss:1.9096076488494873, Valid_ACC:0.38419997692108154
Epoch 433, CIFAR-10 Batch 1:  Train_Loss:1.2047244310379028, Valid_Loss:1.9081485271453857, Valid_ACC:0.384799987077713
Epoch 434, CIFAR-10 Batch 1:  Train_Loss:1.192970633506775, Valid_Loss:1.9029737710952759, Valid_ACC:0.38599997758865356
Epoch 435, CIFAR-10 Batch 1:  Train_Loss:1.1897025108337402, Valid_Loss:1.8950963020324707, Valid_ACC:0.38259997963905334
Epoch 436, CIFAR-10 Batch 1:  Train_Loss:1.1865994930267334, Valid_Loss:1.8997690677642822, Valid_ACC:0.3845999836921692
Epoch 437, CIFAR-10 Batch 1:  Train_Loss:1.18612802028656, Valid_Loss:1.9013795852661133, Valid_ACC:0.38439998030662537
Epoch 438, CIFAR-10 Batch 1:  Train_Loss:1.186445713043213, Valid_Loss:1.8971710205078125, Valid_ACC:0.384799987077713
Epoch 439, CIFAR-10 Batch 1:  Train_Loss:1.1856017112731934, Valid_Loss:1.9071025848388672, Valid_ACC:0.3837999701499939
Epoch 440, CIFAR-10 Batch 1:  Train_Loss:1.1948105096817017, Valid_Loss:1.9313435554504395, Valid_ACC:0.38579997420310974
Epoch 441, CIFAR-10 Batch 1:  Train_Loss:1.1839011907577515, Valid_Loss:1.9243149757385254, Valid_ACC:0.38339999318122864
Epoch 442, CIFAR-10 Batch 1:  Train_Loss:1.2016421556472778, Valid_Loss:1.9086461067199707, Valid_ACC:0.38399994373321533
Epoch 443, CIFAR-10 Batch 1:  Train_Loss:1.1900039911270142, Valid_Loss:1.9159424304962158, Valid_ACC:0.38099995255470276
Epoch 444, CIFAR-10 Batch 1:  Train_Loss:1.1681766510009766, Valid_Loss:1.9190986156463623, Valid_ACC:0.3853999972343445
Epoch 445, CIFAR-10 Batch 1:  Train_Loss:1.17183518409729, Valid_Loss:1.9120256900787354, Valid_ACC:0.38600000739097595
Epoch 446, CIFAR-10 Batch 1:  Train_Loss:1.1804686784744263, Valid_Loss:1.9204903841018677, Valid_ACC:0.3823999762535095
Epoch 447, CIFAR-10 Batch 1:  Train_Loss:1.1684556007385254, Valid_Loss:1.9115583896636963, Valid_ACC:0.3869999647140503
Epoch 448, CIFAR-10 Batch 1:  Train_Loss:1.1740894317626953, Valid_Loss:1.9035518169403076, Valid_ACC:0.3877999782562256
Epoch 449, CIFAR-10 Batch 1:  Train_Loss:1.1784416437149048, Valid_Loss:1.9181218147277832, Valid_ACC:0.38759997487068176
Epoch 450, CIFAR-10 Batch 1:  Train_Loss:1.1765611171722412, Valid_Loss:1.9302979707717896, Valid_ACC:0.3877999782562256
Epoch 451, CIFAR-10 Batch 1:  Train_Loss:1.168770432472229, Valid_Loss:1.9147922992706299, Valid_ACC:0.3862000107765198
Epoch 452, CIFAR-10 Batch 1:  Train_Loss:1.1851751804351807, Valid_Loss:1.9266440868377686, Valid_ACC:0.3821999430656433
Epoch 453, CIFAR-10 Batch 1:  Train_Loss:1.1764636039733887, Valid_Loss:1.9223119020462036, Valid_ACC:0.38339996337890625
Epoch 454, CIFAR-10 Batch 1:  Train_Loss:1.1669937372207642, Valid_Loss:1.9214072227478027, Valid_ACC:0.3835999667644501
Epoch 455, CIFAR-10 Batch 1:  Train_Loss:1.1646356582641602, Valid_Loss:1.9045441150665283, Valid_ACC:0.386199951171875
Epoch 456, CIFAR-10 Batch 1:  Train_Loss:1.146098256111145, Valid_Loss:1.8836307525634766, Valid_ACC:0.38679999113082886
Epoch 457, CIFAR-10 Batch 1:  Train_Loss:1.1463061571121216, Valid_Loss:1.8869765996932983, Valid_ACC:0.38979995250701904
Epoch 458, CIFAR-10 Batch 1:  Train_Loss:1.1510103940963745, Valid_Loss:1.9142775535583496, Valid_ACC:0.38519996404647827
Epoch 459, CIFAR-10 Batch 1:  Train_Loss:1.1529901027679443, Valid_Loss:1.9090124368667603, Valid_ACC:0.38040000200271606
Epoch 460, CIFAR-10 Batch 1:  Train_Loss:1.1342617273330688, Valid_Loss:1.907713532447815, Valid_ACC:0.38739997148513794
Epoch 461, CIFAR-10 Batch 1:  Train_Loss:1.1339373588562012, Valid_Loss:1.8875343799591064, Valid_ACC:0.3863999843597412
Epoch 462, CIFAR-10 Batch 1:  Train_Loss:1.1308242082595825, Valid_Loss:1.8964684009552002, Valid_ACC:0.3877999782562256
Epoch 463, CIFAR-10 Batch 1:  Train_Loss:1.1320724487304688, Valid_Loss:1.9032816886901855, Valid_ACC:0.38919997215270996
Epoch 464, CIFAR-10 Batch 1:  Train_Loss:1.128739356994629, Valid_Loss:1.894189715385437, Valid_ACC:0.3871999680995941
Epoch 465, CIFAR-10 Batch 1:  Train_Loss:1.132872223854065, Valid_Loss:1.8978607654571533, Valid_ACC:0.37699997425079346
Epoch 466, CIFAR-10 Batch 1:  Train_Loss:1.1166937351226807, Valid_Loss:1.901341438293457, Valid_ACC:0.38579997420310974
Epoch 467, CIFAR-10 Batch 1:  Train_Loss:1.1242529153823853, Valid_Loss:1.9151896238327026, Valid_ACC:0.38599997758865356
Epoch 468, CIFAR-10 Batch 1:  Train_Loss:1.125025749206543, Valid_Loss:1.9134825468063354, Valid_ACC:0.38339996337890625
Epoch 469, CIFAR-10 Batch 1:  Train_Loss:1.1149725914001465, Valid_Loss:1.9103811979293823, Valid_ACC:0.3829999566078186
Epoch 470, CIFAR-10 Batch 1:  Train_Loss:1.1209592819213867, Valid_Loss:1.9000492095947266, Valid_ACC:0.3781999945640564
Epoch 471, CIFAR-10 Batch 1:  Train_Loss:1.11014723777771, Valid_Loss:1.8993453979492188, Valid_ACC:0.38999998569488525
Epoch 472, CIFAR-10 Batch 1:  Train_Loss:1.1142245531082153, Valid_Loss:1.8956447839736938, Valid_ACC:0.38600000739097595
Epoch 473, CIFAR-10 Batch 1:  Train_Loss:1.1059128046035767, Valid_Loss:1.9172799587249756, Valid_ACC:0.3869999647140503
Epoch 474, CIFAR-10 Batch 1:  Train_Loss:1.1078641414642334, Valid_Loss:1.9213407039642334, Valid_ACC:0.38819998502731323
Epoch 475, CIFAR-10 Batch 1:  Train_Loss:1.118691086769104, Valid_Loss:1.9095814228057861, Valid_ACC:0.38019999861717224
Epoch 476, CIFAR-10 Batch 1:  Train_Loss:1.1132256984710693, Valid_Loss:1.909482717514038, Valid_ACC:0.3835999667644501
Epoch 477, CIFAR-10 Batch 1:  Train_Loss:1.1148648262023926, Valid_Loss:1.9259182214736938, Valid_ACC:0.3821999430656433
Epoch 478, CIFAR-10 Batch 1:  Train_Loss:1.109824538230896, Valid_Loss:1.9117754697799683, Valid_ACC:0.37959998846054077
Epoch 479, CIFAR-10 Batch 1:  Train_Loss:1.101315975189209, Valid_Loss:1.9270631074905396, Valid_ACC:0.3831999599933624
Epoch 480, CIFAR-10 Batch 1:  Train_Loss:1.1305789947509766, Valid_Loss:1.9378385543823242, Valid_ACC:0.3763999938964844
Epoch 481, CIFAR-10 Batch 1:  Train_Loss:1.1187504529953003, Valid_Loss:1.9180227518081665, Valid_ACC:0.3791999816894531
Epoch 482, CIFAR-10 Batch 1:  Train_Loss:1.1170222759246826, Valid_Loss:1.9256452322006226, Valid_ACC:0.36959993839263916
Epoch 483, CIFAR-10 Batch 1:  Train_Loss:1.119107723236084, Valid_Loss:1.9227755069732666, Valid_ACC:0.37959998846054077
Epoch 484, CIFAR-10 Batch 1:  Train_Loss:1.1654369831085205, Valid_Loss:1.9732170104980469, Valid_ACC:0.36559998989105225
Epoch 485, CIFAR-10 Batch 1:  Train_Loss:1.1851943731307983, Valid_Loss:1.9922544956207275, Valid_ACC:0.3625999689102173
Epoch 486, CIFAR-10 Batch 1:  Train_Loss:1.1217094659805298, Valid_Loss:1.92524254322052, Valid_ACC:0.37939998507499695
Epoch 487, CIFAR-10 Batch 1:  Train_Loss:1.1449384689331055, Valid_Loss:1.9009171724319458, Valid_ACC:0.3813999891281128
Epoch 488, CIFAR-10 Batch 1:  Train_Loss:1.124574899673462, Valid_Loss:1.9252634048461914, Valid_ACC:0.38259994983673096
Epoch 489, CIFAR-10 Batch 1:  Train_Loss:1.093885898590088, Valid_Loss:1.9171509742736816, Valid_ACC:0.38519996404647827
Epoch 490, CIFAR-10 Batch 1:  Train_Loss:1.0936689376831055, Valid_Loss:1.9183560609817505, Valid_ACC:0.3797999918460846
Epoch 491, CIFAR-10 Batch 1:  Train_Loss:1.096435785293579, Valid_Loss:1.9183602333068848, Valid_ACC:0.38279998302459717
Epoch 492, CIFAR-10 Batch 1:  Train_Loss:1.1029423475265503, Valid_Loss:1.9413046836853027, Valid_ACC:0.38439998030662537
Epoch 493, CIFAR-10 Batch 1:  Train_Loss:1.0854750871658325, Valid_Loss:1.93490731716156, Valid_ACC:0.38259997963905334
Epoch 494, CIFAR-10 Batch 1:  Train_Loss:1.1158243417739868, Valid_Loss:1.9378392696380615, Valid_ACC:0.3758000135421753
Epoch 495, CIFAR-10 Batch 1:  Train_Loss:1.1265320777893066, Valid_Loss:1.9411211013793945, Valid_ACC:0.3797999620437622
Epoch 496, CIFAR-10 Batch 1:  Train_Loss:1.1077933311462402, Valid_Loss:1.9342339038848877, Valid_ACC:0.38019996881484985
Epoch 497, CIFAR-10 Batch 1:  Train_Loss:1.0869204998016357, Valid_Loss:1.9182946681976318, Valid_ACC:0.38159996271133423
Epoch 498, CIFAR-10 Batch 1:  Train_Loss:1.0769354104995728, Valid_Loss:1.9174823760986328, Valid_ACC:0.38439998030662537
Epoch 499, CIFAR-10 Batch 1:  Train_Loss:1.080941915512085, Valid_Loss:1.9297152757644653, Valid_ACC:0.38599997758865356
Epoch 500, CIFAR-10 Batch 1:  Train_Loss:1.082714319229126, Valid_Loss:1.9225876331329346, Valid_ACC:0.3819999694824219
Epoch 501, CIFAR-10 Batch 1:  Train_Loss:1.072496771812439, Valid_Loss:1.9168717861175537, Valid_ACC:0.386199951171875
Epoch 502, CIFAR-10 Batch 1:  Train_Loss:1.072765827178955, Valid_Loss:1.9170191287994385, Valid_ACC:0.3803999722003937
Epoch 503, CIFAR-10 Batch 1:  Train_Loss:1.069427490234375, Valid_Loss:1.9339895248413086, Valid_ACC:0.3862000107765198
Epoch 504, CIFAR-10 Batch 1:  Train_Loss:1.0688742399215698, Valid_Loss:1.943269968032837, Valid_ACC:0.3856000006198883
Epoch 505, CIFAR-10 Batch 1:  Train_Loss:1.0717332363128662, Valid_Loss:1.9387274980545044, Valid_ACC:0.38279998302459717
Epoch 506, CIFAR-10 Batch 1:  Train_Loss:1.061289668083191, Valid_Loss:1.9542524814605713, Valid_ACC:0.3823999762535095
Epoch 507, CIFAR-10 Batch 1:  Train_Loss:1.063733458518982, Valid_Loss:1.943894386291504, Valid_ACC:0.3819999694824219
Epoch 508, CIFAR-10 Batch 1:  Train_Loss:1.0668787956237793, Valid_Loss:1.9431666135787964, Valid_ACC:0.38279998302459717
Epoch 509, CIFAR-10 Batch 1:  Train_Loss:1.0633947849273682, Valid_Loss:1.9602172374725342, Valid_ACC:0.38279998302459717
Epoch 510, CIFAR-10 Batch 1:  Train_Loss:1.0636420249938965, Valid_Loss:1.9519314765930176, Valid_ACC:0.38519996404647827
Epoch 511, CIFAR-10 Batch 1:  Train_Loss:1.064896821975708, Valid_Loss:1.9564265012741089, Valid_ACC:0.38439998030662537
Epoch 512, CIFAR-10 Batch 1:  Train_Loss:1.0519179105758667, Valid_Loss:1.946593999862671, Valid_ACC:0.38679996132850647
Epoch 513, CIFAR-10 Batch 1:  Train_Loss:1.0531353950500488, Valid_Loss:1.934585452079773, Valid_ACC:0.3885999917984009
Epoch 514, CIFAR-10 Batch 1:  Train_Loss:1.0552297830581665, Valid_Loss:1.9302971363067627, Valid_ACC:0.38499996066093445
Epoch 515, CIFAR-10 Batch 1:  Train_Loss:1.0606467723846436, Valid_Loss:1.9498211145401, Valid_ACC:0.3831999599933624
Epoch 516, CIFAR-10 Batch 1:  Train_Loss:1.0565412044525146, Valid_Loss:1.9475533962249756, Valid_ACC:0.38659995794296265
Epoch 517, CIFAR-10 Batch 1:  Train_Loss:1.0578993558883667, Valid_Loss:1.9358103275299072, Valid_ACC:0.38819998502731323
Epoch 518, CIFAR-10 Batch 1:  Train_Loss:1.0560855865478516, Valid_Loss:1.9460809230804443, Valid_ACC:0.38519996404647827
Epoch 519, CIFAR-10 Batch 1:  Train_Loss:1.0675573348999023, Valid_Loss:1.9618422985076904, Valid_ACC:0.38159996271133423
Epoch 520, CIFAR-10 Batch 1:  Train_Loss:1.0484497547149658, Valid_Loss:1.9436237812042236, Valid_ACC:0.38260000944137573
Epoch 521, CIFAR-10 Batch 1:  Train_Loss:1.0491907596588135, Valid_Loss:1.9390249252319336, Valid_ACC:0.3848000168800354
Epoch 522, CIFAR-10 Batch 1:  Train_Loss:1.0538309812545776, Valid_Loss:1.939516544342041, Valid_ACC:0.3811999559402466
Epoch 523, CIFAR-10 Batch 1:  Train_Loss:1.056544542312622, Valid_Loss:1.953383445739746, Valid_ACC:0.38119998574256897
Epoch 524, CIFAR-10 Batch 1:  Train_Loss:1.0558784008026123, Valid_Loss:1.9347929954528809, Valid_ACC:0.3837999701499939
Epoch 525, CIFAR-10 Batch 1:  Train_Loss:1.0519098043441772, Valid_Loss:1.9520765542984009, Valid_ACC:0.3789999485015869
Epoch 526, CIFAR-10 Batch 1:  Train_Loss:1.045125126838684, Valid_Loss:1.9374045133590698, Valid_ACC:0.3855999708175659
Epoch 527, CIFAR-10 Batch 1:  Train_Loss:1.0490010976791382, Valid_Loss:1.947439432144165, Valid_ACC:0.38279998302459717
Epoch 528, CIFAR-10 Batch 1:  Train_Loss:1.0459914207458496, Valid_Loss:1.952404260635376, Valid_ACC:0.3837999701499939
Epoch 529, CIFAR-10 Batch 1:  Train_Loss:1.038016676902771, Valid_Loss:1.955918550491333, Valid_ACC:0.3827999532222748
Epoch 530, CIFAR-10 Batch 1:  Train_Loss:1.039351463317871, Valid_Loss:1.959810733795166, Valid_ACC:0.38419997692108154
Epoch 531, CIFAR-10 Batch 1:  Train_Loss:1.0472846031188965, Valid_Loss:1.9358463287353516, Valid_ACC:0.3797999918460846
Epoch 532, CIFAR-10 Batch 1:  Train_Loss:1.0468071699142456, Valid_Loss:1.9697964191436768, Valid_ACC:0.3797999620437622
Epoch 533, CIFAR-10 Batch 1:  Train_Loss:1.0359797477722168, Valid_Loss:1.9436743259429932, Valid_ACC:0.382999986410141
Epoch 534, CIFAR-10 Batch 1:  Train_Loss:1.030207633972168, Valid_Loss:1.9446903467178345, Valid_ACC:0.3827999532222748
Epoch 535, CIFAR-10 Batch 1:  Train_Loss:1.0310864448547363, Valid_Loss:1.9484901428222656, Valid_ACC:0.38499999046325684
Epoch 536, CIFAR-10 Batch 1:  Train_Loss:1.0352749824523926, Valid_Loss:1.9620643854141235, Valid_ACC:0.38419997692108154
Epoch 537, CIFAR-10 Batch 1:  Train_Loss:1.0369949340820312, Valid_Loss:1.9511299133300781, Valid_ACC:0.38419997692108154
Epoch 538, CIFAR-10 Batch 1:  Train_Loss:1.048783302307129, Valid_Loss:1.9392058849334717, Valid_ACC:0.38099998235702515
Epoch 539, CIFAR-10 Batch 1:  Train_Loss:1.0271406173706055, Valid_Loss:1.9427391290664673, Valid_ACC:0.3863999843597412
Epoch 540, CIFAR-10 Batch 1:  Train_Loss:1.0348988771438599, Valid_Loss:1.9410814046859741, Valid_ACC:0.38040000200271606
Epoch 541, CIFAR-10 Batch 1:  Train_Loss:1.0301908254623413, Valid_Loss:1.9646481275558472, Valid_ACC:0.3823999762535095
Epoch 542, CIFAR-10 Batch 1:  Train_Loss:1.0229684114456177, Valid_Loss:1.9684547185897827, Valid_ACC:0.38579994440078735
Epoch 543, CIFAR-10 Batch 1:  Train_Loss:1.0303384065628052, Valid_Loss:1.9459933042526245, Valid_ACC:0.38679999113082886
Epoch 544, CIFAR-10 Batch 1:  Train_Loss:1.028562307357788, Valid_Loss:1.9654239416122437, Valid_ACC:0.3806000053882599
Epoch 545, CIFAR-10 Batch 1:  Train_Loss:1.0338653326034546, Valid_Loss:1.95618736743927, Valid_ACC:0.38099998235702515
Epoch 546, CIFAR-10 Batch 1:  Train_Loss:1.04338538646698, Valid_Loss:1.9824786186218262, Valid_ACC:0.37939998507499695
Epoch 547, CIFAR-10 Batch 1:  Train_Loss:1.032332420349121, Valid_Loss:1.9896987676620483, Valid_ACC:0.3805999755859375
Epoch 548, CIFAR-10 Batch 1:  Train_Loss:1.0298724174499512, Valid_Loss:1.9408955574035645, Valid_ACC:0.38339999318122864
Epoch 549, CIFAR-10 Batch 1:  Train_Loss:1.0275580883026123, Valid_Loss:1.9515055418014526, Valid_ACC:0.3853999674320221
Epoch 550, CIFAR-10 Batch 1:  Train_Loss:1.0235836505889893, Valid_Loss:1.975475549697876, Valid_ACC:0.38739997148513794
Epoch 551, CIFAR-10 Batch 1:  Train_Loss:1.022060751914978, Valid_Loss:1.9538894891738892, Valid_ACC:0.38339999318122864
Epoch 552, CIFAR-10 Batch 1:  Train_Loss:1.0142161846160889, Valid_Loss:1.9600834846496582, Valid_ACC:0.38239994645118713
Epoch 553, CIFAR-10 Batch 1:  Train_Loss:1.0191705226898193, Valid_Loss:1.9723329544067383, Valid_ACC:0.38360002636909485
Epoch 554, CIFAR-10 Batch 1:  Train_Loss:1.0146369934082031, Valid_Loss:1.9674094915390015, Valid_ACC:0.3845999836921692
Epoch 555, CIFAR-10 Batch 1:  Train_Loss:1.0096453428268433, Valid_Loss:1.96832275390625, Valid_ACC:0.3845999836921692
Epoch 556, CIFAR-10 Batch 1:  Train_Loss:1.0180822610855103, Valid_Loss:1.967822551727295, Valid_ACC:0.38279998302459717
Epoch 557, CIFAR-10 Batch 1:  Train_Loss:1.0291494131088257, Valid_Loss:1.9865790605545044, Valid_ACC:0.37779998779296875
Epoch 558, CIFAR-10 Batch 1:  Train_Loss:1.020305871963501, Valid_Loss:1.9888466596603394, Valid_ACC:0.3773999810218811
Epoch 559, CIFAR-10 Batch 1:  Train_Loss:1.0164252519607544, Valid_Loss:1.9758784770965576, Valid_ACC:0.3835999667644501
Epoch 560, CIFAR-10 Batch 1:  Train_Loss:1.0130866765975952, Valid_Loss:1.958528995513916, Valid_ACC:0.3845999836921692
Epoch 561, CIFAR-10 Batch 1:  Train_Loss:1.0121231079101562, Valid_Loss:1.9639068841934204, Valid_ACC:0.38579997420310974
Epoch 562, CIFAR-10 Batch 1:  Train_Loss:1.0206588506698608, Valid_Loss:1.986842393875122, Valid_ACC:0.38279998302459717
Epoch 563, CIFAR-10 Batch 1:  Train_Loss:1.0111942291259766, Valid_Loss:1.9686002731323242, Valid_ACC:0.38179999589920044
Epoch 564, CIFAR-10 Batch 1:  Train_Loss:1.014104962348938, Valid_Loss:1.9933114051818848, Valid_ACC:0.3803999722003937
Epoch 565, CIFAR-10 Batch 1:  Train_Loss:1.0059175491333008, Valid_Loss:1.9598511457443237, Valid_ACC:0.3863999545574188
Epoch 566, CIFAR-10 Batch 1:  Train_Loss:1.009096384048462, Valid_Loss:1.9738054275512695, Valid_ACC:0.38259997963905334
Epoch 567, CIFAR-10 Batch 1:  Train_Loss:1.0029224157333374, Valid_Loss:1.979623556137085, Valid_ACC:0.381399929523468
Epoch 568, CIFAR-10 Batch 1:  Train_Loss:1.0128332376480103, Valid_Loss:1.9700651168823242, Valid_ACC:0.3815999925136566
Epoch 569, CIFAR-10 Batch 1:  Train_Loss:1.0202600955963135, Valid_Loss:1.9771804809570312, Valid_ACC:0.3840000033378601
Epoch 570, CIFAR-10 Batch 1:  Train_Loss:1.00942862033844, Valid_Loss:1.983771562576294, Valid_ACC:0.3787999749183655
Epoch 571, CIFAR-10 Batch 1:  Train_Loss:1.0148721933364868, Valid_Loss:1.998044729232788, Valid_ACC:0.38159996271133423
Epoch 572, CIFAR-10 Batch 1:  Train_Loss:1.0375101566314697, Valid_Loss:2.0310654640197754, Valid_ACC:0.3747999668121338
Epoch 573, CIFAR-10 Batch 1:  Train_Loss:1.0395742654800415, Valid_Loss:2.002312660217285, Valid_ACC:0.37199997901916504
Epoch 574, CIFAR-10 Batch 1:  Train_Loss:1.0655165910720825, Valid_Loss:2.023627281188965, Valid_ACC:0.3741999864578247
Epoch 575, CIFAR-10 Batch 1:  Train_Loss:1.0641353130340576, Valid_Loss:1.9808980226516724, Valid_ACC:0.3601999878883362
Epoch 576, CIFAR-10 Batch 1:  Train_Loss:1.083598256111145, Valid_Loss:1.9558866024017334, Valid_ACC:0.3791999816894531
Epoch 577, CIFAR-10 Batch 1:  Train_Loss:1.1193757057189941, Valid_Loss:1.9574871063232422, Valid_ACC:0.37459996342658997
Epoch 578, CIFAR-10 Batch 1:  Train_Loss:1.0480241775512695, Valid_Loss:1.9482795000076294, Valid_ACC:0.3757999837398529
Epoch 579, CIFAR-10 Batch 1:  Train_Loss:1.0397117137908936, Valid_Loss:1.94838547706604, Valid_ACC:0.3864000141620636
Epoch 580, CIFAR-10 Batch 1:  Train_Loss:1.0292929410934448, Valid_Loss:1.9470466375350952, Valid_ACC:0.3811999559402466
Epoch 581, CIFAR-10 Batch 1:  Train_Loss:1.0538259744644165, Valid_Loss:1.9768610000610352, Valid_ACC:0.3781999945640564
Epoch 582, CIFAR-10 Batch 1:  Train_Loss:1.1203893423080444, Valid_Loss:1.948570728302002, Valid_ACC:0.38040000200271606
Epoch 583, CIFAR-10 Batch 1:  Train_Loss:1.095402717590332, Valid_Loss:1.9961369037628174, Valid_ACC:0.3749999701976776
Epoch 584, CIFAR-10 Batch 1:  Train_Loss:1.0584372282028198, Valid_Loss:1.9457383155822754, Valid_ACC:0.3839999735355377
Epoch 585, CIFAR-10 Batch 1:  Train_Loss:1.0320714712142944, Valid_Loss:1.9468427896499634, Valid_ACC:0.3851999342441559
Epoch 586, CIFAR-10 Batch 1:  Train_Loss:1.0314736366271973, Valid_Loss:1.9749711751937866, Valid_ACC:0.3805999755859375
Epoch 587, CIFAR-10 Batch 1:  Train_Loss:1.0298959016799927, Valid_Loss:1.9686651229858398, Valid_ACC:0.38659998774528503
Epoch 588, CIFAR-10 Batch 1:  Train_Loss:1.023148536682129, Valid_Loss:1.9505397081375122, Valid_ACC:0.38759997487068176
Epoch 589, CIFAR-10 Batch 1:  Train_Loss:1.0305548906326294, Valid_Loss:1.9737451076507568, Valid_ACC:0.38599997758865356
Epoch 590, CIFAR-10 Batch 1:  Train_Loss:1.0617656707763672, Valid_Loss:1.9463673830032349, Valid_ACC:0.37940001487731934
Epoch 591, CIFAR-10 Batch 1:  Train_Loss:1.0252047777175903, Valid_Loss:1.9527405500411987, Valid_ACC:0.3831999897956848
Epoch 592, CIFAR-10 Batch 1:  Train_Loss:1.0218141078948975, Valid_Loss:1.9461443424224854, Valid_ACC:0.3855999708175659
Epoch 593, CIFAR-10 Batch 1:  Train_Loss:1.00450599193573, Valid_Loss:1.957534670829773, Valid_ACC:0.38839998841285706
Epoch 594, CIFAR-10 Batch 1:  Train_Loss:1.008895993232727, Valid_Loss:1.9602785110473633, Valid_ACC:0.38259994983673096
Epoch 595, CIFAR-10 Batch 1:  Train_Loss:1.0077142715454102, Valid_Loss:1.9624230861663818, Valid_ACC:0.3871999680995941
Epoch 596, CIFAR-10 Batch 1:  Train_Loss:1.0308390855789185, Valid_Loss:1.9713399410247803, Valid_ACC:0.3787999749183655
Epoch 597, CIFAR-10 Batch 1:  Train_Loss:1.0522592067718506, Valid_Loss:1.9923036098480225, Valid_ACC:0.3765999674797058
Epoch 598, CIFAR-10 Batch 1:  Train_Loss:1.0285238027572632, Valid_Loss:1.9663851261138916, Valid_ACC:0.3799999952316284
Epoch 599, CIFAR-10 Batch 1:  Train_Loss:1.021533727645874, Valid_Loss:1.9675744771957397, Valid_ACC:0.37779995799064636
Epoch 600, CIFAR-10 Batch 1:  Train_Loss:1.021126627922058, Valid_Loss:1.9617640972137451, Valid_ACC:0.3847999572753906
Epoch 601, CIFAR-10 Batch 1:  Train_Loss:1.0108788013458252, Valid_Loss:1.961400032043457, Valid_ACC:0.38659995794296265
Epoch 602, CIFAR-10 Batch 1:  Train_Loss:1.0105869770050049, Valid_Loss:1.9611179828643799, Valid_ACC:0.384799987077713
Epoch 603, CIFAR-10 Batch 1:  Train_Loss:1.0333013534545898, Valid_Loss:1.9750579595565796, Valid_ACC:0.3779999613761902
Epoch 604, CIFAR-10 Batch 1:  Train_Loss:1.0644831657409668, Valid_Loss:1.9823352098464966, Valid_ACC:0.3726000189781189
Epoch 605, CIFAR-10 Batch 1:  Train_Loss:1.0403839349746704, Valid_Loss:1.9796042442321777, Valid_ACC:0.3797999918460846
Epoch 606, CIFAR-10 Batch 1:  Train_Loss:1.0268503427505493, Valid_Loss:1.9722070693969727, Valid_ACC:0.37999996542930603
Epoch 607, CIFAR-10 Batch 1:  Train_Loss:1.008350133895874, Valid_Loss:1.9710677862167358, Valid_ACC:0.3848000168800354
Epoch 608, CIFAR-10 Batch 1:  Train_Loss:1.0097055435180664, Valid_Loss:1.9635111093521118, Valid_ACC:0.3851999342441559
Epoch 609, CIFAR-10 Batch 1:  Train_Loss:0.9969071745872498, Valid_Loss:1.9753504991531372, Valid_ACC:0.38099998235702515
Epoch 610, CIFAR-10 Batch 1:  Train_Loss:1.0113996267318726, Valid_Loss:1.996660590171814, Valid_ACC:0.3819999694824219
Epoch 611, CIFAR-10 Batch 1:  Train_Loss:1.016344666481018, Valid_Loss:1.9715790748596191, Valid_ACC:0.37779998779296875
Epoch 612, CIFAR-10 Batch 1:  Train_Loss:1.0146878957748413, Valid_Loss:1.97836434841156, Valid_ACC:0.38179999589920044
Epoch 613, CIFAR-10 Batch 1:  Train_Loss:1.017812967300415, Valid_Loss:1.9732519388198853, Valid_ACC:0.3822000026702881
Epoch 614, CIFAR-10 Batch 1:  Train_Loss:1.0229886770248413, Valid_Loss:1.973469853401184, Valid_ACC:0.3765999674797058
Epoch 615, CIFAR-10 Batch 1:  Train_Loss:1.014765739440918, Valid_Loss:1.9711542129516602, Valid_ACC:0.3781999945640564
Epoch 616, CIFAR-10 Batch 1:  Train_Loss:1.0082231760025024, Valid_Loss:1.9818991422653198, Valid_ACC:0.37779998779296875
Epoch 617, CIFAR-10 Batch 1:  Train_Loss:1.0017294883728027, Valid_Loss:1.9811002016067505, Valid_ACC:0.38019996881484985
Epoch 618, CIFAR-10 Batch 1:  Train_Loss:0.9935504198074341, Valid_Loss:1.974461317062378, Valid_ACC:0.38040000200271606
Epoch 619, CIFAR-10 Batch 1:  Train_Loss:0.99139803647995, Valid_Loss:1.9730958938598633, Valid_ACC:0.38339999318122864
Epoch 620, CIFAR-10 Batch 1:  Train_Loss:1.0013538599014282, Valid_Loss:1.9700396060943604, Valid_ACC:0.38279998302459717
Epoch 621, CIFAR-10 Batch 1:  Train_Loss:0.9967284798622131, Valid_Loss:1.9775618314743042, Valid_ACC:0.38519996404647827
Epoch 622, CIFAR-10 Batch 1:  Train_Loss:0.9931219816207886, Valid_Loss:1.9650559425354004, Valid_ACC:0.38359999656677246
Epoch 623, CIFAR-10 Batch 1:  Train_Loss:0.9889200329780579, Valid_Loss:1.9685941934585571, Valid_ACC:0.382999986410141
Epoch 624, CIFAR-10 Batch 1:  Train_Loss:0.9946237802505493, Valid_Loss:1.971251130104065, Valid_ACC:0.3805999755859375
Epoch 625, CIFAR-10 Batch 1:  Train_Loss:1.011218547821045, Valid_Loss:1.9913707971572876, Valid_ACC:0.37379997968673706
Epoch 626, CIFAR-10 Batch 1:  Train_Loss:1.013314127922058, Valid_Loss:1.9827110767364502, Valid_ACC:0.375
Epoch 627, CIFAR-10 Batch 1:  Train_Loss:0.9957650303840637, Valid_Loss:1.9728413820266724, Valid_ACC:0.38019999861717224
Epoch 628, CIFAR-10 Batch 1:  Train_Loss:0.9882675409317017, Valid_Loss:1.9902055263519287, Valid_ACC:0.37439998984336853
Epoch 629, CIFAR-10 Batch 1:  Train_Loss:0.9827707409858704, Valid_Loss:1.9790600538253784, Valid_ACC:0.38099995255470276
Epoch 630, CIFAR-10 Batch 1:  Train_Loss:0.9754759073257446, Valid_Loss:1.9867727756500244, Valid_ACC:0.3831999599933624
Epoch 631, CIFAR-10 Batch 1:  Train_Loss:0.9810878038406372, Valid_Loss:1.9936540126800537, Valid_ACC:0.3821999728679657
Epoch 632, CIFAR-10 Batch 1:  Train_Loss:0.9842756390571594, Valid_Loss:1.9825423955917358, Valid_ACC:0.37699997425079346
Epoch 633, CIFAR-10 Batch 1:  Train_Loss:0.9898648858070374, Valid_Loss:2.0044431686401367, Valid_ACC:0.3760000169277191
Epoch 634, CIFAR-10 Batch 1:  Train_Loss:0.9804644584655762, Valid_Loss:1.9954512119293213, Valid_ACC:0.37839996814727783
Epoch 635, CIFAR-10 Batch 1:  Train_Loss:0.9918639063835144, Valid_Loss:1.9948508739471436, Valid_ACC:0.38019996881484985
Epoch 636, CIFAR-10 Batch 1:  Train_Loss:0.9853758811950684, Valid_Loss:2.012415885925293, Valid_ACC:0.3815999925136566
Epoch 637, CIFAR-10 Batch 1:  Train_Loss:0.9819310903549194, Valid_Loss:1.9971556663513184, Valid_ACC:0.38419997692108154
Epoch 638, CIFAR-10 Batch 1:  Train_Loss:0.977683961391449, Valid_Loss:2.0018467903137207, Valid_ACC:0.38599997758865356
Epoch 639, CIFAR-10 Batch 1:  Train_Loss:0.97074955701828, Valid_Loss:1.9980748891830444, Valid_ACC:0.3845999836921692
Epoch 640, CIFAR-10 Batch 1:  Train_Loss:0.9665182828903198, Valid_Loss:1.9820685386657715, Valid_ACC:0.38159996271133423
Epoch 641, CIFAR-10 Batch 1:  Train_Loss:0.9717888832092285, Valid_Loss:1.992051601409912, Valid_ACC:0.3797999620437622
Epoch 642, CIFAR-10 Batch 1:  Train_Loss:0.9748207330703735, Valid_Loss:1.9758837223052979, Valid_ACC:0.3835999667644501
Epoch 643, CIFAR-10 Batch 1:  Train_Loss:0.9662560224533081, Valid_Loss:1.9848926067352295, Valid_ACC:0.384799987077713
Epoch 644, CIFAR-10 Batch 1:  Train_Loss:0.9667156338691711, Valid_Loss:1.9854774475097656, Valid_ACC:0.38099998235702515
Epoch 645, CIFAR-10 Batch 1:  Train_Loss:0.9617356657981873, Valid_Loss:1.987347960472107, Valid_ACC:0.3879999816417694
Epoch 646, CIFAR-10 Batch 1:  Train_Loss:0.9607361555099487, Valid_Loss:1.9888567924499512, Valid_ACC:0.38599997758865356
Epoch 647, CIFAR-10 Batch 1:  Train_Loss:0.9675427079200745, Valid_Loss:1.9738903045654297, Valid_ACC:0.38019999861717224
Epoch 648, CIFAR-10 Batch 1:  Train_Loss:0.9797171950340271, Valid_Loss:1.9893434047698975, Valid_ACC:0.37779998779296875
Epoch 649, CIFAR-10 Batch 1:  Train_Loss:0.9760286808013916, Valid_Loss:1.9883830547332764, Valid_ACC:0.37839996814727783
Epoch 650, CIFAR-10 Batch 1:  Train_Loss:0.9670546650886536, Valid_Loss:2.003086566925049, Valid_ACC:0.3819999694824219
Epoch 651, CIFAR-10 Batch 1:  Train_Loss:0.9644309282302856, Valid_Loss:1.988194227218628, Valid_ACC:0.3805999755859375
Epoch 652, CIFAR-10 Batch 1:  Train_Loss:0.9613975286483765, Valid_Loss:2.0033111572265625, Valid_ACC:0.38199999928474426
Epoch 653, CIFAR-10 Batch 1:  Train_Loss:0.9674863219261169, Valid_Loss:1.9870878458023071, Valid_ACC:0.3797999918460846
Epoch 654, CIFAR-10 Batch 1:  Train_Loss:0.9695823788642883, Valid_Loss:1.990246295928955, Valid_ACC:0.37959998846054077
Epoch 655, CIFAR-10 Batch 1:  Train_Loss:0.9693904519081116, Valid_Loss:1.9948062896728516, Valid_ACC:0.3806000053882599
Epoch 656, CIFAR-10 Batch 1:  Train_Loss:0.9668805599212646, Valid_Loss:1.9997444152832031, Valid_ACC:0.3831999897956848
Epoch 657, CIFAR-10 Batch 1:  Train_Loss:0.9540324211120605, Valid_Loss:2.000861644744873, Valid_ACC:0.38420000672340393
Epoch 658, CIFAR-10 Batch 1:  Train_Loss:0.9573187828063965, Valid_Loss:1.9966514110565186, Valid_ACC:0.3837999701499939
Epoch 659, CIFAR-10 Batch 1:  Train_Loss:0.9529428482055664, Valid_Loss:1.9977760314941406, Valid_ACC:0.3797999620437622
Epoch 660, CIFAR-10 Batch 1:  Train_Loss:0.9534372091293335, Valid_Loss:1.9846407175064087, Valid_ACC:0.38499999046325684
Epoch 661, CIFAR-10 Batch 1:  Train_Loss:0.9489232897758484, Valid_Loss:1.9910473823547363, Valid_ACC:0.384799987077713
Epoch 662, CIFAR-10 Batch 1:  Train_Loss:0.9546510577201843, Valid_Loss:1.9917409420013428, Valid_ACC:0.38419997692108154
Epoch 663, CIFAR-10 Batch 1:  Train_Loss:0.9600843787193298, Valid_Loss:1.9945728778839111, Valid_ACC:0.38260000944137573
Epoch 664, CIFAR-10 Batch 1:  Train_Loss:0.9621970653533936, Valid_Loss:2.0044217109680176, Valid_ACC:0.38179999589920044
Epoch 665, CIFAR-10 Batch 1:  Train_Loss:0.963650643825531, Valid_Loss:2.0039868354797363, Valid_ACC:0.3808000087738037
Epoch 666, CIFAR-10 Batch 1:  Train_Loss:0.9546797275543213, Valid_Loss:2.0137908458709717, Valid_ACC:0.3791999816894531
Epoch 667, CIFAR-10 Batch 1:  Train_Loss:0.9671785235404968, Valid_Loss:1.994941234588623, Valid_ACC:0.3779999911785126
Epoch 668, CIFAR-10 Batch 1:  Train_Loss:0.9568006992340088, Valid_Loss:2.0015077590942383, Valid_ACC:0.38159996271133423
Epoch 669, CIFAR-10 Batch 1:  Train_Loss:0.956019401550293, Valid_Loss:1.9942238330841064, Valid_ACC:0.38119998574256897
Epoch 670, CIFAR-10 Batch 1:  Train_Loss:0.9486844539642334, Valid_Loss:1.9975593090057373, Valid_ACC:0.38179996609687805
Epoch 671, CIFAR-10 Batch 1:  Train_Loss:0.9534488916397095, Valid_Loss:2.0238301753997803, Valid_ACC:0.37939998507499695
Epoch 672, CIFAR-10 Batch 1:  Train_Loss:0.9604365825653076, Valid_Loss:1.9882738590240479, Valid_ACC:0.37939995527267456
Epoch 673, CIFAR-10 Batch 1:  Train_Loss:0.9521200656890869, Valid_Loss:1.997684359550476, Valid_ACC:0.3822000026702881
Epoch 674, CIFAR-10 Batch 1:  Train_Loss:0.9530894756317139, Valid_Loss:2.0107250213623047, Valid_ACC:0.38259997963905334
Epoch 675, CIFAR-10 Batch 1:  Train_Loss:0.9607349038124084, Valid_Loss:1.9899189472198486, Valid_ACC:0.38099998235702515
Epoch 676, CIFAR-10 Batch 1:  Train_Loss:0.9501687288284302, Valid_Loss:2.008882999420166, Valid_ACC:0.37999996542930603
Epoch 677, CIFAR-10 Batch 1:  Train_Loss:0.9484129548072815, Valid_Loss:1.99497389793396, Valid_ACC:0.3755999803543091
Epoch 678, CIFAR-10 Batch 1:  Train_Loss:0.9435073137283325, Valid_Loss:2.010106325149536, Valid_ACC:0.3797999620437622
Epoch 679, CIFAR-10 Batch 1:  Train_Loss:0.942002534866333, Valid_Loss:2.0003139972686768, Valid_ACC:0.3821999728679657
Epoch 680, CIFAR-10 Batch 1:  Train_Loss:0.9411783814430237, Valid_Loss:1.983492374420166, Valid_ACC:0.3823999762535095
Epoch 681, CIFAR-10 Batch 1:  Train_Loss:0.9423369765281677, Valid_Loss:1.9815335273742676, Valid_ACC:0.382999986410141
Epoch 682, CIFAR-10 Batch 1:  Train_Loss:0.946137547492981, Valid_Loss:2.003129005432129, Valid_ACC:0.3755999803543091
Epoch 683, CIFAR-10 Batch 1:  Train_Loss:0.968753457069397, Valid_Loss:2.0217161178588867, Valid_ACC:0.37380000948905945
Epoch 684, CIFAR-10 Batch 1:  Train_Loss:0.9635289907455444, Valid_Loss:2.0100321769714355, Valid_ACC:0.37059998512268066
Epoch 685, CIFAR-10 Batch 1:  Train_Loss:0.9505188465118408, Valid_Loss:2.0161352157592773, Valid_ACC:0.37179994583129883
Epoch 686, CIFAR-10 Batch 1:  Train_Loss:0.9510645866394043, Valid_Loss:2.01076602935791, Valid_ACC:0.3741999864578247
Epoch 687, CIFAR-10 Batch 1:  Train_Loss:0.9457278847694397, Valid_Loss:2.0015556812286377, Valid_ACC:0.37359997630119324
Epoch 688, CIFAR-10 Batch 1:  Train_Loss:0.9495779871940613, Valid_Loss:2.0111448764801025, Valid_ACC:0.373199999332428
Epoch 689, CIFAR-10 Batch 1:  Train_Loss:0.9650998115539551, Valid_Loss:2.0426101684570312, Valid_ACC:0.37379997968673706
Epoch 690, CIFAR-10 Batch 1:  Train_Loss:0.9445455074310303, Valid_Loss:2.0114049911499023, Valid_ACC:0.37720000743865967
Epoch 691, CIFAR-10 Batch 1:  Train_Loss:0.9504662156105042, Valid_Loss:2.0217936038970947, Valid_ACC:0.3757999837398529
Epoch 692, CIFAR-10 Batch 1:  Train_Loss:0.9752326011657715, Valid_Loss:2.0346856117248535, Valid_ACC:0.36900001764297485
Epoch 693, CIFAR-10 Batch 1:  Train_Loss:0.9729432463645935, Valid_Loss:2.0356380939483643, Valid_ACC:0.3657999634742737
Epoch 694, CIFAR-10 Batch 1:  Train_Loss:0.950078547000885, Valid_Loss:2.02786922454834, Valid_ACC:0.3715999722480774
Epoch 695, CIFAR-10 Batch 1:  Train_Loss:0.96364825963974, Valid_Loss:2.0145504474639893, Valid_ACC:0.3787999749183655
Epoch 696, CIFAR-10 Batch 1:  Train_Loss:0.9619890451431274, Valid_Loss:2.017181873321533, Valid_ACC:0.37379997968673706
Epoch 697, CIFAR-10 Batch 1:  Train_Loss:0.9551288485527039, Valid_Loss:2.0168654918670654, Valid_ACC:0.36959996819496155
Epoch 698, CIFAR-10 Batch 1:  Train_Loss:0.9482285976409912, Valid_Loss:2.014052391052246, Valid_ACC:0.37299999594688416
Epoch 699, CIFAR-10 Batch 1:  Train_Loss:0.959883987903595, Valid_Loss:2.009251594543457, Valid_ACC:0.375
Epoch 700, CIFAR-10 Batch 1:  Train_Loss:0.9456098079681396, Valid_Loss:2.0012593269348145, Valid_ACC:0.37279999256134033
Epoch 701, CIFAR-10 Batch 1:  Train_Loss:0.9394239783287048, Valid_Loss:2.002617597579956, Valid_ACC:0.37059998512268066
Epoch 702, CIFAR-10 Batch 1:  Train_Loss:0.9415612816810608, Valid_Loss:1.9941675662994385, Valid_ACC:0.37860000133514404
Epoch 703, CIFAR-10 Batch 1:  Train_Loss:0.936866283416748, Valid_Loss:2.0024611949920654, Valid_ACC:0.3779999613761902
Epoch 704, CIFAR-10 Batch 1:  Train_Loss:0.9433904886245728, Valid_Loss:2.0007550716400146, Valid_ACC:0.37279999256134033
Epoch 705, CIFAR-10 Batch 1:  Train_Loss:0.9462461471557617, Valid_Loss:2.0063765048980713, Valid_ACC:0.3747999668121338
Epoch 706, CIFAR-10 Batch 1:  Train_Loss:0.9326663613319397, Valid_Loss:1.9968092441558838, Valid_ACC:0.3773999810218811
Epoch 707, CIFAR-10 Batch 1:  Train_Loss:0.9319701194763184, Valid_Loss:1.9888936281204224, Valid_ACC:0.3779999911785126
Epoch 708, CIFAR-10 Batch 1:  Train_Loss:0.9281067252159119, Valid_Loss:2.0090534687042236, Valid_ACC:0.3787999749183655
Epoch 709, CIFAR-10 Batch 1:  Train_Loss:0.9281026721000671, Valid_Loss:1.9859368801116943, Valid_ACC:0.38100001215934753
Epoch 710, CIFAR-10 Batch 1:  Train_Loss:0.9264419078826904, Valid_Loss:2.0058488845825195, Valid_ACC:0.3821999728679657
Epoch 711, CIFAR-10 Batch 1:  Train_Loss:0.9307830929756165, Valid_Loss:2.0000226497650146, Valid_ACC:0.38179996609687805
Epoch 712, CIFAR-10 Batch 1:  Train_Loss:0.9292396306991577, Valid_Loss:1.9993810653686523, Valid_ACC:0.3791999816894531
Epoch 713, CIFAR-10 Batch 1:  Train_Loss:0.9219354391098022, Valid_Loss:1.9886225461959839, Valid_ACC:0.3823999762535095
Epoch 714, CIFAR-10 Batch 1:  Train_Loss:0.9241287112236023, Valid_Loss:2.0094194412231445, Valid_ACC:0.3811999559402466
Epoch 715, CIFAR-10 Batch 1:  Train_Loss:0.9226714968681335, Valid_Loss:2.0120763778686523, Valid_ACC:0.3771999776363373
Epoch 716, CIFAR-10 Batch 1:  Train_Loss:0.9236922860145569, Valid_Loss:2.0117828845977783, Valid_ACC:0.37519997358322144
Epoch 717, CIFAR-10 Batch 1:  Train_Loss:0.9250757694244385, Valid_Loss:2.031827926635742, Valid_ACC:0.38439998030662537
Epoch 718, CIFAR-10 Batch 1:  Train_Loss:0.9274289608001709, Valid_Loss:2.002037525177002, Valid_ACC:0.3779999613761902
Epoch 719, CIFAR-10 Batch 1:  Train_Loss:0.9272796511650085, Valid_Loss:2.016179323196411, Valid_ACC:0.3749999701976776
Epoch 720, CIFAR-10 Batch 1:  Train_Loss:0.9209583401679993, Valid_Loss:2.004981517791748, Valid_ACC:0.3813999891281128
Epoch 721, CIFAR-10 Batch 1:  Train_Loss:0.9235399961471558, Valid_Loss:2.0195164680480957, Valid_ACC:0.3773999810218811
Epoch 722, CIFAR-10 Batch 1:  Train_Loss:0.9206881523132324, Valid_Loss:2.025800943374634, Valid_ACC:0.3779999911785126
Epoch 723, CIFAR-10 Batch 1:  Train_Loss:0.9195507764816284, Valid_Loss:1.9980623722076416, Valid_ACC:0.3819999694824219
Epoch 724, CIFAR-10 Batch 1:  Train_Loss:0.9159154891967773, Valid_Loss:2.0134449005126953, Valid_ACC:0.38099998235702515
Epoch 725, CIFAR-10 Batch 1:  Train_Loss:0.9191222786903381, Valid_Loss:2.0174543857574463, Valid_ACC:0.3803999722003937
Epoch 726, CIFAR-10 Batch 1:  Train_Loss:0.9188750982284546, Valid_Loss:2.0163607597351074, Valid_ACC:0.37439998984336853
Epoch 727, CIFAR-10 Batch 1:  Train_Loss:0.9200908541679382, Valid_Loss:2.0130622386932373, Valid_ACC:0.3760000169277191
Epoch 728, CIFAR-10 Batch 1:  Train_Loss:0.9236905574798584, Valid_Loss:2.016054630279541, Valid_ACC:0.3806000053882599
Epoch 729, CIFAR-10 Batch 1:  Train_Loss:0.9236156940460205, Valid_Loss:2.028139352798462, Valid_ACC:0.37279999256134033
Epoch 730, CIFAR-10 Batch 1:  Train_Loss:0.9215859174728394, Valid_Loss:2.0164263248443604, Valid_ACC:0.37379997968673706
Epoch 731, CIFAR-10 Batch 1:  Train_Loss:0.9191502332687378, Valid_Loss:2.0369086265563965, Valid_ACC:0.37779998779296875
Epoch 732, CIFAR-10 Batch 1:  Train_Loss:0.9152984619140625, Valid_Loss:2.019519329071045, Valid_ACC:0.37839996814727783
Epoch 733, CIFAR-10 Batch 1:  Train_Loss:0.9141866564750671, Valid_Loss:2.007957935333252, Valid_ACC:0.3765999972820282
Epoch 734, CIFAR-10 Batch 1:  Train_Loss:0.9198553562164307, Valid_Loss:2.0277159214019775, Valid_ACC:0.37939995527267456
Epoch 735, CIFAR-10 Batch 1:  Train_Loss:0.9178664088249207, Valid_Loss:2.026582717895508, Valid_ACC:0.3755999803543091
Epoch 736, CIFAR-10 Batch 1:  Train_Loss:0.9171563386917114, Valid_Loss:2.0143399238586426, Valid_ACC:0.37619996070861816
Epoch 737, CIFAR-10 Batch 1:  Train_Loss:0.9161133170127869, Valid_Loss:2.0291216373443604, Valid_ACC:0.37999996542930603
Epoch 738, CIFAR-10 Batch 1:  Train_Loss:0.9188432693481445, Valid_Loss:2.010972261428833, Valid_ACC:0.376399964094162
Epoch 739, CIFAR-10 Batch 1:  Train_Loss:0.9162741303443909, Valid_Loss:2.0541138648986816, Valid_ACC:0.37679994106292725
Epoch 740, CIFAR-10 Batch 1:  Train_Loss:0.9165751934051514, Valid_Loss:2.0267186164855957, Valid_ACC:0.3763999938964844
Epoch 741, CIFAR-10 Batch 1:  Train_Loss:0.9179991483688354, Valid_Loss:2.0260186195373535, Valid_ACC:0.3805999755859375
Epoch 742, CIFAR-10 Batch 1:  Train_Loss:0.9144467711448669, Valid_Loss:2.0319180488586426, Valid_ACC:0.37699997425079346
Epoch 743, CIFAR-10 Batch 1:  Train_Loss:0.9088741540908813, Valid_Loss:2.030452251434326, Valid_ACC:0.3771999776363373
Epoch 744, CIFAR-10 Batch 1:  Train_Loss:0.9123042821884155, Valid_Loss:2.0347299575805664, Valid_ACC:0.3771999776363373
Epoch 745, CIFAR-10 Batch 1:  Train_Loss:0.9151417016983032, Valid_Loss:2.0318150520324707, Valid_ACC:0.37620002031326294
Epoch 746, CIFAR-10 Batch 1:  Train_Loss:0.9169334173202515, Valid_Loss:2.0382633209228516, Valid_ACC:0.37199997901916504
Epoch 747, CIFAR-10 Batch 1:  Train_Loss:0.9121940732002258, Valid_Loss:2.0358710289001465, Valid_ACC:0.3725999891757965
Epoch 748, CIFAR-10 Batch 1:  Train_Loss:0.9115918874740601, Valid_Loss:2.0300910472869873, Valid_ACC:0.37700000405311584
Epoch 749, CIFAR-10 Batch 1:  Train_Loss:0.9129268527030945, Valid_Loss:2.0466175079345703, Valid_ACC:0.37359997630119324
Epoch 750, CIFAR-10 Batch 1:  Train_Loss:0.9117152690887451, Valid_Loss:2.0413777828216553, Valid_ACC:0.3757999539375305
Epoch 751, CIFAR-10 Batch 1:  Train_Loss:0.9132215976715088, Valid_Loss:2.024859666824341, Valid_ACC:0.3747999668121338
Epoch 752, CIFAR-10 Batch 1:  Train_Loss:0.9153180718421936, Valid_Loss:2.029794216156006, Valid_ACC:0.37619999051094055
Epoch 753, CIFAR-10 Batch 1:  Train_Loss:0.9103667736053467, Valid_Loss:2.040808916091919, Valid_ACC:0.376399964094162
Epoch 754, CIFAR-10 Batch 1:  Train_Loss:0.9060155153274536, Valid_Loss:2.028477668762207, Valid_ACC:0.3773999810218811
Epoch 755, CIFAR-10 Batch 1:  Train_Loss:0.9139917492866516, Valid_Loss:2.036632776260376, Valid_ACC:0.3755999803543091
Epoch 756, CIFAR-10 Batch 1:  Train_Loss:0.9130527377128601, Valid_Loss:2.0356626510620117, Valid_ACC:0.3763999938964844
Epoch 757, CIFAR-10 Batch 1:  Train_Loss:0.9171025156974792, Valid_Loss:2.0213184356689453, Valid_ACC:0.37839996814727783
Epoch 758, CIFAR-10 Batch 1:  Train_Loss:0.9145320057868958, Valid_Loss:2.0270848274230957, Valid_ACC:0.3803999722003937
Epoch 759, CIFAR-10 Batch 1:  Train_Loss:0.9079442024230957, Valid_Loss:2.019730567932129, Valid_ACC:0.3831999599933624
Epoch 760, CIFAR-10 Batch 1:  Train_Loss:0.904930591583252, Valid_Loss:2.0149879455566406, Valid_ACC:0.37860000133514404
Epoch 761, CIFAR-10 Batch 1:  Train_Loss:0.9056509733200073, Valid_Loss:2.0314998626708984, Valid_ACC:0.3799999952316284
Epoch 762, CIFAR-10 Batch 1:  Train_Loss:0.9042692184448242, Valid_Loss:2.017012119293213, Valid_ACC:0.3827999532222748
Epoch 763, CIFAR-10 Batch 1:  Train_Loss:0.9032665491104126, Valid_Loss:2.025001287460327, Valid_ACC:0.38019999861717224
Epoch 764, CIFAR-10 Batch 1:  Train_Loss:0.9029989838600159, Valid_Loss:2.029604911804199, Valid_ACC:0.3787999749183655
Epoch 765, CIFAR-10 Batch 1:  Train_Loss:0.9038839936256409, Valid_Loss:2.031794786453247, Valid_ACC:0.3837999701499939
Epoch 766, CIFAR-10 Batch 1:  Train_Loss:0.899928092956543, Valid_Loss:2.0274436473846436, Valid_ACC:0.37959998846054077
Epoch 767, CIFAR-10 Batch 1:  Train_Loss:0.9009380340576172, Valid_Loss:2.0479073524475098, Valid_ACC:0.3775999844074249
Epoch 768, CIFAR-10 Batch 1:  Train_Loss:0.8992506265640259, Valid_Loss:2.0259175300598145, Valid_ACC:0.38199999928474426
Epoch 769, CIFAR-10 Batch 1:  Train_Loss:0.8959729671478271, Valid_Loss:2.039947748184204, Valid_ACC:0.3789999783039093
Epoch 770, CIFAR-10 Batch 1:  Train_Loss:0.8970853090286255, Valid_Loss:2.041818380355835, Valid_ACC:0.37459999322891235
Epoch 771, CIFAR-10 Batch 1:  Train_Loss:0.9003967046737671, Valid_Loss:2.0245463848114014, Valid_ACC:0.3823999762535095
Epoch 772, CIFAR-10 Batch 1:  Train_Loss:0.897409200668335, Valid_Loss:2.0274617671966553, Valid_ACC:0.38119998574256897
Epoch 773, CIFAR-10 Batch 1:  Train_Loss:0.8987337350845337, Valid_Loss:2.042642593383789, Valid_ACC:0.3795999586582184
Epoch 774, CIFAR-10 Batch 1:  Train_Loss:0.9014290571212769, Valid_Loss:2.031465530395508, Valid_ACC:0.37959998846054077
Epoch 775, CIFAR-10 Batch 1:  Train_Loss:0.8993595838546753, Valid_Loss:2.0420336723327637, Valid_ACC:0.3755999803543091
Epoch 776, CIFAR-10 Batch 1:  Train_Loss:0.8990013599395752, Valid_Loss:2.029733180999756, Valid_ACC:0.37959998846054077
Epoch 777, CIFAR-10 Batch 1:  Train_Loss:0.8974685072898865, Valid_Loss:2.041444778442383, Valid_ACC:0.37959998846054077
Epoch 778, CIFAR-10 Batch 1:  Train_Loss:0.8961519002914429, Valid_Loss:2.03924822807312, Valid_ACC:0.3781999945640564
Epoch 779, CIFAR-10 Batch 1:  Train_Loss:0.8970155119895935, Valid_Loss:2.0412425994873047, Valid_ACC:0.3789999783039093
Epoch 780, CIFAR-10 Batch 1:  Train_Loss:0.8996903300285339, Valid_Loss:2.029053211212158, Valid_ACC:0.3783999979496002
Epoch 781, CIFAR-10 Batch 1:  Train_Loss:0.8921465873718262, Valid_Loss:2.0516674518585205, Valid_ACC:0.38259994983673096
Epoch 782, CIFAR-10 Batch 1:  Train_Loss:0.8921234607696533, Valid_Loss:2.048184871673584, Valid_ACC:0.37459999322891235
Epoch 783, CIFAR-10 Batch 1:  Train_Loss:0.891757607460022, Valid_Loss:2.044511318206787, Valid_ACC:0.37439998984336853
Epoch 784, CIFAR-10 Batch 1:  Train_Loss:0.8957312703132629, Valid_Loss:2.0359272956848145, Valid_ACC:0.38259994983673096
Epoch 785, CIFAR-10 Batch 1:  Train_Loss:0.894676923751831, Valid_Loss:2.0340819358825684, Valid_ACC:0.37779998779296875
Epoch 786, CIFAR-10 Batch 1:  Train_Loss:0.8954577445983887, Valid_Loss:2.0291879177093506, Valid_ACC:0.37720000743865967
Epoch 787, CIFAR-10 Batch 1:  Train_Loss:0.894131064414978, Valid_Loss:2.052093505859375, Valid_ACC:0.37699997425079346
Epoch 788, CIFAR-10 Batch 1:  Train_Loss:0.8935745358467102, Valid_Loss:2.042849540710449, Valid_ACC:0.37519997358322144
Epoch 789, CIFAR-10 Batch 1:  Train_Loss:0.8905921578407288, Valid_Loss:2.0308585166931152, Valid_ACC:0.37939995527267456
Epoch 790, CIFAR-10 Batch 1:  Train_Loss:0.8955225944519043, Valid_Loss:2.047553539276123, Valid_ACC:0.37519997358322144
Epoch 791, CIFAR-10 Batch 1:  Train_Loss:0.8935071229934692, Valid_Loss:2.0390782356262207, Valid_ACC:0.3807999789714813
Epoch 792, CIFAR-10 Batch 1:  Train_Loss:0.8909837007522583, Valid_Loss:2.0460853576660156, Valid_ACC:0.37939998507499695
Epoch 793, CIFAR-10 Batch 1:  Train_Loss:0.892753005027771, Valid_Loss:2.03570556640625, Valid_ACC:0.37839996814727783
Epoch 794, CIFAR-10 Batch 1:  Train_Loss:0.8934815526008606, Valid_Loss:2.072953939437866, Valid_ACC:0.37300002574920654
Epoch 795, CIFAR-10 Batch 1:  Train_Loss:0.8929958343505859, Valid_Loss:2.044976234436035, Valid_ACC:0.37459999322891235
Epoch 796, CIFAR-10 Batch 1:  Train_Loss:0.8946166634559631, Valid_Loss:2.0607330799102783, Valid_ACC:0.3739999532699585
Epoch 797, CIFAR-10 Batch 1:  Train_Loss:0.8932200074195862, Valid_Loss:2.060291051864624, Valid_ACC:0.3781999945640564
Epoch 798, CIFAR-10 Batch 1:  Train_Loss:0.8925313949584961, Valid_Loss:2.0571022033691406, Valid_ACC:0.3734000027179718
Epoch 799, CIFAR-10 Batch 1:  Train_Loss:0.896141767501831, Valid_Loss:2.052673101425171, Valid_ACC:0.3775999844074249
Epoch 800, CIFAR-10 Batch 1:  Train_Loss:0.9004528522491455, Valid_Loss:2.077244520187378, Valid_ACC:0.3705999553203583
Epoch 801, CIFAR-10 Batch 1:  Train_Loss:0.8901710510253906, Valid_Loss:2.061861276626587, Valid_ACC:0.3791999816894531
Epoch 802, CIFAR-10 Batch 1:  Train_Loss:0.8939781785011292, Valid_Loss:2.0633223056793213, Valid_ACC:0.37539997696876526
Epoch 803, CIFAR-10 Batch 1:  Train_Loss:0.8940215110778809, Valid_Loss:2.043065071105957, Valid_ACC:0.37779995799064636
Epoch 804, CIFAR-10 Batch 1:  Train_Loss:0.8878895044326782, Valid_Loss:2.0420236587524414, Valid_ACC:0.3765999674797058
Epoch 805, CIFAR-10 Batch 1:  Train_Loss:0.8884785771369934, Valid_Loss:2.0571718215942383, Valid_ACC:0.37839996814727783
Epoch 806, CIFAR-10 Batch 1:  Train_Loss:0.8963100910186768, Valid_Loss:2.0632576942443848, Valid_ACC:0.3781999945640564
Epoch 807, CIFAR-10 Batch 1:  Train_Loss:0.9005074501037598, Valid_Loss:2.052197217941284, Valid_ACC:0.370199978351593
Epoch 808, CIFAR-10 Batch 1:  Train_Loss:0.8939793109893799, Valid_Loss:2.063845157623291, Valid_ACC:0.37459996342658997
Epoch 809, CIFAR-10 Batch 1:  Train_Loss:0.8934386968612671, Valid_Loss:2.071449041366577, Valid_ACC:0.3747999966144562
Epoch 810, CIFAR-10 Batch 1:  Train_Loss:0.8889468908309937, Valid_Loss:2.0542759895324707, Valid_ACC:0.37439998984336853
Epoch 811, CIFAR-10 Batch 1:  Train_Loss:0.8976327180862427, Valid_Loss:2.0706279277801514, Valid_ACC:0.37219998240470886
Epoch 812, CIFAR-10 Batch 1:  Train_Loss:0.8954535126686096, Valid_Loss:2.0763707160949707, Valid_ACC:0.37959998846054077
Epoch 813, CIFAR-10 Batch 1:  Train_Loss:0.899694561958313, Valid_Loss:2.0639076232910156, Valid_ACC:0.3749999403953552
Epoch 814, CIFAR-10 Batch 1:  Train_Loss:0.8890777230262756, Valid_Loss:2.086826801300049, Valid_ACC:0.3739999830722809
Epoch 815, CIFAR-10 Batch 1:  Train_Loss:0.8877366781234741, Valid_Loss:2.056755542755127, Valid_ACC:0.3736000061035156
Epoch 816, CIFAR-10 Batch 1:  Train_Loss:0.8898057341575623, Valid_Loss:2.0570530891418457, Valid_ACC:0.37539994716644287
Epoch 817, CIFAR-10 Batch 1:  Train_Loss:0.8936522006988525, Valid_Loss:2.059885263442993, Valid_ACC:0.3771999776363373
Epoch 818, CIFAR-10 Batch 1:  Train_Loss:0.901242733001709, Valid_Loss:2.057933807373047, Valid_ACC:0.3776000142097473
Epoch 819, CIFAR-10 Batch 1:  Train_Loss:0.8920727968215942, Valid_Loss:2.0387895107269287, Valid_ACC:0.37599998712539673
Epoch 820, CIFAR-10 Batch 1:  Train_Loss:0.8988932371139526, Valid_Loss:2.0751395225524902, Valid_ACC:0.3724000155925751
Epoch 821, CIFAR-10 Batch 1:  Train_Loss:0.8884888887405396, Valid_Loss:2.080078601837158, Valid_ACC:0.3776000142097473
Epoch 822, CIFAR-10 Batch 1:  Train_Loss:0.8911734819412231, Valid_Loss:2.063810348510742, Valid_ACC:0.3783999979496002
Epoch 823, CIFAR-10 Batch 1:  Train_Loss:0.8903379440307617, Valid_Loss:2.067286968231201, Valid_ACC:0.37599995732307434
Epoch 824, CIFAR-10 Batch 1:  Train_Loss:0.8917522430419922, Valid_Loss:2.0572266578674316, Valid_ACC:0.3765999674797058
Epoch 825, CIFAR-10 Batch 1:  Train_Loss:0.8934518098831177, Valid_Loss:2.064072608947754, Valid_ACC:0.38259997963905334
Epoch 826, CIFAR-10 Batch 1:  Train_Loss:0.8896938562393188, Valid_Loss:2.055556297302246, Valid_ACC:0.3765999972820282
Epoch 827, CIFAR-10 Batch 1:  Train_Loss:0.8807738423347473, Valid_Loss:2.050579309463501, Valid_ACC:0.37599998712539673
Epoch 828, CIFAR-10 Batch 1:  Train_Loss:0.8839592337608337, Valid_Loss:2.0494818687438965, Valid_ACC:0.38019999861717224
Epoch 829, CIFAR-10 Batch 1:  Train_Loss:0.88321453332901, Valid_Loss:2.079557418823242, Valid_ACC:0.3823999762535095
Epoch 830, CIFAR-10 Batch 1:  Train_Loss:0.8848593831062317, Valid_Loss:2.0431928634643555, Valid_ACC:0.37379997968673706
Epoch 831, CIFAR-10 Batch 1:  Train_Loss:0.8840924501419067, Valid_Loss:2.049593448638916, Valid_ACC:0.38259997963905334
Epoch 832, CIFAR-10 Batch 1:  Train_Loss:0.8838589191436768, Valid_Loss:2.0502185821533203, Valid_ACC:0.375
Epoch 833, CIFAR-10 Batch 1:  Train_Loss:0.87574303150177, Valid_Loss:2.0668411254882812, Valid_ACC:0.3821999728679657
Epoch 834, CIFAR-10 Batch 1:  Train_Loss:0.882466197013855, Valid_Loss:2.051623821258545, Valid_ACC:0.37279999256134033
Epoch 835, CIFAR-10 Batch 1:  Train_Loss:0.8777081966400146, Valid_Loss:2.063584089279175, Valid_ACC:0.37940001487731934
Epoch 836, CIFAR-10 Batch 1:  Train_Loss:0.8790827393531799, Valid_Loss:2.0515708923339844, Valid_ACC:0.3822000026702881
Epoch 837, CIFAR-10 Batch 1:  Train_Loss:0.8788851499557495, Valid_Loss:2.0680532455444336, Valid_ACC:0.376399964094162
Epoch 838, CIFAR-10 Batch 1:  Train_Loss:0.8735535144805908, Valid_Loss:2.05177903175354, Valid_ACC:0.37839996814727783
Epoch 839, CIFAR-10 Batch 1:  Train_Loss:0.8749958276748657, Valid_Loss:2.0793371200561523, Valid_ACC:0.37699997425079346
Epoch 840, CIFAR-10 Batch 1:  Train_Loss:0.8734986782073975, Valid_Loss:2.0649452209472656, Valid_ACC:0.3811999559402466
Epoch 841, CIFAR-10 Batch 1:  Train_Loss:0.876672625541687, Valid_Loss:2.058123826980591, Valid_ACC:0.37779995799064636
Epoch 842, CIFAR-10 Batch 1:  Train_Loss:0.8721421360969543, Valid_Loss:2.064906358718872, Valid_ACC:0.37599998712539673
Epoch 843, CIFAR-10 Batch 1:  Train_Loss:0.8749622106552124, Valid_Loss:2.0722386837005615, Valid_ACC:0.37220001220703125
Epoch 844, CIFAR-10 Batch 1:  Train_Loss:0.8715251684188843, Valid_Loss:2.0688858032226562, Valid_ACC:0.37699997425079346
Epoch 845, CIFAR-10 Batch 1:  Train_Loss:0.8720802664756775, Valid_Loss:2.062253952026367, Valid_ACC:0.376800000667572
Epoch 846, CIFAR-10 Batch 1:  Train_Loss:0.8757243752479553, Valid_Loss:2.057616949081421, Valid_ACC:0.38260000944137573
Epoch 847, CIFAR-10 Batch 1:  Train_Loss:0.8804589509963989, Valid_Loss:2.0776729583740234, Valid_ACC:0.3736000061035156
Epoch 848, CIFAR-10 Batch 1:  Train_Loss:0.8683637380599976, Valid_Loss:2.0810070037841797, Valid_ACC:0.3771999776363373
Epoch 849, CIFAR-10 Batch 1:  Train_Loss:0.8685950636863708, Valid_Loss:2.079341411590576, Valid_ACC:0.3757999837398529
Epoch 850, CIFAR-10 Batch 1:  Train_Loss:0.8733609914779663, Valid_Loss:2.070035934448242, Valid_ACC:0.37599998712539673
Epoch 851, CIFAR-10 Batch 1:  Train_Loss:0.8753975033760071, Valid_Loss:2.065791368484497, Valid_ACC:0.37699994444847107
Epoch 852, CIFAR-10 Batch 1:  Train_Loss:0.8715649843215942, Valid_Loss:2.0678515434265137, Valid_ACC:0.3747999668121338
Epoch 853, CIFAR-10 Batch 1:  Train_Loss:0.8776772022247314, Valid_Loss:2.078178882598877, Valid_ACC:0.3773999810218811
Epoch 854, CIFAR-10 Batch 1:  Train_Loss:0.8758599162101746, Valid_Loss:2.0664029121398926, Valid_ACC:0.37400001287460327
Epoch 855, CIFAR-10 Batch 1:  Train_Loss:0.8740549683570862, Valid_Loss:2.054837226867676, Valid_ACC:0.3787999749183655
Epoch 856, CIFAR-10 Batch 1:  Train_Loss:0.8702975511550903, Valid_Loss:2.0899009704589844, Valid_ACC:0.37379997968673706
Epoch 857, CIFAR-10 Batch 1:  Train_Loss:0.8713726997375488, Valid_Loss:2.061479330062866, Valid_ACC:0.37859997153282166
Epoch 858, CIFAR-10 Batch 1:  Train_Loss:0.8695204257965088, Valid_Loss:2.064005136489868, Valid_ACC:0.3779999911785126
Epoch 859, CIFAR-10 Batch 1:  Train_Loss:0.8739629983901978, Valid_Loss:2.0490686893463135, Valid_ACC:0.3791999816894531
Epoch 860, CIFAR-10 Batch 1:  Train_Loss:0.8800472617149353, Valid_Loss:2.109950542449951, Valid_ACC:0.36879998445510864
Epoch 861, CIFAR-10 Batch 1:  Train_Loss:0.8803053498268127, Valid_Loss:2.0535435676574707, Valid_ACC:0.37619996070861816
Epoch 862, CIFAR-10 Batch 1:  Train_Loss:0.8741656541824341, Valid_Loss:2.087462902069092, Valid_ACC:0.37040001153945923
Epoch 863, CIFAR-10 Batch 1:  Train_Loss:0.8765259385108948, Valid_Loss:2.0616116523742676, Valid_ACC:0.375
Epoch 864, CIFAR-10 Batch 1:  Train_Loss:0.8712411522865295, Valid_Loss:2.077751398086548, Valid_ACC:0.37400001287460327
Epoch 865, CIFAR-10 Batch 1:  Train_Loss:0.8726365566253662, Valid_Loss:2.0771331787109375, Valid_ACC:0.3693999648094177
Epoch 866, CIFAR-10 Batch 1:  Train_Loss:0.8701454401016235, Valid_Loss:2.0664150714874268, Valid_ACC:0.38019999861717224
Epoch 867, CIFAR-10 Batch 1:  Train_Loss:0.8737858533859253, Valid_Loss:2.0778045654296875, Valid_ACC:0.3707999885082245
Epoch 868, CIFAR-10 Batch 1:  Train_Loss:0.8673796653747559, Valid_Loss:2.072073459625244, Valid_ACC:0.37619996070861816
Epoch 869, CIFAR-10 Batch 1:  Train_Loss:0.8691014051437378, Valid_Loss:2.082855224609375, Valid_ACC:0.3795999586582184
Epoch 870, CIFAR-10 Batch 1:  Train_Loss:0.8679122924804688, Valid_Loss:2.070828676223755, Valid_ACC:0.3747999966144562
Epoch 871, CIFAR-10 Batch 1:  Train_Loss:0.8682608604431152, Valid_Loss:2.088634490966797, Valid_ACC:0.37839996814727783
Epoch 872, CIFAR-10 Batch 1:  Train_Loss:0.8734312057495117, Valid_Loss:2.0628414154052734, Valid_ACC:0.3779999613761902
Epoch 873, CIFAR-10 Batch 1:  Train_Loss:0.8666058778762817, Valid_Loss:2.090792179107666, Valid_ACC:0.38019996881484985
Epoch 874, CIFAR-10 Batch 1:  Train_Loss:0.8704423904418945, Valid_Loss:2.0769615173339844, Valid_ACC:0.37959998846054077
Epoch 875, CIFAR-10 Batch 1:  Train_Loss:0.874272882938385, Valid_Loss:2.0713822841644287, Valid_ACC:0.37859997153282166
Epoch 876, CIFAR-10 Batch 1:  Train_Loss:0.8706059455871582, Valid_Loss:2.0716207027435303, Valid_ACC:0.38179996609687805
Epoch 877, CIFAR-10 Batch 1:  Train_Loss:0.8644753694534302, Valid_Loss:2.071697235107422, Valid_ACC:0.3795999586582184
Epoch 878, CIFAR-10 Batch 1:  Train_Loss:0.8701364994049072, Valid_Loss:2.0743465423583984, Valid_ACC:0.38040000200271606
Epoch 879, CIFAR-10 Batch 1:  Train_Loss:0.8703755736351013, Valid_Loss:2.0560407638549805, Valid_ACC:0.38179996609687805
Epoch 880, CIFAR-10 Batch 1:  Train_Loss:0.8683347702026367, Valid_Loss:2.0355024337768555, Valid_ACC:0.37699997425079346
Epoch 881, CIFAR-10 Batch 1:  Train_Loss:0.8652447462081909, Valid_Loss:2.0829854011535645, Valid_ACC:0.3815999925136566
Epoch 882, CIFAR-10 Batch 1:  Train_Loss:0.8708615303039551, Valid_Loss:2.0728535652160645, Valid_ACC:0.3791999816894531
Epoch 883, CIFAR-10 Batch 1:  Train_Loss:0.8719345331192017, Valid_Loss:2.0840954780578613, Valid_ACC:0.3787999749183655
Epoch 884, CIFAR-10 Batch 1:  Train_Loss:0.8665722608566284, Valid_Loss:2.0849249362945557, Valid_ACC:0.38159996271133423
Epoch 885, CIFAR-10 Batch 1:  Train_Loss:0.8665322065353394, Valid_Loss:2.0719237327575684, Valid_ACC:0.3783999979496002
Epoch 886, CIFAR-10 Batch 1:  Train_Loss:0.8677012324333191, Valid_Loss:2.073031187057495, Valid_ACC:0.379800021648407
Epoch 887, CIFAR-10 Batch 1:  Train_Loss:0.8659496307373047, Valid_Loss:2.0716261863708496, Valid_ACC:0.3797999918460846
Epoch 888, CIFAR-10 Batch 1:  Train_Loss:0.8698230981826782, Valid_Loss:2.07650089263916, Valid_ACC:0.373199999332428
Epoch 889, CIFAR-10 Batch 1:  Train_Loss:0.8718123435974121, Valid_Loss:2.07088303565979, Valid_ACC:0.38019999861717224
Epoch 890, CIFAR-10 Batch 1:  Train_Loss:0.8609991669654846, Valid_Loss:2.090367317199707, Valid_ACC:0.3789999783039093
Epoch 891, CIFAR-10 Batch 1:  Train_Loss:0.8630509376525879, Valid_Loss:2.1046090126037598, Valid_ACC:0.3757999539375305
Epoch 892, CIFAR-10 Batch 1:  Train_Loss:0.8606171607971191, Valid_Loss:2.0740044116973877, Valid_ACC:0.3811999559402466
Epoch 893, CIFAR-10 Batch 1:  Train_Loss:0.8617499470710754, Valid_Loss:2.087233543395996, Valid_ACC:0.38420000672340393
Epoch 894, CIFAR-10 Batch 1:  Train_Loss:0.8661083579063416, Valid_Loss:2.095025062561035, Valid_ACC:0.37519997358322144
Epoch 895, CIFAR-10 Batch 1:  Train_Loss:0.8664731979370117, Valid_Loss:2.083369731903076, Valid_ACC:0.3734000027179718
Epoch 896, CIFAR-10 Batch 1:  Train_Loss:0.8643870949745178, Valid_Loss:2.1162667274475098, Valid_ACC:0.37220001220703125
Epoch 897, CIFAR-10 Batch 1:  Train_Loss:0.8635351061820984, Valid_Loss:2.0904970169067383, Valid_ACC:0.38100001215934753
Epoch 898, CIFAR-10 Batch 1:  Train_Loss:0.8631453514099121, Valid_Loss:2.0782101154327393, Valid_ACC:0.3797999620437622
Epoch 899, CIFAR-10 Batch 1:  Train_Loss:0.8613348007202148, Valid_Loss:2.0793819427490234, Valid_ACC:0.38499999046325684
Epoch 900, CIFAR-10 Batch 1:  Train_Loss:0.8663676977157593, Valid_Loss:2.099494695663452, Valid_ACC:0.3739999830722809
Epoch 901, CIFAR-10 Batch 1:  Train_Loss:0.8665100336074829, Valid_Loss:2.0800936222076416, Valid_ACC:0.37939998507499695
Epoch 902, CIFAR-10 Batch 1:  Train_Loss:0.8679698705673218, Valid_Loss:2.078493356704712, Valid_ACC:0.3771999776363373
Epoch 903, CIFAR-10 Batch 1:  Train_Loss:0.8635666370391846, Valid_Loss:2.0978407859802246, Valid_ACC:0.37519997358322144
Epoch 904, CIFAR-10 Batch 1:  Train_Loss:0.8637182712554932, Valid_Loss:2.0698676109313965, Valid_ACC:0.3824000060558319
Epoch 905, CIFAR-10 Batch 1:  Train_Loss:0.8590942025184631, Valid_Loss:2.0859568119049072, Valid_ACC:0.3783999979496002
Epoch 906, CIFAR-10 Batch 1:  Train_Loss:0.8568550944328308, Valid_Loss:2.074667453765869, Valid_ACC:0.37679997086524963
Epoch 907, CIFAR-10 Batch 1:  Train_Loss:0.8580480813980103, Valid_Loss:2.063864231109619, Valid_ACC:0.37779998779296875
Epoch 908, CIFAR-10 Batch 1:  Train_Loss:0.8633864521980286, Valid_Loss:2.1009879112243652, Valid_ACC:0.37619999051094055
Epoch 909, CIFAR-10 Batch 1:  Train_Loss:0.8661049604415894, Valid_Loss:2.0923166275024414, Valid_ACC:0.3709999918937683
Epoch 910, CIFAR-10 Batch 1:  Train_Loss:0.8614046573638916, Valid_Loss:2.086672067642212, Valid_ACC:0.37959998846054077
Epoch 911, CIFAR-10 Batch 1:  Train_Loss:0.8588201403617859, Valid_Loss:2.0730884075164795, Valid_ACC:0.3806000053882599
Epoch 912, CIFAR-10 Batch 1:  Train_Loss:0.8583254814147949, Valid_Loss:2.0825815200805664, Valid_ACC:0.3765999674797058
Epoch 913, CIFAR-10 Batch 1:  Train_Loss:0.8586700558662415, Valid_Loss:2.0719218254089355, Valid_ACC:0.3747999966144562
Epoch 914, CIFAR-10 Batch 1:  Train_Loss:0.8587354421615601, Valid_Loss:2.095729112625122, Valid_ACC:0.37379997968673706
Epoch 915, CIFAR-10 Batch 1:  Train_Loss:0.8563944697380066, Valid_Loss:2.0859713554382324, Valid_ACC:0.3747999668121338
Epoch 916, CIFAR-10 Batch 1:  Train_Loss:0.855861485004425, Valid_Loss:2.0979976654052734, Valid_ACC:0.37619996070861816
Epoch 917, CIFAR-10 Batch 1:  Train_Loss:0.8582175374031067, Valid_Loss:2.0812246799468994, Valid_ACC:0.38099998235702515
Epoch 918, CIFAR-10 Batch 1:  Train_Loss:0.8636180758476257, Valid_Loss:2.102142810821533, Valid_ACC:0.3755999803543091
Epoch 919, CIFAR-10 Batch 1:  Train_Loss:0.8634281754493713, Valid_Loss:2.0789315700531006, Valid_ACC:0.3822000026702881
Epoch 920, CIFAR-10 Batch 1:  Train_Loss:0.8568563461303711, Valid_Loss:2.093996047973633, Valid_ACC:0.37540000677108765
Epoch 921, CIFAR-10 Batch 1:  Train_Loss:0.8607938885688782, Valid_Loss:2.0791475772857666, Valid_ACC:0.3755999505519867
Epoch 922, CIFAR-10 Batch 1:  Train_Loss:0.8593324422836304, Valid_Loss:2.1086554527282715, Valid_ACC:0.37679997086524963
Epoch 923, CIFAR-10 Batch 1:  Train_Loss:0.8546252846717834, Valid_Loss:2.0985450744628906, Valid_ACC:0.37299999594688416
Epoch 924, CIFAR-10 Batch 1:  Train_Loss:0.8542594909667969, Valid_Loss:2.0983829498291016, Valid_ACC:0.373199999332428
Epoch 925, CIFAR-10 Batch 1:  Train_Loss:0.8563987612724304, Valid_Loss:2.098348617553711, Valid_ACC:0.37439998984336853
Epoch 926, CIFAR-10 Batch 1:  Train_Loss:0.8568150401115417, Valid_Loss:2.0941567420959473, Valid_ACC:0.37999996542930603
Epoch 927, CIFAR-10 Batch 1:  Train_Loss:0.8619332313537598, Valid_Loss:2.0888352394104004, Valid_ACC:0.3747999668121338
Epoch 928, CIFAR-10 Batch 1:  Train_Loss:0.8617706298828125, Valid_Loss:2.1108181476593018, Valid_ACC:0.3681999444961548
Epoch 929, CIFAR-10 Batch 1:  Train_Loss:0.852563738822937, Valid_Loss:2.0991387367248535, Valid_ACC:0.37839996814727783
Epoch 930, CIFAR-10 Batch 1:  Train_Loss:0.8538100123405457, Valid_Loss:2.0791847705841064, Valid_ACC:0.3791999816894531
Epoch 931, CIFAR-10 Batch 1:  Train_Loss:0.8531228303909302, Valid_Loss:2.0926992893218994, Valid_ACC:0.3765999972820282
Epoch 932, CIFAR-10 Batch 1:  Train_Loss:0.85396808385849, Valid_Loss:2.0902657508850098, Valid_ACC:0.3755999803543091
Epoch 933, CIFAR-10 Batch 1:  Train_Loss:0.8585189580917358, Valid_Loss:2.081071376800537, Valid_ACC:0.37699997425079346
Epoch 934, CIFAR-10 Batch 1:  Train_Loss:0.8523783683776855, Valid_Loss:2.104063034057617, Valid_ACC:0.3797999918460846
Epoch 935, CIFAR-10 Batch 1:  Train_Loss:0.8532865643501282, Valid_Loss:2.074775218963623, Valid_ACC:0.3771999776363373
Epoch 936, CIFAR-10 Batch 1:  Train_Loss:0.8548564314842224, Valid_Loss:2.080108165740967, Valid_ACC:0.37859994173049927
Epoch 937, CIFAR-10 Batch 1:  Train_Loss:0.8543187379837036, Valid_Loss:2.100113868713379, Valid_ACC:0.3709999918937683
Epoch 938, CIFAR-10 Batch 1:  Train_Loss:0.8507277965545654, Valid_Loss:2.072334051132202, Valid_ACC:0.3821999728679657
Epoch 939, CIFAR-10 Batch 1:  Train_Loss:0.8507479429244995, Valid_Loss:2.0930585861206055, Valid_ACC:0.37939998507499695
Epoch 940, CIFAR-10 Batch 1:  Train_Loss:0.8504034280776978, Valid_Loss:2.0884556770324707, Valid_ACC:0.38259997963905334
Epoch 941, CIFAR-10 Batch 1:  Train_Loss:0.8514840006828308, Valid_Loss:2.0825414657592773, Valid_ACC:0.3787999749183655
Epoch 942, CIFAR-10 Batch 1:  Train_Loss:0.8500950336456299, Valid_Loss:2.1150856018066406, Valid_ACC:0.38119998574256897
Epoch 943, CIFAR-10 Batch 1:  Train_Loss:0.8515649437904358, Valid_Loss:2.0986289978027344, Valid_ACC:0.375
Epoch 944, CIFAR-10 Batch 1:  Train_Loss:0.848429262638092, Valid_Loss:2.097686529159546, Valid_ACC:0.37999993562698364
Epoch 945, CIFAR-10 Batch 1:  Train_Loss:0.8540310859680176, Valid_Loss:2.0948565006256104, Valid_ACC:0.3805999755859375
Epoch 946, CIFAR-10 Batch 1:  Train_Loss:0.8601443767547607, Valid_Loss:2.0935325622558594, Valid_ACC:0.3708000183105469
Epoch 947, CIFAR-10 Batch 1:  Train_Loss:0.8532071113586426, Valid_Loss:2.101346015930176, Valid_ACC:0.3790000081062317
Epoch 948, CIFAR-10 Batch 1:  Train_Loss:0.8535785675048828, Valid_Loss:2.117736339569092, Valid_ACC:0.3831999897956848
Epoch 949, CIFAR-10 Batch 1:  Train_Loss:0.8529576659202576, Valid_Loss:2.10184383392334, Valid_ACC:0.37939995527267456
Epoch 950, CIFAR-10 Batch 1:  Train_Loss:0.8568310737609863, Valid_Loss:2.1002066135406494, Valid_ACC:0.38279998302459717
Epoch 951, CIFAR-10 Batch 1:  Train_Loss:0.8528480529785156, Valid_Loss:2.1101207733154297, Valid_ACC:0.3763999938964844
Epoch 952, CIFAR-10 Batch 1:  Train_Loss:0.850590705871582, Valid_Loss:2.098527193069458, Valid_ACC:0.38019999861717224
Epoch 953, CIFAR-10 Batch 1:  Train_Loss:0.8510756492614746, Valid_Loss:2.1025285720825195, Valid_ACC:0.38099998235702515
Epoch 954, CIFAR-10 Batch 1:  Train_Loss:0.8515228033065796, Valid_Loss:2.093662977218628, Valid_ACC:0.3749999701976776
Epoch 955, CIFAR-10 Batch 1:  Train_Loss:0.8470646739006042, Valid_Loss:2.1151838302612305, Valid_ACC:0.3783999979496002
Epoch 956, CIFAR-10 Batch 1:  Train_Loss:0.852900505065918, Valid_Loss:2.0803451538085938, Valid_ACC:0.3773999810218811
Epoch 957, CIFAR-10 Batch 1:  Train_Loss:0.8513891100883484, Valid_Loss:2.1004598140716553, Valid_ACC:0.3789999783039093
Epoch 958, CIFAR-10 Batch 1:  Train_Loss:0.8514536619186401, Valid_Loss:2.092334032058716, Valid_ACC:0.3763999938964844
Epoch 959, CIFAR-10 Batch 1:  Train_Loss:0.8531790971755981, Valid_Loss:2.140242099761963, Valid_ACC:0.37199994921684265
Epoch 960, CIFAR-10 Batch 1:  Train_Loss:0.8472186923027039, Valid_Loss:2.113478660583496, Valid_ACC:0.3791999816894531
Epoch 961, CIFAR-10 Batch 1:  Train_Loss:0.8548462986946106, Valid_Loss:2.1088850498199463, Valid_ACC:0.37619999051094055
Epoch 962, CIFAR-10 Batch 1:  Train_Loss:0.8478697538375854, Valid_Loss:2.1100966930389404, Valid_ACC:0.3736000061035156
Epoch 963, CIFAR-10 Batch 1:  Train_Loss:0.8535206913948059, Valid_Loss:2.1163132190704346, Valid_ACC:0.37919995188713074
Epoch 964, CIFAR-10 Batch 1:  Train_Loss:0.859865128993988, Valid_Loss:2.1330270767211914, Valid_ACC:0.3758000135421753
Epoch 965, CIFAR-10 Batch 1:  Train_Loss:0.8619452714920044, Valid_Loss:2.1188249588012695, Valid_ACC:0.373199999332428
Epoch 966, CIFAR-10 Batch 1:  Train_Loss:0.862837553024292, Valid_Loss:2.144937038421631, Valid_ACC:0.37439998984336853
Epoch 967, CIFAR-10 Batch 1:  Train_Loss:0.8587545156478882, Valid_Loss:2.1240010261535645, Valid_ACC:0.37439998984336853
Epoch 968, CIFAR-10 Batch 1:  Train_Loss:0.8582675457000732, Valid_Loss:2.1061604022979736, Valid_ACC:0.37279999256134033
Epoch 969, CIFAR-10 Batch 1:  Train_Loss:0.8619143962860107, Valid_Loss:2.1260948181152344, Valid_ACC:0.37299999594688416
Epoch 970, CIFAR-10 Batch 1:  Train_Loss:0.8608047366142273, Valid_Loss:2.109057664871216, Valid_ACC:0.37119999527931213
Epoch 971, CIFAR-10 Batch 1:  Train_Loss:0.8545998334884644, Valid_Loss:2.1013994216918945, Valid_ACC:0.3739999830722809
Epoch 972, CIFAR-10 Batch 1:  Train_Loss:0.849248468875885, Valid_Loss:2.0941853523254395, Valid_ACC:0.37679997086524963
Epoch 973, CIFAR-10 Batch 1:  Train_Loss:0.8489248752593994, Valid_Loss:2.1044161319732666, Valid_ACC:0.3781999945640564
Epoch 974, CIFAR-10 Batch 1:  Train_Loss:0.8482057452201843, Valid_Loss:2.09531307220459, Valid_ACC:0.3765999972820282
Epoch 975, CIFAR-10 Batch 1:  Train_Loss:0.8452895879745483, Valid_Loss:2.09445858001709, Valid_ACC:0.3771999478340149
Epoch 976, CIFAR-10 Batch 1:  Train_Loss:0.8452377319335938, Valid_Loss:2.099609375, Valid_ACC:0.3757999539375305
Epoch 977, CIFAR-10 Batch 1:  Train_Loss:0.8474835157394409, Valid_Loss:2.108473062515259, Valid_ACC:0.37439998984336853
Epoch 978, CIFAR-10 Batch 1:  Train_Loss:0.8467003107070923, Valid_Loss:2.1147148609161377, Valid_ACC:0.37540000677108765
Epoch 979, CIFAR-10 Batch 1:  Train_Loss:0.8480001091957092, Valid_Loss:2.1254162788391113, Valid_ACC:0.37379997968673706
Epoch 980, CIFAR-10 Batch 1:  Train_Loss:0.8544119596481323, Valid_Loss:2.1198980808258057, Valid_ACC:0.3707999885082245
Epoch 981, CIFAR-10 Batch 1:  Train_Loss:0.852206289768219, Valid_Loss:2.1074349880218506, Valid_ACC:0.3747999668121338
Epoch 982, CIFAR-10 Batch 1:  Train_Loss:0.8473179936408997, Valid_Loss:2.1112747192382812, Valid_ACC:0.3763999938964844
Epoch 983, CIFAR-10 Batch 1:  Train_Loss:0.8492540121078491, Valid_Loss:2.1105339527130127, Valid_ACC:0.3789999783039093
Epoch 984, CIFAR-10 Batch 1:  Train_Loss:0.8454976677894592, Valid_Loss:2.12811541557312, Valid_ACC:0.3755999803543091
Epoch 985, CIFAR-10 Batch 1:  Train_Loss:0.8515530228614807, Valid_Loss:2.1012282371520996, Valid_ACC:0.37219998240470886
Epoch 986, CIFAR-10 Batch 1:  Train_Loss:0.847356379032135, Valid_Loss:2.1117658615112305, Valid_ACC:0.37800002098083496
Epoch 987, CIFAR-10 Batch 1:  Train_Loss:0.8452438712120056, Valid_Loss:2.095750331878662, Valid_ACC:0.3774000108242035
Epoch 988, CIFAR-10 Batch 1:  Train_Loss:0.8483508825302124, Valid_Loss:2.122251510620117, Valid_ACC:0.37300002574920654
Epoch 989, CIFAR-10 Batch 1:  Train_Loss:0.8514211773872375, Valid_Loss:2.1445956230163574, Valid_ACC:0.3707999587059021
Epoch 990, CIFAR-10 Batch 1:  Train_Loss:0.8492727279663086, Valid_Loss:2.0907373428344727, Valid_ACC:0.37439996004104614
Epoch 991, CIFAR-10 Batch 1:  Train_Loss:0.8505231738090515, Valid_Loss:2.1198654174804688, Valid_ACC:0.37119996547698975
Epoch 992, CIFAR-10 Batch 1:  Train_Loss:0.8502232432365417, Valid_Loss:2.0954933166503906, Valid_ACC:0.3755999803543091
Epoch 993, CIFAR-10 Batch 1:  Train_Loss:0.8450801968574524, Valid_Loss:2.1169209480285645, Valid_ACC:0.37779998779296875
Epoch 994, CIFAR-10 Batch 1:  Train_Loss:0.8442087769508362, Valid_Loss:2.077350378036499, Valid_ACC:0.3736000061035156
Epoch 995, CIFAR-10 Batch 1:  Train_Loss:0.8388144373893738, Valid_Loss:2.0993998050689697, Valid_ACC:0.3779999911785126
Epoch 996, CIFAR-10 Batch 1:  Train_Loss:0.842678964138031, Valid_Loss:2.111168146133423, Valid_ACC:0.37459999322891235
Epoch 997, CIFAR-10 Batch 1:  Train_Loss:0.8442729711532593, Valid_Loss:2.0882718563079834, Valid_ACC:0.37940001487731934
Epoch 998, CIFAR-10 Batch 1:  Train_Loss:0.8392833471298218, Valid_Loss:2.1043989658355713, Valid_ACC:0.37279999256134033
Epoch 999, CIFAR-10 Batch 1:  Train_Loss:0.8403100967407227, Valid_Loss:2.1212308406829834, Valid_ACC:0.3781999945640564
Epoch 1000, CIFAR-10 Batch 1:  Train_Loss:0.8408797383308411, Valid_Loss:2.1069557666778564, Valid_ACC:0.3755999803543091
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Train-the-Model">Fully Train the Model<a class="anchor-link" href="#Fully-Train-the-Model">&#182;</a></h3><p>Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Loop over all batches</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
            
    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training...
Epoch  1, CIFAR-10 Batch 1:  Train_Loss:2.281609535217285, Valid_Loss:2.273404598236084, Valid_ACC:0.16419999301433563
Epoch  1, CIFAR-10 Batch 2:  Train_Loss:2.2297492027282715, Valid_Loss:2.2331418991088867, Valid_ACC:0.196399986743927
Epoch  1, CIFAR-10 Batch 3:  Train_Loss:2.2063937187194824, Valid_Loss:2.2088000774383545, Valid_ACC:0.23219998180866241
Epoch  1, CIFAR-10 Batch 4:  Train_Loss:2.181515693664551, Valid_Loss:2.1785407066345215, Valid_ACC:0.24159997701644897
Epoch  1, CIFAR-10 Batch 5:  Train_Loss:2.1289165019989014, Valid_Loss:2.127790927886963, Valid_ACC:0.25919997692108154
Epoch  2, CIFAR-10 Batch 1:  Train_Loss:2.09226393699646, Valid_Loss:2.101652145385742, Valid_ACC:0.2735999822616577
Epoch  2, CIFAR-10 Batch 2:  Train_Loss:2.0531132221221924, Valid_Loss:2.0861668586730957, Valid_ACC:0.284199982881546
Epoch  2, CIFAR-10 Batch 3:  Train_Loss:2.0381906032562256, Valid_Loss:2.0559921264648438, Valid_ACC:0.30640000104904175
Epoch  2, CIFAR-10 Batch 4:  Train_Loss:2.0150609016418457, Valid_Loss:2.040015459060669, Valid_ACC:0.30559998750686646
Epoch  2, CIFAR-10 Batch 5:  Train_Loss:2.014587163925171, Valid_Loss:2.0337846279144287, Valid_ACC:0.30639997124671936
Epoch  3, CIFAR-10 Batch 1:  Train_Loss:2.0023841857910156, Valid_Loss:2.015777587890625, Valid_ACC:0.3097999691963196
Epoch  3, CIFAR-10 Batch 2:  Train_Loss:1.9426085948944092, Valid_Loss:2.0075578689575195, Valid_ACC:0.3157999813556671
Epoch  3, CIFAR-10 Batch 3:  Train_Loss:1.9648083448410034, Valid_Loss:1.9949562549591064, Valid_ACC:0.3277999758720398
Epoch  3, CIFAR-10 Batch 4:  Train_Loss:1.9545236825942993, Valid_Loss:1.9866931438446045, Valid_ACC:0.3357999622821808
Epoch  3, CIFAR-10 Batch 5:  Train_Loss:1.9342992305755615, Valid_Loss:1.9633113145828247, Valid_ACC:0.3481999635696411
Epoch  4, CIFAR-10 Batch 1:  Train_Loss:1.9471580982208252, Valid_Loss:1.9561889171600342, Valid_ACC:0.3423999845981598
Epoch  4, CIFAR-10 Batch 2:  Train_Loss:1.885911226272583, Valid_Loss:1.9540550708770752, Valid_ACC:0.35199999809265137
Epoch  4, CIFAR-10 Batch 3:  Train_Loss:1.913200855255127, Valid_Loss:1.9564695358276367, Valid_ACC:0.3473999798297882
Epoch  4, CIFAR-10 Batch 4:  Train_Loss:1.9120780229568481, Valid_Loss:1.9535634517669678, Valid_ACC:0.3474000096321106
Epoch  4, CIFAR-10 Batch 5:  Train_Loss:1.885560393333435, Valid_Loss:1.9301202297210693, Valid_ACC:0.3610000014305115
Epoch  5, CIFAR-10 Batch 1:  Train_Loss:1.9098765850067139, Valid_Loss:1.9316644668579102, Valid_ACC:0.35099998116493225
Epoch  5, CIFAR-10 Batch 2:  Train_Loss:1.8500241041183472, Valid_Loss:1.9188426733016968, Valid_ACC:0.37119996547698975
Epoch  5, CIFAR-10 Batch 3:  Train_Loss:1.8784056901931763, Valid_Loss:1.9172567129135132, Valid_ACC:0.36739999055862427
Epoch  5, CIFAR-10 Batch 4:  Train_Loss:1.8747155666351318, Valid_Loss:1.9192692041397095, Valid_ACC:0.3628000020980835
Epoch  5, CIFAR-10 Batch 5:  Train_Loss:1.8503165245056152, Valid_Loss:1.9010491371154785, Valid_ACC:0.3741999864578247
Epoch  6, CIFAR-10 Batch 1:  Train_Loss:1.8751450777053833, Valid_Loss:1.9003082513809204, Valid_ACC:0.36959999799728394
Epoch  6, CIFAR-10 Batch 2:  Train_Loss:1.8339719772338867, Valid_Loss:1.8977762460708618, Valid_ACC:0.3779999613761902
Epoch  6, CIFAR-10 Batch 3:  Train_Loss:1.8648724555969238, Valid_Loss:1.9050791263580322, Valid_ACC:0.37439996004104614
Epoch  6, CIFAR-10 Batch 4:  Train_Loss:1.8590139150619507, Valid_Loss:1.9015464782714844, Valid_ACC:0.3691999912261963
Epoch  6, CIFAR-10 Batch 5:  Train_Loss:1.8244786262512207, Valid_Loss:1.8798048496246338, Valid_ACC:0.38440001010894775
Epoch  7, CIFAR-10 Batch 1:  Train_Loss:1.8507113456726074, Valid_Loss:1.8847622871398926, Valid_ACC:0.3765999674797058
Epoch  7, CIFAR-10 Batch 2:  Train_Loss:1.8274624347686768, Valid_Loss:1.883544683456421, Valid_ACC:0.3853999376296997
Epoch  7, CIFAR-10 Batch 3:  Train_Loss:1.8529824018478394, Valid_Loss:1.8888733386993408, Valid_ACC:0.3789999783039093
Epoch  7, CIFAR-10 Batch 4:  Train_Loss:1.8320592641830444, Valid_Loss:1.8798400163650513, Valid_ACC:0.3821999430656433
Epoch  7, CIFAR-10 Batch 5:  Train_Loss:1.807938814163208, Valid_Loss:1.8685044050216675, Valid_ACC:0.38819995522499084
Epoch  8, CIFAR-10 Batch 1:  Train_Loss:1.8395473957061768, Valid_Loss:1.8752039670944214, Valid_ACC:0.37939995527267456
Epoch  8, CIFAR-10 Batch 2:  Train_Loss:1.805716872215271, Valid_Loss:1.8634594678878784, Valid_ACC:0.39399996399879456
Epoch  8, CIFAR-10 Batch 3:  Train_Loss:1.8373234272003174, Valid_Loss:1.87309992313385, Valid_ACC:0.3853999674320221
Epoch  8, CIFAR-10 Batch 4:  Train_Loss:1.8124010562896729, Valid_Loss:1.8588351011276245, Valid_ACC:0.3879999816417694
Epoch  8, CIFAR-10 Batch 5:  Train_Loss:1.7971137762069702, Valid_Loss:1.8624954223632812, Valid_ACC:0.3887999653816223
Epoch  9, CIFAR-10 Batch 1:  Train_Loss:1.8215230703353882, Valid_Loss:1.8551645278930664, Valid_ACC:0.39640000462532043
Epoch  9, CIFAR-10 Batch 2:  Train_Loss:1.7921600341796875, Valid_Loss:1.8509328365325928, Valid_ACC:0.40080001950263977
Epoch  9, CIFAR-10 Batch 3:  Train_Loss:1.8182992935180664, Valid_Loss:1.8503508567810059, Valid_ACC:0.39500001072883606
Epoch  9, CIFAR-10 Batch 4:  Train_Loss:1.796837568283081, Valid_Loss:1.8438628911972046, Valid_ACC:0.39539995789527893
Epoch  9, CIFAR-10 Batch 5:  Train_Loss:1.7764601707458496, Valid_Loss:1.8478062152862549, Valid_ACC:0.39699995517730713
Epoch 10, CIFAR-10 Batch 1:  Train_Loss:1.8124339580535889, Valid_Loss:1.8580195903778076, Valid_ACC:0.3933999836444855
Epoch 10, CIFAR-10 Batch 2:  Train_Loss:1.7814563512802124, Valid_Loss:1.8472557067871094, Valid_ACC:0.4025999903678894
Epoch 10, CIFAR-10 Batch 3:  Train_Loss:1.809388518333435, Valid_Loss:1.8434984683990479, Valid_ACC:0.40219995379447937
Epoch 10, CIFAR-10 Batch 4:  Train_Loss:1.7897553443908691, Valid_Loss:1.8404641151428223, Valid_ACC:0.3977999687194824
Epoch 10, CIFAR-10 Batch 5:  Train_Loss:1.7615739107131958, Valid_Loss:1.8369619846343994, Valid_ACC:0.4015999734401703
Epoch 11, CIFAR-10 Batch 1:  Train_Loss:1.8016196489334106, Valid_Loss:1.8474884033203125, Valid_ACC:0.3965999484062195
Epoch 11, CIFAR-10 Batch 2:  Train_Loss:1.7777055501937866, Valid_Loss:1.8409852981567383, Valid_ACC:0.40439996123313904
Epoch 11, CIFAR-10 Batch 3:  Train_Loss:1.7976642847061157, Valid_Loss:1.8322492837905884, Valid_ACC:0.4023999869823456
Epoch 11, CIFAR-10 Batch 4:  Train_Loss:1.7768161296844482, Valid_Loss:1.83017098903656, Valid_ACC:0.4031999707221985
Epoch 11, CIFAR-10 Batch 5:  Train_Loss:1.7452136278152466, Valid_Loss:1.8269258737564087, Valid_ACC:0.4023999869823456
Epoch 12, CIFAR-10 Batch 1:  Train_Loss:1.7934597730636597, Valid_Loss:1.8389451503753662, Valid_ACC:0.40119999647140503
Epoch 12, CIFAR-10 Batch 2:  Train_Loss:1.7603669166564941, Valid_Loss:1.8310819864273071, Valid_ACC:0.40759995579719543
Epoch 12, CIFAR-10 Batch 3:  Train_Loss:1.7882344722747803, Valid_Loss:1.8247532844543457, Valid_ACC:0.4047999680042267
Epoch 12, CIFAR-10 Batch 4:  Train_Loss:1.7695459127426147, Valid_Loss:1.817204475402832, Valid_ACC:0.4043999910354614
Epoch 12, CIFAR-10 Batch 5:  Train_Loss:1.746508002281189, Valid_Loss:1.8317034244537354, Valid_ACC:0.3997999429702759
Epoch 13, CIFAR-10 Batch 1:  Train_Loss:1.7849210500717163, Valid_Loss:1.8301893472671509, Valid_ACC:0.4039999842643738
Epoch 13, CIFAR-10 Batch 2:  Train_Loss:1.7650701999664307, Valid_Loss:1.839892864227295, Valid_ACC:0.39879995584487915
Epoch 13, CIFAR-10 Batch 3:  Train_Loss:1.7829724550247192, Valid_Loss:1.8214621543884277, Valid_ACC:0.4016000032424927
Epoch 13, CIFAR-10 Batch 4:  Train_Loss:1.7587460279464722, Valid_Loss:1.8115911483764648, Valid_ACC:0.409199982881546
Epoch 13, CIFAR-10 Batch 5:  Train_Loss:1.7226316928863525, Valid_Loss:1.8101184368133545, Valid_ACC:0.41119998693466187
Epoch 14, CIFAR-10 Batch 1:  Train_Loss:1.7782390117645264, Valid_Loss:1.8249249458312988, Valid_ACC:0.4027999937534332
Epoch 14, CIFAR-10 Batch 2:  Train_Loss:1.731309413909912, Valid_Loss:1.808371901512146, Valid_ACC:0.41179999709129333
Epoch 14, CIFAR-10 Batch 3:  Train_Loss:1.7684962749481201, Valid_Loss:1.8097789287567139, Valid_ACC:0.40940001606941223
Epoch 14, CIFAR-10 Batch 4:  Train_Loss:1.750473976135254, Valid_Loss:1.8025546073913574, Valid_ACC:0.4147999882698059
Epoch 14, CIFAR-10 Batch 5:  Train_Loss:1.7064573764801025, Valid_Loss:1.7995247840881348, Valid_ACC:0.41519999504089355
Epoch 15, CIFAR-10 Batch 1:  Train_Loss:1.7750685214996338, Valid_Loss:1.826040267944336, Valid_ACC:0.40039998292922974
Epoch 15, CIFAR-10 Batch 2:  Train_Loss:1.7209163904190063, Valid_Loss:1.8064478635787964, Valid_ACC:0.4075999855995178
Epoch 15, CIFAR-10 Batch 3:  Train_Loss:1.765538215637207, Valid_Loss:1.8065195083618164, Valid_ACC:0.40880000591278076
Epoch 15, CIFAR-10 Batch 4:  Train_Loss:1.7417176961898804, Valid_Loss:1.7989411354064941, Valid_ACC:0.41499999165534973
Epoch 15, CIFAR-10 Batch 5:  Train_Loss:1.697831630706787, Valid_Loss:1.7966334819793701, Valid_ACC:0.41759997606277466
Epoch 16, CIFAR-10 Batch 1:  Train_Loss:1.7679725885391235, Valid_Loss:1.8215497732162476, Valid_ACC:0.40059998631477356
Epoch 16, CIFAR-10 Batch 2:  Train_Loss:1.709987759590149, Valid_Loss:1.80100679397583, Valid_ACC:0.41179996728897095
Epoch 16, CIFAR-10 Batch 3:  Train_Loss:1.754058599472046, Valid_Loss:1.8018040657043457, Valid_ACC:0.4083999991416931
Epoch 16, CIFAR-10 Batch 4:  Train_Loss:1.731074571609497, Valid_Loss:1.788640022277832, Valid_ACC:0.41759997606277466
Epoch 16, CIFAR-10 Batch 5:  Train_Loss:1.688002347946167, Valid_Loss:1.7886968851089478, Valid_ACC:0.42139995098114014
Epoch 17, CIFAR-10 Batch 1:  Train_Loss:1.748975396156311, Valid_Loss:1.8001199960708618, Valid_ACC:0.4115999937057495
Epoch 17, CIFAR-10 Batch 2:  Train_Loss:1.6983305215835571, Valid_Loss:1.787834644317627, Valid_ACC:0.4179999828338623
Epoch 17, CIFAR-10 Batch 3:  Train_Loss:1.7440890073776245, Valid_Loss:1.7913312911987305, Valid_ACC:0.41419997811317444
Epoch 17, CIFAR-10 Batch 4:  Train_Loss:1.7226903438568115, Valid_Loss:1.7794126272201538, Valid_ACC:0.42339998483657837
Epoch 17, CIFAR-10 Batch 5:  Train_Loss:1.6850980520248413, Valid_Loss:1.7804756164550781, Valid_ACC:0.42239999771118164
Epoch 18, CIFAR-10 Batch 1:  Train_Loss:1.7511541843414307, Valid_Loss:1.8007313013076782, Valid_ACC:0.4131999909877777
Epoch 18, CIFAR-10 Batch 2:  Train_Loss:1.6918913125991821, Valid_Loss:1.7871168851852417, Valid_ACC:0.41940000653266907
Epoch 18, CIFAR-10 Batch 3:  Train_Loss:1.7423341274261475, Valid_Loss:1.7875028848648071, Valid_ACC:0.41579997539520264
Epoch 18, CIFAR-10 Batch 4:  Train_Loss:1.7207696437835693, Valid_Loss:1.7772718667984009, Valid_ACC:0.4235999584197998
Epoch 18, CIFAR-10 Batch 5:  Train_Loss:1.6691718101501465, Valid_Loss:1.77280855178833, Valid_ACC:0.4225999712944031
Epoch 19, CIFAR-10 Batch 1:  Train_Loss:1.7296645641326904, Valid_Loss:1.7745952606201172, Valid_ACC:0.42399999499320984
Epoch 19, CIFAR-10 Batch 2:  Train_Loss:1.6828244924545288, Valid_Loss:1.7759382724761963, Valid_ACC:0.42379993200302124
Epoch 19, CIFAR-10 Batch 3:  Train_Loss:1.7325445413589478, Valid_Loss:1.7736471891403198, Valid_ACC:0.42219996452331543
Epoch 19, CIFAR-10 Batch 4:  Train_Loss:1.7076871395111084, Valid_Loss:1.763395071029663, Valid_ACC:0.42899999022483826
Epoch 19, CIFAR-10 Batch 5:  Train_Loss:1.6614800691604614, Valid_Loss:1.7653499841690063, Valid_ACC:0.42719998955726624
Epoch 20, CIFAR-10 Batch 1:  Train_Loss:1.7221448421478271, Valid_Loss:1.7752156257629395, Valid_ACC:0.4229999780654907
Epoch 20, CIFAR-10 Batch 2:  Train_Loss:1.6752755641937256, Valid_Loss:1.7676823139190674, Valid_ACC:0.4261999726295471
Epoch 20, CIFAR-10 Batch 3:  Train_Loss:1.7229974269866943, Valid_Loss:1.761601448059082, Valid_ACC:0.42739996314048767
Epoch 20, CIFAR-10 Batch 4:  Train_Loss:1.704866647720337, Valid_Loss:1.7600115537643433, Valid_ACC:0.4275999665260315
Epoch 20, CIFAR-10 Batch 5:  Train_Loss:1.66362464427948, Valid_Loss:1.763195276260376, Valid_ACC:0.4251999855041504
Epoch 21, CIFAR-10 Batch 1:  Train_Loss:1.7151821851730347, Valid_Loss:1.7685129642486572, Valid_ACC:0.429999977350235
Epoch 21, CIFAR-10 Batch 2:  Train_Loss:1.6652264595031738, Valid_Loss:1.7564812898635864, Valid_ACC:0.4309999942779541
Epoch 21, CIFAR-10 Batch 3:  Train_Loss:1.7221405506134033, Valid_Loss:1.7617160081863403, Valid_ACC:0.42559999227523804
Epoch 21, CIFAR-10 Batch 4:  Train_Loss:1.6928151845932007, Valid_Loss:1.754577875137329, Valid_ACC:0.429999977350235
Epoch 21, CIFAR-10 Batch 5:  Train_Loss:1.654323935508728, Valid_Loss:1.760642647743225, Valid_ACC:0.42659997940063477
Epoch 22, CIFAR-10 Batch 1:  Train_Loss:1.7088173627853394, Valid_Loss:1.7702350616455078, Valid_ACC:0.42319998145103455
Epoch 22, CIFAR-10 Batch 2:  Train_Loss:1.6649456024169922, Valid_Loss:1.7556638717651367, Valid_ACC:0.42979997396469116
Epoch 22, CIFAR-10 Batch 3:  Train_Loss:1.709519624710083, Valid_Loss:1.759065866470337, Valid_ACC:0.4277999699115753
Epoch 22, CIFAR-10 Batch 4:  Train_Loss:1.6916669607162476, Valid_Loss:1.7535239458084106, Valid_ACC:0.42879998683929443
Epoch 22, CIFAR-10 Batch 5:  Train_Loss:1.6351431608200073, Valid_Loss:1.7429343461990356, Valid_ACC:0.4341999888420105
Epoch 23, CIFAR-10 Batch 1:  Train_Loss:1.6983065605163574, Valid_Loss:1.761606216430664, Valid_ACC:0.42779994010925293
Epoch 23, CIFAR-10 Batch 2:  Train_Loss:1.6482865810394287, Valid_Loss:1.7444512844085693, Valid_ACC:0.434999942779541
Epoch 23, CIFAR-10 Batch 3:  Train_Loss:1.7046033143997192, Valid_Loss:1.7530794143676758, Valid_ACC:0.43299996852874756
Epoch 23, CIFAR-10 Batch 4:  Train_Loss:1.6783900260925293, Valid_Loss:1.742688775062561, Valid_ACC:0.43039998412132263
Epoch 23, CIFAR-10 Batch 5:  Train_Loss:1.6358548402786255, Valid_Loss:1.742344856262207, Valid_ACC:0.43799999356269836
Epoch 24, CIFAR-10 Batch 1:  Train_Loss:1.6890461444854736, Valid_Loss:1.749673843383789, Valid_ACC:0.4342000484466553
Epoch 24, CIFAR-10 Batch 2:  Train_Loss:1.6485075950622559, Valid_Loss:1.7469587326049805, Valid_ACC:0.43199995160102844
Epoch 24, CIFAR-10 Batch 3:  Train_Loss:1.7028318643569946, Valid_Loss:1.7462114095687866, Valid_ACC:0.4307999908924103
Epoch 24, CIFAR-10 Batch 4:  Train_Loss:1.6829071044921875, Valid_Loss:1.7439051866531372, Valid_ACC:0.43279996514320374
Epoch 24, CIFAR-10 Batch 5:  Train_Loss:1.6333357095718384, Valid_Loss:1.7363266944885254, Valid_ACC:0.4357999861240387
Epoch 25, CIFAR-10 Batch 1:  Train_Loss:1.6864761114120483, Valid_Loss:1.7446134090423584, Valid_ACC:0.433199942111969
Epoch 25, CIFAR-10 Batch 2:  Train_Loss:1.6306486129760742, Valid_Loss:1.7132502794265747, Valid_ACC:0.44179996848106384
Epoch 25, CIFAR-10 Batch 3:  Train_Loss:1.6038804054260254, Valid_Loss:1.66945481300354, Valid_ACC:0.4479999542236328
Epoch 25, CIFAR-10 Batch 4:  Train_Loss:1.601156234741211, Valid_Loss:1.655030369758606, Valid_ACC:0.45239996910095215
Epoch 25, CIFAR-10 Batch 5:  Train_Loss:1.579005479812622, Valid_Loss:1.6573798656463623, Valid_ACC:0.4545999765396118
Epoch 26, CIFAR-10 Batch 1:  Train_Loss:1.6220629215240479, Valid_Loss:1.6754570007324219, Valid_ACC:0.4461999535560608
Epoch 26, CIFAR-10 Batch 2:  Train_Loss:1.5695704221725464, Valid_Loss:1.6478991508483887, Valid_ACC:0.4567999541759491
Epoch 26, CIFAR-10 Batch 3:  Train_Loss:1.5582479238510132, Valid_Loss:1.6386767625808716, Valid_ACC:0.459199994802475
Epoch 26, CIFAR-10 Batch 4:  Train_Loss:1.5734751224517822, Valid_Loss:1.6285841464996338, Valid_ACC:0.46059995889663696
Epoch 26, CIFAR-10 Batch 5:  Train_Loss:1.546326994895935, Valid_Loss:1.609886646270752, Valid_ACC:0.47279998660087585
Epoch 27, CIFAR-10 Batch 1:  Train_Loss:1.5804685354232788, Valid_Loss:1.627746343612671, Valid_ACC:0.46299996972084045
Epoch 27, CIFAR-10 Batch 2:  Train_Loss:1.5276246070861816, Valid_Loss:1.6051899194717407, Valid_ACC:0.4753999412059784
Epoch 27, CIFAR-10 Batch 3:  Train_Loss:1.5203479528427124, Valid_Loss:1.6186673641204834, Valid_ACC:0.47019994258880615
Epoch 27, CIFAR-10 Batch 4:  Train_Loss:1.5423657894134521, Valid_Loss:1.6049766540527344, Valid_ACC:0.4737999737262726
Epoch 27, CIFAR-10 Batch 5:  Train_Loss:1.535142421722412, Valid_Loss:1.5986487865447998, Valid_ACC:0.47659996151924133
Epoch 28, CIFAR-10 Batch 1:  Train_Loss:1.5640467405319214, Valid_Loss:1.611694574356079, Valid_ACC:0.46959996223449707
Epoch 28, CIFAR-10 Batch 2:  Train_Loss:1.5182234048843384, Valid_Loss:1.596853494644165, Valid_ACC:0.4795999526977539
Epoch 28, CIFAR-10 Batch 3:  Train_Loss:1.5015532970428467, Valid_Loss:1.5957064628601074, Valid_ACC:0.47279995679855347
Epoch 28, CIFAR-10 Batch 4:  Train_Loss:1.5179131031036377, Valid_Loss:1.5854101181030273, Valid_ACC:0.4789999723434448
Epoch 28, CIFAR-10 Batch 5:  Train_Loss:1.5146182775497437, Valid_Loss:1.5875006914138794, Valid_ACC:0.4801999628543854
Epoch 29, CIFAR-10 Batch 1:  Train_Loss:1.5519566535949707, Valid_Loss:1.6045620441436768, Valid_ACC:0.4729999601840973
Epoch 29, CIFAR-10 Batch 2:  Train_Loss:1.511168360710144, Valid_Loss:1.6008342504501343, Valid_ACC:0.4771999418735504
Epoch 29, CIFAR-10 Batch 3:  Train_Loss:1.4825085401535034, Valid_Loss:1.579979658126831, Valid_ACC:0.4795999526977539
Epoch 29, CIFAR-10 Batch 4:  Train_Loss:1.5423803329467773, Valid_Loss:1.608608603477478, Valid_ACC:0.4673999547958374
Epoch 29, CIFAR-10 Batch 5:  Train_Loss:1.5061759948730469, Valid_Loss:1.579441785812378, Valid_ACC:0.4837999641895294
Epoch 30, CIFAR-10 Batch 1:  Train_Loss:1.5373660326004028, Valid_Loss:1.586337685585022, Valid_ACC:0.47939997911453247
Epoch 30, CIFAR-10 Batch 2:  Train_Loss:1.495237112045288, Valid_Loss:1.5885640382766724, Valid_ACC:0.47839996218681335
Epoch 30, CIFAR-10 Batch 3:  Train_Loss:1.4694862365722656, Valid_Loss:1.58415949344635, Valid_ACC:0.4827999472618103
Epoch 30, CIFAR-10 Batch 4:  Train_Loss:1.51826810836792, Valid_Loss:1.587950348854065, Valid_ACC:0.47499996423721313
Epoch 30, CIFAR-10 Batch 5:  Train_Loss:1.5007312297821045, Valid_Loss:1.5625580549240112, Valid_ACC:0.48799994587898254
Epoch 31, CIFAR-10 Batch 1:  Train_Loss:1.530489444732666, Valid_Loss:1.5725529193878174, Valid_ACC:0.48399993777275085
Epoch 31, CIFAR-10 Batch 2:  Train_Loss:1.4775865077972412, Valid_Loss:1.5663490295410156, Valid_ACC:0.49119994044303894
Epoch 31, CIFAR-10 Batch 3:  Train_Loss:1.4508090019226074, Valid_Loss:1.5619670152664185, Valid_ACC:0.4891999363899231
Epoch 31, CIFAR-10 Batch 4:  Train_Loss:1.502063274383545, Valid_Loss:1.5751585960388184, Valid_ACC:0.4893999397754669
Epoch 31, CIFAR-10 Batch 5:  Train_Loss:1.49215829372406, Valid_Loss:1.5562206506729126, Valid_ACC:0.49139994382858276
Epoch 32, CIFAR-10 Batch 1:  Train_Loss:1.5092653036117554, Valid_Loss:1.5549614429473877, Valid_ACC:0.4877999424934387
Epoch 32, CIFAR-10 Batch 2:  Train_Loss:1.4780217409133911, Valid_Loss:1.5741345882415771, Valid_ACC:0.48819994926452637
Epoch 32, CIFAR-10 Batch 3:  Train_Loss:1.4481011629104614, Valid_Loss:1.56289541721344, Valid_ACC:0.49039995670318604
Epoch 32, CIFAR-10 Batch 4:  Train_Loss:1.5008633136749268, Valid_Loss:1.5713430643081665, Valid_ACC:0.48659998178482056
Epoch 32, CIFAR-10 Batch 5:  Train_Loss:1.4952205419540405, Valid_Loss:1.552515983581543, Valid_ACC:0.49139994382858276
Epoch 33, CIFAR-10 Batch 1:  Train_Loss:1.5004233121871948, Valid_Loss:1.5549275875091553, Valid_ACC:0.4896000027656555
Epoch 33, CIFAR-10 Batch 2:  Train_Loss:1.4705123901367188, Valid_Loss:1.5606906414031982, Valid_ACC:0.4931999742984772
Epoch 33, CIFAR-10 Batch 3:  Train_Loss:1.4532326459884644, Valid_Loss:1.5713489055633545, Valid_ACC:0.4875999689102173
Epoch 33, CIFAR-10 Batch 4:  Train_Loss:1.4928762912750244, Valid_Loss:1.5684547424316406, Valid_ACC:0.4927999675273895
Epoch 33, CIFAR-10 Batch 5:  Train_Loss:1.485422134399414, Valid_Loss:1.5465900897979736, Valid_ACC:0.49299997091293335
Epoch 34, CIFAR-10 Batch 1:  Train_Loss:1.494858980178833, Valid_Loss:1.5504523515701294, Valid_ACC:0.4925999641418457
Epoch 34, CIFAR-10 Batch 2:  Train_Loss:1.4610644578933716, Valid_Loss:1.5461554527282715, Valid_ACC:0.49959996342658997
Epoch 34, CIFAR-10 Batch 3:  Train_Loss:1.433131217956543, Valid_Loss:1.547958493232727, Valid_ACC:0.4963999390602112
Epoch 34, CIFAR-10 Batch 4:  Train_Loss:1.47493314743042, Valid_Loss:1.5546917915344238, Valid_ACC:0.4923999607563019
Epoch 34, CIFAR-10 Batch 5:  Train_Loss:1.4759186506271362, Valid_Loss:1.539139986038208, Valid_ACC:0.4989999532699585
Epoch 35, CIFAR-10 Batch 1:  Train_Loss:1.4970604181289673, Valid_Loss:1.5567373037338257, Valid_ACC:0.49039995670318604
Epoch 35, CIFAR-10 Batch 2:  Train_Loss:1.4712574481964111, Valid_Loss:1.5651214122772217, Valid_ACC:0.48719993233680725
Epoch 35, CIFAR-10 Batch 3:  Train_Loss:1.4372942447662354, Valid_Loss:1.555468201637268, Valid_ACC:0.49059996008872986
Epoch 35, CIFAR-10 Batch 4:  Train_Loss:1.4832098484039307, Valid_Loss:1.561133861541748, Valid_ACC:0.4901999235153198
Epoch 35, CIFAR-10 Batch 5:  Train_Loss:1.4773625135421753, Valid_Loss:1.5361852645874023, Valid_ACC:0.49359995126724243
Epoch 36, CIFAR-10 Batch 1:  Train_Loss:1.4760665893554688, Valid_Loss:1.5357334613800049, Valid_ACC:0.4968000054359436
Epoch 36, CIFAR-10 Batch 2:  Train_Loss:1.4502202272415161, Valid_Loss:1.5423336029052734, Valid_ACC:0.4949999451637268
Epoch 36, CIFAR-10 Batch 3:  Train_Loss:1.4144022464752197, Valid_Loss:1.5375993251800537, Valid_ACC:0.5003999471664429
Epoch 36, CIFAR-10 Batch 4:  Train_Loss:1.4555490016937256, Valid_Loss:1.5355579853057861, Valid_ACC:0.5013999342918396
Epoch 36, CIFAR-10 Batch 5:  Train_Loss:1.4598710536956787, Valid_Loss:1.5272221565246582, Valid_ACC:0.502799928188324
Epoch 37, CIFAR-10 Batch 1:  Train_Loss:1.4698742628097534, Valid_Loss:1.5282567739486694, Valid_ACC:0.5019999742507935
Epoch 37, CIFAR-10 Batch 2:  Train_Loss:1.4440019130706787, Valid_Loss:1.533646583557129, Valid_ACC:0.503600001335144
Epoch 37, CIFAR-10 Batch 3:  Train_Loss:1.408433437347412, Valid_Loss:1.53226900100708, Valid_ACC:0.49939998984336853
Epoch 37, CIFAR-10 Batch 4:  Train_Loss:1.45419442653656, Valid_Loss:1.5337951183319092, Valid_ACC:0.5011999607086182
Epoch 37, CIFAR-10 Batch 5:  Train_Loss:1.4554075002670288, Valid_Loss:1.5309611558914185, Valid_ACC:0.5041999816894531
Epoch 38, CIFAR-10 Batch 1:  Train_Loss:1.472992181777954, Valid_Loss:1.5367406606674194, Valid_ACC:0.4975999593734741
Epoch 38, CIFAR-10 Batch 2:  Train_Loss:1.441542148590088, Valid_Loss:1.5296450853347778, Valid_ACC:0.5023999214172363
Epoch 38, CIFAR-10 Batch 3:  Train_Loss:1.4027804136276245, Valid_Loss:1.526478886604309, Valid_ACC:0.5061999559402466
Epoch 38, CIFAR-10 Batch 4:  Train_Loss:1.4388272762298584, Valid_Loss:1.5237675905227661, Valid_ACC:0.5043999552726746
Epoch 38, CIFAR-10 Batch 5:  Train_Loss:1.4546434879302979, Valid_Loss:1.528854250907898, Valid_ACC:0.5021999478340149
Epoch 39, CIFAR-10 Batch 1:  Train_Loss:1.470158338546753, Valid_Loss:1.5367423295974731, Valid_ACC:0.5001999139785767
Epoch 39, CIFAR-10 Batch 2:  Train_Loss:1.4446983337402344, Valid_Loss:1.5373997688293457, Valid_ACC:0.5003999471664429
Epoch 39, CIFAR-10 Batch 3:  Train_Loss:1.3872472047805786, Valid_Loss:1.5148791074752808, Valid_ACC:0.5067999362945557
Epoch 39, CIFAR-10 Batch 4:  Train_Loss:1.4292080402374268, Valid_Loss:1.5154179334640503, Valid_ACC:0.5015999674797058
Epoch 39, CIFAR-10 Batch 5:  Train_Loss:1.4538003206253052, Valid_Loss:1.5207037925720215, Valid_ACC:0.5023999214172363
Epoch 40, CIFAR-10 Batch 1:  Train_Loss:1.4591965675354004, Valid_Loss:1.5314733982086182, Valid_ACC:0.4981999397277832
Epoch 40, CIFAR-10 Batch 2:  Train_Loss:1.4468313455581665, Valid_Loss:1.5458166599273682, Valid_ACC:0.49379995465278625
Epoch 40, CIFAR-10 Batch 3:  Train_Loss:1.3912315368652344, Valid_Loss:1.514549970626831, Valid_ACC:0.5071999430656433
Epoch 40, CIFAR-10 Batch 4:  Train_Loss:1.4368329048156738, Valid_Loss:1.5235618352890015, Valid_ACC:0.5039999485015869
Epoch 40, CIFAR-10 Batch 5:  Train_Loss:1.438675880432129, Valid_Loss:1.509911298751831, Valid_ACC:0.5095999836921692
Epoch 41, CIFAR-10 Batch 1:  Train_Loss:1.4526596069335938, Valid_Loss:1.523000955581665, Valid_ACC:0.5035999417304993
Epoch 41, CIFAR-10 Batch 2:  Train_Loss:1.42549729347229, Valid_Loss:1.5184296369552612, Valid_ACC:0.5035999417304993
Epoch 41, CIFAR-10 Batch 3:  Train_Loss:1.3940858840942383, Valid_Loss:1.5138288736343384, Valid_ACC:0.5021999478340149
Epoch 41, CIFAR-10 Batch 4:  Train_Loss:1.456977128982544, Valid_Loss:1.5450818538665771, Valid_ACC:0.4955999553203583
Epoch 41, CIFAR-10 Batch 5:  Train_Loss:1.4439717531204224, Valid_Loss:1.511495590209961, Valid_ACC:0.5045999884605408
Epoch 42, CIFAR-10 Batch 1:  Train_Loss:1.4495753049850464, Valid_Loss:1.5218814611434937, Valid_ACC:0.5029999613761902
Epoch 42, CIFAR-10 Batch 2:  Train_Loss:1.4340288639068604, Valid_Loss:1.5431480407714844, Valid_ACC:0.49359995126724243
Epoch 42, CIFAR-10 Batch 3:  Train_Loss:1.39517080783844, Valid_Loss:1.5159369707107544, Valid_ACC:0.5005999803543091
Epoch 42, CIFAR-10 Batch 4:  Train_Loss:1.4591535329818726, Valid_Loss:1.5469368696212769, Valid_ACC:0.4955999255180359
Epoch 42, CIFAR-10 Batch 5:  Train_Loss:1.4434107542037964, Valid_Loss:1.5213123559951782, Valid_ACC:0.5037999153137207
Epoch 43, CIFAR-10 Batch 1:  Train_Loss:1.440127968788147, Valid_Loss:1.5105211734771729, Valid_ACC:0.5045999884605408
Epoch 43, CIFAR-10 Batch 2:  Train_Loss:1.4545384645462036, Valid_Loss:1.5433146953582764, Valid_ACC:0.49279993772506714
Epoch 43, CIFAR-10 Batch 3:  Train_Loss:1.400862216949463, Valid_Loss:1.532167911529541, Valid_ACC:0.502799928188324
Epoch 43, CIFAR-10 Batch 4:  Train_Loss:1.427755355834961, Valid_Loss:1.51737380027771, Valid_ACC:0.4986000061035156
Epoch 43, CIFAR-10 Batch 5:  Train_Loss:1.4382059574127197, Valid_Loss:1.5157595872879028, Valid_ACC:0.5077999234199524
Epoch 44, CIFAR-10 Batch 1:  Train_Loss:1.4521691799163818, Valid_Loss:1.523092269897461, Valid_ACC:0.500999927520752
Epoch 44, CIFAR-10 Batch 2:  Train_Loss:1.4318304061889648, Valid_Loss:1.5357797145843506, Valid_ACC:0.49619996547698975
Epoch 44, CIFAR-10 Batch 3:  Train_Loss:1.3949170112609863, Valid_Loss:1.516007661819458, Valid_ACC:0.5035999417304993
Epoch 44, CIFAR-10 Batch 4:  Train_Loss:1.4316707849502563, Valid_Loss:1.521722674369812, Valid_ACC:0.49619996547698975
Epoch 44, CIFAR-10 Batch 5:  Train_Loss:1.4301913976669312, Valid_Loss:1.506544828414917, Valid_ACC:0.5116000175476074
Epoch 45, CIFAR-10 Batch 1:  Train_Loss:1.429266333580017, Valid_Loss:1.5069422721862793, Valid_ACC:0.5031999349594116
Epoch 45, CIFAR-10 Batch 2:  Train_Loss:1.4127475023269653, Valid_Loss:1.5150940418243408, Valid_ACC:0.5053999423980713
Epoch 45, CIFAR-10 Batch 3:  Train_Loss:1.3860397338867188, Valid_Loss:1.5060425996780396, Valid_ACC:0.49999991059303284
Epoch 45, CIFAR-10 Batch 4:  Train_Loss:1.4239182472229004, Valid_Loss:1.5151816606521606, Valid_ACC:0.5051999092102051
Epoch 45, CIFAR-10 Batch 5:  Train_Loss:1.4183157682418823, Valid_Loss:1.496273398399353, Valid_ACC:0.5115999579429626
Epoch 46, CIFAR-10 Batch 1:  Train_Loss:1.4136818647384644, Valid_Loss:1.5028141736984253, Valid_ACC:0.509399950504303
Epoch 46, CIFAR-10 Batch 2:  Train_Loss:1.406517744064331, Valid_Loss:1.5014585256576538, Valid_ACC:0.5125999450683594
Epoch 46, CIFAR-10 Batch 3:  Train_Loss:1.3761603832244873, Valid_Loss:1.499441385269165, Valid_ACC:0.5079999566078186
Epoch 46, CIFAR-10 Batch 4:  Train_Loss:1.4093668460845947, Valid_Loss:1.5030529499053955, Valid_ACC:0.5067999362945557
Epoch 46, CIFAR-10 Batch 5:  Train_Loss:1.4140349626541138, Valid_Loss:1.493158221244812, Valid_ACC:0.5139999389648438
Epoch 47, CIFAR-10 Batch 1:  Train_Loss:1.4102187156677246, Valid_Loss:1.4999010562896729, Valid_ACC:0.5069999694824219
Epoch 47, CIFAR-10 Batch 2:  Train_Loss:1.4043598175048828, Valid_Loss:1.5048781633377075, Valid_ACC:0.509399950504303
Epoch 47, CIFAR-10 Batch 3:  Train_Loss:1.3657190799713135, Valid_Loss:1.4961291551589966, Valid_ACC:0.5109999775886536
Epoch 47, CIFAR-10 Batch 4:  Train_Loss:1.4063905477523804, Valid_Loss:1.507279872894287, Valid_ACC:0.5067999362945557
Epoch 47, CIFAR-10 Batch 5:  Train_Loss:1.41666579246521, Valid_Loss:1.4895744323730469, Valid_ACC:0.5131999254226685
Epoch 48, CIFAR-10 Batch 1:  Train_Loss:1.4067786931991577, Valid_Loss:1.4949254989624023, Valid_ACC:0.5097999572753906
Epoch 48, CIFAR-10 Batch 2:  Train_Loss:1.3983204364776611, Valid_Loss:1.4974654912948608, Valid_ACC:0.5047999620437622
Epoch 48, CIFAR-10 Batch 3:  Train_Loss:1.3634588718414307, Valid_Loss:1.5007641315460205, Valid_ACC:0.5087999105453491
Epoch 48, CIFAR-10 Batch 4:  Train_Loss:1.4239861965179443, Valid_Loss:1.5220568180084229, Valid_ACC:0.4991999566555023
Epoch 48, CIFAR-10 Batch 5:  Train_Loss:1.4182745218276978, Valid_Loss:1.4963022470474243, Valid_ACC:0.5095999240875244
Epoch 49, CIFAR-10 Batch 1:  Train_Loss:1.4110920429229736, Valid_Loss:1.4944360256195068, Valid_ACC:0.5069999694824219
Epoch 49, CIFAR-10 Batch 2:  Train_Loss:1.4095274209976196, Valid_Loss:1.515572428703308, Valid_ACC:0.5057999491691589
Epoch 49, CIFAR-10 Batch 3:  Train_Loss:1.3608112335205078, Valid_Loss:1.494884729385376, Valid_ACC:0.5073999762535095
Epoch 49, CIFAR-10 Batch 4:  Train_Loss:1.393700361251831, Valid_Loss:1.495159387588501, Valid_ACC:0.5083999633789062
Epoch 49, CIFAR-10 Batch 5:  Train_Loss:1.4067007303237915, Valid_Loss:1.4887888431549072, Valid_ACC:0.5157999396324158
Epoch 50, CIFAR-10 Batch 1:  Train_Loss:1.4024449586868286, Valid_Loss:1.4916906356811523, Valid_ACC:0.5137999057769775
Epoch 50, CIFAR-10 Batch 2:  Train_Loss:1.3931289911270142, Valid_Loss:1.4920811653137207, Valid_ACC:0.5095999836921692
Epoch 50, CIFAR-10 Batch 3:  Train_Loss:1.3466920852661133, Valid_Loss:1.4881527423858643, Valid_ACC:0.5123999118804932
Epoch 50, CIFAR-10 Batch 4:  Train_Loss:1.3964104652404785, Valid_Loss:1.5012526512145996, Valid_ACC:0.5123999714851379
Epoch 50, CIFAR-10 Batch 5:  Train_Loss:1.4014641046524048, Valid_Loss:1.48152756690979, Valid_ACC:0.5167999267578125
Epoch 51, CIFAR-10 Batch 1:  Train_Loss:1.3904987573623657, Valid_Loss:1.4873703718185425, Valid_ACC:0.5113999247550964
Epoch 51, CIFAR-10 Batch 2:  Train_Loss:1.389094352722168, Valid_Loss:1.4991631507873535, Valid_ACC:0.5133999586105347
Epoch 51, CIFAR-10 Batch 3:  Train_Loss:1.3551141023635864, Valid_Loss:1.4883966445922852, Valid_ACC:0.5097998976707458
Epoch 51, CIFAR-10 Batch 4:  Train_Loss:1.400999665260315, Valid_Loss:1.5096670389175415, Valid_ACC:0.5065999627113342
Epoch 51, CIFAR-10 Batch 5:  Train_Loss:1.4061744213104248, Valid_Loss:1.4844942092895508, Valid_ACC:0.5153999328613281
Epoch 52, CIFAR-10 Batch 1:  Train_Loss:1.3850736618041992, Valid_Loss:1.478898286819458, Valid_ACC:0.5169999599456787
Epoch 52, CIFAR-10 Batch 2:  Train_Loss:1.375156044960022, Valid_Loss:1.4816665649414062, Valid_ACC:0.51419997215271
Epoch 52, CIFAR-10 Batch 3:  Train_Loss:1.3457099199295044, Valid_Loss:1.4789586067199707, Valid_ACC:0.5123999118804932
Epoch 52, CIFAR-10 Batch 4:  Train_Loss:1.3874266147613525, Valid_Loss:1.4908959865570068, Valid_ACC:0.5107999444007874
Epoch 52, CIFAR-10 Batch 5:  Train_Loss:1.3922436237335205, Valid_Loss:1.4871289730072021, Valid_ACC:0.5155999660491943
Epoch 53, CIFAR-10 Batch 1:  Train_Loss:1.382869839668274, Valid_Loss:1.4810585975646973, Valid_ACC:0.5159999132156372
Epoch 53, CIFAR-10 Batch 2:  Train_Loss:1.3962029218673706, Valid_Loss:1.5028117895126343, Valid_ACC:0.5065999627113342
Epoch 53, CIFAR-10 Batch 3:  Train_Loss:1.3354072570800781, Valid_Loss:1.4784965515136719, Valid_ACC:0.5181999206542969
Epoch 53, CIFAR-10 Batch 4:  Train_Loss:1.4021074771881104, Valid_Loss:1.5052160024642944, Valid_ACC:0.5069999694824219
Epoch 53, CIFAR-10 Batch 5:  Train_Loss:1.3974542617797852, Valid_Loss:1.4788316488265991, Valid_ACC:0.5166000127792358
Epoch 54, CIFAR-10 Batch 1:  Train_Loss:1.3734310865402222, Valid_Loss:1.4780231714248657, Valid_ACC:0.5179999470710754
Epoch 54, CIFAR-10 Batch 2:  Train_Loss:1.3695518970489502, Valid_Loss:1.4731225967407227, Valid_ACC:0.5209999680519104
Epoch 54, CIFAR-10 Batch 3:  Train_Loss:1.3308097124099731, Valid_Loss:1.4699504375457764, Valid_ACC:0.514799952507019
Epoch 54, CIFAR-10 Batch 4:  Train_Loss:1.3746716976165771, Valid_Loss:1.4827384948730469, Valid_ACC:0.5139999389648438
Epoch 54, CIFAR-10 Batch 5:  Train_Loss:1.387864589691162, Valid_Loss:1.4770164489746094, Valid_ACC:0.5199999213218689
Epoch 55, CIFAR-10 Batch 1:  Train_Loss:1.3733386993408203, Valid_Loss:1.4808025360107422, Valid_ACC:0.512199878692627
Epoch 55, CIFAR-10 Batch 2:  Train_Loss:1.370896339416504, Valid_Loss:1.4775466918945312, Valid_ACC:0.5153999328613281
Epoch 55, CIFAR-10 Batch 3:  Train_Loss:1.3265506029129028, Valid_Loss:1.4712716341018677, Valid_ACC:0.5159999132156372
Epoch 55, CIFAR-10 Batch 4:  Train_Loss:1.3691436052322388, Valid_Loss:1.4781434535980225, Valid_ACC:0.515999972820282
Epoch 55, CIFAR-10 Batch 5:  Train_Loss:1.390722632408142, Valid_Loss:1.4741023778915405, Valid_ACC:0.5199999809265137
Epoch 56, CIFAR-10 Batch 1:  Train_Loss:1.3712913990020752, Valid_Loss:1.4722827672958374, Valid_ACC:0.5187999606132507
Epoch 56, CIFAR-10 Batch 2:  Train_Loss:1.3706562519073486, Valid_Loss:1.4739022254943848, Valid_ACC:0.5161999464035034
Epoch 56, CIFAR-10 Batch 3:  Train_Loss:1.3302448987960815, Valid_Loss:1.4708290100097656, Valid_ACC:0.5211999416351318
Epoch 56, CIFAR-10 Batch 4:  Train_Loss:1.3814654350280762, Valid_Loss:1.4944530725479126, Valid_ACC:0.5143999457359314
Epoch 56, CIFAR-10 Batch 5:  Train_Loss:1.380551815032959, Valid_Loss:1.479488730430603, Valid_ACC:0.5187999606132507
Epoch 57, CIFAR-10 Batch 1:  Train_Loss:1.3643743991851807, Valid_Loss:1.469782829284668, Valid_ACC:0.5203999280929565
Epoch 57, CIFAR-10 Batch 2:  Train_Loss:1.3698925971984863, Valid_Loss:1.4731426239013672, Valid_ACC:0.5159999132156372
Epoch 57, CIFAR-10 Batch 3:  Train_Loss:1.333053708076477, Valid_Loss:1.4750971794128418, Valid_ACC:0.5141999125480652
Epoch 57, CIFAR-10 Batch 4:  Train_Loss:1.357492446899414, Valid_Loss:1.4769659042358398, Valid_ACC:0.5171999335289001
Epoch 57, CIFAR-10 Batch 5:  Train_Loss:1.3753435611724854, Valid_Loss:1.4652495384216309, Valid_ACC:0.5215999484062195
Epoch 58, CIFAR-10 Batch 1:  Train_Loss:1.3535652160644531, Valid_Loss:1.4661165475845337, Valid_ACC:0.519399881362915
Epoch 58, CIFAR-10 Batch 2:  Train_Loss:1.3578029870986938, Valid_Loss:1.4609076976776123, Valid_ACC:0.5231999158859253
Epoch 58, CIFAR-10 Batch 3:  Train_Loss:1.3219680786132812, Valid_Loss:1.4680440425872803, Valid_ACC:0.5191999673843384
Epoch 58, CIFAR-10 Batch 4:  Train_Loss:1.3644850254058838, Valid_Loss:1.4788724184036255, Valid_ACC:0.5195999145507812
Epoch 58, CIFAR-10 Batch 5:  Train_Loss:1.3789647817611694, Valid_Loss:1.4821372032165527, Valid_ACC:0.5163999795913696
Epoch 59, CIFAR-10 Batch 1:  Train_Loss:1.3586355447769165, Valid_Loss:1.4624086618423462, Valid_ACC:0.5213999152183533
Epoch 59, CIFAR-10 Batch 2:  Train_Loss:1.3632276058197021, Valid_Loss:1.4735668897628784, Valid_ACC:0.5151999592781067
Epoch 59, CIFAR-10 Batch 3:  Train_Loss:1.3174490928649902, Valid_Loss:1.4639651775360107, Valid_ACC:0.5184000134468079
Epoch 59, CIFAR-10 Batch 4:  Train_Loss:1.3578249216079712, Valid_Loss:1.4730606079101562, Valid_ACC:0.5145999789237976
Epoch 59, CIFAR-10 Batch 5:  Train_Loss:1.3805173635482788, Valid_Loss:1.461614727973938, Valid_ACC:0.5209999680519104
Epoch 60, CIFAR-10 Batch 1:  Train_Loss:1.3447178602218628, Valid_Loss:1.4602484703063965, Valid_ACC:0.5229999423027039
Epoch 60, CIFAR-10 Batch 2:  Train_Loss:1.3529030084609985, Valid_Loss:1.466101050376892, Valid_ACC:0.5227999091148376
Epoch 60, CIFAR-10 Batch 3:  Train_Loss:1.3155056238174438, Valid_Loss:1.4591302871704102, Valid_ACC:0.5203999280929565
Epoch 60, CIFAR-10 Batch 4:  Train_Loss:1.358593463897705, Valid_Loss:1.477083444595337, Valid_ACC:0.5195999145507812
Epoch 60, CIFAR-10 Batch 5:  Train_Loss:1.365346908569336, Valid_Loss:1.4606972932815552, Valid_ACC:0.5255999565124512
Epoch 61, CIFAR-10 Batch 1:  Train_Loss:1.3446037769317627, Valid_Loss:1.4644272327423096, Valid_ACC:0.5179999470710754
Epoch 61, CIFAR-10 Batch 2:  Train_Loss:1.3629200458526611, Valid_Loss:1.473111629486084, Valid_ACC:0.5199999213218689
Epoch 61, CIFAR-10 Batch 3:  Train_Loss:1.31427800655365, Valid_Loss:1.4588251113891602, Valid_ACC:0.5203999876976013
Epoch 61, CIFAR-10 Batch 4:  Train_Loss:1.3508867025375366, Valid_Loss:1.4735661745071411, Valid_ACC:0.5201999545097351
Epoch 61, CIFAR-10 Batch 5:  Train_Loss:1.3643193244934082, Valid_Loss:1.4594579935073853, Valid_ACC:0.5255999565124512
Epoch 62, CIFAR-10 Batch 1:  Train_Loss:1.345930814743042, Valid_Loss:1.4641766548156738, Valid_ACC:0.5205999612808228
Epoch 62, CIFAR-10 Batch 2:  Train_Loss:1.3545453548431396, Valid_Loss:1.4695826768875122, Valid_ACC:0.5185999274253845
Epoch 62, CIFAR-10 Batch 3:  Train_Loss:1.3130319118499756, Valid_Loss:1.4626048803329468, Valid_ACC:0.5231999754905701
Epoch 62, CIFAR-10 Batch 4:  Train_Loss:1.3533189296722412, Valid_Loss:1.4766695499420166, Valid_ACC:0.5195999145507812
Epoch 62, CIFAR-10 Batch 5:  Train_Loss:1.3611851930618286, Valid_Loss:1.456687569618225, Valid_ACC:0.5259999632835388
Epoch 63, CIFAR-10 Batch 1:  Train_Loss:1.3417390584945679, Valid_Loss:1.4556142091751099, Valid_ACC:0.5249999761581421
Epoch 63, CIFAR-10 Batch 2:  Train_Loss:1.348191738128662, Valid_Loss:1.4627412557601929, Valid_ACC:0.5223999619483948
Epoch 63, CIFAR-10 Batch 3:  Train_Loss:1.3140668869018555, Valid_Loss:1.463683843612671, Valid_ACC:0.5181999206542969
Epoch 63, CIFAR-10 Batch 4:  Train_Loss:1.3508388996124268, Valid_Loss:1.4716778993606567, Valid_ACC:0.5183999538421631
Epoch 63, CIFAR-10 Batch 5:  Train_Loss:1.3656678199768066, Valid_Loss:1.4578505754470825, Valid_ACC:0.5261999368667603
Epoch 64, CIFAR-10 Batch 1:  Train_Loss:1.3434057235717773, Valid_Loss:1.4545952081680298, Valid_ACC:0.5247998833656311
Epoch 64, CIFAR-10 Batch 2:  Train_Loss:1.335890293121338, Valid_Loss:1.453657865524292, Valid_ACC:0.5217999219894409
Epoch 64, CIFAR-10 Batch 3:  Train_Loss:1.303016185760498, Valid_Loss:1.453190565109253, Valid_ACC:0.5197999477386475
Epoch 64, CIFAR-10 Batch 4:  Train_Loss:1.329451560974121, Valid_Loss:1.4532170295715332, Valid_ACC:0.5239999294281006
Epoch 64, CIFAR-10 Batch 5:  Train_Loss:1.3473576307296753, Valid_Loss:1.4473048448562622, Valid_ACC:0.5265998840332031
Epoch 65, CIFAR-10 Batch 1:  Train_Loss:1.3361036777496338, Valid_Loss:1.4569226503372192, Valid_ACC:0.5203999280929565
Epoch 65, CIFAR-10 Batch 2:  Train_Loss:1.3463668823242188, Valid_Loss:1.4632432460784912, Valid_ACC:0.5263999700546265
Epoch 65, CIFAR-10 Batch 3:  Train_Loss:1.3019883632659912, Valid_Loss:1.4525160789489746, Valid_ACC:0.5255999565124512
Epoch 65, CIFAR-10 Batch 4:  Train_Loss:1.3526458740234375, Valid_Loss:1.4795414209365845, Valid_ACC:0.5179999470710754
Epoch 65, CIFAR-10 Batch 5:  Train_Loss:1.355346918106079, Valid_Loss:1.4652289152145386, Valid_ACC:0.5263999104499817
Epoch 66, CIFAR-10 Batch 1:  Train_Loss:1.3348298072814941, Valid_Loss:1.4511629343032837, Valid_ACC:0.5247999429702759
Epoch 66, CIFAR-10 Batch 2:  Train_Loss:1.3316792249679565, Valid_Loss:1.451253056526184, Valid_ACC:0.5239999294281006
Epoch 66, CIFAR-10 Batch 3:  Train_Loss:1.30190110206604, Valid_Loss:1.4508960247039795, Valid_ACC:0.5215999484062195
Epoch 66, CIFAR-10 Batch 4:  Train_Loss:1.3395918607711792, Valid_Loss:1.4685696363449097, Valid_ACC:0.5195999145507812
Epoch 66, CIFAR-10 Batch 5:  Train_Loss:1.348142147064209, Valid_Loss:1.456945538520813, Valid_ACC:0.5265998840332031
Epoch 67, CIFAR-10 Batch 1:  Train_Loss:1.3341399431228638, Valid_Loss:1.4483363628387451, Valid_ACC:0.5263999104499817
Epoch 67, CIFAR-10 Batch 2:  Train_Loss:1.3332278728485107, Valid_Loss:1.451267957687378, Valid_ACC:0.5239999294281006
Epoch 67, CIFAR-10 Batch 3:  Train_Loss:1.2953132390975952, Valid_Loss:1.4462658166885376, Valid_ACC:0.5239999294281006
Epoch 67, CIFAR-10 Batch 4:  Train_Loss:1.3356921672821045, Valid_Loss:1.462551474571228, Valid_ACC:0.5265999436378479
Epoch 67, CIFAR-10 Batch 5:  Train_Loss:1.3473058938980103, Valid_Loss:1.4572148323059082, Valid_ACC:0.5255998969078064
Epoch 68, CIFAR-10 Batch 1:  Train_Loss:1.3321659564971924, Valid_Loss:1.442112684249878, Valid_ACC:0.5281999707221985
Epoch 68, CIFAR-10 Batch 2:  Train_Loss:1.329904556274414, Valid_Loss:1.4450467824935913, Valid_ACC:0.5321999192237854
Epoch 68, CIFAR-10 Batch 3:  Train_Loss:1.2975120544433594, Valid_Loss:1.4491431713104248, Valid_ACC:0.5239999294281006
Epoch 68, CIFAR-10 Batch 4:  Train_Loss:1.3151764869689941, Valid_Loss:1.4478747844696045, Valid_ACC:0.5247999429702759
Epoch 68, CIFAR-10 Batch 5:  Train_Loss:1.3381086587905884, Valid_Loss:1.4495623111724854, Valid_ACC:0.5303999185562134
Epoch 69, CIFAR-10 Batch 1:  Train_Loss:1.3423168659210205, Valid_Loss:1.463050127029419, Valid_ACC:0.5173999667167664
Epoch 69, CIFAR-10 Batch 2:  Train_Loss:1.3547877073287964, Valid_Loss:1.4752689599990845, Valid_ACC:0.5193999409675598
Epoch 69, CIFAR-10 Batch 3:  Train_Loss:1.3094664812088013, Valid_Loss:1.4576483964920044, Valid_ACC:0.5163999199867249
Epoch 69, CIFAR-10 Batch 4:  Train_Loss:1.326667070388794, Valid_Loss:1.4583114385604858, Valid_ACC:0.5231999158859253
Epoch 69, CIFAR-10 Batch 5:  Train_Loss:1.3336974382400513, Valid_Loss:1.4389972686767578, Valid_ACC:0.5321999788284302
Epoch 70, CIFAR-10 Batch 1:  Train_Loss:1.328390121459961, Valid_Loss:1.4511299133300781, Valid_ACC:0.5215999484062195
Epoch 70, CIFAR-10 Batch 2:  Train_Loss:1.319382667541504, Valid_Loss:1.4433923959732056, Valid_ACC:0.5273999571800232
Epoch 70, CIFAR-10 Batch 3:  Train_Loss:1.2910982370376587, Valid_Loss:1.4434748888015747, Valid_ACC:0.525399923324585
Epoch 70, CIFAR-10 Batch 4:  Train_Loss:1.3250906467437744, Valid_Loss:1.4532870054244995, Valid_ACC:0.5261999368667603
Epoch 70, CIFAR-10 Batch 5:  Train_Loss:1.3349215984344482, Valid_Loss:1.4469773769378662, Valid_ACC:0.5309999585151672
Epoch 71, CIFAR-10 Batch 1:  Train_Loss:1.3331266641616821, Valid_Loss:1.4505292177200317, Valid_ACC:0.5245999097824097
Epoch 71, CIFAR-10 Batch 2:  Train_Loss:1.3047206401824951, Valid_Loss:1.4348723888397217, Valid_ACC:0.5305999517440796
Epoch 71, CIFAR-10 Batch 3:  Train_Loss:1.295731782913208, Valid_Loss:1.447097659111023, Valid_ACC:0.5187999606132507
Epoch 71, CIFAR-10 Batch 4:  Train_Loss:1.3109867572784424, Valid_Loss:1.443651795387268, Valid_ACC:0.5277999639511108
Epoch 71, CIFAR-10 Batch 5:  Train_Loss:1.3320066928863525, Valid_Loss:1.4431334733963013, Valid_ACC:0.5299999713897705
Epoch 72, CIFAR-10 Batch 1:  Train_Loss:1.3193378448486328, Valid_Loss:1.4394807815551758, Valid_ACC:0.5251998901367188
Epoch 72, CIFAR-10 Batch 2:  Train_Loss:1.3159682750701904, Valid_Loss:1.4405028820037842, Valid_ACC:0.527199923992157
Epoch 72, CIFAR-10 Batch 3:  Train_Loss:1.2941341400146484, Valid_Loss:1.448575735092163, Valid_ACC:0.5221999883651733
Epoch 72, CIFAR-10 Batch 4:  Train_Loss:1.321182370185852, Valid_Loss:1.4494999647140503, Valid_ACC:0.5255999565124512
Epoch 72, CIFAR-10 Batch 5:  Train_Loss:1.3324896097183228, Valid_Loss:1.4472647905349731, Valid_ACC:0.5291999578475952
Epoch 73, CIFAR-10 Batch 1:  Train_Loss:1.3053430318832397, Valid_Loss:1.4346923828125, Valid_ACC:0.5283999443054199
Epoch 73, CIFAR-10 Batch 2:  Train_Loss:1.309525489807129, Valid_Loss:1.4389177560806274, Valid_ACC:0.5285999774932861
Epoch 73, CIFAR-10 Batch 3:  Train_Loss:1.2775177955627441, Valid_Loss:1.4381263256072998, Valid_ACC:0.5263999104499817
Epoch 73, CIFAR-10 Batch 4:  Train_Loss:1.3063368797302246, Valid_Loss:1.4379607439041138, Valid_ACC:0.5335999727249146
Epoch 73, CIFAR-10 Batch 5:  Train_Loss:1.333125114440918, Valid_Loss:1.45018470287323, Valid_ACC:0.5281999111175537
Epoch 74, CIFAR-10 Batch 1:  Train_Loss:1.3121867179870605, Valid_Loss:1.4432742595672607, Valid_ACC:0.5241999626159668
Epoch 74, CIFAR-10 Batch 2:  Train_Loss:1.3277063369750977, Valid_Loss:1.455482840538025, Valid_ACC:0.5225999355316162
Epoch 74, CIFAR-10 Batch 3:  Train_Loss:1.2790801525115967, Valid_Loss:1.440050721168518, Valid_ACC:0.5299999713897705
Epoch 74, CIFAR-10 Batch 4:  Train_Loss:1.3093490600585938, Valid_Loss:1.4462922811508179, Valid_ACC:0.5275999307632446
Epoch 74, CIFAR-10 Batch 5:  Train_Loss:1.321061134338379, Valid_Loss:1.4373791217803955, Valid_ACC:0.5293999910354614
Epoch 75, CIFAR-10 Batch 1:  Train_Loss:1.3072417974472046, Valid_Loss:1.434329628944397, Valid_ACC:0.5279999375343323
Epoch 75, CIFAR-10 Batch 2:  Train_Loss:1.3129587173461914, Valid_Loss:1.4485385417938232, Valid_ACC:0.5219999551773071
Epoch 75, CIFAR-10 Batch 3:  Train_Loss:1.2653822898864746, Valid_Loss:1.4336124658584595, Valid_ACC:0.5257999897003174
Epoch 75, CIFAR-10 Batch 4:  Train_Loss:1.32364022731781, Valid_Loss:1.4582618474960327, Valid_ACC:0.5203999280929565
Epoch 75, CIFAR-10 Batch 5:  Train_Loss:1.3261394500732422, Valid_Loss:1.4505541324615479, Valid_ACC:0.5279999375343323
Epoch 76, CIFAR-10 Batch 1:  Train_Loss:1.3221036195755005, Valid_Loss:1.4549050331115723, Valid_ACC:0.5201999545097351
Epoch 76, CIFAR-10 Batch 2:  Train_Loss:1.3242640495300293, Valid_Loss:1.449938178062439, Valid_ACC:0.5281999111175537
Epoch 76, CIFAR-10 Batch 3:  Train_Loss:1.2930433750152588, Valid_Loss:1.4494537115097046, Valid_ACC:0.5219999551773071
Epoch 76, CIFAR-10 Batch 4:  Train_Loss:1.3115676641464233, Valid_Loss:1.450906753540039, Valid_ACC:0.5255999565124512
Epoch 76, CIFAR-10 Batch 5:  Train_Loss:1.3254395723342896, Valid_Loss:1.4425491094589233, Valid_ACC:0.5299999117851257
Epoch 77, CIFAR-10 Batch 1:  Train_Loss:1.29933762550354, Valid_Loss:1.437870740890503, Valid_ACC:0.5305999517440796
Epoch 77, CIFAR-10 Batch 2:  Train_Loss:1.305272102355957, Valid_Loss:1.435297966003418, Valid_ACC:0.5279999375343323
Epoch 77, CIFAR-10 Batch 3:  Train_Loss:1.2624456882476807, Valid_Loss:1.4326900243759155, Valid_ACC:0.5299999713897705
Epoch 77, CIFAR-10 Batch 4:  Train_Loss:1.2949378490447998, Valid_Loss:1.435104489326477, Valid_ACC:0.5281999111175537
Epoch 77, CIFAR-10 Batch 5:  Train_Loss:1.3140041828155518, Valid_Loss:1.4339120388031006, Valid_ACC:0.5305999517440796
Epoch 78, CIFAR-10 Batch 1:  Train_Loss:1.291846513748169, Valid_Loss:1.4365249872207642, Valid_ACC:0.5299999713897705
Epoch 78, CIFAR-10 Batch 2:  Train_Loss:1.3006072044372559, Valid_Loss:1.435798168182373, Valid_ACC:0.5279999375343323
Epoch 78, CIFAR-10 Batch 3:  Train_Loss:1.2713149785995483, Valid_Loss:1.4361964464187622, Valid_ACC:0.5243999361991882
Epoch 78, CIFAR-10 Batch 4:  Train_Loss:1.3022823333740234, Valid_Loss:1.4427372217178345, Valid_ACC:0.5263999104499817
Epoch 78, CIFAR-10 Batch 5:  Train_Loss:1.3115959167480469, Valid_Loss:1.4329057931900024, Valid_ACC:0.531999945640564
Epoch 79, CIFAR-10 Batch 1:  Train_Loss:1.2869293689727783, Valid_Loss:1.430375576019287, Valid_ACC:0.5271999835968018
Epoch 79, CIFAR-10 Batch 2:  Train_Loss:1.3326433897018433, Valid_Loss:1.4677995443344116, Valid_ACC:0.515999972820282
Epoch 79, CIFAR-10 Batch 3:  Train_Loss:1.2684109210968018, Valid_Loss:1.4458564519882202, Valid_ACC:0.5255999565124512
Epoch 79, CIFAR-10 Batch 4:  Train_Loss:1.2885844707489014, Valid_Loss:1.4364269971847534, Valid_ACC:0.527999997138977
Epoch 79, CIFAR-10 Batch 5:  Train_Loss:1.319077968597412, Valid_Loss:1.4221301078796387, Valid_ACC:0.5339999198913574
Epoch 80, CIFAR-10 Batch 1:  Train_Loss:1.2873477935791016, Valid_Loss:1.432861328125, Valid_ACC:0.5295999050140381
Epoch 80, CIFAR-10 Batch 2:  Train_Loss:1.3000165224075317, Valid_Loss:1.4387149810791016, Valid_ACC:0.5247999429702759
Epoch 80, CIFAR-10 Batch 3:  Train_Loss:1.258432149887085, Valid_Loss:1.4422581195831299, Valid_ACC:0.5273999571800232
Epoch 80, CIFAR-10 Batch 4:  Train_Loss:1.2992480993270874, Valid_Loss:1.4409782886505127, Valid_ACC:0.5283999443054199
Epoch 80, CIFAR-10 Batch 5:  Train_Loss:1.3122483491897583, Valid_Loss:1.426626443862915, Valid_ACC:0.5359999537467957
Epoch 81, CIFAR-10 Batch 1:  Train_Loss:1.2885724306106567, Valid_Loss:1.4352612495422363, Valid_ACC:0.5287998914718628
Epoch 81, CIFAR-10 Batch 2:  Train_Loss:1.3073062896728516, Valid_Loss:1.4418772459030151, Valid_ACC:0.5291998982429504
Epoch 81, CIFAR-10 Batch 3:  Train_Loss:1.2531726360321045, Valid_Loss:1.4300129413604736, Valid_ACC:0.528999924659729
Epoch 81, CIFAR-10 Batch 4:  Train_Loss:1.2900421619415283, Valid_Loss:1.4366474151611328, Valid_ACC:0.5293999314308167
Epoch 81, CIFAR-10 Batch 5:  Train_Loss:1.3034802675247192, Valid_Loss:1.4410773515701294, Valid_ACC:0.5269999504089355
Epoch 82, CIFAR-10 Batch 1:  Train_Loss:1.2884353399276733, Valid_Loss:1.4426417350769043, Valid_ACC:0.521399974822998
Epoch 82, CIFAR-10 Batch 2:  Train_Loss:1.3073316812515259, Valid_Loss:1.4416941404342651, Valid_ACC:0.5273999571800232
Epoch 82, CIFAR-10 Batch 3:  Train_Loss:1.268510341644287, Valid_Loss:1.4464937448501587, Valid_ACC:0.5233999490737915
Epoch 82, CIFAR-10 Batch 4:  Train_Loss:1.3041963577270508, Valid_Loss:1.4467878341674805, Valid_ACC:0.5243999361991882
Epoch 82, CIFAR-10 Batch 5:  Train_Loss:1.3158682584762573, Valid_Loss:1.4418872594833374, Valid_ACC:0.5305999517440796
Epoch 83, CIFAR-10 Batch 1:  Train_Loss:1.2885842323303223, Valid_Loss:1.4403188228607178, Valid_ACC:0.5241999626159668
Epoch 83, CIFAR-10 Batch 2:  Train_Loss:1.3030335903167725, Valid_Loss:1.436090111732483, Valid_ACC:0.5299999713897705
Epoch 83, CIFAR-10 Batch 3:  Train_Loss:1.280587911605835, Valid_Loss:1.4517590999603271, Valid_ACC:0.5203999876976013
Epoch 83, CIFAR-10 Batch 4:  Train_Loss:1.294010043144226, Valid_Loss:1.439901351928711, Valid_ACC:0.5255999565124512
Epoch 83, CIFAR-10 Batch 5:  Train_Loss:1.3064262866973877, Valid_Loss:1.4340128898620605, Valid_ACC:0.5345999002456665
Epoch 84, CIFAR-10 Batch 1:  Train_Loss:1.2791327238082886, Valid_Loss:1.4286314249038696, Valid_ACC:0.5255999565124512
Epoch 84, CIFAR-10 Batch 2:  Train_Loss:1.2803735733032227, Valid_Loss:1.4234200716018677, Valid_ACC:0.5309999585151672
Epoch 84, CIFAR-10 Batch 3:  Train_Loss:1.2513995170593262, Valid_Loss:1.4258787631988525, Valid_ACC:0.5293999910354614
Epoch 84, CIFAR-10 Batch 4:  Train_Loss:1.293529748916626, Valid_Loss:1.437748670578003, Valid_ACC:0.5287998914718628
Epoch 84, CIFAR-10 Batch 5:  Train_Loss:1.3062100410461426, Valid_Loss:1.4266728162765503, Valid_ACC:0.5331999063491821
Epoch 85, CIFAR-10 Batch 1:  Train_Loss:1.2773147821426392, Valid_Loss:1.4330650568008423, Valid_ACC:0.5284000039100647
Epoch 85, CIFAR-10 Batch 2:  Train_Loss:1.2892460823059082, Valid_Loss:1.4361729621887207, Valid_ACC:0.5255999565124512
Epoch 85, CIFAR-10 Batch 3:  Train_Loss:1.2403564453125, Valid_Loss:1.4236679077148438, Valid_ACC:0.5313999652862549
Epoch 85, CIFAR-10 Batch 4:  Train_Loss:1.2911489009857178, Valid_Loss:1.4367237091064453, Valid_ACC:0.5323998928070068
Epoch 85, CIFAR-10 Batch 5:  Train_Loss:1.2960096597671509, Valid_Loss:1.4217718839645386, Valid_ACC:0.5361999273300171
Epoch 86, CIFAR-10 Batch 1:  Train_Loss:1.2732982635498047, Valid_Loss:1.4311258792877197, Valid_ACC:0.5281999111175537
Epoch 86, CIFAR-10 Batch 2:  Train_Loss:1.2870303392410278, Valid_Loss:1.4378762245178223, Valid_ACC:0.5257999300956726
Epoch 86, CIFAR-10 Batch 3:  Train_Loss:1.2366158962249756, Valid_Loss:1.4168223142623901, Valid_ACC:0.5349999666213989
Epoch 86, CIFAR-10 Batch 4:  Train_Loss:1.278910756111145, Valid_Loss:1.432422399520874, Valid_ACC:0.5305999517440796
Epoch 86, CIFAR-10 Batch 5:  Train_Loss:1.297186017036438, Valid_Loss:1.4394813776016235, Valid_ACC:0.5291999578475952
Epoch 87, CIFAR-10 Batch 1:  Train_Loss:1.2703983783721924, Valid_Loss:1.428444266319275, Valid_ACC:0.5301998853683472
Epoch 87, CIFAR-10 Batch 2:  Train_Loss:1.2736289501190186, Valid_Loss:1.424655795097351, Valid_ACC:0.5317999124526978
Epoch 87, CIFAR-10 Batch 3:  Train_Loss:1.2489956617355347, Valid_Loss:1.4261679649353027, Valid_ACC:0.5309998989105225
Epoch 87, CIFAR-10 Batch 4:  Train_Loss:1.2832541465759277, Valid_Loss:1.4338445663452148, Valid_ACC:0.5285999774932861
Epoch 87, CIFAR-10 Batch 5:  Train_Loss:1.2991622686386108, Valid_Loss:1.4245359897613525, Valid_ACC:0.5327999591827393
Epoch 88, CIFAR-10 Batch 1:  Train_Loss:1.2593014240264893, Valid_Loss:1.4211668968200684, Valid_ACC:0.5335999131202698
Epoch 88, CIFAR-10 Batch 2:  Train_Loss:1.271938681602478, Valid_Loss:1.4198988676071167, Valid_ACC:0.5349999666213989
Epoch 88, CIFAR-10 Batch 3:  Train_Loss:1.2300713062286377, Valid_Loss:1.4166264533996582, Valid_ACC:0.5325999855995178
Epoch 88, CIFAR-10 Batch 4:  Train_Loss:1.2747855186462402, Valid_Loss:1.4301421642303467, Valid_ACC:0.528999924659729
Epoch 88, CIFAR-10 Batch 5:  Train_Loss:1.2905242443084717, Valid_Loss:1.4321858882904053, Valid_ACC:0.532599925994873
Epoch 89, CIFAR-10 Batch 1:  Train_Loss:1.2731561660766602, Valid_Loss:1.43403160572052, Valid_ACC:0.5265999436378479
Epoch 89, CIFAR-10 Batch 2:  Train_Loss:1.2733750343322754, Valid_Loss:1.422275185585022, Valid_ACC:0.5327999591827393
Epoch 89, CIFAR-10 Batch 3:  Train_Loss:1.2371721267700195, Valid_Loss:1.421211838722229, Valid_ACC:0.5349999070167542
Epoch 89, CIFAR-10 Batch 4:  Train_Loss:1.2810615301132202, Valid_Loss:1.4338457584381104, Valid_ACC:0.528999924659729
Epoch 89, CIFAR-10 Batch 5:  Train_Loss:1.2880074977874756, Valid_Loss:1.4161850214004517, Valid_ACC:0.5343999862670898
Epoch 90, CIFAR-10 Batch 1:  Train_Loss:1.2659902572631836, Valid_Loss:1.4285147190093994, Valid_ACC:0.5309998989105225
Epoch 90, CIFAR-10 Batch 2:  Train_Loss:1.2843748331069946, Valid_Loss:1.4326575994491577, Valid_ACC:0.5257999300956726
Epoch 90, CIFAR-10 Batch 3:  Train_Loss:1.222640037536621, Valid_Loss:1.4136927127838135, Valid_ACC:0.5371999740600586
Epoch 90, CIFAR-10 Batch 4:  Train_Loss:1.2806493043899536, Valid_Loss:1.4337425231933594, Valid_ACC:0.5317999124526978
Epoch 90, CIFAR-10 Batch 5:  Train_Loss:1.2826173305511475, Valid_Loss:1.4160534143447876, Valid_ACC:0.5387998819351196
Epoch 91, CIFAR-10 Batch 1:  Train_Loss:1.257478952407837, Valid_Loss:1.4255205392837524, Valid_ACC:0.5317999124526978
Epoch 91, CIFAR-10 Batch 2:  Train_Loss:1.2750102281570435, Valid_Loss:1.4301303625106812, Valid_ACC:0.5291999578475952
Epoch 91, CIFAR-10 Batch 3:  Train_Loss:1.2363371849060059, Valid_Loss:1.419932246208191, Valid_ACC:0.5317999124526978
Epoch 91, CIFAR-10 Batch 4:  Train_Loss:1.2865030765533447, Valid_Loss:1.4408297538757324, Valid_ACC:0.5267999172210693
Epoch 91, CIFAR-10 Batch 5:  Train_Loss:1.2911731004714966, Valid_Loss:1.4212815761566162, Valid_ACC:0.5381999611854553
Epoch 92, CIFAR-10 Batch 1:  Train_Loss:1.264076828956604, Valid_Loss:1.4192173480987549, Valid_ACC:0.5393999218940735
Epoch 92, CIFAR-10 Batch 2:  Train_Loss:1.2563951015472412, Valid_Loss:1.4172463417053223, Valid_ACC:0.5315999388694763
Epoch 92, CIFAR-10 Batch 3:  Train_Loss:1.2263638973236084, Valid_Loss:1.4120458364486694, Valid_ACC:0.5345999002456665
Epoch 92, CIFAR-10 Batch 4:  Train_Loss:1.2695653438568115, Valid_Loss:1.4265568256378174, Valid_ACC:0.5341999530792236
Epoch 92, CIFAR-10 Batch 5:  Train_Loss:1.2887485027313232, Valid_Loss:1.4283549785614014, Valid_ACC:0.5331999063491821
Epoch 93, CIFAR-10 Batch 1:  Train_Loss:1.2574126720428467, Valid_Loss:1.4346015453338623, Valid_ACC:0.5281999707221985
Epoch 93, CIFAR-10 Batch 2:  Train_Loss:1.267478585243225, Valid_Loss:1.4249831438064575, Valid_ACC:0.532599925994873
Epoch 93, CIFAR-10 Batch 3:  Train_Loss:1.221901774406433, Valid_Loss:1.4126505851745605, Valid_ACC:0.5363999605178833
Epoch 93, CIFAR-10 Batch 4:  Train_Loss:1.259556770324707, Valid_Loss:1.4206292629241943, Valid_ACC:0.5347999334335327
Epoch 93, CIFAR-10 Batch 5:  Train_Loss:1.2743966579437256, Valid_Loss:1.4087135791778564, Valid_ACC:0.5393999218940735
Epoch 94, CIFAR-10 Batch 1:  Train_Loss:1.2421314716339111, Valid_Loss:1.4112035036087036, Valid_ACC:0.5363999605178833
Epoch 94, CIFAR-10 Batch 2:  Train_Loss:1.2551672458648682, Valid_Loss:1.4126317501068115, Valid_ACC:0.5379999279975891
Epoch 94, CIFAR-10 Batch 3:  Train_Loss:1.2224326133728027, Valid_Loss:1.415114164352417, Valid_ACC:0.5347999930381775
Epoch 94, CIFAR-10 Batch 4:  Train_Loss:1.2494935989379883, Valid_Loss:1.4143226146697998, Valid_ACC:0.5369999408721924
Epoch 94, CIFAR-10 Batch 5:  Train_Loss:1.2842369079589844, Valid_Loss:1.430747628211975, Valid_ACC:0.5335999131202698
Epoch 95, CIFAR-10 Batch 1:  Train_Loss:1.2459125518798828, Valid_Loss:1.418489933013916, Valid_ACC:0.5329999923706055
Epoch 95, CIFAR-10 Batch 2:  Train_Loss:1.273505449295044, Valid_Loss:1.42307710647583, Valid_ACC:0.5285999774932861
Epoch 95, CIFAR-10 Batch 3:  Train_Loss:1.2352572679519653, Valid_Loss:1.4211902618408203, Valid_ACC:0.5283999443054199
Epoch 95, CIFAR-10 Batch 4:  Train_Loss:1.2611533403396606, Valid_Loss:1.4312678575515747, Valid_ACC:0.5279999375343323
Epoch 95, CIFAR-10 Batch 5:  Train_Loss:1.2726620435714722, Valid_Loss:1.4155192375183105, Valid_ACC:0.5371999144554138
Epoch 96, CIFAR-10 Batch 1:  Train_Loss:1.2538230419158936, Valid_Loss:1.4322558641433716, Valid_ACC:0.5261999368667603
Epoch 96, CIFAR-10 Batch 2:  Train_Loss:1.2740291357040405, Valid_Loss:1.4280587434768677, Valid_ACC:0.5287999510765076
Epoch 96, CIFAR-10 Batch 3:  Train_Loss:1.2266703844070435, Valid_Loss:1.4179511070251465, Valid_ACC:0.5327999591827393
Epoch 96, CIFAR-10 Batch 4:  Train_Loss:1.2722208499908447, Valid_Loss:1.4319819211959839, Valid_ACC:0.5279999375343323
Epoch 96, CIFAR-10 Batch 5:  Train_Loss:1.2737720012664795, Valid_Loss:1.412575364112854, Valid_ACC:0.5377998948097229
Epoch 97, CIFAR-10 Batch 1:  Train_Loss:1.2413585186004639, Valid_Loss:1.4078466892242432, Valid_ACC:0.5367999076843262
Epoch 97, CIFAR-10 Batch 2:  Train_Loss:1.2487891912460327, Valid_Loss:1.41157865524292, Valid_ACC:0.5341999530792236
Epoch 97, CIFAR-10 Batch 3:  Train_Loss:1.2153717279434204, Valid_Loss:1.412437081336975, Valid_ACC:0.5335999727249146
Epoch 97, CIFAR-10 Batch 4:  Train_Loss:1.2715998888015747, Valid_Loss:1.4268989562988281, Valid_ACC:0.5317999124526978
Epoch 97, CIFAR-10 Batch 5:  Train_Loss:1.2796404361724854, Valid_Loss:1.4280030727386475, Valid_ACC:0.5331999063491821
Epoch 98, CIFAR-10 Batch 1:  Train_Loss:1.2521114349365234, Valid_Loss:1.4240000247955322, Valid_ACC:0.5325999855995178
Epoch 98, CIFAR-10 Batch 2:  Train_Loss:1.2596793174743652, Valid_Loss:1.4182339906692505, Valid_ACC:0.5365999937057495
Epoch 98, CIFAR-10 Batch 3:  Train_Loss:1.2247473001480103, Valid_Loss:1.4180562496185303, Valid_ACC:0.5317999720573425
Epoch 98, CIFAR-10 Batch 4:  Train_Loss:1.2692227363586426, Valid_Loss:1.4367179870605469, Valid_ACC:0.5265998840332031
Epoch 98, CIFAR-10 Batch 5:  Train_Loss:1.2778130769729614, Valid_Loss:1.4287102222442627, Valid_ACC:0.5357999801635742
Epoch 99, CIFAR-10 Batch 1:  Train_Loss:1.2333875894546509, Valid_Loss:1.4110745191574097, Valid_ACC:0.5331999063491821
Epoch 99, CIFAR-10 Batch 2:  Train_Loss:1.2491180896759033, Valid_Loss:1.41205632686615, Valid_ACC:0.5357999801635742
Epoch 99, CIFAR-10 Batch 3:  Train_Loss:1.205514907836914, Valid_Loss:1.4060323238372803, Valid_ACC:0.5377999544143677
Epoch 99, CIFAR-10 Batch 4:  Train_Loss:1.2366530895233154, Valid_Loss:1.4127845764160156, Valid_ACC:0.5395999550819397
Epoch 99, CIFAR-10 Batch 5:  Train_Loss:1.281870722770691, Valid_Loss:1.4267081022262573, Valid_ACC:0.5335999727249146
Epoch 100, CIFAR-10 Batch 1:  Train_Loss:1.247654676437378, Valid_Loss:1.419743299484253, Valid_ACC:0.5335999727249146
Epoch 100, CIFAR-10 Batch 2:  Train_Loss:1.2581682205200195, Valid_Loss:1.4192593097686768, Valid_ACC:0.5307999849319458
Epoch 100, CIFAR-10 Batch 3:  Train_Loss:1.2076166868209839, Valid_Loss:1.409597635269165, Valid_ACC:0.5385999083518982
Epoch 100, CIFAR-10 Batch 4:  Train_Loss:1.2562813758850098, Valid_Loss:1.423654556274414, Valid_ACC:0.5377999544143677
Epoch 100, CIFAR-10 Batch 5:  Train_Loss:1.262937068939209, Valid_Loss:1.412942886352539, Valid_ACC:0.5379999279975891
Epoch 101, CIFAR-10 Batch 1:  Train_Loss:1.2270231246948242, Valid_Loss:1.4079409837722778, Valid_ACC:0.538599967956543
Epoch 101, CIFAR-10 Batch 2:  Train_Loss:1.2415599822998047, Valid_Loss:1.4124667644500732, Valid_ACC:0.5351999402046204
Epoch 101, CIFAR-10 Batch 3:  Train_Loss:1.1951394081115723, Valid_Loss:1.4058221578598022, Valid_ACC:0.5389999151229858
Epoch 101, CIFAR-10 Batch 4:  Train_Loss:1.2553739547729492, Valid_Loss:1.421976089477539, Valid_ACC:0.53739994764328
Epoch 101, CIFAR-10 Batch 5:  Train_Loss:1.2672263383865356, Valid_Loss:1.4088541269302368, Valid_ACC:0.5415999889373779
Epoch 102, CIFAR-10 Batch 1:  Train_Loss:1.2547916173934937, Valid_Loss:1.4555456638336182, Valid_ACC:0.5212000012397766
Epoch 102, CIFAR-10 Batch 2:  Train_Loss:1.2406576871871948, Valid_Loss:1.4102485179901123, Valid_ACC:0.5385999083518982
Epoch 102, CIFAR-10 Batch 3:  Train_Loss:1.2015247344970703, Valid_Loss:1.4081974029541016, Valid_ACC:0.5389999151229858
Epoch 102, CIFAR-10 Batch 4:  Train_Loss:1.2429441213607788, Valid_Loss:1.4150824546813965, Valid_ACC:0.5379999279975891
Epoch 102, CIFAR-10 Batch 5:  Train_Loss:1.2573436498641968, Valid_Loss:1.4081954956054688, Valid_ACC:0.5399999022483826
Epoch 103, CIFAR-10 Batch 1:  Train_Loss:1.2226693630218506, Valid_Loss:1.4042093753814697, Valid_ACC:0.5397999286651611
Epoch 103, CIFAR-10 Batch 2:  Train_Loss:1.2447943687438965, Valid_Loss:1.409193515777588, Valid_ACC:0.5359998941421509
Epoch 103, CIFAR-10 Batch 3:  Train_Loss:1.202438473701477, Valid_Loss:1.4091274738311768, Valid_ACC:0.5387999415397644
Epoch 103, CIFAR-10 Batch 4:  Train_Loss:1.2398282289505005, Valid_Loss:1.4112695455551147, Valid_ACC:0.540399968624115
Epoch 103, CIFAR-10 Batch 5:  Train_Loss:1.2662523984909058, Valid_Loss:1.421130657196045, Valid_ACC:0.5360000133514404
Epoch 104, CIFAR-10 Batch 1:  Train_Loss:1.2277953624725342, Valid_Loss:1.404066562652588, Valid_ACC:0.542199969291687
Epoch 104, CIFAR-10 Batch 2:  Train_Loss:1.2407094240188599, Valid_Loss:1.4065074920654297, Valid_ACC:0.5365999341011047
Epoch 104, CIFAR-10 Batch 3:  Train_Loss:1.196237325668335, Valid_Loss:1.4041481018066406, Valid_ACC:0.5439999103546143
Epoch 104, CIFAR-10 Batch 4:  Train_Loss:1.2442138195037842, Valid_Loss:1.413918375968933, Valid_ACC:0.5375999212265015
Epoch 104, CIFAR-10 Batch 5:  Train_Loss:1.258775234222412, Valid_Loss:1.4126137495040894, Valid_ACC:0.5383999347686768
Epoch 105, CIFAR-10 Batch 1:  Train_Loss:1.2224009037017822, Valid_Loss:1.40794038772583, Valid_ACC:0.5353999733924866
Epoch 105, CIFAR-10 Batch 2:  Train_Loss:1.266432285308838, Valid_Loss:1.42216157913208, Valid_ACC:0.5313999652862549
Epoch 105, CIFAR-10 Batch 3:  Train_Loss:1.2007472515106201, Valid_Loss:1.410192608833313, Valid_ACC:0.536799967288971
Epoch 105, CIFAR-10 Batch 4:  Train_Loss:1.2428447008132935, Valid_Loss:1.4142885208129883, Valid_ACC:0.53739994764328
Epoch 105, CIFAR-10 Batch 5:  Train_Loss:1.27390456199646, Valid_Loss:1.4156372547149658, Valid_ACC:0.53739994764328
Epoch 106, CIFAR-10 Batch 1:  Train_Loss:1.2269282341003418, Valid_Loss:1.4148703813552856, Valid_ACC:0.5389999747276306
Epoch 106, CIFAR-10 Batch 2:  Train_Loss:1.2434306144714355, Valid_Loss:1.4117059707641602, Valid_ACC:0.5333999395370483
Epoch 106, CIFAR-10 Batch 3:  Train_Loss:1.1957521438598633, Valid_Loss:1.4038758277893066, Valid_ACC:0.5395998954772949
Epoch 106, CIFAR-10 Batch 4:  Train_Loss:1.2498270273208618, Valid_Loss:1.4181560277938843, Valid_ACC:0.5361999273300171
Epoch 106, CIFAR-10 Batch 5:  Train_Loss:1.2779450416564941, Valid_Loss:1.4245023727416992, Valid_ACC:0.5361999273300171
Epoch 107, CIFAR-10 Batch 1:  Train_Loss:1.2433578968048096, Valid_Loss:1.4413245916366577, Valid_ACC:0.52239990234375
Epoch 107, CIFAR-10 Batch 2:  Train_Loss:1.2440000772476196, Valid_Loss:1.4119455814361572, Valid_ACC:0.5403999090194702
Epoch 107, CIFAR-10 Batch 3:  Train_Loss:1.2130298614501953, Valid_Loss:1.4194599390029907, Valid_ACC:0.530799925327301
Epoch 107, CIFAR-10 Batch 4:  Train_Loss:1.2372548580169678, Valid_Loss:1.4132871627807617, Valid_ACC:0.538399875164032
Epoch 107, CIFAR-10 Batch 5:  Train_Loss:1.2586865425109863, Valid_Loss:1.413609266281128, Valid_ACC:0.5405999422073364
Epoch 108, CIFAR-10 Batch 1:  Train_Loss:1.2223575115203857, Valid_Loss:1.4066442251205444, Valid_ACC:0.5377999544143677
Epoch 108, CIFAR-10 Batch 2:  Train_Loss:1.2479875087738037, Valid_Loss:1.4107863903045654, Valid_ACC:0.5297999382019043
Epoch 108, CIFAR-10 Batch 3:  Train_Loss:1.1921842098236084, Valid_Loss:1.4095995426177979, Valid_ACC:0.5371999144554138
Epoch 108, CIFAR-10 Batch 4:  Train_Loss:1.2364543676376343, Valid_Loss:1.411525011062622, Valid_ACC:0.5395999550819397
Epoch 108, CIFAR-10 Batch 5:  Train_Loss:1.2608189582824707, Valid_Loss:1.4102208614349365, Valid_ACC:0.5403999090194702
Epoch 109, CIFAR-10 Batch 1:  Train_Loss:1.2223589420318604, Valid_Loss:1.4127378463745117, Valid_ACC:0.5379999876022339
Epoch 109, CIFAR-10 Batch 2:  Train_Loss:1.2469584941864014, Valid_Loss:1.4195793867111206, Valid_ACC:0.5307999849319458
Epoch 109, CIFAR-10 Batch 3:  Train_Loss:1.1826177835464478, Valid_Loss:1.4062069654464722, Valid_ACC:0.5397999286651611
Epoch 109, CIFAR-10 Batch 4:  Train_Loss:1.2713693380355835, Valid_Loss:1.4377706050872803, Valid_ACC:0.5293999910354614
Epoch 109, CIFAR-10 Batch 5:  Train_Loss:1.2535505294799805, Valid_Loss:1.4098199605941772, Valid_ACC:0.5367999076843262
Epoch 110, CIFAR-10 Batch 1:  Train_Loss:1.2192929983139038, Valid_Loss:1.414614200592041, Valid_ACC:0.5349999666213989
Epoch 110, CIFAR-10 Batch 2:  Train_Loss:1.2411069869995117, Valid_Loss:1.4141619205474854, Valid_ACC:0.5347999334335327
Epoch 110, CIFAR-10 Batch 3:  Train_Loss:1.1836137771606445, Valid_Loss:1.4028279781341553, Valid_ACC:0.5445999503135681
Epoch 110, CIFAR-10 Batch 4:  Train_Loss:1.2472915649414062, Valid_Loss:1.4176591634750366, Valid_ACC:0.5361999869346619
Epoch 110, CIFAR-10 Batch 5:  Train_Loss:1.257415533065796, Valid_Loss:1.426579475402832, Valid_ACC:0.5335999131202698
Epoch 111, CIFAR-10 Batch 1:  Train_Loss:1.2134088277816772, Valid_Loss:1.405522346496582, Valid_ACC:0.5429999828338623
Epoch 111, CIFAR-10 Batch 2:  Train_Loss:1.23324453830719, Valid_Loss:1.4044134616851807, Valid_ACC:0.5388000011444092
Epoch 111, CIFAR-10 Batch 3:  Train_Loss:1.1774168014526367, Valid_Loss:1.3996022939682007, Valid_ACC:0.5411999225616455
Epoch 111, CIFAR-10 Batch 4:  Train_Loss:1.2257028818130493, Valid_Loss:1.4054172039031982, Valid_ACC:0.5439999103546143
Epoch 111, CIFAR-10 Batch 5:  Train_Loss:1.2464715242385864, Valid_Loss:1.3987178802490234, Valid_ACC:0.5459998846054077
Epoch 112, CIFAR-10 Batch 1:  Train_Loss:1.1963300704956055, Valid_Loss:1.3970837593078613, Valid_ACC:0.5417999029159546
Epoch 112, CIFAR-10 Batch 2:  Train_Loss:1.2288215160369873, Valid_Loss:1.4026062488555908, Valid_ACC:0.5343999266624451
Epoch 112, CIFAR-10 Batch 3:  Train_Loss:1.1791934967041016, Valid_Loss:1.39998197555542, Valid_ACC:0.5393999814987183
Epoch 112, CIFAR-10 Batch 4:  Train_Loss:1.2145036458969116, Valid_Loss:1.3919142484664917, Valid_ACC:0.544999897480011
Epoch 112, CIFAR-10 Batch 5:  Train_Loss:1.2445886135101318, Valid_Loss:1.3995347023010254, Valid_ACC:0.5417999625205994
Epoch 113, CIFAR-10 Batch 1:  Train_Loss:1.2032185792922974, Valid_Loss:1.4051270484924316, Valid_ACC:0.5425999164581299
Epoch 113, CIFAR-10 Batch 2:  Train_Loss:1.2285370826721191, Valid_Loss:1.3997069597244263, Valid_ACC:0.5399999022483826
Epoch 113, CIFAR-10 Batch 3:  Train_Loss:1.1718332767486572, Valid_Loss:1.3936518430709839, Valid_ACC:0.5455999374389648
Epoch 113, CIFAR-10 Batch 4:  Train_Loss:1.225732445716858, Valid_Loss:1.4009987115859985, Valid_ACC:0.5459998846054077
Epoch 113, CIFAR-10 Batch 5:  Train_Loss:1.2452621459960938, Valid_Loss:1.4110877513885498, Valid_ACC:0.5401999354362488
Epoch 114, CIFAR-10 Batch 1:  Train_Loss:1.2000614404678345, Valid_Loss:1.4022092819213867, Valid_ACC:0.5445998907089233
Epoch 114, CIFAR-10 Batch 2:  Train_Loss:1.2270691394805908, Valid_Loss:1.4030389785766602, Valid_ACC:0.5375999212265015
Epoch 114, CIFAR-10 Batch 3:  Train_Loss:1.174733281135559, Valid_Loss:1.3957188129425049, Valid_ACC:0.5451999306678772
Epoch 114, CIFAR-10 Batch 4:  Train_Loss:1.2428641319274902, Valid_Loss:1.415968656539917, Valid_ACC:0.5377998948097229
Epoch 114, CIFAR-10 Batch 5:  Train_Loss:1.2393074035644531, Valid_Loss:1.3985507488250732, Valid_ACC:0.5435999631881714
Epoch 115, CIFAR-10 Batch 1:  Train_Loss:1.1979807615280151, Valid_Loss:1.4053964614868164, Valid_ACC:0.5405999422073364
Epoch 115, CIFAR-10 Batch 2:  Train_Loss:1.2389681339263916, Valid_Loss:1.4219307899475098, Valid_ACC:0.5293999314308167
Epoch 115, CIFAR-10 Batch 3:  Train_Loss:1.183617115020752, Valid_Loss:1.4069077968597412, Valid_ACC:0.5331999063491821
Epoch 115, CIFAR-10 Batch 4:  Train_Loss:1.2184317111968994, Valid_Loss:1.3986964225769043, Valid_ACC:0.5433999300003052
Epoch 115, CIFAR-10 Batch 5:  Train_Loss:1.2420992851257324, Valid_Loss:1.3953274488449097, Valid_ACC:0.5457999110221863
Epoch 116, CIFAR-10 Batch 1:  Train_Loss:1.1949435472488403, Valid_Loss:1.3955552577972412, Valid_ACC:0.5453999042510986
Epoch 116, CIFAR-10 Batch 2:  Train_Loss:1.2170803546905518, Valid_Loss:1.3971922397613525, Valid_ACC:0.5411999225616455
Epoch 116, CIFAR-10 Batch 3:  Train_Loss:1.174616813659668, Valid_Loss:1.3967113494873047, Valid_ACC:0.5451999306678772
Epoch 116, CIFAR-10 Batch 4:  Train_Loss:1.2233576774597168, Valid_Loss:1.4048726558685303, Valid_ACC:0.5425999760627747
Epoch 116, CIFAR-10 Batch 5:  Train_Loss:1.2347949743270874, Valid_Loss:1.3975365161895752, Valid_ACC:0.5465999841690063
Epoch 117, CIFAR-10 Batch 1:  Train_Loss:1.202621340751648, Valid_Loss:1.4120886325836182, Valid_ACC:0.5377999544143677
Epoch 117, CIFAR-10 Batch 2:  Train_Loss:1.2215149402618408, Valid_Loss:1.4009629487991333, Valid_ACC:0.5423999428749084
Epoch 117, CIFAR-10 Batch 3:  Train_Loss:1.1642310619354248, Valid_Loss:1.3948218822479248, Valid_ACC:0.5455999374389648
Epoch 117, CIFAR-10 Batch 4:  Train_Loss:1.2177424430847168, Valid_Loss:1.398665189743042, Valid_ACC:0.5463999509811401
Epoch 117, CIFAR-10 Batch 5:  Train_Loss:1.2321898937225342, Valid_Loss:1.4041109085083008, Valid_ACC:0.5413998961448669
Epoch 118, CIFAR-10 Batch 1:  Train_Loss:1.204783320426941, Valid_Loss:1.4005399942398071, Valid_ACC:0.5439999103546143
Epoch 118, CIFAR-10 Batch 2:  Train_Loss:1.2251993417739868, Valid_Loss:1.4118609428405762, Valid_ACC:0.5305998921394348
Epoch 118, CIFAR-10 Batch 3:  Train_Loss:1.1783783435821533, Valid_Loss:1.4025124311447144, Valid_ACC:0.5369999408721924
Epoch 118, CIFAR-10 Batch 4:  Train_Loss:1.208976149559021, Valid_Loss:1.397077202796936, Valid_ACC:0.5465999245643616
Epoch 118, CIFAR-10 Batch 5:  Train_Loss:1.2268767356872559, Valid_Loss:1.3948054313659668, Valid_ACC:0.5479999780654907
Epoch 119, CIFAR-10 Batch 1:  Train_Loss:1.1900537014007568, Valid_Loss:1.3922502994537354, Valid_ACC:0.545799970626831
Epoch 119, CIFAR-10 Batch 2:  Train_Loss:1.2294024229049683, Valid_Loss:1.3999178409576416, Valid_ACC:0.5413999557495117
Epoch 119, CIFAR-10 Batch 3:  Train_Loss:1.159543752670288, Valid_Loss:1.3890447616577148, Valid_ACC:0.5471999049186707
Epoch 119, CIFAR-10 Batch 4:  Train_Loss:1.223339557647705, Valid_Loss:1.409022331237793, Valid_ACC:0.5395999550819397
Epoch 119, CIFAR-10 Batch 5:  Train_Loss:1.2495373487472534, Valid_Loss:1.4268779754638672, Valid_ACC:0.5293999314308167
Epoch 120, CIFAR-10 Batch 1:  Train_Loss:1.199957013130188, Valid_Loss:1.4071115255355835, Valid_ACC:0.5331999659538269
Epoch 120, CIFAR-10 Batch 2:  Train_Loss:1.2113103866577148, Valid_Loss:1.396506905555725, Valid_ACC:0.5431999564170837
Epoch 120, CIFAR-10 Batch 3:  Train_Loss:1.1734591722488403, Valid_Loss:1.3998305797576904, Valid_ACC:0.5381999015808105
Epoch 120, CIFAR-10 Batch 4:  Train_Loss:1.2180527448654175, Valid_Loss:1.4056898355484009, Valid_ACC:0.5411999225616455
Epoch 120, CIFAR-10 Batch 5:  Train_Loss:1.2291312217712402, Valid_Loss:1.4088209867477417, Valid_ACC:0.543199896812439
Epoch 121, CIFAR-10 Batch 1:  Train_Loss:1.1927516460418701, Valid_Loss:1.4070210456848145, Valid_ACC:0.5363999605178833
Epoch 121, CIFAR-10 Batch 2:  Train_Loss:1.2091190814971924, Valid_Loss:1.401911973953247, Valid_ACC:0.5349999070167542
Epoch 121, CIFAR-10 Batch 3:  Train_Loss:1.1648848056793213, Valid_Loss:1.3965731859207153, Valid_ACC:0.544999897480011
Epoch 121, CIFAR-10 Batch 4:  Train_Loss:1.2008957862854004, Valid_Loss:1.3895130157470703, Valid_ACC:0.5471999645233154
Epoch 121, CIFAR-10 Batch 5:  Train_Loss:1.2340795993804932, Valid_Loss:1.3982775211334229, Valid_ACC:0.5435999035835266
Epoch 122, CIFAR-10 Batch 1:  Train_Loss:1.1855727434158325, Valid_Loss:1.3972808122634888, Valid_ACC:0.5397999286651611
Epoch 122, CIFAR-10 Batch 2:  Train_Loss:1.2188342809677124, Valid_Loss:1.4065477848052979, Valid_ACC:0.5371999740600586
Epoch 122, CIFAR-10 Batch 3:  Train_Loss:1.1949408054351807, Valid_Loss:1.4084516763687134, Valid_ACC:0.5349999666213989
Epoch 122, CIFAR-10 Batch 4:  Train_Loss:1.212045669555664, Valid_Loss:1.4048881530761719, Valid_ACC:0.5425999760627747
Epoch 122, CIFAR-10 Batch 5:  Train_Loss:1.2329519987106323, Valid_Loss:1.391141414642334, Valid_ACC:0.5467999577522278
Epoch 123, CIFAR-10 Batch 1:  Train_Loss:1.201336145401001, Valid_Loss:1.4203808307647705, Valid_ACC:0.5315999984741211
Epoch 123, CIFAR-10 Batch 2:  Train_Loss:1.2105565071105957, Valid_Loss:1.4034085273742676, Valid_ACC:0.5377999544143677
Epoch 123, CIFAR-10 Batch 3:  Train_Loss:1.1656761169433594, Valid_Loss:1.3912683725357056, Valid_ACC:0.5459999442100525
Epoch 123, CIFAR-10 Batch 4:  Train_Loss:1.2041436433792114, Valid_Loss:1.3997315168380737, Valid_ACC:0.5439999103546143
Epoch 123, CIFAR-10 Batch 5:  Train_Loss:1.2218985557556152, Valid_Loss:1.3893191814422607, Valid_ACC:0.5475999116897583
Epoch 124, CIFAR-10 Batch 1:  Train_Loss:1.184605598449707, Valid_Loss:1.4033126831054688, Valid_ACC:0.539199948310852
Epoch 124, CIFAR-10 Batch 2:  Train_Loss:1.2195936441421509, Valid_Loss:1.4050222635269165, Valid_ACC:0.5347999334335327
Epoch 124, CIFAR-10 Batch 3:  Train_Loss:1.1566047668457031, Valid_Loss:1.392812728881836, Valid_ACC:0.5427999496459961
Epoch 124, CIFAR-10 Batch 4:  Train_Loss:1.23390531539917, Valid_Loss:1.4202027320861816, Valid_ACC:0.5379999279975891
Epoch 124, CIFAR-10 Batch 5:  Train_Loss:1.2267972230911255, Valid_Loss:1.3956449031829834, Valid_ACC:0.5481998920440674
Epoch 125, CIFAR-10 Batch 1:  Train_Loss:1.1825867891311646, Valid_Loss:1.3871855735778809, Valid_ACC:0.5471999645233154
Epoch 125, CIFAR-10 Batch 2:  Train_Loss:1.208019733428955, Valid_Loss:1.3981372117996216, Valid_ACC:0.5431999564170837
Epoch 125, CIFAR-10 Batch 3:  Train_Loss:1.168168306350708, Valid_Loss:1.3951363563537598, Valid_ACC:0.542199969291687
Epoch 125, CIFAR-10 Batch 4:  Train_Loss:1.20212721824646, Valid_Loss:1.3954224586486816, Valid_ACC:0.5461999177932739
Epoch 125, CIFAR-10 Batch 5:  Train_Loss:1.2194178104400635, Valid_Loss:1.3906171321868896, Valid_ACC:0.5477999448776245
Epoch 126, CIFAR-10 Batch 1:  Train_Loss:1.1773864030838013, Valid_Loss:1.3833361864089966, Valid_ACC:0.5463998913764954
Epoch 126, CIFAR-10 Batch 2:  Train_Loss:1.207810640335083, Valid_Loss:1.3939647674560547, Valid_ACC:0.53739994764328
Epoch 126, CIFAR-10 Batch 3:  Train_Loss:1.1520366668701172, Valid_Loss:1.3894497156143188, Valid_ACC:0.5441998839378357
Epoch 126, CIFAR-10 Batch 4:  Train_Loss:1.2075482606887817, Valid_Loss:1.4027602672576904, Valid_ACC:0.5433999300003052
Epoch 126, CIFAR-10 Batch 5:  Train_Loss:1.2216070890426636, Valid_Loss:1.3907960653305054, Valid_ACC:0.5479999780654907
Epoch 127, CIFAR-10 Batch 1:  Train_Loss:1.1744128465652466, Valid_Loss:1.3931609392166138, Valid_ACC:0.5409998893737793
Epoch 127, CIFAR-10 Batch 2:  Train_Loss:1.2083622217178345, Valid_Loss:1.3980140686035156, Valid_ACC:0.5381999611854553
Epoch 127, CIFAR-10 Batch 3:  Train_Loss:1.1435858011245728, Valid_Loss:1.3877294063568115, Valid_ACC:0.5471999049186707
Epoch 127, CIFAR-10 Batch 4:  Train_Loss:1.2103419303894043, Valid_Loss:1.402854084968567, Valid_ACC:0.5407999753952026
Epoch 127, CIFAR-10 Batch 5:  Train_Loss:1.2156938314437866, Valid_Loss:1.39236581325531, Valid_ACC:0.5451999306678772
Epoch 128, CIFAR-10 Batch 1:  Train_Loss:1.2197520732879639, Valid_Loss:1.4559255838394165, Valid_ACC:0.5203999876976013
Epoch 128, CIFAR-10 Batch 2:  Train_Loss:1.2139052152633667, Valid_Loss:1.4076714515686035, Valid_ACC:0.5341999530792236
Epoch 128, CIFAR-10 Batch 3:  Train_Loss:1.1593760251998901, Valid_Loss:1.3958086967468262, Valid_ACC:0.5475999712944031
Epoch 128, CIFAR-10 Batch 4:  Train_Loss:1.2334845066070557, Valid_Loss:1.4233089685440063, Valid_ACC:0.5323999524116516
Epoch 128, CIFAR-10 Batch 5:  Train_Loss:1.231113314628601, Valid_Loss:1.3938055038452148, Valid_ACC:0.5449999570846558
Epoch 129, CIFAR-10 Batch 1:  Train_Loss:1.1829440593719482, Valid_Loss:1.4088717699050903, Valid_ACC:0.536799967288971
Epoch 129, CIFAR-10 Batch 2:  Train_Loss:1.2083582878112793, Valid_Loss:1.3973376750946045, Valid_ACC:0.5435999035835266
Epoch 129, CIFAR-10 Batch 3:  Train_Loss:1.1448447704315186, Valid_Loss:1.386379361152649, Valid_ACC:0.5449999570846558
Epoch 129, CIFAR-10 Batch 4:  Train_Loss:1.210150957107544, Valid_Loss:1.4062402248382568, Valid_ACC:0.5393999218940735
Epoch 129, CIFAR-10 Batch 5:  Train_Loss:1.2117942571640015, Valid_Loss:1.3964956998825073, Valid_ACC:0.5445999503135681
Epoch 130, CIFAR-10 Batch 1:  Train_Loss:1.1763912439346313, Valid_Loss:1.3980050086975098, Valid_ACC:0.5347999334335327
Epoch 130, CIFAR-10 Batch 2:  Train_Loss:1.202505350112915, Valid_Loss:1.3960820436477661, Valid_ACC:0.542199969291687
Epoch 130, CIFAR-10 Batch 3:  Train_Loss:1.1646002531051636, Valid_Loss:1.3964498043060303, Valid_ACC:0.5425999164581299
Epoch 130, CIFAR-10 Batch 4:  Train_Loss:1.2083827257156372, Valid_Loss:1.4052255153656006, Valid_ACC:0.5405999422073364
Epoch 130, CIFAR-10 Batch 5:  Train_Loss:1.2244672775268555, Valid_Loss:1.394580364227295, Valid_ACC:0.5445998907089233
Epoch 131, CIFAR-10 Batch 1:  Train_Loss:1.1763179302215576, Valid_Loss:1.4035453796386719, Valid_ACC:0.5377999544143677
Epoch 131, CIFAR-10 Batch 2:  Train_Loss:1.210640549659729, Valid_Loss:1.407720923423767, Valid_ACC:0.5377999544143677
Epoch 131, CIFAR-10 Batch 3:  Train_Loss:1.156655192375183, Valid_Loss:1.3917248249053955, Valid_ACC:0.5455999374389648
Epoch 131, CIFAR-10 Batch 4:  Train_Loss:1.202052354812622, Valid_Loss:1.40354585647583, Valid_ACC:0.5397999286651611
Epoch 131, CIFAR-10 Batch 5:  Train_Loss:1.224829077720642, Valid_Loss:1.4039745330810547, Valid_ACC:0.5421999096870422
Epoch 132, CIFAR-10 Batch 1:  Train_Loss:1.1739386320114136, Valid_Loss:1.3981164693832397, Valid_ACC:0.5357999205589294
Epoch 132, CIFAR-10 Batch 2:  Train_Loss:1.2066388130187988, Valid_Loss:1.394105076789856, Valid_ACC:0.5459998846054077
Epoch 132, CIFAR-10 Batch 3:  Train_Loss:1.1452339887619019, Valid_Loss:1.3905304670333862, Valid_ACC:0.5443999171257019
Epoch 132, CIFAR-10 Batch 4:  Train_Loss:1.212700366973877, Valid_Loss:1.4109746217727661, Valid_ACC:0.5371999740600586
Epoch 132, CIFAR-10 Batch 5:  Train_Loss:1.220192790031433, Valid_Loss:1.396552562713623, Valid_ACC:0.5461999177932739
Epoch 133, CIFAR-10 Batch 1:  Train_Loss:1.2014479637145996, Valid_Loss:1.4377776384353638, Valid_ACC:0.5277999639511108
Epoch 133, CIFAR-10 Batch 2:  Train_Loss:1.2279053926467896, Valid_Loss:1.416076421737671, Valid_ACC:0.535599946975708
Epoch 133, CIFAR-10 Batch 3:  Train_Loss:1.1502879858016968, Valid_Loss:1.3924930095672607, Valid_ACC:0.5431999564170837
Epoch 133, CIFAR-10 Batch 4:  Train_Loss:1.196851134300232, Valid_Loss:1.3977017402648926, Valid_ACC:0.5411999225616455
Epoch 133, CIFAR-10 Batch 5:  Train_Loss:1.2041358947753906, Valid_Loss:1.3909953832626343, Valid_ACC:0.5451998710632324
Epoch 134, CIFAR-10 Batch 1:  Train_Loss:1.1709071397781372, Valid_Loss:1.4045076370239258, Valid_ACC:0.5361999273300171
Epoch 134, CIFAR-10 Batch 2:  Train_Loss:1.2195978164672852, Valid_Loss:1.4013185501098633, Valid_ACC:0.5377999544143677
Epoch 134, CIFAR-10 Batch 3:  Train_Loss:1.1642552614212036, Valid_Loss:1.407774806022644, Valid_ACC:0.5395998954772949
Epoch 134, CIFAR-10 Batch 4:  Train_Loss:1.2014962434768677, Valid_Loss:1.4092451333999634, Valid_ACC:0.5367999076843262
Epoch 134, CIFAR-10 Batch 5:  Train_Loss:1.2167420387268066, Valid_Loss:1.3964835405349731, Valid_ACC:0.5455998778343201
Epoch 135, CIFAR-10 Batch 1:  Train_Loss:1.1724804639816284, Valid_Loss:1.4031744003295898, Valid_ACC:0.5391998887062073
Epoch 135, CIFAR-10 Batch 2:  Train_Loss:1.2298219203948975, Valid_Loss:1.4185715913772583, Valid_ACC:0.5361999273300171
Epoch 135, CIFAR-10 Batch 3:  Train_Loss:1.1677172183990479, Valid_Loss:1.4102325439453125, Valid_ACC:0.5367999076843262
Epoch 135, CIFAR-10 Batch 4:  Train_Loss:1.2058318853378296, Valid_Loss:1.4095239639282227, Valid_ACC:0.5387999415397644
Epoch 135, CIFAR-10 Batch 5:  Train_Loss:1.2220821380615234, Valid_Loss:1.40156888961792, Valid_ACC:0.5455998778343201
Epoch 136, CIFAR-10 Batch 1:  Train_Loss:1.1832962036132812, Valid_Loss:1.4100300073623657, Valid_ACC:0.536799967288971
Epoch 136, CIFAR-10 Batch 2:  Train_Loss:1.2052432298660278, Valid_Loss:1.4003868103027344, Valid_ACC:0.5419999957084656
Epoch 136, CIFAR-10 Batch 3:  Train_Loss:1.1320432424545288, Valid_Loss:1.3845090866088867, Valid_ACC:0.5465999245643616
Epoch 136, CIFAR-10 Batch 4:  Train_Loss:1.1956602334976196, Valid_Loss:1.4036763906478882, Valid_ACC:0.5387999415397644
Epoch 136, CIFAR-10 Batch 5:  Train_Loss:1.2037193775177002, Valid_Loss:1.3881165981292725, Valid_ACC:0.547999918460846
Epoch 137, CIFAR-10 Batch 1:  Train_Loss:1.1603429317474365, Valid_Loss:1.3982725143432617, Valid_ACC:0.5415999889373779
Epoch 137, CIFAR-10 Batch 2:  Train_Loss:1.209193229675293, Valid_Loss:1.3977826833724976, Valid_ACC:0.5437999367713928
Epoch 137, CIFAR-10 Batch 3:  Train_Loss:1.1397178173065186, Valid_Loss:1.3933733701705933, Valid_ACC:0.5461999773979187
Epoch 137, CIFAR-10 Batch 4:  Train_Loss:1.1868891716003418, Valid_Loss:1.392691969871521, Valid_ACC:0.546799898147583
Epoch 137, CIFAR-10 Batch 5:  Train_Loss:1.2290500402450562, Valid_Loss:1.4036754369735718, Valid_ACC:0.5383999347686768
Epoch 138, CIFAR-10 Batch 1:  Train_Loss:1.1625738143920898, Valid_Loss:1.3924626111984253, Valid_ACC:0.5445999503135681
Epoch 138, CIFAR-10 Batch 2:  Train_Loss:1.2076350450515747, Valid_Loss:1.4004380702972412, Valid_ACC:0.5413999557495117
Epoch 138, CIFAR-10 Batch 3:  Train_Loss:1.1453688144683838, Valid_Loss:1.3918544054031372, Valid_ACC:0.542199969291687
Epoch 138, CIFAR-10 Batch 4:  Train_Loss:1.197251319885254, Valid_Loss:1.401595950126648, Valid_ACC:0.5371999144554138
Epoch 138, CIFAR-10 Batch 5:  Train_Loss:1.2176192998886108, Valid_Loss:1.4079928398132324, Valid_ACC:0.5399999618530273
Epoch 139, CIFAR-10 Batch 1:  Train_Loss:1.1679168939590454, Valid_Loss:1.4077068567276, Valid_ACC:0.5425999760627747
Epoch 139, CIFAR-10 Batch 2:  Train_Loss:1.1894066333770752, Valid_Loss:1.3833038806915283, Valid_ACC:0.5509998798370361
Epoch 139, CIFAR-10 Batch 3:  Train_Loss:1.1358163356781006, Valid_Loss:1.3847289085388184, Valid_ACC:0.5473999381065369
Epoch 139, CIFAR-10 Batch 4:  Train_Loss:1.1972291469573975, Valid_Loss:1.4060684442520142, Valid_ACC:0.5405999422073364
Epoch 139, CIFAR-10 Batch 5:  Train_Loss:1.2100845575332642, Valid_Loss:1.4083672761917114, Valid_ACC:0.5371999144554138
Epoch 140, CIFAR-10 Batch 1:  Train_Loss:1.1598705053329468, Valid_Loss:1.398569941520691, Valid_ACC:0.5433999300003052
Epoch 140, CIFAR-10 Batch 2:  Train_Loss:1.188859224319458, Valid_Loss:1.394608736038208, Valid_ACC:0.5473999381065369
Epoch 140, CIFAR-10 Batch 3:  Train_Loss:1.136928677558899, Valid_Loss:1.389643669128418, Valid_ACC:0.5457999110221863
Epoch 140, CIFAR-10 Batch 4:  Train_Loss:1.1834417581558228, Valid_Loss:1.3929637670516968, Valid_ACC:0.5465999841690063
Epoch 140, CIFAR-10 Batch 5:  Train_Loss:1.243032693862915, Valid_Loss:1.4480984210968018, Valid_ACC:0.5273999571800232
Epoch 141, CIFAR-10 Batch 1:  Train_Loss:1.1923328638076782, Valid_Loss:1.4302371740341187, Valid_ACC:0.5293999910354614
Epoch 141, CIFAR-10 Batch 2:  Train_Loss:1.203885555267334, Valid_Loss:1.4069339036941528, Valid_ACC:0.538399875164032
Epoch 141, CIFAR-10 Batch 3:  Train_Loss:1.1354990005493164, Valid_Loss:1.3910961151123047, Valid_ACC:0.5407999753952026
Epoch 141, CIFAR-10 Batch 4:  Train_Loss:1.1772252321243286, Valid_Loss:1.3909969329833984, Valid_ACC:0.546799898147583
Epoch 141, CIFAR-10 Batch 5:  Train_Loss:1.2027239799499512, Valid_Loss:1.390868067741394, Valid_ACC:0.5467999577522278
Epoch 142, CIFAR-10 Batch 1:  Train_Loss:1.1439906358718872, Valid_Loss:1.3825443983078003, Valid_ACC:0.5477999448776245
Epoch 142, CIFAR-10 Batch 2:  Train_Loss:1.175876259803772, Valid_Loss:1.3873611688613892, Valid_ACC:0.5489999055862427
Epoch 142, CIFAR-10 Batch 3:  Train_Loss:1.1293312311172485, Valid_Loss:1.3842005729675293, Valid_ACC:0.5447999238967896
Epoch 142, CIFAR-10 Batch 4:  Train_Loss:1.1744240522384644, Valid_Loss:1.3870993852615356, Valid_ACC:0.546799898147583
Epoch 142, CIFAR-10 Batch 5:  Train_Loss:1.1920253038406372, Valid_Loss:1.3891096115112305, Valid_ACC:0.5487999320030212
Epoch 143, CIFAR-10 Batch 1:  Train_Loss:1.1385164260864258, Valid_Loss:1.3875709772109985, Valid_ACC:0.5465998649597168
Epoch 143, CIFAR-10 Batch 2:  Train_Loss:1.190914511680603, Valid_Loss:1.3999037742614746, Valid_ACC:0.540399968624115
Epoch 143, CIFAR-10 Batch 3:  Train_Loss:1.1273813247680664, Valid_Loss:1.388632893562317, Valid_ACC:0.5509998798370361
Epoch 143, CIFAR-10 Batch 4:  Train_Loss:1.1705716848373413, Valid_Loss:1.3868159055709839, Valid_ACC:0.5473999381065369
Epoch 143, CIFAR-10 Batch 5:  Train_Loss:1.1998246908187866, Valid_Loss:1.3950878381729126, Valid_ACC:0.5519999265670776
Epoch 144, CIFAR-10 Batch 1:  Train_Loss:1.1463044881820679, Valid_Loss:1.3893725872039795, Valid_ACC:0.5421999096870422
Epoch 144, CIFAR-10 Batch 2:  Train_Loss:1.175715684890747, Valid_Loss:1.3807153701782227, Valid_ACC:0.5461999177932739
Epoch 144, CIFAR-10 Batch 3:  Train_Loss:1.117415189743042, Valid_Loss:1.3791301250457764, Valid_ACC:0.5493999123573303
Epoch 144, CIFAR-10 Batch 4:  Train_Loss:1.1610413789749146, Valid_Loss:1.3791285753250122, Valid_ACC:0.5531999468803406
Epoch 144, CIFAR-10 Batch 5:  Train_Loss:1.1958636045455933, Valid_Loss:1.389752745628357, Valid_ACC:0.5507999658584595
Epoch 145, CIFAR-10 Batch 1:  Train_Loss:1.1532090902328491, Valid_Loss:1.4170005321502686, Valid_ACC:0.5297999382019043
Epoch 145, CIFAR-10 Batch 2:  Train_Loss:1.1703388690948486, Valid_Loss:1.381777286529541, Valid_ACC:0.548799991607666
Epoch 145, CIFAR-10 Batch 3:  Train_Loss:1.1271893978118896, Valid_Loss:1.3870759010314941, Valid_ACC:0.543999969959259
Epoch 145, CIFAR-10 Batch 4:  Train_Loss:1.1748175621032715, Valid_Loss:1.3921339511871338, Valid_ACC:0.5429999232292175
Epoch 145, CIFAR-10 Batch 5:  Train_Loss:1.2023766040802002, Valid_Loss:1.3962265253067017, Valid_ACC:0.5475999116897583
Epoch 146, CIFAR-10 Batch 1:  Train_Loss:1.149530291557312, Valid_Loss:1.411879062652588, Valid_ACC:0.5359998941421509
Epoch 146, CIFAR-10 Batch 2:  Train_Loss:1.1963512897491455, Valid_Loss:1.4021730422973633, Valid_ACC:0.5399999022483826
Epoch 146, CIFAR-10 Batch 3:  Train_Loss:1.1640952825546265, Valid_Loss:1.4155282974243164, Valid_ACC:0.5301999449729919
Epoch 146, CIFAR-10 Batch 4:  Train_Loss:1.171378493309021, Valid_Loss:1.395081877708435, Valid_ACC:0.5445999503135681
Epoch 146, CIFAR-10 Batch 5:  Train_Loss:1.1896506547927856, Valid_Loss:1.3863551616668701, Valid_ACC:0.5483999252319336
Epoch 147, CIFAR-10 Batch 1:  Train_Loss:1.1320983171463013, Valid_Loss:1.3819798231124878, Valid_ACC:0.5459999442100525
Epoch 147, CIFAR-10 Batch 2:  Train_Loss:1.1906943321228027, Valid_Loss:1.3986763954162598, Valid_ACC:0.5429999232292175
Epoch 147, CIFAR-10 Batch 3:  Train_Loss:1.1306054592132568, Valid_Loss:1.3923665285110474, Valid_ACC:0.5429999828338623
Epoch 147, CIFAR-10 Batch 4:  Train_Loss:1.1660685539245605, Valid_Loss:1.390406847000122, Valid_ACC:0.5453999042510986
Epoch 147, CIFAR-10 Batch 5:  Train_Loss:1.1807372570037842, Valid_Loss:1.379064679145813, Valid_ACC:0.5517999529838562
Epoch 148, CIFAR-10 Batch 1:  Train_Loss:1.1314417123794556, Valid_Loss:1.4000471830368042, Valid_ACC:0.5421999096870422
Epoch 148, CIFAR-10 Batch 2:  Train_Loss:1.1650863885879517, Valid_Loss:1.377570390701294, Valid_ACC:0.5511999130249023
Epoch 148, CIFAR-10 Batch 3:  Train_Loss:1.1184476613998413, Valid_Loss:1.3861550092697144, Valid_ACC:0.5433999300003052
Epoch 148, CIFAR-10 Batch 4:  Train_Loss:1.1652029752731323, Valid_Loss:1.3896626234054565, Valid_ACC:0.5451999306678772
Epoch 148, CIFAR-10 Batch 5:  Train_Loss:1.186462640762329, Valid_Loss:1.3816652297973633, Valid_ACC:0.5509999394416809
Epoch 149, CIFAR-10 Batch 1:  Train_Loss:1.1250427961349487, Valid_Loss:1.3925827741622925, Valid_ACC:0.5423999428749084
Epoch 149, CIFAR-10 Batch 2:  Train_Loss:1.1646952629089355, Valid_Loss:1.375016212463379, Valid_ACC:0.55159991979599
Epoch 149, CIFAR-10 Batch 3:  Train_Loss:1.1073848009109497, Valid_Loss:1.3783146142959595, Valid_ACC:0.5501999258995056
Epoch 149, CIFAR-10 Batch 4:  Train_Loss:1.1772780418395996, Valid_Loss:1.3975181579589844, Valid_ACC:0.5455999970436096
Epoch 149, CIFAR-10 Batch 5:  Train_Loss:1.1762309074401855, Valid_Loss:1.3839114904403687, Valid_ACC:0.5521999597549438
Epoch 150, CIFAR-10 Batch 1:  Train_Loss:1.1248198747634888, Valid_Loss:1.397336483001709, Valid_ACC:0.5459998846054077
Epoch 150, CIFAR-10 Batch 2:  Train_Loss:1.1687923669815063, Valid_Loss:1.3817439079284668, Valid_ACC:0.549799919128418
Epoch 150, CIFAR-10 Batch 3:  Train_Loss:1.1004917621612549, Valid_Loss:1.3765480518341064, Valid_ACC:0.5511999130249023
Epoch 150, CIFAR-10 Batch 4:  Train_Loss:1.1662245988845825, Valid_Loss:1.3890125751495361, Valid_ACC:0.5463999509811401
Epoch 150, CIFAR-10 Batch 5:  Train_Loss:1.181995153427124, Valid_Loss:1.3828524351119995, Valid_ACC:0.5511999130249023
Epoch 151, CIFAR-10 Batch 1:  Train_Loss:1.1357719898223877, Valid_Loss:1.4059827327728271, Valid_ACC:0.5361999273300171
Epoch 151, CIFAR-10 Batch 2:  Train_Loss:1.164852261543274, Valid_Loss:1.3856565952301025, Valid_ACC:0.5467999577522278
Epoch 151, CIFAR-10 Batch 3:  Train_Loss:1.1099867820739746, Valid_Loss:1.3784191608428955, Valid_ACC:0.5489999055862427
Epoch 151, CIFAR-10 Batch 4:  Train_Loss:1.1603467464447021, Valid_Loss:1.3869858980178833, Valid_ACC:0.547999918460846
Epoch 151, CIFAR-10 Batch 5:  Train_Loss:1.169222354888916, Valid_Loss:1.3835477828979492, Valid_ACC:0.5491999387741089
Epoch 152, CIFAR-10 Batch 1:  Train_Loss:1.1258982419967651, Valid_Loss:1.3783166408538818, Valid_ACC:0.5489999651908875
Epoch 152, CIFAR-10 Batch 2:  Train_Loss:1.160343885421753, Valid_Loss:1.378803014755249, Valid_ACC:0.5465999245643616
Epoch 152, CIFAR-10 Batch 3:  Train_Loss:1.1076557636260986, Valid_Loss:1.3795088529586792, Valid_ACC:0.5465999245643616
Epoch 152, CIFAR-10 Batch 4:  Train_Loss:1.2160837650299072, Valid_Loss:1.4292676448822021, Valid_ACC:0.5349999666213989
Epoch 152, CIFAR-10 Batch 5:  Train_Loss:1.193385124206543, Valid_Loss:1.3965492248535156, Valid_ACC:0.5495998859405518
Epoch 153, CIFAR-10 Batch 1:  Train_Loss:1.1665749549865723, Valid_Loss:1.4360551834106445, Valid_ACC:0.5265999436378479
Epoch 153, CIFAR-10 Batch 2:  Train_Loss:1.1894924640655518, Valid_Loss:1.4016180038452148, Valid_ACC:0.543799877166748
Epoch 153, CIFAR-10 Batch 3:  Train_Loss:1.1194000244140625, Valid_Loss:1.393404245376587, Valid_ACC:0.5425999164581299
Epoch 153, CIFAR-10 Batch 4:  Train_Loss:1.1577262878417969, Valid_Loss:1.3910490274429321, Valid_ACC:0.5449999570846558
Epoch 153, CIFAR-10 Batch 5:  Train_Loss:1.175944209098816, Valid_Loss:1.383903980255127, Valid_ACC:0.5501999258995056
Epoch 154, CIFAR-10 Batch 1:  Train_Loss:1.1305543184280396, Valid_Loss:1.4001351594924927, Valid_ACC:0.5403999090194702
Epoch 154, CIFAR-10 Batch 2:  Train_Loss:1.1629480123519897, Valid_Loss:1.3797204494476318, Valid_ACC:0.5487999320030212
Epoch 154, CIFAR-10 Batch 3:  Train_Loss:1.0973286628723145, Valid_Loss:1.3798483610153198, Valid_ACC:0.5481998920440674
Epoch 154, CIFAR-10 Batch 4:  Train_Loss:1.140243411064148, Valid_Loss:1.3818159103393555, Valid_ACC:0.5511999130249023
Epoch 154, CIFAR-10 Batch 5:  Train_Loss:1.1632715463638306, Valid_Loss:1.3777337074279785, Valid_ACC:0.553399920463562
Epoch 155, CIFAR-10 Batch 1:  Train_Loss:1.105845332145691, Valid_Loss:1.381360650062561, Valid_ACC:0.550399899482727
Epoch 155, CIFAR-10 Batch 2:  Train_Loss:1.1633615493774414, Valid_Loss:1.3779733180999756, Valid_ACC:0.546799898147583
Epoch 155, CIFAR-10 Batch 3:  Train_Loss:1.0965338945388794, Valid_Loss:1.377142310142517, Valid_ACC:0.5511999130249023
Epoch 155, CIFAR-10 Batch 4:  Train_Loss:1.1466295719146729, Valid_Loss:1.3878763914108276, Valid_ACC:0.5509999394416809
Epoch 155, CIFAR-10 Batch 5:  Train_Loss:1.1721700429916382, Valid_Loss:1.3861995935440063, Valid_ACC:0.5499999523162842
Epoch 156, CIFAR-10 Batch 1:  Train_Loss:1.1279881000518799, Valid_Loss:1.4007846117019653, Valid_ACC:0.5407999157905579
Epoch 156, CIFAR-10 Batch 2:  Train_Loss:1.1585121154785156, Valid_Loss:1.3882724046707153, Valid_ACC:0.546799898147583
Epoch 156, CIFAR-10 Batch 3:  Train_Loss:1.1011377573013306, Valid_Loss:1.3786768913269043, Valid_ACC:0.5515999794006348
Epoch 156, CIFAR-10 Batch 4:  Train_Loss:1.1424331665039062, Valid_Loss:1.3824867010116577, Valid_ACC:0.5513999462127686
Epoch 156, CIFAR-10 Batch 5:  Train_Loss:1.1677796840667725, Valid_Loss:1.3838213682174683, Valid_ACC:0.5499999523162842
Epoch 157, CIFAR-10 Batch 1:  Train_Loss:1.1216323375701904, Valid_Loss:1.3897058963775635, Valid_ACC:0.5487999320030212
Epoch 157, CIFAR-10 Batch 2:  Train_Loss:1.1544992923736572, Valid_Loss:1.3756552934646606, Valid_ACC:0.5553999543190002
Epoch 157, CIFAR-10 Batch 3:  Train_Loss:1.0969116687774658, Valid_Loss:1.3779302835464478, Valid_ACC:0.5493999719619751
Epoch 157, CIFAR-10 Batch 4:  Train_Loss:1.1346962451934814, Valid_Loss:1.3855948448181152, Valid_ACC:0.5521999597549438
Epoch 157, CIFAR-10 Batch 5:  Train_Loss:1.1656320095062256, Valid_Loss:1.3816869258880615, Valid_ACC:0.5525999665260315
Epoch 158, CIFAR-10 Batch 1:  Train_Loss:1.1065770387649536, Valid_Loss:1.3718867301940918, Valid_ACC:0.5507999062538147
Epoch 158, CIFAR-10 Batch 2:  Train_Loss:1.1648859977722168, Valid_Loss:1.3770382404327393, Valid_ACC:0.5519999265670776
Epoch 158, CIFAR-10 Batch 3:  Train_Loss:1.0875097513198853, Valid_Loss:1.3720535039901733, Valid_ACC:0.5487999320030212
Epoch 158, CIFAR-10 Batch 4:  Train_Loss:1.1396889686584473, Valid_Loss:1.3858907222747803, Valid_ACC:0.547999918460846
Epoch 158, CIFAR-10 Batch 5:  Train_Loss:1.1660388708114624, Valid_Loss:1.398973822593689, Valid_ACC:0.5417999625205994
Epoch 159, CIFAR-10 Batch 1:  Train_Loss:1.1062769889831543, Valid_Loss:1.380843162536621, Valid_ACC:0.5483999252319336
Epoch 159, CIFAR-10 Batch 2:  Train_Loss:1.1554985046386719, Valid_Loss:1.3798868656158447, Valid_ACC:0.546799898147583
Epoch 159, CIFAR-10 Batch 3:  Train_Loss:1.0932587385177612, Valid_Loss:1.3782835006713867, Valid_ACC:0.546799898147583
Epoch 159, CIFAR-10 Batch 4:  Train_Loss:1.1275124549865723, Valid_Loss:1.3750133514404297, Valid_ACC:0.5493999123573303
Epoch 159, CIFAR-10 Batch 5:  Train_Loss:1.1520490646362305, Valid_Loss:1.3766074180603027, Valid_ACC:0.5561999082565308
Epoch 160, CIFAR-10 Batch 1:  Train_Loss:1.1058785915374756, Valid_Loss:1.3778314590454102, Valid_ACC:0.5501999258995056
Epoch 160, CIFAR-10 Batch 2:  Train_Loss:1.1484378576278687, Valid_Loss:1.3797886371612549, Valid_ACC:0.544999897480011
Epoch 160, CIFAR-10 Batch 3:  Train_Loss:1.0886954069137573, Valid_Loss:1.3714392185211182, Valid_ACC:0.550399899482727
Epoch 160, CIFAR-10 Batch 4:  Train_Loss:1.1448196172714233, Valid_Loss:1.3877211809158325, Valid_ACC:0.5477999448776245
Epoch 160, CIFAR-10 Batch 5:  Train_Loss:1.1680636405944824, Valid_Loss:1.3907256126403809, Valid_ACC:0.5455999374389648
Epoch 161, CIFAR-10 Batch 1:  Train_Loss:1.115414023399353, Valid_Loss:1.3897545337677002, Valid_ACC:0.5457998514175415
Epoch 161, CIFAR-10 Batch 2:  Train_Loss:1.1664289236068726, Valid_Loss:1.3841105699539185, Valid_ACC:0.5483999252319336
Epoch 161, CIFAR-10 Batch 3:  Train_Loss:1.0971635580062866, Valid_Loss:1.3796987533569336, Valid_ACC:0.5501999258995056
Epoch 161, CIFAR-10 Batch 4:  Train_Loss:1.1483440399169922, Valid_Loss:1.3917959928512573, Valid_ACC:0.5453999042510986
Epoch 161, CIFAR-10 Batch 5:  Train_Loss:1.1642637252807617, Valid_Loss:1.3760185241699219, Valid_ACC:0.5537999272346497
Epoch 162, CIFAR-10 Batch 1:  Train_Loss:1.1166199445724487, Valid_Loss:1.3944451808929443, Valid_ACC:0.5429999232292175
Epoch 162, CIFAR-10 Batch 2:  Train_Loss:1.151502013206482, Valid_Loss:1.3876488208770752, Valid_ACC:0.5457999110221863
Epoch 162, CIFAR-10 Batch 3:  Train_Loss:1.09775710105896, Valid_Loss:1.3753494024276733, Valid_ACC:0.5509999394416809
Epoch 162, CIFAR-10 Batch 4:  Train_Loss:1.1319966316223145, Valid_Loss:1.3788853883743286, Valid_ACC:0.5523999333381653
Epoch 162, CIFAR-10 Batch 5:  Train_Loss:1.1475156545639038, Valid_Loss:1.3737379312515259, Valid_ACC:0.556399941444397
Epoch 163, CIFAR-10 Batch 1:  Train_Loss:1.0995638370513916, Valid_Loss:1.3902313709259033, Valid_ACC:0.5443999171257019
Epoch 163, CIFAR-10 Batch 2:  Train_Loss:1.140339970588684, Valid_Loss:1.3794816732406616, Valid_ACC:0.5495999455451965
Epoch 163, CIFAR-10 Batch 3:  Train_Loss:1.0835676193237305, Valid_Loss:1.3705568313598633, Valid_ACC:0.5505999326705933
Epoch 163, CIFAR-10 Batch 4:  Train_Loss:1.1303906440734863, Valid_Loss:1.387252926826477, Valid_ACC:0.5503999590873718
Epoch 163, CIFAR-10 Batch 5:  Train_Loss:1.1778688430786133, Valid_Loss:1.4032546281814575, Valid_ACC:0.5429999232292175
Epoch 164, CIFAR-10 Batch 1:  Train_Loss:1.1413795948028564, Valid_Loss:1.4342665672302246, Valid_ACC:0.5267999768257141
Epoch 164, CIFAR-10 Batch 2:  Train_Loss:1.1930018663406372, Valid_Loss:1.4082993268966675, Valid_ACC:0.538599967956543
Epoch 164, CIFAR-10 Batch 3:  Train_Loss:1.1475508213043213, Valid_Loss:1.4169646501541138, Valid_ACC:0.530799925327301
Epoch 164, CIFAR-10 Batch 4:  Train_Loss:1.134842038154602, Valid_Loss:1.3864190578460693, Valid_ACC:0.5481999516487122
Epoch 164, CIFAR-10 Batch 5:  Train_Loss:1.1710407733917236, Valid_Loss:1.3875669240951538, Valid_ACC:0.5471999645233154
Epoch 165, CIFAR-10 Batch 1:  Train_Loss:1.1121068000793457, Valid_Loss:1.3898515701293945, Valid_ACC:0.5437999367713928
Epoch 165, CIFAR-10 Batch 2:  Train_Loss:1.1448652744293213, Valid_Loss:1.3817285299301147, Valid_ACC:0.5505999326705933
Epoch 165, CIFAR-10 Batch 3:  Train_Loss:1.1097012758255005, Valid_Loss:1.3947227001190186, Valid_ACC:0.5429999232292175
Epoch 165, CIFAR-10 Batch 4:  Train_Loss:1.1437830924987793, Valid_Loss:1.3949532508850098, Valid_ACC:0.5445999503135681
Epoch 165, CIFAR-10 Batch 5:  Train_Loss:1.183657169342041, Valid_Loss:1.3969230651855469, Valid_ACC:0.5467999577522278
Epoch 166, CIFAR-10 Batch 1:  Train_Loss:1.128119945526123, Valid_Loss:1.4193085432052612, Valid_ACC:0.535599946975708
Epoch 166, CIFAR-10 Batch 2:  Train_Loss:1.1486475467681885, Valid_Loss:1.382187843322754, Valid_ACC:0.5491998791694641
Epoch 166, CIFAR-10 Batch 3:  Train_Loss:1.0915615558624268, Valid_Loss:1.3898247480392456, Valid_ACC:0.5477998852729797
Epoch 166, CIFAR-10 Batch 4:  Train_Loss:1.1363794803619385, Valid_Loss:1.3981598615646362, Valid_ACC:0.5445998907089233
Epoch 166, CIFAR-10 Batch 5:  Train_Loss:1.1663986444473267, Valid_Loss:1.395251989364624, Valid_ACC:0.5473999381065369
Epoch 167, CIFAR-10 Batch 1:  Train_Loss:1.1076736450195312, Valid_Loss:1.3719449043273926, Valid_ACC:0.5573999881744385
Epoch 167, CIFAR-10 Batch 2:  Train_Loss:1.1673219203948975, Valid_Loss:1.3921186923980713, Valid_ACC:0.5447999238967896
Epoch 167, CIFAR-10 Batch 3:  Train_Loss:1.0916669368743896, Valid_Loss:1.3842240571975708, Valid_ACC:0.5447999238967896
Epoch 167, CIFAR-10 Batch 4:  Train_Loss:1.123552918434143, Valid_Loss:1.379157304763794, Valid_ACC:0.5517999529838562
Epoch 167, CIFAR-10 Batch 5:  Train_Loss:1.180888295173645, Valid_Loss:1.403014898300171, Valid_ACC:0.5451999306678772
Epoch 168, CIFAR-10 Batch 1:  Train_Loss:1.1105849742889404, Valid_Loss:1.3882226943969727, Valid_ACC:0.5469999313354492
Epoch 168, CIFAR-10 Batch 2:  Train_Loss:1.1551892757415771, Valid_Loss:1.3939745426177979, Valid_ACC:0.5447999238967896
Epoch 168, CIFAR-10 Batch 3:  Train_Loss:1.0837111473083496, Valid_Loss:1.3802026510238647, Valid_ACC:0.5513999462127686
Epoch 168, CIFAR-10 Batch 4:  Train_Loss:1.1208375692367554, Valid_Loss:1.383609652519226, Valid_ACC:0.5501999258995056
Epoch 168, CIFAR-10 Batch 5:  Train_Loss:1.1532412767410278, Valid_Loss:1.3792730569839478, Valid_ACC:0.5521999597549438
Epoch 169, CIFAR-10 Batch 1:  Train_Loss:1.0896058082580566, Valid_Loss:1.3813279867172241, Valid_ACC:0.5477999448776245
Epoch 169, CIFAR-10 Batch 2:  Train_Loss:1.1325184106826782, Valid_Loss:1.3748551607131958, Valid_ACC:0.5511999130249023
Epoch 169, CIFAR-10 Batch 3:  Train_Loss:1.0892258882522583, Valid_Loss:1.3874444961547852, Valid_ACC:0.5447999238967896
Epoch 169, CIFAR-10 Batch 4:  Train_Loss:1.1199464797973633, Valid_Loss:1.384393572807312, Valid_ACC:0.5493999123573303
Epoch 169, CIFAR-10 Batch 5:  Train_Loss:1.151820182800293, Valid_Loss:1.3882007598876953, Valid_ACC:0.5511999726295471
Epoch 170, CIFAR-10 Batch 1:  Train_Loss:1.0978840589523315, Valid_Loss:1.3848068714141846, Valid_ACC:0.5453999042510986
Epoch 170, CIFAR-10 Batch 2:  Train_Loss:1.1300687789916992, Valid_Loss:1.3799536228179932, Valid_ACC:0.5485999584197998
Epoch 170, CIFAR-10 Batch 3:  Train_Loss:1.0690104961395264, Valid_Loss:1.3731261491775513, Valid_ACC:0.556399941444397
Epoch 170, CIFAR-10 Batch 4:  Train_Loss:1.1262657642364502, Valid_Loss:1.3830136060714722, Valid_ACC:0.5499999523162842
Epoch 170, CIFAR-10 Batch 5:  Train_Loss:1.157124400138855, Valid_Loss:1.389549732208252, Valid_ACC:0.5491999387741089
Epoch 171, CIFAR-10 Batch 1:  Train_Loss:1.0818008184432983, Valid_Loss:1.375654935836792, Valid_ACC:0.5501999258995056
Epoch 171, CIFAR-10 Batch 2:  Train_Loss:1.1283791065216064, Valid_Loss:1.3755464553833008, Valid_ACC:0.5525999069213867
Epoch 171, CIFAR-10 Batch 3:  Train_Loss:1.0769163370132446, Valid_Loss:1.3773071765899658, Valid_ACC:0.5475999116897583
Epoch 171, CIFAR-10 Batch 4:  Train_Loss:1.1255749464035034, Valid_Loss:1.384136438369751, Valid_ACC:0.5519999265670776
Epoch 171, CIFAR-10 Batch 5:  Train_Loss:1.1469154357910156, Valid_Loss:1.3949699401855469, Valid_ACC:0.548799991607666
Epoch 172, CIFAR-10 Batch 1:  Train_Loss:1.0855437517166138, Valid_Loss:1.3802728652954102, Valid_ACC:0.5483999252319336
Epoch 172, CIFAR-10 Batch 2:  Train_Loss:1.118484377861023, Valid_Loss:1.3646957874298096, Valid_ACC:0.5559999346733093
Epoch 172, CIFAR-10 Batch 3:  Train_Loss:1.064976692199707, Valid_Loss:1.3687219619750977, Valid_ACC:0.554599940776825
Epoch 172, CIFAR-10 Batch 4:  Train_Loss:1.1278549432754517, Valid_Loss:1.391300916671753, Valid_ACC:0.5455999374389648
Epoch 172, CIFAR-10 Batch 5:  Train_Loss:1.1471949815750122, Valid_Loss:1.385931372642517, Valid_ACC:0.5477999448776245
Epoch 173, CIFAR-10 Batch 1:  Train_Loss:1.128312349319458, Valid_Loss:1.4465266466140747, Valid_ACC:0.5287999510765076
Epoch 173, CIFAR-10 Batch 2:  Train_Loss:1.186152696609497, Valid_Loss:1.4183696508407593, Valid_ACC:0.5363999605178833
Epoch 173, CIFAR-10 Batch 3:  Train_Loss:1.0941566228866577, Valid_Loss:1.3909947872161865, Valid_ACC:0.5437999367713928
Epoch 173, CIFAR-10 Batch 4:  Train_Loss:1.1137715578079224, Valid_Loss:1.380204439163208, Valid_ACC:0.5529999732971191
Epoch 173, CIFAR-10 Batch 5:  Train_Loss:1.1571149826049805, Valid_Loss:1.403571605682373, Valid_ACC:0.5465999245643616
Epoch 174, CIFAR-10 Batch 1:  Train_Loss:1.106361985206604, Valid_Loss:1.4035265445709229, Valid_ACC:0.5427999496459961
Epoch 174, CIFAR-10 Batch 2:  Train_Loss:1.1362850666046143, Valid_Loss:1.3883236646652222, Valid_ACC:0.5469999313354492
Epoch 174, CIFAR-10 Batch 3:  Train_Loss:1.1070383787155151, Valid_Loss:1.4003363847732544, Valid_ACC:0.5409999489784241
Epoch 174, CIFAR-10 Batch 4:  Train_Loss:1.1224762201309204, Valid_Loss:1.3951002359390259, Valid_ACC:0.5433999300003052
Epoch 174, CIFAR-10 Batch 5:  Train_Loss:1.1608242988586426, Valid_Loss:1.4065762758255005, Valid_ACC:0.540399968624115
Epoch 175, CIFAR-10 Batch 1:  Train_Loss:1.1094813346862793, Valid_Loss:1.4207208156585693, Valid_ACC:0.5393999218940735
Epoch 175, CIFAR-10 Batch 2:  Train_Loss:1.1462223529815674, Valid_Loss:1.3906581401824951, Valid_ACC:0.5493999123573303
Epoch 175, CIFAR-10 Batch 3:  Train_Loss:1.0808910131454468, Valid_Loss:1.394026756286621, Valid_ACC:0.5441999435424805
Epoch 175, CIFAR-10 Batch 4:  Train_Loss:1.1146976947784424, Valid_Loss:1.3828351497650146, Valid_ACC:0.5481999516487122
Epoch 175, CIFAR-10 Batch 5:  Train_Loss:1.1402056217193604, Valid_Loss:1.3836596012115479, Valid_ACC:0.5511999130249023
Epoch 176, CIFAR-10 Batch 1:  Train_Loss:1.0942662954330444, Valid_Loss:1.401473879814148, Valid_ACC:0.5461999177932739
Epoch 176, CIFAR-10 Batch 2:  Train_Loss:1.159785509109497, Valid_Loss:1.4046365022659302, Valid_ACC:0.5453999638557434
Epoch 176, CIFAR-10 Batch 3:  Train_Loss:1.11029052734375, Valid_Loss:1.4059709310531616, Valid_ACC:0.5369998812675476
Epoch 176, CIFAR-10 Batch 4:  Train_Loss:1.1275306940078735, Valid_Loss:1.3896899223327637, Valid_ACC:0.5441999435424805
Epoch 176, CIFAR-10 Batch 5:  Train_Loss:1.129133701324463, Valid_Loss:1.3786523342132568, Valid_ACC:0.5519999265670776
Epoch 177, CIFAR-10 Batch 1:  Train_Loss:1.0938146114349365, Valid_Loss:1.4028668403625488, Valid_ACC:0.542199969291687
Epoch 177, CIFAR-10 Batch 2:  Train_Loss:1.1600823402404785, Valid_Loss:1.4011472463607788, Valid_ACC:0.5429999232292175
Epoch 177, CIFAR-10 Batch 3:  Train_Loss:1.0820268392562866, Valid_Loss:1.3918508291244507, Valid_ACC:0.5453999638557434
Epoch 177, CIFAR-10 Batch 4:  Train_Loss:1.111716628074646, Valid_Loss:1.3872593641281128, Valid_ACC:0.5469998717308044
Epoch 177, CIFAR-10 Batch 5:  Train_Loss:1.150819182395935, Valid_Loss:1.4019372463226318, Valid_ACC:0.5427999496459961
Epoch 178, CIFAR-10 Batch 1:  Train_Loss:1.0897960662841797, Valid_Loss:1.387162208557129, Valid_ACC:0.5481999516487122
Epoch 178, CIFAR-10 Batch 2:  Train_Loss:1.1288737058639526, Valid_Loss:1.383171796798706, Valid_ACC:0.549799919128418
Epoch 178, CIFAR-10 Batch 3:  Train_Loss:1.069741129875183, Valid_Loss:1.3898519277572632, Valid_ACC:0.5511999130249023
Epoch 178, CIFAR-10 Batch 4:  Train_Loss:1.1295665502548218, Valid_Loss:1.3867547512054443, Valid_ACC:0.5485999584197998
Epoch 178, CIFAR-10 Batch 5:  Train_Loss:1.137618064880371, Valid_Loss:1.390399694442749, Valid_ACC:0.5525999665260315
Epoch 179, CIFAR-10 Batch 1:  Train_Loss:1.089058518409729, Valid_Loss:1.3760920763015747, Valid_ACC:0.5543999075889587
Epoch 179, CIFAR-10 Batch 2:  Train_Loss:1.1308526992797852, Valid_Loss:1.379481315612793, Valid_ACC:0.5525999665260315
Epoch 179, CIFAR-10 Batch 3:  Train_Loss:1.052832841873169, Valid_Loss:1.3731305599212646, Valid_ACC:0.5561999678611755
Epoch 179, CIFAR-10 Batch 4:  Train_Loss:1.1042702198028564, Valid_Loss:1.3794960975646973, Valid_ACC:0.554599940776825
Epoch 179, CIFAR-10 Batch 5:  Train_Loss:1.1493291854858398, Valid_Loss:1.3841490745544434, Valid_ACC:0.5527999401092529
Epoch 180, CIFAR-10 Batch 1:  Train_Loss:1.0708653926849365, Valid_Loss:1.3746235370635986, Valid_ACC:0.5529999136924744
Epoch 180, CIFAR-10 Batch 2:  Train_Loss:1.1325790882110596, Valid_Loss:1.3842577934265137, Valid_ACC:0.5489999651908875
Epoch 180, CIFAR-10 Batch 3:  Train_Loss:1.0620346069335938, Valid_Loss:1.3751771450042725, Valid_ACC:0.5511999130249023
Epoch 180, CIFAR-10 Batch 4:  Train_Loss:1.0951554775238037, Valid_Loss:1.3676685094833374, Valid_ACC:0.5591999292373657
Epoch 180, CIFAR-10 Batch 5:  Train_Loss:1.1208237409591675, Valid_Loss:1.3669893741607666, Valid_ACC:0.5595999956130981
Epoch 181, CIFAR-10 Batch 1:  Train_Loss:1.063668966293335, Valid_Loss:1.3623013496398926, Valid_ACC:0.5575999021530151
Epoch 181, CIFAR-10 Batch 2:  Train_Loss:1.1277613639831543, Valid_Loss:1.381912350654602, Valid_ACC:0.5501999258995056
Epoch 181, CIFAR-10 Batch 3:  Train_Loss:1.0530955791473389, Valid_Loss:1.3765795230865479, Valid_ACC:0.5547999143600464
Epoch 181, CIFAR-10 Batch 4:  Train_Loss:1.0925331115722656, Valid_Loss:1.3702588081359863, Valid_ACC:0.5549999475479126
Epoch 181, CIFAR-10 Batch 5:  Train_Loss:1.1263206005096436, Valid_Loss:1.370042085647583, Valid_ACC:0.5587999820709229
Epoch 182, CIFAR-10 Batch 1:  Train_Loss:1.0686802864074707, Valid_Loss:1.37326180934906, Valid_ACC:0.5511999726295471
Epoch 182, CIFAR-10 Batch 2:  Train_Loss:1.1232415437698364, Valid_Loss:1.3838821649551392, Valid_ACC:0.5491999387741089
Epoch 182, CIFAR-10 Batch 3:  Train_Loss:1.0549869537353516, Valid_Loss:1.3672596216201782, Valid_ACC:0.555199921131134
Epoch 182, CIFAR-10 Batch 4:  Train_Loss:1.0938209295272827, Valid_Loss:1.375563383102417, Valid_ACC:0.5573999285697937
Epoch 182, CIFAR-10 Batch 5:  Train_Loss:1.1313356161117554, Valid_Loss:1.3769543170928955, Valid_ACC:0.5517999529838562
Epoch 183, CIFAR-10 Batch 1:  Train_Loss:1.076807975769043, Valid_Loss:1.3741703033447266, Valid_ACC:0.553399920463562
Epoch 183, CIFAR-10 Batch 2:  Train_Loss:1.1281373500823975, Valid_Loss:1.378801703453064, Valid_ACC:0.5539999604225159
Epoch 183, CIFAR-10 Batch 3:  Train_Loss:1.069704532623291, Valid_Loss:1.3750417232513428, Valid_ACC:0.553399920463562
Epoch 183, CIFAR-10 Batch 4:  Train_Loss:1.128753423690796, Valid_Loss:1.3926434516906738, Valid_ACC:0.5443999171257019
Epoch 183, CIFAR-10 Batch 5:  Train_Loss:1.1371358633041382, Valid_Loss:1.381760597229004, Valid_ACC:0.5529999136924744
Epoch 184, CIFAR-10 Batch 1:  Train_Loss:1.0756571292877197, Valid_Loss:1.3850458860397339, Valid_ACC:0.5461999177932739
Epoch 184, CIFAR-10 Batch 2:  Train_Loss:1.1042978763580322, Valid_Loss:1.3773503303527832, Valid_ACC:0.5535998940467834
Epoch 184, CIFAR-10 Batch 3:  Train_Loss:1.0444198846817017, Valid_Loss:1.3649379014968872, Valid_ACC:0.5599998831748962
Epoch 184, CIFAR-10 Batch 4:  Train_Loss:1.103125810623169, Valid_Loss:1.3753834962844849, Valid_ACC:0.5523999333381653
Epoch 184, CIFAR-10 Batch 5:  Train_Loss:1.1194143295288086, Valid_Loss:1.3681660890579224, Valid_ACC:0.556999921798706
Epoch 185, CIFAR-10 Batch 1:  Train_Loss:1.0629345178604126, Valid_Loss:1.3800393342971802, Valid_ACC:0.5501999258995056
Epoch 185, CIFAR-10 Batch 2:  Train_Loss:1.126857876777649, Valid_Loss:1.3858072757720947, Valid_ACC:0.548599898815155
Epoch 185, CIFAR-10 Batch 3:  Train_Loss:1.0632846355438232, Valid_Loss:1.385998249053955, Valid_ACC:0.5491999387741089
Epoch 185, CIFAR-10 Batch 4:  Train_Loss:1.0922012329101562, Valid_Loss:1.3667887449264526, Valid_ACC:0.5557999014854431
Epoch 185, CIFAR-10 Batch 5:  Train_Loss:1.1155493259429932, Valid_Loss:1.3754569292068481, Valid_ACC:0.5561999082565308
Epoch 186, CIFAR-10 Batch 1:  Train_Loss:1.0648940801620483, Valid_Loss:1.3707499504089355, Valid_ACC:0.5589998960494995
Epoch 186, CIFAR-10 Batch 2:  Train_Loss:1.1104718446731567, Valid_Loss:1.3701313734054565, Valid_ACC:0.556199848651886
Epoch 186, CIFAR-10 Batch 3:  Train_Loss:1.0382254123687744, Valid_Loss:1.3682403564453125, Valid_ACC:0.5571998953819275
Epoch 186, CIFAR-10 Batch 4:  Train_Loss:1.0968044996261597, Valid_Loss:1.3704373836517334, Valid_ACC:0.5519999265670776
Epoch 186, CIFAR-10 Batch 5:  Train_Loss:1.1240636110305786, Valid_Loss:1.3826427459716797, Valid_ACC:0.5521999597549438
Epoch 187, CIFAR-10 Batch 1:  Train_Loss:1.0656710863113403, Valid_Loss:1.3669981956481934, Valid_ACC:0.5553998947143555
Epoch 187, CIFAR-10 Batch 2:  Train_Loss:1.104337453842163, Valid_Loss:1.3674507141113281, Valid_ACC:0.5565999150276184
Epoch 187, CIFAR-10 Batch 3:  Train_Loss:1.0616536140441895, Valid_Loss:1.3729716539382935, Valid_ACC:0.5551999807357788
Epoch 187, CIFAR-10 Batch 4:  Train_Loss:1.0964913368225098, Valid_Loss:1.3829206228256226, Valid_ACC:0.5483999252319336
Epoch 187, CIFAR-10 Batch 5:  Train_Loss:1.1187657117843628, Valid_Loss:1.3601369857788086, Valid_ACC:0.5589999556541443
Epoch 188, CIFAR-10 Batch 1:  Train_Loss:1.0526089668273926, Valid_Loss:1.3660380840301514, Valid_ACC:0.5533999800682068
Epoch 188, CIFAR-10 Batch 2:  Train_Loss:1.0943657159805298, Valid_Loss:1.3655979633331299, Valid_ACC:0.5577999353408813
Epoch 188, CIFAR-10 Batch 3:  Train_Loss:1.0425643920898438, Valid_Loss:1.3669325113296509, Valid_ACC:0.556999921798706
Epoch 188, CIFAR-10 Batch 4:  Train_Loss:1.0872796773910522, Valid_Loss:1.3645867109298706, Valid_ACC:0.5553999543190002
Epoch 188, CIFAR-10 Batch 5:  Train_Loss:1.1150729656219482, Valid_Loss:1.3747613430023193, Valid_ACC:0.553399920463562
Epoch 189, CIFAR-10 Batch 1:  Train_Loss:1.0537521839141846, Valid_Loss:1.3661768436431885, Valid_ACC:0.5557999014854431
Epoch 189, CIFAR-10 Batch 2:  Train_Loss:1.1067469120025635, Valid_Loss:1.375154972076416, Valid_ACC:0.558199942111969
Epoch 189, CIFAR-10 Batch 3:  Train_Loss:1.049497127532959, Valid_Loss:1.3703911304473877, Valid_ACC:0.5541999340057373
Epoch 189, CIFAR-10 Batch 4:  Train_Loss:1.086958646774292, Valid_Loss:1.3665655851364136, Valid_ACC:0.5575999021530151
Epoch 189, CIFAR-10 Batch 5:  Train_Loss:1.108468770980835, Valid_Loss:1.3619483709335327, Valid_ACC:0.5597999691963196
Epoch 190, CIFAR-10 Batch 1:  Train_Loss:1.0515854358673096, Valid_Loss:1.3598418235778809, Valid_ACC:0.5607999563217163
Epoch 190, CIFAR-10 Batch 2:  Train_Loss:1.1171810626983643, Valid_Loss:1.3801836967468262, Valid_ACC:0.5557999610900879
Epoch 190, CIFAR-10 Batch 3:  Train_Loss:1.0417215824127197, Valid_Loss:1.365471601486206, Valid_ACC:0.554599940776825
Epoch 190, CIFAR-10 Batch 4:  Train_Loss:1.0878630876541138, Valid_Loss:1.3699251413345337, Valid_ACC:0.5551999807357788
Epoch 190, CIFAR-10 Batch 5:  Train_Loss:1.1131041049957275, Valid_Loss:1.3763771057128906, Valid_ACC:0.554599940776825
Epoch 191, CIFAR-10 Batch 1:  Train_Loss:1.0566028356552124, Valid_Loss:1.3721163272857666, Valid_ACC:0.5527999401092529
Epoch 191, CIFAR-10 Batch 2:  Train_Loss:1.1022309064865112, Valid_Loss:1.3682405948638916, Valid_ACC:0.5539999008178711
Epoch 191, CIFAR-10 Batch 3:  Train_Loss:1.0432096719741821, Valid_Loss:1.365797519683838, Valid_ACC:0.5557999014854431
Epoch 191, CIFAR-10 Batch 4:  Train_Loss:1.1082913875579834, Valid_Loss:1.3839669227600098, Valid_ACC:0.5489999055862427
Epoch 191, CIFAR-10 Batch 5:  Train_Loss:1.1088324785232544, Valid_Loss:1.367065191268921, Valid_ACC:0.5581998825073242
Epoch 192, CIFAR-10 Batch 1:  Train_Loss:1.0607982873916626, Valid_Loss:1.3801394701004028, Valid_ACC:0.5513999462127686
Epoch 192, CIFAR-10 Batch 2:  Train_Loss:1.09321129322052, Valid_Loss:1.3714385032653809, Valid_ACC:0.5549999475479126
Epoch 192, CIFAR-10 Batch 3:  Train_Loss:1.0458711385726929, Valid_Loss:1.376084327697754, Valid_ACC:0.5511999130249023
Epoch 192, CIFAR-10 Batch 4:  Train_Loss:1.1018085479736328, Valid_Loss:1.390519618988037, Valid_ACC:0.5461999177932739
Epoch 192, CIFAR-10 Batch 5:  Train_Loss:1.1166332960128784, Valid_Loss:1.3647257089614868, Valid_ACC:0.5626000165939331
Epoch 193, CIFAR-10 Batch 1:  Train_Loss:1.0455905199050903, Valid_Loss:1.364271640777588, Valid_ACC:0.5599998831748962
Epoch 193, CIFAR-10 Batch 2:  Train_Loss:1.0938879251480103, Valid_Loss:1.3676350116729736, Valid_ACC:0.5605999231338501
Epoch 193, CIFAR-10 Batch 3:  Train_Loss:1.0395854711532593, Valid_Loss:1.366121768951416, Valid_ACC:0.556999921798706
Epoch 193, CIFAR-10 Batch 4:  Train_Loss:1.1088786125183105, Valid_Loss:1.3887128829956055, Valid_ACC:0.5465999245643616
Epoch 193, CIFAR-10 Batch 5:  Train_Loss:1.111266851425171, Valid_Loss:1.3622331619262695, Valid_ACC:0.5623999238014221
Epoch 194, CIFAR-10 Batch 1:  Train_Loss:1.040642261505127, Valid_Loss:1.3665978908538818, Valid_ACC:0.5559999346733093
Epoch 194, CIFAR-10 Batch 2:  Train_Loss:1.0978842973709106, Valid_Loss:1.3718162775039673, Valid_ACC:0.55159991979599
Epoch 194, CIFAR-10 Batch 3:  Train_Loss:1.0469708442687988, Valid_Loss:1.3784226179122925, Valid_ACC:0.5499998927116394
Epoch 194, CIFAR-10 Batch 4:  Train_Loss:1.0878126621246338, Valid_Loss:1.3817481994628906, Valid_ACC:0.5463999509811401
Epoch 194, CIFAR-10 Batch 5:  Train_Loss:1.0996057987213135, Valid_Loss:1.3616008758544922, Valid_ACC:0.5603998899459839
Epoch 195, CIFAR-10 Batch 1:  Train_Loss:1.0437088012695312, Valid_Loss:1.3620562553405762, Valid_ACC:0.5593999624252319
Epoch 195, CIFAR-10 Batch 2:  Train_Loss:1.0795707702636719, Valid_Loss:1.3661993741989136, Valid_ACC:0.558199942111969
Epoch 195, CIFAR-10 Batch 3:  Train_Loss:1.0372799634933472, Valid_Loss:1.3660725355148315, Valid_ACC:0.5537999272346497
Epoch 195, CIFAR-10 Batch 4:  Train_Loss:1.0903170108795166, Valid_Loss:1.3801578283309937, Valid_ACC:0.5517998933792114
Epoch 195, CIFAR-10 Batch 5:  Train_Loss:1.1160588264465332, Valid_Loss:1.3729133605957031, Valid_ACC:0.5543999671936035
Epoch 196, CIFAR-10 Batch 1:  Train_Loss:1.0462971925735474, Valid_Loss:1.371824860572815, Valid_ACC:0.5583999156951904
Epoch 196, CIFAR-10 Batch 2:  Train_Loss:1.1003100872039795, Valid_Loss:1.3754032850265503, Valid_ACC:0.556399941444397
Epoch 196, CIFAR-10 Batch 3:  Train_Loss:1.038221001625061, Valid_Loss:1.381477952003479, Valid_ACC:0.5529999136924744
Epoch 196, CIFAR-10 Batch 4:  Train_Loss:1.076911449432373, Valid_Loss:1.3743016719818115, Valid_ACC:0.5547999739646912
Epoch 196, CIFAR-10 Batch 5:  Train_Loss:1.0989941358566284, Valid_Loss:1.3637397289276123, Valid_ACC:0.5577999353408813
Epoch 197, CIFAR-10 Batch 1:  Train_Loss:1.0427809953689575, Valid_Loss:1.3707797527313232, Valid_ACC:0.556399941444397
Epoch 197, CIFAR-10 Batch 2:  Train_Loss:1.0852543115615845, Valid_Loss:1.3598053455352783, Valid_ACC:0.5627999305725098
Epoch 197, CIFAR-10 Batch 3:  Train_Loss:1.030603051185608, Valid_Loss:1.3692585229873657, Valid_ACC:0.5543999671936035
Epoch 197, CIFAR-10 Batch 4:  Train_Loss:1.0672403573989868, Valid_Loss:1.3639897108078003, Valid_ACC:0.5587999224662781
Epoch 197, CIFAR-10 Batch 5:  Train_Loss:1.1000075340270996, Valid_Loss:1.3622550964355469, Valid_ACC:0.5617998838424683
Epoch 198, CIFAR-10 Batch 1:  Train_Loss:1.0636401176452637, Valid_Loss:1.3977609872817993, Valid_ACC:0.5425999164581299
Epoch 198, CIFAR-10 Batch 2:  Train_Loss:1.0878980159759521, Valid_Loss:1.3636462688446045, Valid_ACC:0.5579999089241028
Epoch 198, CIFAR-10 Batch 3:  Train_Loss:1.0211076736450195, Valid_Loss:1.3663713932037354, Valid_ACC:0.5593999028205872
Epoch 198, CIFAR-10 Batch 4:  Train_Loss:1.0749925374984741, Valid_Loss:1.3706142902374268, Valid_ACC:0.554599940776825
Epoch 198, CIFAR-10 Batch 5:  Train_Loss:1.1032766103744507, Valid_Loss:1.3689825534820557, Valid_ACC:0.558199942111969
Epoch 199, CIFAR-10 Batch 1:  Train_Loss:1.072651982307434, Valid_Loss:1.4078969955444336, Valid_ACC:0.5399999618530273
Epoch 199, CIFAR-10 Batch 2:  Train_Loss:1.094150424003601, Valid_Loss:1.367275357246399, Valid_ACC:0.5577999353408813
Epoch 199, CIFAR-10 Batch 3:  Train_Loss:1.0605850219726562, Valid_Loss:1.391955852508545, Valid_ACC:0.5447999238967896
Epoch 199, CIFAR-10 Batch 4:  Train_Loss:1.070371150970459, Valid_Loss:1.373460054397583, Valid_ACC:0.5519999265670776
Epoch 199, CIFAR-10 Batch 5:  Train_Loss:1.0855131149291992, Valid_Loss:1.3600425720214844, Valid_ACC:0.5609999299049377
Epoch 200, CIFAR-10 Batch 1:  Train_Loss:1.042237639427185, Valid_Loss:1.3772673606872559, Valid_ACC:0.5523999333381653
Epoch 200, CIFAR-10 Batch 2:  Train_Loss:1.0906563997268677, Valid_Loss:1.3723828792572021, Valid_ACC:0.5521999597549438
Epoch 200, CIFAR-10 Batch 3:  Train_Loss:1.0151832103729248, Valid_Loss:1.3597619533538818, Valid_ACC:0.5589999556541443
Epoch 200, CIFAR-10 Batch 4:  Train_Loss:1.0902841091156006, Valid_Loss:1.3778067827224731, Valid_ACC:0.5535999536514282
Epoch 200, CIFAR-10 Batch 5:  Train_Loss:1.084941029548645, Valid_Loss:1.3615010976791382, Valid_ACC:0.5601999163627625
Epoch 201, CIFAR-10 Batch 1:  Train_Loss:1.038051724433899, Valid_Loss:1.362688660621643, Valid_ACC:0.5573999285697937
Epoch 201, CIFAR-10 Batch 2:  Train_Loss:1.0717759132385254, Valid_Loss:1.357515573501587, Valid_ACC:0.5647999048233032
Epoch 201, CIFAR-10 Batch 3:  Train_Loss:1.0135917663574219, Valid_Loss:1.3634731769561768, Valid_ACC:0.5583999156951904
Epoch 201, CIFAR-10 Batch 4:  Train_Loss:1.1026111841201782, Valid_Loss:1.386647343635559, Valid_ACC:0.5529999136924744
Epoch 201, CIFAR-10 Batch 5:  Train_Loss:1.0985534191131592, Valid_Loss:1.3766188621520996, Valid_ACC:0.5527999401092529
Epoch 202, CIFAR-10 Batch 1:  Train_Loss:1.0409139394760132, Valid_Loss:1.3786555528640747, Valid_ACC:0.5523999333381653
Epoch 202, CIFAR-10 Batch 2:  Train_Loss:1.1201410293579102, Valid_Loss:1.3857879638671875, Valid_ACC:0.5523999333381653
Epoch 202, CIFAR-10 Batch 3:  Train_Loss:1.0244625806808472, Valid_Loss:1.3702633380889893, Valid_ACC:0.5587999224662781
Epoch 202, CIFAR-10 Batch 4:  Train_Loss:1.0723308324813843, Valid_Loss:1.3732720613479614, Valid_ACC:0.5535999536514282
Epoch 202, CIFAR-10 Batch 5:  Train_Loss:1.0849645137786865, Valid_Loss:1.3574542999267578, Valid_ACC:0.5647999048233032
Epoch 203, CIFAR-10 Batch 1:  Train_Loss:1.0472980737686157, Valid_Loss:1.3884482383728027, Valid_ACC:0.5459999442100525
Epoch 203, CIFAR-10 Batch 2:  Train_Loss:1.0821059942245483, Valid_Loss:1.3675408363342285, Valid_ACC:0.5579999089241028
Epoch 203, CIFAR-10 Batch 3:  Train_Loss:1.0367908477783203, Valid_Loss:1.382914662361145, Valid_ACC:0.5495998859405518
Epoch 203, CIFAR-10 Batch 4:  Train_Loss:1.0954875946044922, Valid_Loss:1.3960906267166138, Valid_ACC:0.5445999503135681
Epoch 203, CIFAR-10 Batch 5:  Train_Loss:1.100193738937378, Valid_Loss:1.360327959060669, Valid_ACC:0.5585999488830566
Epoch 204, CIFAR-10 Batch 1:  Train_Loss:1.036612868309021, Valid_Loss:1.3685284852981567, Valid_ACC:0.558199942111969
Epoch 204, CIFAR-10 Batch 2:  Train_Loss:1.0783848762512207, Valid_Loss:1.3593443632125854, Valid_ACC:0.5613999366760254
Epoch 204, CIFAR-10 Batch 3:  Train_Loss:1.028364658355713, Valid_Loss:1.3751213550567627, Valid_ACC:0.5523999333381653
Epoch 204, CIFAR-10 Batch 4:  Train_Loss:1.0633981227874756, Valid_Loss:1.3691030740737915, Valid_ACC:0.5559999346733093
Epoch 204, CIFAR-10 Batch 5:  Train_Loss:1.0861525535583496, Valid_Loss:1.3576374053955078, Valid_ACC:0.561799943447113
Epoch 205, CIFAR-10 Batch 1:  Train_Loss:1.0380476713180542, Valid_Loss:1.3663853406906128, Valid_ACC:0.5539999604225159
Epoch 205, CIFAR-10 Batch 2:  Train_Loss:1.075744867324829, Valid_Loss:1.3635859489440918, Valid_ACC:0.5585999488830566
Epoch 205, CIFAR-10 Batch 3:  Train_Loss:1.0215544700622559, Valid_Loss:1.3755172491073608, Valid_ACC:0.5555999279022217
Epoch 205, CIFAR-10 Batch 4:  Train_Loss:1.085752010345459, Valid_Loss:1.3851150274276733, Valid_ACC:0.5455999374389648
Epoch 205, CIFAR-10 Batch 5:  Train_Loss:1.088611364364624, Valid_Loss:1.3548262119293213, Valid_ACC:0.5631999373435974
Epoch 206, CIFAR-10 Batch 1:  Train_Loss:1.0461543798446655, Valid_Loss:1.372252345085144, Valid_ACC:0.5529999136924744
Epoch 206, CIFAR-10 Batch 2:  Train_Loss:1.081620216369629, Valid_Loss:1.367142915725708, Valid_ACC:0.5595999360084534
Epoch 206, CIFAR-10 Batch 3:  Train_Loss:1.0084971189498901, Valid_Loss:1.3706382513046265, Valid_ACC:0.5555999279022217
Epoch 206, CIFAR-10 Batch 4:  Train_Loss:1.0785338878631592, Valid_Loss:1.3713183403015137, Valid_ACC:0.5529999732971191
Epoch 206, CIFAR-10 Batch 5:  Train_Loss:1.0800492763519287, Valid_Loss:1.3553242683410645, Valid_ACC:0.5637999176979065
Epoch 207, CIFAR-10 Batch 1:  Train_Loss:1.0595815181732178, Valid_Loss:1.3997411727905273, Valid_ACC:0.5411999225616455
Epoch 207, CIFAR-10 Batch 2:  Train_Loss:1.093605637550354, Valid_Loss:1.3740265369415283, Valid_ACC:0.553399920463562
Epoch 207, CIFAR-10 Batch 3:  Train_Loss:1.0456457138061523, Valid_Loss:1.390901803970337, Valid_ACC:0.5469999313354492
Epoch 207, CIFAR-10 Batch 4:  Train_Loss:1.0727121829986572, Valid_Loss:1.3756418228149414, Valid_ACC:0.5535998940467834
Epoch 207, CIFAR-10 Batch 5:  Train_Loss:1.0993165969848633, Valid_Loss:1.3654518127441406, Valid_ACC:0.5585999488830566
Epoch 208, CIFAR-10 Batch 1:  Train_Loss:1.0504106283187866, Valid_Loss:1.3597488403320312, Valid_ACC:0.5607999563217163
Epoch 208, CIFAR-10 Batch 2:  Train_Loss:1.0929222106933594, Valid_Loss:1.373547077178955, Valid_ACC:0.5525999665260315
Epoch 208, CIFAR-10 Batch 3:  Train_Loss:1.0493083000183105, Valid_Loss:1.397904634475708, Valid_ACC:0.5471999645233154
Epoch 208, CIFAR-10 Batch 4:  Train_Loss:1.0679088830947876, Valid_Loss:1.3723416328430176, Valid_ACC:0.5515999794006348
Epoch 208, CIFAR-10 Batch 5:  Train_Loss:1.1339200735092163, Valid_Loss:1.3958745002746582, Valid_ACC:0.5465999245643616
Epoch 209, CIFAR-10 Batch 1:  Train_Loss:1.0493632555007935, Valid_Loss:1.380371332168579, Valid_ACC:0.553399920463562
Epoch 209, CIFAR-10 Batch 2:  Train_Loss:1.0859754085540771, Valid_Loss:1.3671560287475586, Valid_ACC:0.5575999021530151
Epoch 209, CIFAR-10 Batch 3:  Train_Loss:1.0190728902816772, Valid_Loss:1.3747996091842651, Valid_ACC:0.5481998920440674
Epoch 209, CIFAR-10 Batch 4:  Train_Loss:1.0556666851043701, Valid_Loss:1.3706170320510864, Valid_ACC:0.5559998750686646
Epoch 209, CIFAR-10 Batch 5:  Train_Loss:1.0848517417907715, Valid_Loss:1.355087399482727, Valid_ACC:0.5627999305725098
Epoch 210, CIFAR-10 Batch 1:  Train_Loss:1.0550930500030518, Valid_Loss:1.3615915775299072, Valid_ACC:0.5593999624252319
Epoch 210, CIFAR-10 Batch 2:  Train_Loss:1.0843935012817383, Valid_Loss:1.3727396726608276, Valid_ACC:0.5549999475479126
Epoch 210, CIFAR-10 Batch 3:  Train_Loss:1.0174918174743652, Valid_Loss:1.3795424699783325, Valid_ACC:0.5507999062538147
Epoch 210, CIFAR-10 Batch 4:  Train_Loss:1.0855093002319336, Valid_Loss:1.3946524858474731, Valid_ACC:0.5493999123573303
Epoch 210, CIFAR-10 Batch 5:  Train_Loss:1.1243515014648438, Valid_Loss:1.374423861503601, Valid_ACC:0.5503999590873718
Epoch 211, CIFAR-10 Batch 1:  Train_Loss:1.0443336963653564, Valid_Loss:1.3595808744430542, Valid_ACC:0.5597999691963196
Epoch 211, CIFAR-10 Batch 2:  Train_Loss:1.1104915142059326, Valid_Loss:1.3877215385437012, Valid_ACC:0.5477999448776245
Epoch 211, CIFAR-10 Batch 3:  Train_Loss:1.0363755226135254, Valid_Loss:1.3803532123565674, Valid_ACC:0.5501999258995056
Epoch 211, CIFAR-10 Batch 4:  Train_Loss:1.0464307069778442, Valid_Loss:1.3559060096740723, Valid_ACC:0.5621998906135559
Epoch 211, CIFAR-10 Batch 5:  Train_Loss:1.0786383152008057, Valid_Loss:1.3590502738952637, Valid_ACC:0.5605999231338501
Epoch 212, CIFAR-10 Batch 1:  Train_Loss:1.0423873662948608, Valid_Loss:1.3614161014556885, Valid_ACC:0.5607999563217163
Epoch 212, CIFAR-10 Batch 2:  Train_Loss:1.0787386894226074, Valid_Loss:1.364863395690918, Valid_ACC:0.5547999739646912
Epoch 212, CIFAR-10 Batch 3:  Train_Loss:1.0104384422302246, Valid_Loss:1.3691498041152954, Valid_ACC:0.5557999610900879
Epoch 212, CIFAR-10 Batch 4:  Train_Loss:1.0580869913101196, Valid_Loss:1.3694401979446411, Valid_ACC:0.5537999868392944
Epoch 212, CIFAR-10 Batch 5:  Train_Loss:1.0909556150436401, Valid_Loss:1.3651199340820312, Valid_ACC:0.5565999150276184
Epoch 213, CIFAR-10 Batch 1:  Train_Loss:1.0247327089309692, Valid_Loss:1.3569679260253906, Valid_ACC:0.5583999156951904
Epoch 213, CIFAR-10 Batch 2:  Train_Loss:1.0702614784240723, Valid_Loss:1.3631601333618164, Valid_ACC:0.5583999156951904
Epoch 213, CIFAR-10 Batch 3:  Train_Loss:1.0332224369049072, Valid_Loss:1.3869609832763672, Valid_ACC:0.5479999780654907
Epoch 213, CIFAR-10 Batch 4:  Train_Loss:1.0599241256713867, Valid_Loss:1.3737062215805054, Valid_ACC:0.5501999258995056
Epoch 213, CIFAR-10 Batch 5:  Train_Loss:1.0787605047225952, Valid_Loss:1.3528603315353394, Valid_ACC:0.5589999556541443
Epoch 214, CIFAR-10 Batch 1:  Train_Loss:1.014761209487915, Valid_Loss:1.356966257095337, Valid_ACC:0.5593999624252319
Epoch 214, CIFAR-10 Batch 2:  Train_Loss:1.064217448234558, Valid_Loss:1.3606693744659424, Valid_ACC:0.559999942779541
Epoch 214, CIFAR-10 Batch 3:  Train_Loss:0.9978699684143066, Valid_Loss:1.3608921766281128, Valid_ACC:0.5585999488830566
Epoch 214, CIFAR-10 Batch 4:  Train_Loss:1.0658869743347168, Valid_Loss:1.380016565322876, Valid_ACC:0.5501999855041504
Epoch 214, CIFAR-10 Batch 5:  Train_Loss:1.069077730178833, Valid_Loss:1.350304126739502, Valid_ACC:0.5629999041557312
Epoch 215, CIFAR-10 Batch 1:  Train_Loss:1.0252368450164795, Valid_Loss:1.358480453491211, Valid_ACC:0.5587999224662781
Epoch 215, CIFAR-10 Batch 2:  Train_Loss:1.0678775310516357, Valid_Loss:1.3631746768951416, Valid_ACC:0.5582000017166138
Epoch 215, CIFAR-10 Batch 3:  Train_Loss:1.0053483247756958, Valid_Loss:1.3669359683990479, Valid_ACC:0.5577999353408813
Epoch 215, CIFAR-10 Batch 4:  Train_Loss:1.0700229406356812, Valid_Loss:1.3847150802612305, Valid_ACC:0.5489999055862427
Epoch 215, CIFAR-10 Batch 5:  Train_Loss:1.0791103839874268, Valid_Loss:1.3633732795715332, Valid_ACC:0.5587999820709229
Epoch 216, CIFAR-10 Batch 1:  Train_Loss:1.0161616802215576, Valid_Loss:1.361185908317566, Valid_ACC:0.5567999482154846
Epoch 216, CIFAR-10 Batch 2:  Train_Loss:1.0802528858184814, Valid_Loss:1.3716617822647095, Valid_ACC:0.554599940776825
Epoch 216, CIFAR-10 Batch 3:  Train_Loss:1.0118731260299683, Valid_Loss:1.3795807361602783, Valid_ACC:0.5539999008178711
Epoch 216, CIFAR-10 Batch 4:  Train_Loss:1.048295497894287, Valid_Loss:1.3653678894042969, Valid_ACC:0.5583999156951904
Epoch 216, CIFAR-10 Batch 5:  Train_Loss:1.0993402004241943, Valid_Loss:1.3774337768554688, Valid_ACC:0.5561999082565308
Epoch 217, CIFAR-10 Batch 1:  Train_Loss:1.025132417678833, Valid_Loss:1.3613661527633667, Valid_ACC:0.553399920463562
Epoch 217, CIFAR-10 Batch 2:  Train_Loss:1.0569170713424683, Valid_Loss:1.3598730564117432, Valid_ACC:0.5621999502182007
Epoch 217, CIFAR-10 Batch 3:  Train_Loss:0.9976109862327576, Valid_Loss:1.3666304349899292, Valid_ACC:0.5561999082565308
Epoch 217, CIFAR-10 Batch 4:  Train_Loss:1.0725430250167847, Valid_Loss:1.3774864673614502, Valid_ACC:0.5507999658584595
Epoch 217, CIFAR-10 Batch 5:  Train_Loss:1.0812673568725586, Valid_Loss:1.367327332496643, Valid_ACC:0.5553999543190002
Epoch 218, CIFAR-10 Batch 1:  Train_Loss:1.0188870429992676, Valid_Loss:1.3557575941085815, Valid_ACC:0.5615999102592468
Epoch 218, CIFAR-10 Batch 2:  Train_Loss:1.054803490638733, Valid_Loss:1.362280249595642, Valid_ACC:0.5623999238014221
Epoch 218, CIFAR-10 Batch 3:  Train_Loss:1.0124990940093994, Valid_Loss:1.3722121715545654, Valid_ACC:0.5537999272346497
Epoch 218, CIFAR-10 Batch 4:  Train_Loss:1.036881446838379, Valid_Loss:1.3609042167663574, Valid_ACC:0.5567999482154846
Epoch 218, CIFAR-10 Batch 5:  Train_Loss:1.078904628753662, Valid_Loss:1.3673263788223267, Valid_ACC:0.556999921798706
Epoch 219, CIFAR-10 Batch 1:  Train_Loss:1.0206959247589111, Valid_Loss:1.3598419427871704, Valid_ACC:0.5565999150276184
Epoch 219, CIFAR-10 Batch 2:  Train_Loss:1.0793073177337646, Valid_Loss:1.3726518154144287, Valid_ACC:0.554599940776825
Epoch 219, CIFAR-10 Batch 3:  Train_Loss:0.9943938255310059, Valid_Loss:1.3677517175674438, Valid_ACC:0.5561999082565308
Epoch 219, CIFAR-10 Batch 4:  Train_Loss:1.0538119077682495, Valid_Loss:1.3781884908676147, Valid_ACC:0.5533999800682068
Epoch 219, CIFAR-10 Batch 5:  Train_Loss:1.0741376876831055, Valid_Loss:1.3623456954956055, Valid_ACC:0.5585999488830566
Epoch 220, CIFAR-10 Batch 1:  Train_Loss:1.0311719179153442, Valid_Loss:1.3601527214050293, Valid_ACC:0.5589998960494995
Epoch 220, CIFAR-10 Batch 2:  Train_Loss:1.0514624118804932, Valid_Loss:1.3527307510375977, Valid_ACC:0.5621998906135559
Epoch 220, CIFAR-10 Batch 3:  Train_Loss:0.9992102384567261, Valid_Loss:1.3648946285247803, Valid_ACC:0.556999921798706
Epoch 220, CIFAR-10 Batch 4:  Train_Loss:1.0485279560089111, Valid_Loss:1.357605218887329, Valid_ACC:0.5607998967170715
Epoch 220, CIFAR-10 Batch 5:  Train_Loss:1.0734610557556152, Valid_Loss:1.3581303358078003, Valid_ACC:0.5619999170303345
Epoch 221, CIFAR-10 Batch 1:  Train_Loss:1.0334556102752686, Valid_Loss:1.3590933084487915, Valid_ACC:0.5617998838424683
Epoch 221, CIFAR-10 Batch 2:  Train_Loss:1.0920383930206299, Valid_Loss:1.382603645324707, Valid_ACC:0.5521999001502991
Epoch 221, CIFAR-10 Batch 3:  Train_Loss:0.9945400953292847, Valid_Loss:1.3666694164276123, Valid_ACC:0.558199942111969
Epoch 221, CIFAR-10 Batch 4:  Train_Loss:1.0392436981201172, Valid_Loss:1.36210036277771, Valid_ACC:0.5619999170303345
Epoch 221, CIFAR-10 Batch 5:  Train_Loss:1.0790536403656006, Valid_Loss:1.3651741743087769, Valid_ACC:0.5561999082565308
Epoch 222, CIFAR-10 Batch 1:  Train_Loss:1.0409023761749268, Valid_Loss:1.3729252815246582, Valid_ACC:0.556399941444397
Epoch 222, CIFAR-10 Batch 2:  Train_Loss:1.0735574960708618, Valid_Loss:1.371883749961853, Valid_ACC:0.5579999089241028
Epoch 222, CIFAR-10 Batch 3:  Train_Loss:1.0030708312988281, Valid_Loss:1.3754503726959229, Valid_ACC:0.5543999075889587
Epoch 222, CIFAR-10 Batch 4:  Train_Loss:1.0327998399734497, Valid_Loss:1.3533519506454468, Valid_ACC:0.5633999109268188
Epoch 222, CIFAR-10 Batch 5:  Train_Loss:1.0647175312042236, Valid_Loss:1.3563520908355713, Valid_ACC:0.5621999502182007
Epoch 223, CIFAR-10 Batch 1:  Train_Loss:1.0093846321105957, Valid_Loss:1.3501148223876953, Valid_ACC:0.5659999251365662
Epoch 223, CIFAR-10 Batch 2:  Train_Loss:1.060511589050293, Valid_Loss:1.3579487800598145, Valid_ACC:0.5623999834060669
Epoch 223, CIFAR-10 Batch 3:  Train_Loss:0.9922693967819214, Valid_Loss:1.3665552139282227, Valid_ACC:0.5585998892784119
Epoch 223, CIFAR-10 Batch 4:  Train_Loss:1.0432878732681274, Valid_Loss:1.3647892475128174, Valid_ACC:0.5565999746322632
Epoch 223, CIFAR-10 Batch 5:  Train_Loss:1.0599771738052368, Valid_Loss:1.3511449098587036, Valid_ACC:0.5647999048233032
Epoch 224, CIFAR-10 Batch 1:  Train_Loss:1.016976237297058, Valid_Loss:1.3542875051498413, Valid_ACC:0.5585999488830566
Epoch 224, CIFAR-10 Batch 2:  Train_Loss:1.05523681640625, Valid_Loss:1.3567553758621216, Valid_ACC:0.5641999244689941
Epoch 224, CIFAR-10 Batch 3:  Train_Loss:1.0042229890823364, Valid_Loss:1.374376654624939, Valid_ACC:0.5521999597549438
Epoch 224, CIFAR-10 Batch 4:  Train_Loss:1.0590089559555054, Valid_Loss:1.382468581199646, Valid_ACC:0.5501999258995056
Epoch 224, CIFAR-10 Batch 5:  Train_Loss:1.0554141998291016, Valid_Loss:1.3522803783416748, Valid_ACC:0.5637999176979065
Epoch 225, CIFAR-10 Batch 1:  Train_Loss:1.0256092548370361, Valid_Loss:1.3664681911468506, Valid_ACC:0.555199921131134
Epoch 225, CIFAR-10 Batch 2:  Train_Loss:1.0490106344223022, Valid_Loss:1.3650416135787964, Valid_ACC:0.5601999163627625
Epoch 225, CIFAR-10 Batch 3:  Train_Loss:1.018823504447937, Valid_Loss:1.3933687210083008, Valid_ACC:0.5481999516487122
Epoch 225, CIFAR-10 Batch 4:  Train_Loss:1.063342809677124, Valid_Loss:1.3844677209854126, Valid_ACC:0.5501999258995056
Epoch 225, CIFAR-10 Batch 5:  Train_Loss:1.0636334419250488, Valid_Loss:1.3514137268066406, Valid_ACC:0.5637999176979065
Epoch 226, CIFAR-10 Batch 1:  Train_Loss:1.0128273963928223, Valid_Loss:1.3488012552261353, Valid_ACC:0.562999963760376
Epoch 226, CIFAR-10 Batch 2:  Train_Loss:1.0608129501342773, Valid_Loss:1.3700498342514038, Valid_ACC:0.5557999610900879
Epoch 226, CIFAR-10 Batch 3:  Train_Loss:0.9894413352012634, Valid_Loss:1.3643296957015991, Valid_ACC:0.5567999482154846
Epoch 226, CIFAR-10 Batch 4:  Train_Loss:1.037343978881836, Valid_Loss:1.371579885482788, Valid_ACC:0.556999921798706
Epoch 226, CIFAR-10 Batch 5:  Train_Loss:1.0686960220336914, Valid_Loss:1.3543897867202759, Valid_ACC:0.5627999305725098
Epoch 227, CIFAR-10 Batch 1:  Train_Loss:1.025580883026123, Valid_Loss:1.3490440845489502, Valid_ACC:0.5679999589920044
Epoch 227, CIFAR-10 Batch 2:  Train_Loss:1.068054437637329, Valid_Loss:1.369123101234436, Valid_ACC:0.5595999360084534
Epoch 227, CIFAR-10 Batch 3:  Train_Loss:0.9828664660453796, Valid_Loss:1.3569388389587402, Valid_ACC:0.5623999834060669
Epoch 227, CIFAR-10 Batch 4:  Train_Loss:1.0524243116378784, Valid_Loss:1.3860669136047363, Valid_ACC:0.550399899482727
Epoch 227, CIFAR-10 Batch 5:  Train_Loss:1.1014424562454224, Valid_Loss:1.3724677562713623, Valid_ACC:0.5525999665260315
Epoch 228, CIFAR-10 Batch 1:  Train_Loss:1.033475637435913, Valid_Loss:1.3769493103027344, Valid_ACC:0.5515999794006348
Epoch 228, CIFAR-10 Batch 2:  Train_Loss:1.0789775848388672, Valid_Loss:1.3788566589355469, Valid_ACC:0.5559999346733093
Epoch 228, CIFAR-10 Batch 3:  Train_Loss:1.0108394622802734, Valid_Loss:1.3715143203735352, Valid_ACC:0.5573999285697937
Epoch 228, CIFAR-10 Batch 4:  Train_Loss:1.0332705974578857, Valid_Loss:1.3718242645263672, Valid_ACC:0.5593999624252319
Epoch 228, CIFAR-10 Batch 5:  Train_Loss:1.0914016962051392, Valid_Loss:1.3917462825775146, Valid_ACC:0.5461999773979187
Epoch 229, CIFAR-10 Batch 1:  Train_Loss:1.0450890064239502, Valid_Loss:1.3871403932571411, Valid_ACC:0.5489999651908875
Epoch 229, CIFAR-10 Batch 2:  Train_Loss:1.0695922374725342, Valid_Loss:1.3760700225830078, Valid_ACC:0.5547999739646912
Epoch 229, CIFAR-10 Batch 3:  Train_Loss:1.016580581665039, Valid_Loss:1.389353632926941, Valid_ACC:0.5493999123573303
Epoch 229, CIFAR-10 Batch 4:  Train_Loss:1.0549044609069824, Valid_Loss:1.38273286819458, Valid_ACC:0.5515999794006348
Epoch 229, CIFAR-10 Batch 5:  Train_Loss:1.0836503505706787, Valid_Loss:1.3866297006607056, Valid_ACC:0.5531999468803406
Epoch 230, CIFAR-10 Batch 1:  Train_Loss:1.028843879699707, Valid_Loss:1.3742444515228271, Valid_ACC:0.5551999807357788
Epoch 230, CIFAR-10 Batch 2:  Train_Loss:1.0419398546218872, Valid_Loss:1.3632702827453613, Valid_ACC:0.559199869632721
Epoch 230, CIFAR-10 Batch 3:  Train_Loss:0.9916465878486633, Valid_Loss:1.3662867546081543, Valid_ACC:0.556999921798706
Epoch 230, CIFAR-10 Batch 4:  Train_Loss:1.0253243446350098, Valid_Loss:1.365871787071228, Valid_ACC:0.5593999028205872
Epoch 230, CIFAR-10 Batch 5:  Train_Loss:1.0697965621948242, Valid_Loss:1.3723599910736084, Valid_ACC:0.5541999340057373
Epoch 231, CIFAR-10 Batch 1:  Train_Loss:1.0134191513061523, Valid_Loss:1.3638945817947388, Valid_ACC:0.5571999549865723
Epoch 231, CIFAR-10 Batch 2:  Train_Loss:1.0454964637756348, Valid_Loss:1.362237572669983, Valid_ACC:0.5593999624252319
Epoch 231, CIFAR-10 Batch 3:  Train_Loss:0.9917210340499878, Valid_Loss:1.3760168552398682, Valid_ACC:0.5551999807357788
Epoch 231, CIFAR-10 Batch 4:  Train_Loss:1.0443828105926514, Valid_Loss:1.3779367208480835, Valid_ACC:0.5579999685287476
Epoch 231, CIFAR-10 Batch 5:  Train_Loss:1.0660921335220337, Valid_Loss:1.3655263185501099, Valid_ACC:0.5623999238014221
Epoch 232, CIFAR-10 Batch 1:  Train_Loss:1.0285378694534302, Valid_Loss:1.3686914443969727, Valid_ACC:0.5541999936103821
Epoch 232, CIFAR-10 Batch 2:  Train_Loss:1.0545002222061157, Valid_Loss:1.370284080505371, Valid_ACC:0.5579999089241028
Epoch 232, CIFAR-10 Batch 3:  Train_Loss:1.0072954893112183, Valid_Loss:1.3771421909332275, Valid_ACC:0.5553999543190002
Epoch 232, CIFAR-10 Batch 4:  Train_Loss:1.0205061435699463, Valid_Loss:1.3671319484710693, Valid_ACC:0.5589999556541443
Epoch 232, CIFAR-10 Batch 5:  Train_Loss:1.0598500967025757, Valid_Loss:1.3694770336151123, Valid_ACC:0.5591999292373657
Epoch 233, CIFAR-10 Batch 1:  Train_Loss:1.027367353439331, Valid_Loss:1.386418104171753, Valid_ACC:0.5503999590873718
Epoch 233, CIFAR-10 Batch 2:  Train_Loss:1.0496461391448975, Valid_Loss:1.3668384552001953, Valid_ACC:0.5605999231338501
Epoch 233, CIFAR-10 Batch 3:  Train_Loss:0.9971411228179932, Valid_Loss:1.384133219718933, Valid_ACC:0.556399941444397
Epoch 233, CIFAR-10 Batch 4:  Train_Loss:1.0344581604003906, Valid_Loss:1.3697185516357422, Valid_ACC:0.5591999292373657
Epoch 233, CIFAR-10 Batch 5:  Train_Loss:1.0682932138442993, Valid_Loss:1.385172724723816, Valid_ACC:0.5509999394416809
Epoch 234, CIFAR-10 Batch 1:  Train_Loss:1.0148051977157593, Valid_Loss:1.3730019330978394, Valid_ACC:0.5535999536514282
Epoch 234, CIFAR-10 Batch 2:  Train_Loss:1.0407235622406006, Valid_Loss:1.36589515209198, Valid_ACC:0.561799943447113
Epoch 234, CIFAR-10 Batch 3:  Train_Loss:0.9936704039573669, Valid_Loss:1.3716216087341309, Valid_ACC:0.5623999238014221
Epoch 234, CIFAR-10 Batch 4:  Train_Loss:1.0205423831939697, Valid_Loss:1.3544367551803589, Valid_ACC:0.5641999244689941
Epoch 234, CIFAR-10 Batch 5:  Train_Loss:1.0431733131408691, Valid_Loss:1.3586515188217163, Valid_ACC:0.5667999386787415
Epoch 235, CIFAR-10 Batch 1:  Train_Loss:1.0057859420776367, Valid_Loss:1.3537991046905518, Valid_ACC:0.5691999793052673
Epoch 235, CIFAR-10 Batch 2:  Train_Loss:1.016372799873352, Valid_Loss:1.334176778793335, Valid_ACC:0.5749999284744263
Epoch 235, CIFAR-10 Batch 3:  Train_Loss:0.9532536864280701, Valid_Loss:1.3307301998138428, Valid_ACC:0.5773999094963074
Epoch 235, CIFAR-10 Batch 4:  Train_Loss:0.9833633899688721, Valid_Loss:1.3239370584487915, Valid_ACC:0.5759999752044678
Epoch 235, CIFAR-10 Batch 5:  Train_Loss:0.9873718023300171, Valid_Loss:1.3131911754608154, Valid_ACC:0.5813999176025391
Epoch 236, CIFAR-10 Batch 1:  Train_Loss:0.9699856042861938, Valid_Loss:1.3090214729309082, Valid_ACC:0.5779998898506165
Epoch 236, CIFAR-10 Batch 2:  Train_Loss:0.9789308905601501, Valid_Loss:1.2962926626205444, Valid_ACC:0.5873998999595642
Epoch 236, CIFAR-10 Batch 3:  Train_Loss:0.9232010841369629, Valid_Loss:1.3088480234146118, Valid_ACC:0.5755999088287354
Epoch 236, CIFAR-10 Batch 4:  Train_Loss:0.9508904814720154, Valid_Loss:1.2947756052017212, Valid_ACC:0.5873998999595642
Epoch 236, CIFAR-10 Batch 5:  Train_Loss:0.971515417098999, Valid_Loss:1.2995972633361816, Valid_ACC:0.5853999257087708
Epoch 237, CIFAR-10 Batch 1:  Train_Loss:0.9643480181694031, Valid_Loss:1.2990176677703857, Valid_ACC:0.5811999440193176
Epoch 237, CIFAR-10 Batch 2:  Train_Loss:0.9691308736801147, Valid_Loss:1.2977098226547241, Valid_ACC:0.5839999318122864
Epoch 237, CIFAR-10 Batch 3:  Train_Loss:0.9393999576568604, Valid_Loss:1.3106677532196045, Valid_ACC:0.5793999433517456
Epoch 237, CIFAR-10 Batch 4:  Train_Loss:0.9591758847236633, Valid_Loss:1.2880514860153198, Valid_ACC:0.5853999257087708
Epoch 237, CIFAR-10 Batch 5:  Train_Loss:0.9622882008552551, Valid_Loss:1.2948485612869263, Valid_ACC:0.5855998992919922
Epoch 238, CIFAR-10 Batch 1:  Train_Loss:0.944330632686615, Valid_Loss:1.307354211807251, Valid_ACC:0.5809999108314514
Epoch 238, CIFAR-10 Batch 2:  Train_Loss:0.9589552283287048, Valid_Loss:1.289729118347168, Valid_ACC:0.5861998796463013
Epoch 238, CIFAR-10 Batch 3:  Train_Loss:0.9396063685417175, Valid_Loss:1.3180336952209473, Valid_ACC:0.5727999210357666
Epoch 238, CIFAR-10 Batch 4:  Train_Loss:0.9410027265548706, Valid_Loss:1.2828519344329834, Valid_ACC:0.5923999547958374
Epoch 238, CIFAR-10 Batch 5:  Train_Loss:0.9489132761955261, Valid_Loss:1.2820600271224976, Valid_ACC:0.5931999683380127
Epoch 239, CIFAR-10 Batch 1:  Train_Loss:0.9382020235061646, Valid_Loss:1.2840306758880615, Valid_ACC:0.5903998613357544
Epoch 239, CIFAR-10 Batch 2:  Train_Loss:0.9582407474517822, Valid_Loss:1.276484727859497, Valid_ACC:0.590199887752533
Epoch 239, CIFAR-10 Batch 3:  Train_Loss:0.9063190817832947, Valid_Loss:1.2834258079528809, Valid_ACC:0.5857999324798584
Epoch 239, CIFAR-10 Batch 4:  Train_Loss:0.9298039078712463, Valid_Loss:1.277846336364746, Valid_ACC:0.5929999351501465
Epoch 239, CIFAR-10 Batch 5:  Train_Loss:0.9405736327171326, Valid_Loss:1.2806919813156128, Valid_ACC:0.5929999351501465
Epoch 240, CIFAR-10 Batch 1:  Train_Loss:0.9250211119651794, Valid_Loss:1.287721872329712, Valid_ACC:0.5885999202728271
Epoch 240, CIFAR-10 Batch 2:  Train_Loss:0.9555683732032776, Valid_Loss:1.279439926147461, Valid_ACC:0.5905998945236206
Epoch 240, CIFAR-10 Batch 3:  Train_Loss:0.934084415435791, Valid_Loss:1.3104721307754517, Valid_ACC:0.5735998749732971
Epoch 240, CIFAR-10 Batch 4:  Train_Loss:0.919356107711792, Valid_Loss:1.276647925376892, Valid_ACC:0.5959998965263367
Epoch 240, CIFAR-10 Batch 5:  Train_Loss:0.9584110975265503, Valid_Loss:1.3027088642120361, Valid_ACC:0.5821999311447144
Epoch 241, CIFAR-10 Batch 1:  Train_Loss:0.9422358274459839, Valid_Loss:1.3046767711639404, Valid_ACC:0.5827999114990234
Epoch 241, CIFAR-10 Batch 2:  Train_Loss:0.9368340373039246, Valid_Loss:1.2859880924224854, Valid_ACC:0.5863999128341675
Epoch 241, CIFAR-10 Batch 3:  Train_Loss:0.9143465757369995, Valid_Loss:1.2855020761489868, Valid_ACC:0.5883998870849609
Epoch 241, CIFAR-10 Batch 4:  Train_Loss:0.9659000635147095, Valid_Loss:1.30142343044281, Valid_ACC:0.5867998600006104
Epoch 241, CIFAR-10 Batch 5:  Train_Loss:0.9290285706520081, Valid_Loss:1.2692102193832397, Valid_ACC:0.5953999161720276
Epoch 242, CIFAR-10 Batch 1:  Train_Loss:0.9256114959716797, Valid_Loss:1.2757601737976074, Valid_ACC:0.5961999297142029
Epoch 242, CIFAR-10 Batch 2:  Train_Loss:0.9476935863494873, Valid_Loss:1.2792582511901855, Valid_ACC:0.5941999554634094
Epoch 242, CIFAR-10 Batch 3:  Train_Loss:0.9055555462837219, Valid_Loss:1.2885525226593018, Valid_ACC:0.5881999135017395
Epoch 242, CIFAR-10 Batch 4:  Train_Loss:0.9415066242218018, Valid_Loss:1.2852264642715454, Valid_ACC:0.5879999399185181
Epoch 242, CIFAR-10 Batch 5:  Train_Loss:0.9352256059646606, Valid_Loss:1.2775342464447021, Valid_ACC:0.5881999731063843
Epoch 243, CIFAR-10 Batch 1:  Train_Loss:0.9039629101753235, Valid_Loss:1.2623647451400757, Valid_ACC:0.5961999297142029
Epoch 243, CIFAR-10 Batch 2:  Train_Loss:0.9380336403846741, Valid_Loss:1.2781363725662231, Valid_ACC:0.5883999466896057
Epoch 243, CIFAR-10 Batch 3:  Train_Loss:0.8970987200737, Valid_Loss:1.2788721323013306, Valid_ACC:0.5905998945236206
Epoch 243, CIFAR-10 Batch 4:  Train_Loss:0.9116827845573425, Valid_Loss:1.2712324857711792, Valid_ACC:0.5907999277114868
Epoch 243, CIFAR-10 Batch 5:  Train_Loss:0.9115440249443054, Valid_Loss:1.2633577585220337, Valid_ACC:0.5953999757766724
Epoch 244, CIFAR-10 Batch 1:  Train_Loss:0.9013334512710571, Valid_Loss:1.2637077569961548, Valid_ACC:0.5981999039649963
Epoch 244, CIFAR-10 Batch 2:  Train_Loss:0.9247211813926697, Valid_Loss:1.2753894329071045, Valid_ACC:0.5935999155044556
Epoch 244, CIFAR-10 Batch 3:  Train_Loss:0.8848098516464233, Valid_Loss:1.2718371152877808, Valid_ACC:0.5961999297142029
Epoch 244, CIFAR-10 Batch 4:  Train_Loss:0.9264686107635498, Valid_Loss:1.2717190980911255, Valid_ACC:0.5917999148368835
Epoch 244, CIFAR-10 Batch 5:  Train_Loss:0.9186331033706665, Valid_Loss:1.2712849378585815, Valid_ACC:0.5919999480247498
Epoch 245, CIFAR-10 Batch 1:  Train_Loss:0.946809709072113, Valid_Loss:1.2758432626724243, Valid_ACC:0.5891999006271362
Epoch 245, CIFAR-10 Batch 2:  Train_Loss:0.94251549243927, Valid_Loss:1.2754303216934204, Valid_ACC:0.5963999032974243
Epoch 245, CIFAR-10 Batch 3:  Train_Loss:0.8946710824966431, Valid_Loss:1.2707672119140625, Valid_ACC:0.5925999283790588
Epoch 245, CIFAR-10 Batch 4:  Train_Loss:0.9038628935813904, Valid_Loss:1.2608938217163086, Valid_ACC:0.5991998910903931
Epoch 245, CIFAR-10 Batch 5:  Train_Loss:0.9240471720695496, Valid_Loss:1.2722842693328857, Valid_ACC:0.5927999019622803
Epoch 246, CIFAR-10 Batch 1:  Train_Loss:0.9066352248191833, Valid_Loss:1.2801635265350342, Valid_ACC:0.5873998999595642
Epoch 246, CIFAR-10 Batch 2:  Train_Loss:0.9144719839096069, Valid_Loss:1.2684458494186401, Valid_ACC:0.5911999344825745
Epoch 246, CIFAR-10 Batch 3:  Train_Loss:0.8863282799720764, Valid_Loss:1.265234351158142, Valid_ACC:0.5913999676704407
Epoch 246, CIFAR-10 Batch 4:  Train_Loss:0.895960807800293, Valid_Loss:1.254469871520996, Valid_ACC:0.5977998971939087
Epoch 246, CIFAR-10 Batch 5:  Train_Loss:0.9061555862426758, Valid_Loss:1.262174367904663, Valid_ACC:0.5997999310493469
Epoch 247, CIFAR-10 Batch 1:  Train_Loss:0.8972359895706177, Valid_Loss:1.2611744403839111, Valid_ACC:0.5943999290466309
Epoch 247, CIFAR-10 Batch 2:  Train_Loss:0.9062613248825073, Valid_Loss:1.2605866193771362, Valid_ACC:0.5943999290466309
Epoch 247, CIFAR-10 Batch 3:  Train_Loss:0.8694934844970703, Valid_Loss:1.262366533279419, Valid_ACC:0.5871999263763428
Epoch 247, CIFAR-10 Batch 4:  Train_Loss:0.9156186580657959, Valid_Loss:1.268874168395996, Valid_ACC:0.592799961566925
Epoch 247, CIFAR-10 Batch 5:  Train_Loss:0.9111793041229248, Valid_Loss:1.2618529796600342, Valid_ACC:0.595599889755249
Epoch 248, CIFAR-10 Batch 1:  Train_Loss:0.900583803653717, Valid_Loss:1.2578352689743042, Valid_ACC:0.5969999432563782
Epoch 248, CIFAR-10 Batch 2:  Train_Loss:0.8956775665283203, Valid_Loss:1.2523599863052368, Valid_ACC:0.5987999439239502
Epoch 248, CIFAR-10 Batch 3:  Train_Loss:0.8720451593399048, Valid_Loss:1.2614965438842773, Valid_ACC:0.5917998552322388
Epoch 248, CIFAR-10 Batch 4:  Train_Loss:0.9072674512863159, Valid_Loss:1.267098307609558, Valid_ACC:0.5923998951911926
Epoch 248, CIFAR-10 Batch 5:  Train_Loss:0.8956606388092041, Valid_Loss:1.2570209503173828, Valid_ACC:0.5971999168395996
Epoch 249, CIFAR-10 Batch 1:  Train_Loss:0.8785430788993835, Valid_Loss:1.2457929849624634, Valid_ACC:0.5981999039649963
Epoch 249, CIFAR-10 Batch 2:  Train_Loss:0.89649498462677, Valid_Loss:1.2448561191558838, Valid_ACC:0.6029999256134033
Epoch 249, CIFAR-10 Batch 3:  Train_Loss:0.8494493961334229, Valid_Loss:1.249722957611084, Valid_ACC:0.5979999303817749
Epoch 249, CIFAR-10 Batch 4:  Train_Loss:0.9094808101654053, Valid_Loss:1.2670961618423462, Valid_ACC:0.5913999080657959
Epoch 249, CIFAR-10 Batch 5:  Train_Loss:0.8972307443618774, Valid_Loss:1.255752444267273, Valid_ACC:0.5997998714447021
Epoch 250, CIFAR-10 Batch 1:  Train_Loss:0.8867878913879395, Valid_Loss:1.2481868267059326, Valid_ACC:0.5997998714447021
Epoch 250, CIFAR-10 Batch 2:  Train_Loss:0.908786952495575, Valid_Loss:1.251649260520935, Valid_ACC:0.5947999358177185
Epoch 250, CIFAR-10 Batch 3:  Train_Loss:0.8471157550811768, Valid_Loss:1.2479933500289917, Valid_ACC:0.5941998958587646
Epoch 250, CIFAR-10 Batch 4:  Train_Loss:0.9389470219612122, Valid_Loss:1.2847033739089966, Valid_ACC:0.5883998870849609
Epoch 250, CIFAR-10 Batch 5:  Train_Loss:0.8878746032714844, Valid_Loss:1.2555739879608154, Valid_ACC:0.5959999561309814
Epoch 251, CIFAR-10 Batch 1:  Train_Loss:0.8849959373474121, Valid_Loss:1.2679026126861572, Valid_ACC:0.5901999473571777
Epoch 251, CIFAR-10 Batch 2:  Train_Loss:0.9031149744987488, Valid_Loss:1.2590327262878418, Valid_ACC:0.5959998965263367
Epoch 251, CIFAR-10 Batch 3:  Train_Loss:0.857785165309906, Valid_Loss:1.2543771266937256, Valid_ACC:0.5935999751091003
Epoch 251, CIFAR-10 Batch 4:  Train_Loss:0.9316432476043701, Valid_Loss:1.2803726196289062, Valid_ACC:0.5867999196052551
Epoch 251, CIFAR-10 Batch 5:  Train_Loss:0.887110710144043, Valid_Loss:1.2593203783035278, Valid_ACC:0.595599889755249
Epoch 252, CIFAR-10 Batch 1:  Train_Loss:0.8817895650863647, Valid_Loss:1.2706656455993652, Valid_ACC:0.5911999344825745
Epoch 252, CIFAR-10 Batch 2:  Train_Loss:0.9068337082862854, Valid_Loss:1.26682710647583, Valid_ACC:0.5895999073982239
Epoch 252, CIFAR-10 Batch 3:  Train_Loss:0.8686435222625732, Valid_Loss:1.2660750150680542, Valid_ACC:0.5913999080657959
Epoch 252, CIFAR-10 Batch 4:  Train_Loss:0.9062978029251099, Valid_Loss:1.2674256563186646, Valid_ACC:0.5933999419212341
Epoch 252, CIFAR-10 Batch 5:  Train_Loss:0.8920167684555054, Valid_Loss:1.2522032260894775, Valid_ACC:0.5995998382568359
Epoch 253, CIFAR-10 Batch 1:  Train_Loss:0.8637433052062988, Valid_Loss:1.2468544244766235, Valid_ACC:0.5977998971939087
Epoch 253, CIFAR-10 Batch 2:  Train_Loss:0.8874310255050659, Valid_Loss:1.2583227157592773, Valid_ACC:0.5949999094009399
Epoch 253, CIFAR-10 Batch 3:  Train_Loss:0.8577667474746704, Valid_Loss:1.2618868350982666, Valid_ACC:0.5923999547958374
Epoch 253, CIFAR-10 Batch 4:  Train_Loss:0.883984386920929, Valid_Loss:1.2567232847213745, Valid_ACC:0.5935999155044556
Epoch 253, CIFAR-10 Batch 5:  Train_Loss:0.8891230821609497, Valid_Loss:1.2548896074295044, Valid_ACC:0.5955999493598938
Epoch 254, CIFAR-10 Batch 1:  Train_Loss:0.8690645098686218, Valid_Loss:1.2452623844146729, Valid_ACC:0.6011998653411865
Epoch 254, CIFAR-10 Batch 2:  Train_Loss:0.8910204172134399, Valid_Loss:1.2449100017547607, Valid_ACC:0.6007999181747437
Epoch 254, CIFAR-10 Batch 3:  Train_Loss:0.8365393280982971, Valid_Loss:1.246098279953003, Valid_ACC:0.5977999567985535
Epoch 254, CIFAR-10 Batch 4:  Train_Loss:0.9069199562072754, Valid_Loss:1.2696831226348877, Valid_ACC:0.5869999527931213
Epoch 254, CIFAR-10 Batch 5:  Train_Loss:0.8771953582763672, Valid_Loss:1.2460594177246094, Valid_ACC:0.602199912071228
Epoch 255, CIFAR-10 Batch 1:  Train_Loss:0.8664350509643555, Valid_Loss:1.2513363361358643, Valid_ACC:0.5953999161720276
Epoch 255, CIFAR-10 Batch 2:  Train_Loss:0.8843879699707031, Valid_Loss:1.244630217552185, Valid_ACC:0.6033998727798462
Epoch 255, CIFAR-10 Batch 3:  Train_Loss:0.8283993005752563, Valid_Loss:1.2468451261520386, Valid_ACC:0.600399911403656
Epoch 255, CIFAR-10 Batch 4:  Train_Loss:0.890709638595581, Valid_Loss:1.2492214441299438, Valid_ACC:0.597399890422821
Epoch 255, CIFAR-10 Batch 5:  Train_Loss:0.8752662539482117, Valid_Loss:1.2376046180725098, Valid_ACC:0.6033999919891357
Epoch 256, CIFAR-10 Batch 1:  Train_Loss:0.8698862195014954, Valid_Loss:1.2686320543289185, Valid_ACC:0.5931999087333679
Epoch 256, CIFAR-10 Batch 2:  Train_Loss:0.8792645931243896, Valid_Loss:1.2418893575668335, Valid_ACC:0.6031998991966248
Epoch 256, CIFAR-10 Batch 3:  Train_Loss:0.8422126770019531, Valid_Loss:1.241075038909912, Valid_ACC:0.5977998971939087
Epoch 256, CIFAR-10 Batch 4:  Train_Loss:0.8800562620162964, Valid_Loss:1.2496623992919922, Valid_ACC:0.5961998701095581
Epoch 256, CIFAR-10 Batch 5:  Train_Loss:0.8748674988746643, Valid_Loss:1.244187355041504, Valid_ACC:0.5999999046325684
Epoch 257, CIFAR-10 Batch 1:  Train_Loss:0.8749220371246338, Valid_Loss:1.2656828165054321, Valid_ACC:0.590799868106842
Epoch 257, CIFAR-10 Batch 2:  Train_Loss:0.875451922416687, Valid_Loss:1.2523707151412964, Valid_ACC:0.5965998768806458
Epoch 257, CIFAR-10 Batch 3:  Train_Loss:0.8508455753326416, Valid_Loss:1.2601203918457031, Valid_ACC:0.5929999351501465
Epoch 257, CIFAR-10 Batch 4:  Train_Loss:0.8766320943832397, Valid_Loss:1.2569005489349365, Valid_ACC:0.5979999303817749
Epoch 257, CIFAR-10 Batch 5:  Train_Loss:0.8959119319915771, Valid_Loss:1.275163173675537, Valid_ACC:0.5899999141693115
Epoch 258, CIFAR-10 Batch 1:  Train_Loss:0.8603951930999756, Valid_Loss:1.2438502311706543, Valid_ACC:0.5983998775482178
Epoch 258, CIFAR-10 Batch 2:  Train_Loss:0.869462251663208, Valid_Loss:1.241744875907898, Valid_ACC:0.5979999303817749
Epoch 258, CIFAR-10 Batch 3:  Train_Loss:0.8410272598266602, Valid_Loss:1.249463677406311, Valid_ACC:0.5945999026298523
Epoch 258, CIFAR-10 Batch 4:  Train_Loss:0.8713037371635437, Valid_Loss:1.253083348274231, Valid_ACC:0.5953999161720276
Epoch 258, CIFAR-10 Batch 5:  Train_Loss:0.8816981315612793, Valid_Loss:1.258471965789795, Valid_ACC:0.5931999087333679
Epoch 259, CIFAR-10 Batch 1:  Train_Loss:0.861627459526062, Valid_Loss:1.2419841289520264, Valid_ACC:0.6009999513626099
Epoch 259, CIFAR-10 Batch 2:  Train_Loss:0.8625094294548035, Valid_Loss:1.2365024089813232, Valid_ACC:0.6027998924255371
Epoch 259, CIFAR-10 Batch 3:  Train_Loss:0.8347985744476318, Valid_Loss:1.2520861625671387, Valid_ACC:0.5959998965263367
Epoch 259, CIFAR-10 Batch 4:  Train_Loss:0.9078141450881958, Valid_Loss:1.2779971361160278, Valid_ACC:0.5827999114990234
Epoch 259, CIFAR-10 Batch 5:  Train_Loss:0.8738821148872375, Valid_Loss:1.253738522529602, Valid_ACC:0.5937999486923218
Epoch 260, CIFAR-10 Batch 1:  Train_Loss:0.8675447106361389, Valid_Loss:1.2471879720687866, Valid_ACC:0.5975998640060425
Epoch 260, CIFAR-10 Batch 2:  Train_Loss:0.8955469131469727, Valid_Loss:1.2546666860580444, Valid_ACC:0.5949999094009399
Epoch 260, CIFAR-10 Batch 3:  Train_Loss:0.8430161476135254, Valid_Loss:1.2602555751800537, Valid_ACC:0.5907999277114868
Epoch 260, CIFAR-10 Batch 4:  Train_Loss:0.8596742153167725, Valid_Loss:1.2462893724441528, Valid_ACC:0.6007998585700989
Epoch 260, CIFAR-10 Batch 5:  Train_Loss:0.8689801692962646, Valid_Loss:1.2475327253341675, Valid_ACC:0.6001999378204346
Epoch 261, CIFAR-10 Batch 1:  Train_Loss:0.8651445508003235, Valid_Loss:1.2551262378692627, Valid_ACC:0.5979998707771301
Epoch 261, CIFAR-10 Batch 2:  Train_Loss:0.8745837211608887, Valid_Loss:1.2487244606018066, Valid_ACC:0.5989999175071716
Epoch 261, CIFAR-10 Batch 3:  Train_Loss:0.8562553524971008, Valid_Loss:1.2663497924804688, Valid_ACC:0.5905998945236206
Epoch 261, CIFAR-10 Batch 4:  Train_Loss:0.8682045340538025, Valid_Loss:1.248773217201233, Valid_ACC:0.5971999168395996
Epoch 261, CIFAR-10 Batch 5:  Train_Loss:0.8817312717437744, Valid_Loss:1.2499940395355225, Valid_ACC:0.6001999378204346
Epoch 262, CIFAR-10 Batch 1:  Train_Loss:0.8509594202041626, Valid_Loss:1.2568191289901733, Valid_ACC:0.5975998640060425
Epoch 262, CIFAR-10 Batch 2:  Train_Loss:0.8747098445892334, Valid_Loss:1.2366578578948975, Valid_ACC:0.6025999188423157
Epoch 262, CIFAR-10 Batch 3:  Train_Loss:0.8257322311401367, Valid_Loss:1.2527801990509033, Valid_ACC:0.5937999486923218
Epoch 262, CIFAR-10 Batch 4:  Train_Loss:0.8513108491897583, Valid_Loss:1.2390055656433105, Valid_ACC:0.6011999249458313
Epoch 262, CIFAR-10 Batch 5:  Train_Loss:0.8610190153121948, Valid_Loss:1.2395994663238525, Valid_ACC:0.6035998463630676
Epoch 263, CIFAR-10 Batch 1:  Train_Loss:0.8419973254203796, Valid_Loss:1.2375295162200928, Valid_ACC:0.601599931716919
Epoch 263, CIFAR-10 Batch 2:  Train_Loss:0.8702698945999146, Valid_Loss:1.2454019784927368, Valid_ACC:0.602199912071228
Epoch 263, CIFAR-10 Batch 3:  Train_Loss:0.8386421203613281, Valid_Loss:1.2610042095184326, Valid_ACC:0.5867998600006104
Epoch 263, CIFAR-10 Batch 4:  Train_Loss:0.8616853952407837, Valid_Loss:1.2502557039260864, Valid_ACC:0.5997998714447021
Epoch 263, CIFAR-10 Batch 5:  Train_Loss:0.864503026008606, Valid_Loss:1.249415397644043, Valid_ACC:0.5969999432563782
Epoch 264, CIFAR-10 Batch 1:  Train_Loss:0.8513602018356323, Valid_Loss:1.2641034126281738, Valid_ACC:0.5931999087333679
Epoch 264, CIFAR-10 Batch 2:  Train_Loss:0.8658078908920288, Valid_Loss:1.2377126216888428, Valid_ACC:0.6039999723434448
Epoch 264, CIFAR-10 Batch 3:  Train_Loss:0.8187901377677917, Valid_Loss:1.240549921989441, Valid_ACC:0.5987999439239502
Epoch 264, CIFAR-10 Batch 4:  Train_Loss:0.8625467419624329, Valid_Loss:1.2481751441955566, Valid_ACC:0.5959999561309814
Epoch 264, CIFAR-10 Batch 5:  Train_Loss:0.8536254167556763, Valid_Loss:1.2397644519805908, Valid_ACC:0.6027998924255371
Epoch 265, CIFAR-10 Batch 1:  Train_Loss:0.8413987159729004, Valid_Loss:1.2419441938400269, Valid_ACC:0.6011999845504761
Epoch 265, CIFAR-10 Batch 2:  Train_Loss:0.890641987323761, Valid_Loss:1.2583719491958618, Valid_ACC:0.5915998816490173
Epoch 265, CIFAR-10 Batch 3:  Train_Loss:0.8259356021881104, Valid_Loss:1.2534067630767822, Valid_ACC:0.5929999351501465
Epoch 265, CIFAR-10 Batch 4:  Train_Loss:0.8738421201705933, Valid_Loss:1.2621045112609863, Valid_ACC:0.5925998687744141
Epoch 265, CIFAR-10 Batch 5:  Train_Loss:0.8841601014137268, Valid_Loss:1.2535772323608398, Valid_ACC:0.5955999493598938
Epoch 266, CIFAR-10 Batch 1:  Train_Loss:0.894382655620575, Valid_Loss:1.27268648147583, Valid_ACC:0.5879999399185181
Epoch 266, CIFAR-10 Batch 2:  Train_Loss:0.8528023362159729, Valid_Loss:1.2339636087417603, Valid_ACC:0.6019999384880066
Epoch 266, CIFAR-10 Batch 3:  Train_Loss:0.8278843760490417, Valid_Loss:1.2465617656707764, Valid_ACC:0.5945999622344971
Epoch 266, CIFAR-10 Batch 4:  Train_Loss:0.8623247146606445, Valid_Loss:1.2533581256866455, Valid_ACC:0.5953999161720276
Epoch 266, CIFAR-10 Batch 5:  Train_Loss:0.8462758660316467, Valid_Loss:1.2358843088150024, Valid_ACC:0.6037998795509338
Epoch 267, CIFAR-10 Batch 1:  Train_Loss:0.8466640710830688, Valid_Loss:1.2491320371627808, Valid_ACC:0.5991998910903931
Epoch 267, CIFAR-10 Batch 2:  Train_Loss:0.8758035898208618, Valid_Loss:1.2566306591033936, Valid_ACC:0.5915998816490173
Epoch 267, CIFAR-10 Batch 3:  Train_Loss:0.8265779614448547, Valid_Loss:1.2507861852645874, Valid_ACC:0.5997999310493469
Epoch 267, CIFAR-10 Batch 4:  Train_Loss:0.8468320369720459, Valid_Loss:1.241047739982605, Valid_ACC:0.5963999032974243
Epoch 267, CIFAR-10 Batch 5:  Train_Loss:0.849712073802948, Valid_Loss:1.2475099563598633, Valid_ACC:0.597399890422821
Epoch 268, CIFAR-10 Batch 1:  Train_Loss:0.8416178226470947, Valid_Loss:1.2346477508544922, Valid_ACC:0.6045998930931091
Epoch 268, CIFAR-10 Batch 2:  Train_Loss:0.8582139015197754, Valid_Loss:1.234242558479309, Valid_ACC:0.6001999378204346
Epoch 268, CIFAR-10 Batch 3:  Train_Loss:0.8090072274208069, Valid_Loss:1.2391822338104248, Valid_ACC:0.5991998910903931
Epoch 268, CIFAR-10 Batch 4:  Train_Loss:0.8477728962898254, Valid_Loss:1.2369601726531982, Valid_ACC:0.5995999574661255
Epoch 268, CIFAR-10 Batch 5:  Train_Loss:0.8512047529220581, Valid_Loss:1.234005093574524, Valid_ACC:0.6039999127388
Epoch 269, CIFAR-10 Batch 1:  Train_Loss:0.8318748474121094, Valid_Loss:1.2348430156707764, Valid_ACC:0.6047998666763306
Epoch 269, CIFAR-10 Batch 2:  Train_Loss:0.8584829568862915, Valid_Loss:1.2372632026672363, Valid_ACC:0.6055998802185059
Epoch 269, CIFAR-10 Batch 3:  Train_Loss:0.8132120966911316, Valid_Loss:1.2458853721618652, Valid_ACC:0.5965998768806458
Epoch 269, CIFAR-10 Batch 4:  Train_Loss:0.8389397859573364, Valid_Loss:1.2435952425003052, Valid_ACC:0.6007999181747437
Epoch 269, CIFAR-10 Batch 5:  Train_Loss:0.866316556930542, Valid_Loss:1.2534501552581787, Valid_ACC:0.5997999310493469
Epoch 270, CIFAR-10 Batch 1:  Train_Loss:0.8345456123352051, Valid_Loss:1.24259352684021, Valid_ACC:0.6013998985290527
Epoch 270, CIFAR-10 Batch 2:  Train_Loss:0.8554612398147583, Valid_Loss:1.2381819486618042, Valid_ACC:0.6071998476982117
Epoch 270, CIFAR-10 Batch 3:  Train_Loss:0.8182408809661865, Valid_Loss:1.247887372970581, Valid_ACC:0.5973999500274658
Epoch 270, CIFAR-10 Batch 4:  Train_Loss:0.8586024045944214, Valid_Loss:1.2469089031219482, Valid_ACC:0.6005999445915222
Epoch 270, CIFAR-10 Batch 5:  Train_Loss:0.8501244783401489, Valid_Loss:1.2445077896118164, Valid_ACC:0.6019998788833618
Epoch 271, CIFAR-10 Batch 1:  Train_Loss:0.8385775685310364, Valid_Loss:1.2502124309539795, Valid_ACC:0.5993998646736145
Epoch 271, CIFAR-10 Batch 2:  Train_Loss:0.846513032913208, Valid_Loss:1.2375688552856445, Valid_ACC:0.5983998775482178
Epoch 271, CIFAR-10 Batch 3:  Train_Loss:0.8121917247772217, Valid_Loss:1.2428431510925293, Valid_ACC:0.5975999236106873
Epoch 271, CIFAR-10 Batch 4:  Train_Loss:0.8592678308486938, Valid_Loss:1.259232759475708, Valid_ACC:0.5929999351501465
Epoch 271, CIFAR-10 Batch 5:  Train_Loss:0.8502851724624634, Valid_Loss:1.2390235662460327, Valid_ACC:0.6039998531341553
Epoch 272, CIFAR-10 Batch 1:  Train_Loss:0.8417282700538635, Valid_Loss:1.2518439292907715, Valid_ACC:0.6019999384880066
Epoch 272, CIFAR-10 Batch 2:  Train_Loss:0.8556316494941711, Valid_Loss:1.2422711849212646, Valid_ACC:0.5999999046325684
Epoch 272, CIFAR-10 Batch 3:  Train_Loss:0.8104265332221985, Valid_Loss:1.234209418296814, Valid_ACC:0.6013998985290527
Epoch 272, CIFAR-10 Batch 4:  Train_Loss:0.8463917970657349, Valid_Loss:1.2385871410369873, Valid_ACC:0.6009999513626099
Epoch 272, CIFAR-10 Batch 5:  Train_Loss:0.8538445830345154, Valid_Loss:1.2325435876846313, Valid_ACC:0.6017998456954956
Epoch 273, CIFAR-10 Batch 1:  Train_Loss:0.8254653811454773, Valid_Loss:1.2445940971374512, Valid_ACC:0.5971999168395996
Epoch 273, CIFAR-10 Batch 2:  Train_Loss:0.8573151230812073, Valid_Loss:1.2344098091125488, Valid_ACC:0.6045998930931091
Epoch 273, CIFAR-10 Batch 3:  Train_Loss:0.8280535936355591, Valid_Loss:1.2401765584945679, Valid_ACC:0.6029999256134033
Epoch 273, CIFAR-10 Batch 4:  Train_Loss:0.8432811498641968, Valid_Loss:1.2375450134277344, Valid_ACC:0.6015998721122742
Epoch 273, CIFAR-10 Batch 5:  Train_Loss:0.8471361994743347, Valid_Loss:1.2292970418930054, Valid_ACC:0.6061999201774597
Epoch 274, CIFAR-10 Batch 1:  Train_Loss:0.8321459293365479, Valid_Loss:1.2425546646118164, Valid_ACC:0.6017998456954956
Epoch 274, CIFAR-10 Batch 2:  Train_Loss:0.8544422388076782, Valid_Loss:1.2449103593826294, Valid_ACC:0.5993999242782593
Epoch 274, CIFAR-10 Batch 3:  Train_Loss:0.8101582527160645, Valid_Loss:1.2438619136810303, Valid_ACC:0.5983999371528625
Epoch 274, CIFAR-10 Batch 4:  Train_Loss:0.8825072050094604, Valid_Loss:1.2673282623291016, Valid_ACC:0.5917999148368835
Epoch 274, CIFAR-10 Batch 5:  Train_Loss:0.8708912134170532, Valid_Loss:1.2440956830978394, Valid_ACC:0.5997998714447021
Epoch 275, CIFAR-10 Batch 1:  Train_Loss:0.8410917520523071, Valid_Loss:1.2336902618408203, Valid_ACC:0.6027998924255371
Epoch 275, CIFAR-10 Batch 2:  Train_Loss:0.8495674729347229, Valid_Loss:1.23439359664917, Valid_ACC:0.6039998531341553
Epoch 275, CIFAR-10 Batch 3:  Train_Loss:0.8092824220657349, Valid_Loss:1.238519549369812, Valid_ACC:0.5979999303817749
Epoch 275, CIFAR-10 Batch 4:  Train_Loss:0.8634600043296814, Valid_Loss:1.261269450187683, Valid_ACC:0.5953999161720276
Epoch 275, CIFAR-10 Batch 5:  Train_Loss:0.849311351776123, Valid_Loss:1.2370647192001343, Valid_ACC:0.6039998531341553
Epoch 276, CIFAR-10 Batch 1:  Train_Loss:0.8366721868515015, Valid_Loss:1.2356873750686646, Valid_ACC:0.6057999730110168
Epoch 276, CIFAR-10 Batch 2:  Train_Loss:0.8423522710800171, Valid_Loss:1.2401739358901978, Valid_ACC:0.6001999378204346
Epoch 276, CIFAR-10 Batch 3:  Train_Loss:0.8139566779136658, Valid_Loss:1.2456645965576172, Valid_ACC:0.5975998640060425
Epoch 276, CIFAR-10 Batch 4:  Train_Loss:0.8455377817153931, Valid_Loss:1.2382900714874268, Valid_ACC:0.6055999398231506
Epoch 276, CIFAR-10 Batch 5:  Train_Loss:0.8478006720542908, Valid_Loss:1.252213954925537, Valid_ACC:0.5997999310493469
Epoch 277, CIFAR-10 Batch 1:  Train_Loss:0.8265564441680908, Valid_Loss:1.2471166849136353, Valid_ACC:0.5987999439239502
Epoch 277, CIFAR-10 Batch 2:  Train_Loss:0.8668380379676819, Valid_Loss:1.2616029977798462, Valid_ACC:0.5907999873161316
Epoch 277, CIFAR-10 Batch 3:  Train_Loss:0.8149049282073975, Valid_Loss:1.2469663619995117, Valid_ACC:0.5957998633384705
Epoch 277, CIFAR-10 Batch 4:  Train_Loss:0.838677167892456, Valid_Loss:1.244745135307312, Valid_ACC:0.5999999642372131
Epoch 277, CIFAR-10 Batch 5:  Train_Loss:0.851983904838562, Valid_Loss:1.2538479566574097, Valid_ACC:0.5991998910903931
Epoch 278, CIFAR-10 Batch 1:  Train_Loss:0.8265664577484131, Valid_Loss:1.2355936765670776, Valid_ACC:0.6065999269485474
Epoch 278, CIFAR-10 Batch 2:  Train_Loss:0.8547885417938232, Valid_Loss:1.243086814880371, Valid_ACC:0.5991999506950378
Epoch 278, CIFAR-10 Batch 3:  Train_Loss:0.8237531185150146, Valid_Loss:1.2519800662994385, Valid_ACC:0.5961998701095581
Epoch 278, CIFAR-10 Batch 4:  Train_Loss:0.8521957397460938, Valid_Loss:1.251943826675415, Valid_ACC:0.5949999094009399
Epoch 278, CIFAR-10 Batch 5:  Train_Loss:0.8312281966209412, Valid_Loss:1.2423057556152344, Valid_ACC:0.6005998849868774
Epoch 279, CIFAR-10 Batch 1:  Train_Loss:0.8279441595077515, Valid_Loss:1.2401186227798462, Valid_ACC:0.6025998592376709
Epoch 279, CIFAR-10 Batch 2:  Train_Loss:0.8480972051620483, Valid_Loss:1.234465479850769, Valid_ACC:0.6017999649047852
Epoch 279, CIFAR-10 Batch 3:  Train_Loss:0.8116154074668884, Valid_Loss:1.2368569374084473, Valid_ACC:0.6005999445915222
Epoch 279, CIFAR-10 Batch 4:  Train_Loss:0.8277377486228943, Valid_Loss:1.238511323928833, Valid_ACC:0.6041998863220215
Epoch 279, CIFAR-10 Batch 5:  Train_Loss:0.8395432829856873, Valid_Loss:1.2439826726913452, Valid_ACC:0.5975999236106873
Epoch 280, CIFAR-10 Batch 1:  Train_Loss:0.823429524898529, Valid_Loss:1.2543359994888306, Valid_ACC:0.5949999094009399
Epoch 280, CIFAR-10 Batch 2:  Train_Loss:0.8430730104446411, Valid_Loss:1.2425322532653809, Valid_ACC:0.5995999574661255
Epoch 280, CIFAR-10 Batch 3:  Train_Loss:0.8100049495697021, Valid_Loss:1.2482877969741821, Valid_ACC:0.5963999032974243
Epoch 280, CIFAR-10 Batch 4:  Train_Loss:0.8472015261650085, Valid_Loss:1.24955153465271, Valid_ACC:0.598599910736084
Epoch 280, CIFAR-10 Batch 5:  Train_Loss:0.836029052734375, Valid_Loss:1.233219861984253, Valid_ACC:0.6025998592376709
Epoch 281, CIFAR-10 Batch 1:  Train_Loss:0.837590217590332, Valid_Loss:1.2687307596206665, Valid_ACC:0.5931999087333679
Epoch 281, CIFAR-10 Batch 2:  Train_Loss:0.8418591022491455, Valid_Loss:1.248840093612671, Valid_ACC:0.5953999161720276
Epoch 281, CIFAR-10 Batch 3:  Train_Loss:0.8222630620002747, Valid_Loss:1.246828556060791, Valid_ACC:0.5951998829841614
Epoch 281, CIFAR-10 Batch 4:  Train_Loss:0.853769063949585, Valid_Loss:1.2558492422103882, Valid_ACC:0.5927999019622803
Epoch 281, CIFAR-10 Batch 5:  Train_Loss:0.8357056379318237, Valid_Loss:1.2335171699523926, Valid_ACC:0.6007999181747437
Epoch 282, CIFAR-10 Batch 1:  Train_Loss:0.8281040787696838, Valid_Loss:1.243642807006836, Valid_ACC:0.5983999371528625
Epoch 282, CIFAR-10 Batch 2:  Train_Loss:0.8580844402313232, Valid_Loss:1.2567082643508911, Valid_ACC:0.5907999277114868
Epoch 282, CIFAR-10 Batch 3:  Train_Loss:0.8208631277084351, Valid_Loss:1.244598150253296, Valid_ACC:0.5953999757766724
Epoch 282, CIFAR-10 Batch 4:  Train_Loss:0.8474960327148438, Valid_Loss:1.2478479146957397, Valid_ACC:0.5961999297142029
Epoch 282, CIFAR-10 Batch 5:  Train_Loss:0.8371303677558899, Valid_Loss:1.2391669750213623, Valid_ACC:0.6067999601364136
Epoch 283, CIFAR-10 Batch 1:  Train_Loss:0.8241322040557861, Valid_Loss:1.235577940940857, Valid_ACC:0.6031998991966248
Epoch 283, CIFAR-10 Batch 2:  Train_Loss:0.8295093774795532, Valid_Loss:1.2385547161102295, Valid_ACC:0.6001999378204346
Epoch 283, CIFAR-10 Batch 3:  Train_Loss:0.8006919622421265, Valid_Loss:1.2411969900131226, Valid_ACC:0.6003999710083008
Epoch 283, CIFAR-10 Batch 4:  Train_Loss:0.8310979604721069, Valid_Loss:1.243596076965332, Valid_ACC:0.6009999513626099
Epoch 283, CIFAR-10 Batch 5:  Train_Loss:0.8241795301437378, Valid_Loss:1.2347098588943481, Valid_ACC:0.6053999066352844
Epoch 284, CIFAR-10 Batch 1:  Train_Loss:0.8265412449836731, Valid_Loss:1.256752371788025, Valid_ACC:0.5961999297142029
Epoch 284, CIFAR-10 Batch 2:  Train_Loss:0.8439003229141235, Valid_Loss:1.24836266040802, Valid_ACC:0.5963999032974243
Epoch 284, CIFAR-10 Batch 3:  Train_Loss:0.8186990022659302, Valid_Loss:1.249064564704895, Valid_ACC:0.5967998504638672
Epoch 284, CIFAR-10 Batch 4:  Train_Loss:0.8340827226638794, Valid_Loss:1.2433462142944336, Valid_ACC:0.6013998985290527
Epoch 284, CIFAR-10 Batch 5:  Train_Loss:0.8476109504699707, Valid_Loss:1.2365248203277588, Valid_ACC:0.6055999398231506
Epoch 285, CIFAR-10 Batch 1:  Train_Loss:0.8210805058479309, Valid_Loss:1.234122395515442, Valid_ACC:0.6057999134063721
Epoch 285, CIFAR-10 Batch 2:  Train_Loss:0.8335492014884949, Valid_Loss:1.2370457649230957, Valid_ACC:0.6029999256134033
Epoch 285, CIFAR-10 Batch 3:  Train_Loss:0.8059539198875427, Valid_Loss:1.2417967319488525, Valid_ACC:0.601599931716919
Epoch 285, CIFAR-10 Batch 4:  Train_Loss:0.8300694823265076, Valid_Loss:1.2386164665222168, Valid_ACC:0.6025999188423157
Epoch 285, CIFAR-10 Batch 5:  Train_Loss:0.8265023231506348, Valid_Loss:1.2348647117614746, Valid_ACC:0.6043999195098877
Epoch 286, CIFAR-10 Batch 1:  Train_Loss:0.8165114521980286, Valid_Loss:1.2391228675842285, Valid_ACC:0.6041998863220215
Epoch 286, CIFAR-10 Batch 2:  Train_Loss:0.8360127806663513, Valid_Loss:1.2345188856124878, Valid_ACC:0.6073999404907227
Epoch 286, CIFAR-10 Batch 3:  Train_Loss:0.8074816465377808, Valid_Loss:1.2501001358032227, Valid_ACC:0.5931999087333679
Epoch 286, CIFAR-10 Batch 4:  Train_Loss:0.8360015153884888, Valid_Loss:1.2522242069244385, Valid_ACC:0.5977998971939087
Epoch 286, CIFAR-10 Batch 5:  Train_Loss:0.8173967599868774, Valid_Loss:1.226347804069519, Valid_ACC:0.6089999675750732
Epoch 287, CIFAR-10 Batch 1:  Train_Loss:0.8246256709098816, Valid_Loss:1.2395637035369873, Valid_ACC:0.6025998592376709
Epoch 287, CIFAR-10 Batch 2:  Train_Loss:0.8275829553604126, Valid_Loss:1.23147714138031, Valid_ACC:0.6027998924255371
Epoch 287, CIFAR-10 Batch 3:  Train_Loss:0.8099625110626221, Valid_Loss:1.240730881690979, Valid_ACC:0.598599910736084
Epoch 287, CIFAR-10 Batch 4:  Train_Loss:0.8252155780792236, Valid_Loss:1.2432838678359985, Valid_ACC:0.6007999181747437
Epoch 287, CIFAR-10 Batch 5:  Train_Loss:0.8394771814346313, Valid_Loss:1.2389109134674072, Valid_ACC:0.6025999188423157
Epoch 288, CIFAR-10 Batch 1:  Train_Loss:0.8067073225975037, Valid_Loss:1.238413691520691, Valid_ACC:0.6013998985290527
Epoch 288, CIFAR-10 Batch 2:  Train_Loss:0.8294997811317444, Valid_Loss:1.2464776039123535, Valid_ACC:0.5957999229431152
Epoch 288, CIFAR-10 Batch 3:  Train_Loss:0.8055465221405029, Valid_Loss:1.2379988431930542, Valid_ACC:0.5987999439239502
Epoch 288, CIFAR-10 Batch 4:  Train_Loss:0.8303267359733582, Valid_Loss:1.2422596216201782, Valid_ACC:0.5977999567985535
Epoch 288, CIFAR-10 Batch 5:  Train_Loss:0.8244553208351135, Valid_Loss:1.242862343788147, Valid_ACC:0.6049999594688416
Epoch 289, CIFAR-10 Batch 1:  Train_Loss:0.843866765499115, Valid_Loss:1.264463186264038, Valid_ACC:0.5917999744415283
Epoch 289, CIFAR-10 Batch 2:  Train_Loss:0.8509729504585266, Valid_Loss:1.2643550634384155, Valid_ACC:0.5915999412536621
Epoch 289, CIFAR-10 Batch 3:  Train_Loss:0.800105094909668, Valid_Loss:1.238185167312622, Valid_ACC:0.597599983215332
Epoch 289, CIFAR-10 Batch 4:  Train_Loss:0.8340888023376465, Valid_Loss:1.2484811544418335, Valid_ACC:0.5961998701095581
Epoch 289, CIFAR-10 Batch 5:  Train_Loss:0.8362855911254883, Valid_Loss:1.2574107646942139, Valid_ACC:0.5959998965263367
Epoch 290, CIFAR-10 Batch 1:  Train_Loss:0.8177739381790161, Valid_Loss:1.2519727945327759, Valid_ACC:0.5983999371528625
Epoch 290, CIFAR-10 Batch 2:  Train_Loss:0.8324463367462158, Valid_Loss:1.2400693893432617, Valid_ACC:0.5947998762130737
Epoch 290, CIFAR-10 Batch 3:  Train_Loss:0.8001917600631714, Valid_Loss:1.2290618419647217, Valid_ACC:0.601599931716919
Epoch 290, CIFAR-10 Batch 4:  Train_Loss:0.8185873031616211, Valid_Loss:1.2332932949066162, Valid_ACC:0.605199933052063
Epoch 290, CIFAR-10 Batch 5:  Train_Loss:0.8255190849304199, Valid_Loss:1.2287482023239136, Valid_ACC:0.6055999398231506
Epoch 291, CIFAR-10 Batch 1:  Train_Loss:0.8110073804855347, Valid_Loss:1.2386360168457031, Valid_ACC:0.605199933052063
Epoch 291, CIFAR-10 Batch 2:  Train_Loss:0.8231497406959534, Valid_Loss:1.2343482971191406, Valid_ACC:0.6031999588012695
Epoch 291, CIFAR-10 Batch 3:  Train_Loss:0.7932071685791016, Valid_Loss:1.2386445999145508, Valid_ACC:0.600399911403656
Epoch 291, CIFAR-10 Batch 4:  Train_Loss:0.8483285903930664, Valid_Loss:1.2596216201782227, Valid_ACC:0.5915998220443726
Epoch 291, CIFAR-10 Batch 5:  Train_Loss:0.8859983682632446, Valid_Loss:1.2784446477890015, Valid_ACC:0.5865999460220337
Epoch 292, CIFAR-10 Batch 1:  Train_Loss:0.8237700462341309, Valid_Loss:1.24990713596344, Valid_ACC:0.5977998971939087
Epoch 292, CIFAR-10 Batch 2:  Train_Loss:0.8383387327194214, Valid_Loss:1.2411839962005615, Valid_ACC:0.5983998775482178
Epoch 292, CIFAR-10 Batch 3:  Train_Loss:0.8012428283691406, Valid_Loss:1.243614912033081, Valid_ACC:0.5939998626708984
Epoch 292, CIFAR-10 Batch 4:  Train_Loss:0.8485509157180786, Valid_Loss:1.2611180543899536, Valid_ACC:0.5949999094009399
Epoch 292, CIFAR-10 Batch 5:  Train_Loss:0.8138255476951599, Valid_Loss:1.2321211099624634, Valid_ACC:0.6061999201774597
Epoch 293, CIFAR-10 Batch 1:  Train_Loss:0.8312698006629944, Valid_Loss:1.2461562156677246, Valid_ACC:0.5959998965263367
Epoch 293, CIFAR-10 Batch 2:  Train_Loss:0.8260635137557983, Valid_Loss:1.2342671155929565, Valid_ACC:0.5993998646736145
Epoch 293, CIFAR-10 Batch 3:  Train_Loss:0.797671914100647, Valid_Loss:1.2405608892440796, Valid_ACC:0.595599889755249
Epoch 293, CIFAR-10 Batch 4:  Train_Loss:0.8565002679824829, Valid_Loss:1.2674386501312256, Valid_ACC:0.5891999006271362
Epoch 293, CIFAR-10 Batch 5:  Train_Loss:0.8288158178329468, Valid_Loss:1.2593965530395508, Valid_ACC:0.5959998965263367
Epoch 294, CIFAR-10 Batch 1:  Train_Loss:0.829819917678833, Valid_Loss:1.257636308670044, Valid_ACC:0.5951999425888062
Epoch 294, CIFAR-10 Batch 2:  Train_Loss:0.835517406463623, Valid_Loss:1.236691951751709, Valid_ACC:0.6033998727798462
Epoch 294, CIFAR-10 Batch 3:  Train_Loss:0.8016761541366577, Valid_Loss:1.2467854022979736, Valid_ACC:0.6007999181747437
Epoch 294, CIFAR-10 Batch 4:  Train_Loss:0.9311891794204712, Valid_Loss:1.3196544647216797, Valid_ACC:0.5687999129295349
Epoch 294, CIFAR-10 Batch 5:  Train_Loss:0.8584685921669006, Valid_Loss:1.2696577310562134, Valid_ACC:0.5897999405860901
Epoch 295, CIFAR-10 Batch 1:  Train_Loss:0.8207624554634094, Valid_Loss:1.2339980602264404, Valid_ACC:0.6039999127388
Epoch 295, CIFAR-10 Batch 2:  Train_Loss:0.8379324078559875, Valid_Loss:1.2356761693954468, Valid_ACC:0.596799910068512
Epoch 295, CIFAR-10 Batch 3:  Train_Loss:0.7941766977310181, Valid_Loss:1.236250638961792, Valid_ACC:0.6001999378204346
Epoch 295, CIFAR-10 Batch 4:  Train_Loss:0.8710998296737671, Valid_Loss:1.2819337844848633, Valid_ACC:0.5881998538970947
Epoch 295, CIFAR-10 Batch 5:  Train_Loss:0.8410282731056213, Valid_Loss:1.2669587135314941, Valid_ACC:0.590999960899353
Epoch 296, CIFAR-10 Batch 1:  Train_Loss:0.825814425945282, Valid_Loss:1.2479796409606934, Valid_ACC:0.5987999439239502
Epoch 296, CIFAR-10 Batch 2:  Train_Loss:0.8248313665390015, Valid_Loss:1.2367119789123535, Valid_ACC:0.6001999378204346
Epoch 296, CIFAR-10 Batch 3:  Train_Loss:0.8148306012153625, Valid_Loss:1.2563902139663696, Valid_ACC:0.5915998816490173
Epoch 296, CIFAR-10 Batch 4:  Train_Loss:0.8768044114112854, Valid_Loss:1.2752861976623535, Valid_ACC:0.5883999466896057
Epoch 296, CIFAR-10 Batch 5:  Train_Loss:0.8170918226242065, Valid_Loss:1.2443314790725708, Valid_ACC:0.6007999181747437
Epoch 297, CIFAR-10 Batch 1:  Train_Loss:0.8151786923408508, Valid_Loss:1.2388689517974854, Valid_ACC:0.6013998985290527
Epoch 297, CIFAR-10 Batch 2:  Train_Loss:0.8292259573936462, Valid_Loss:1.2355592250823975, Valid_ACC:0.602199912071228
Epoch 297, CIFAR-10 Batch 3:  Train_Loss:0.7898967266082764, Valid_Loss:1.2368965148925781, Valid_ACC:0.6013998985290527
Epoch 297, CIFAR-10 Batch 4:  Train_Loss:0.8923713564872742, Valid_Loss:1.2957972288131714, Valid_ACC:0.5825998783111572
Epoch 297, CIFAR-10 Batch 5:  Train_Loss:0.847672700881958, Valid_Loss:1.2678941488265991, Valid_ACC:0.5911999344825745
Epoch 298, CIFAR-10 Batch 1:  Train_Loss:0.8277270793914795, Valid_Loss:1.2438679933547974, Valid_ACC:0.6035999655723572
Epoch 298, CIFAR-10 Batch 2:  Train_Loss:0.824065089225769, Valid_Loss:1.232407808303833, Valid_ACC:0.6029999256134033
Epoch 298, CIFAR-10 Batch 3:  Train_Loss:0.8247736692428589, Valid_Loss:1.259341835975647, Valid_ACC:0.5935999751091003
Epoch 298, CIFAR-10 Batch 4:  Train_Loss:0.8787845969200134, Valid_Loss:1.2753351926803589, Valid_ACC:0.5895999073982239
Epoch 298, CIFAR-10 Batch 5:  Train_Loss:0.8329909443855286, Valid_Loss:1.2506085634231567, Valid_ACC:0.5955999493598938
Epoch 299, CIFAR-10 Batch 1:  Train_Loss:0.8372345566749573, Valid_Loss:1.245263934135437, Valid_ACC:0.5991999506950378
Epoch 299, CIFAR-10 Batch 2:  Train_Loss:0.8268671631813049, Valid_Loss:1.2363407611846924, Valid_ACC:0.5999999046325684
Epoch 299, CIFAR-10 Batch 3:  Train_Loss:0.7891517281532288, Valid_Loss:1.239975094795227, Valid_ACC:0.5981999039649963
Epoch 299, CIFAR-10 Batch 4:  Train_Loss:0.8574605584144592, Valid_Loss:1.266198992729187, Valid_ACC:0.5937999486923218
Epoch 299, CIFAR-10 Batch 5:  Train_Loss:0.8374847769737244, Valid_Loss:1.255534291267395, Valid_ACC:0.5979999303817749
Epoch 300, CIFAR-10 Batch 1:  Train_Loss:0.8390011787414551, Valid_Loss:1.262943148612976, Valid_ACC:0.595599889755249
Epoch 300, CIFAR-10 Batch 2:  Train_Loss:0.8191465139389038, Valid_Loss:1.2385132312774658, Valid_ACC:0.598599910736084
Epoch 300, CIFAR-10 Batch 3:  Train_Loss:0.7874193787574768, Valid_Loss:1.2485167980194092, Valid_ACC:0.5957999229431152
Epoch 300, CIFAR-10 Batch 4:  Train_Loss:0.8696874380111694, Valid_Loss:1.276265025138855, Valid_ACC:0.5867999196052551
Epoch 300, CIFAR-10 Batch 5:  Train_Loss:0.8670026063919067, Valid_Loss:1.2676680088043213, Valid_ACC:0.5903999209403992
Epoch 301, CIFAR-10 Batch 1:  Train_Loss:0.8208959102630615, Valid_Loss:1.2426598072052002, Valid_ACC:0.602199912071228
Epoch 301, CIFAR-10 Batch 2:  Train_Loss:0.8229361772537231, Valid_Loss:1.232271432876587, Valid_ACC:0.5991998910903931
Epoch 301, CIFAR-10 Batch 3:  Train_Loss:0.7809010148048401, Valid_Loss:1.235598087310791, Valid_ACC:0.5995998978614807
Epoch 301, CIFAR-10 Batch 4:  Train_Loss:0.8325880765914917, Valid_Loss:1.2511204481124878, Valid_ACC:0.5921999216079712
Epoch 301, CIFAR-10 Batch 5:  Train_Loss:0.8296090960502625, Valid_Loss:1.247556447982788, Valid_ACC:0.5983999371528625
Epoch 302, CIFAR-10 Batch 1:  Train_Loss:0.837615966796875, Valid_Loss:1.2620375156402588, Valid_ACC:0.5893999338150024
Epoch 302, CIFAR-10 Batch 2:  Train_Loss:0.8292768001556396, Valid_Loss:1.2426038980484009, Valid_ACC:0.6005999445915222
Epoch 302, CIFAR-10 Batch 3:  Train_Loss:0.7819352149963379, Valid_Loss:1.2312690019607544, Valid_ACC:0.6005999445915222
Epoch 302, CIFAR-10 Batch 4:  Train_Loss:0.8312116265296936, Valid_Loss:1.2551205158233643, Valid_ACC:0.5951999425888062
Epoch 302, CIFAR-10 Batch 5:  Train_Loss:0.8434816002845764, Valid_Loss:1.2611767053604126, Valid_ACC:0.5949999094009399
Epoch 303, CIFAR-10 Batch 1:  Train_Loss:0.8415307998657227, Valid_Loss:1.2570171356201172, Valid_ACC:0.5967999696731567
Epoch 303, CIFAR-10 Batch 2:  Train_Loss:0.8138125538825989, Valid_Loss:1.2328227758407593, Valid_ACC:0.600399911403656
Epoch 303, CIFAR-10 Batch 3:  Train_Loss:0.7880511283874512, Valid_Loss:1.2386608123779297, Valid_ACC:0.5993998646736145
Epoch 303, CIFAR-10 Batch 4:  Train_Loss:0.8236504793167114, Valid_Loss:1.2483381032943726, Valid_ACC:0.598599910736084
Epoch 303, CIFAR-10 Batch 5:  Train_Loss:0.8556351661682129, Valid_Loss:1.2634979486465454, Valid_ACC:0.5949999094009399
Epoch 304, CIFAR-10 Batch 1:  Train_Loss:0.8524768948554993, Valid_Loss:1.265026569366455, Valid_ACC:0.5941998958587646
Epoch 304, CIFAR-10 Batch 2:  Train_Loss:0.8350853323936462, Valid_Loss:1.247424840927124, Valid_ACC:0.595599889755249
Epoch 304, CIFAR-10 Batch 3:  Train_Loss:0.8016418218612671, Valid_Loss:1.2395918369293213, Valid_ACC:0.5999999046325684
Epoch 304, CIFAR-10 Batch 4:  Train_Loss:0.8216558694839478, Valid_Loss:1.2444567680358887, Valid_ACC:0.5953999161720276
Epoch 304, CIFAR-10 Batch 5:  Train_Loss:0.8214860558509827, Valid_Loss:1.2495369911193848, Valid_ACC:0.5995999574661255
Epoch 305, CIFAR-10 Batch 1:  Train_Loss:0.830675482749939, Valid_Loss:1.2471603155136108, Valid_ACC:0.6007998585700989
Epoch 305, CIFAR-10 Batch 2:  Train_Loss:0.8110097646713257, Valid_Loss:1.2342392206192017, Valid_ACC:0.6017999053001404
Epoch 305, CIFAR-10 Batch 3:  Train_Loss:0.7855247855186462, Valid_Loss:1.2329034805297852, Valid_ACC:0.6031998991966248
Epoch 305, CIFAR-10 Batch 4:  Train_Loss:0.8335480690002441, Valid_Loss:1.247928500175476, Valid_ACC:0.601399838924408
Epoch 305, CIFAR-10 Batch 5:  Train_Loss:0.8260179162025452, Valid_Loss:1.2374969720840454, Valid_ACC:0.6047998666763306
Epoch 306, CIFAR-10 Batch 1:  Train_Loss:0.8130447864532471, Valid_Loss:1.2418699264526367, Valid_ACC:0.597399890422821
Epoch 306, CIFAR-10 Batch 2:  Train_Loss:0.8149001598358154, Valid_Loss:1.237229824066162, Valid_ACC:0.6023999452590942
Epoch 306, CIFAR-10 Batch 3:  Train_Loss:0.7869770526885986, Valid_Loss:1.2407362461090088, Valid_ACC:0.6025998592376709
Epoch 306, CIFAR-10 Batch 4:  Train_Loss:0.8305764198303223, Valid_Loss:1.2495546340942383, Valid_ACC:0.5979999303817749
Epoch 306, CIFAR-10 Batch 5:  Train_Loss:0.8265320062637329, Valid_Loss:1.2314553260803223, Valid_ACC:0.6027999520301819
Epoch 307, CIFAR-10 Batch 1:  Train_Loss:0.8102297782897949, Valid_Loss:1.2476857900619507, Valid_ACC:0.6005998849868774
Epoch 307, CIFAR-10 Batch 2:  Train_Loss:0.8357341289520264, Valid_Loss:1.2441076040267944, Valid_ACC:0.6001999378204346
Epoch 307, CIFAR-10 Batch 3:  Train_Loss:0.7866790294647217, Valid_Loss:1.2336649894714355, Valid_ACC:0.6055999398231506
Epoch 307, CIFAR-10 Batch 4:  Train_Loss:0.8293083310127258, Valid_Loss:1.2482633590698242, Valid_ACC:0.5977998971939087
Epoch 307, CIFAR-10 Batch 5:  Train_Loss:0.8420000672340393, Valid_Loss:1.244650959968567, Valid_ACC:0.6013998985290527
Epoch 308, CIFAR-10 Batch 1:  Train_Loss:0.8501942753791809, Valid_Loss:1.2776073217391968, Valid_ACC:0.5881999135017395
Epoch 308, CIFAR-10 Batch 2:  Train_Loss:0.8379735946655273, Valid_Loss:1.249745488166809, Valid_ACC:0.5977998375892639
Epoch 308, CIFAR-10 Batch 3:  Train_Loss:0.7981706857681274, Valid_Loss:1.240958571434021, Valid_ACC:0.597399890422821
Epoch 308, CIFAR-10 Batch 4:  Train_Loss:0.8128958940505981, Valid_Loss:1.2308800220489502, Valid_ACC:0.602199912071228
Epoch 308, CIFAR-10 Batch 5:  Train_Loss:0.8289375305175781, Valid_Loss:1.250397801399231, Valid_ACC:0.6013999581336975
Epoch 309, CIFAR-10 Batch 1:  Train_Loss:0.829944372177124, Valid_Loss:1.2759263515472412, Valid_ACC:0.590399980545044
Epoch 309, CIFAR-10 Batch 2:  Train_Loss:0.8341453075408936, Valid_Loss:1.2465944290161133, Valid_ACC:0.5973999500274658
Epoch 309, CIFAR-10 Batch 3:  Train_Loss:0.7972536087036133, Valid_Loss:1.2409874200820923, Valid_ACC:0.6025999784469604
Epoch 309, CIFAR-10 Batch 4:  Train_Loss:0.8260606527328491, Valid_Loss:1.2466322183609009, Valid_ACC:0.5957999229431152
Epoch 309, CIFAR-10 Batch 5:  Train_Loss:0.8401560187339783, Valid_Loss:1.2505028247833252, Valid_ACC:0.5999999046325684
Epoch 310, CIFAR-10 Batch 1:  Train_Loss:0.8127840757369995, Valid_Loss:1.2528820037841797, Valid_ACC:0.5963999032974243
Epoch 310, CIFAR-10 Batch 2:  Train_Loss:0.8308848142623901, Valid_Loss:1.2461683750152588, Valid_ACC:0.595599889755249
Epoch 310, CIFAR-10 Batch 3:  Train_Loss:0.8344687223434448, Valid_Loss:1.2692633867263794, Valid_ACC:0.5849999189376831
Epoch 310, CIFAR-10 Batch 4:  Train_Loss:0.8347030878067017, Valid_Loss:1.2470929622650146, Valid_ACC:0.5975999236106873
Epoch 310, CIFAR-10 Batch 5:  Train_Loss:0.8293946981430054, Valid_Loss:1.2412970066070557, Valid_ACC:0.6033998727798462
Epoch 311, CIFAR-10 Batch 1:  Train_Loss:0.8284872770309448, Valid_Loss:1.2552709579467773, Valid_ACC:0.5959998965263367
Epoch 311, CIFAR-10 Batch 2:  Train_Loss:0.8396496772766113, Valid_Loss:1.2448253631591797, Valid_ACC:0.600399911403656
Epoch 311, CIFAR-10 Batch 3:  Train_Loss:0.7956161499023438, Valid_Loss:1.248390793800354, Valid_ACC:0.6013999581336975
Epoch 311, CIFAR-10 Batch 4:  Train_Loss:0.8371274471282959, Valid_Loss:1.2535169124603271, Valid_ACC:0.5913999080657959
Epoch 311, CIFAR-10 Batch 5:  Train_Loss:0.8188197612762451, Valid_Loss:1.2428566217422485, Valid_ACC:0.6029999256134033
Epoch 312, CIFAR-10 Batch 1:  Train_Loss:0.8057152628898621, Valid_Loss:1.2374495267868042, Valid_ACC:0.6037999391555786
Epoch 312, CIFAR-10 Batch 2:  Train_Loss:0.820507824420929, Valid_Loss:1.2286804914474487, Valid_ACC:0.6031999588012695
Epoch 312, CIFAR-10 Batch 3:  Train_Loss:0.7917749881744385, Valid_Loss:1.240492582321167, Valid_ACC:0.5961999297142029
Epoch 312, CIFAR-10 Batch 4:  Train_Loss:0.8156546354293823, Valid_Loss:1.246947169303894, Valid_ACC:0.5971999168395996
Epoch 312, CIFAR-10 Batch 5:  Train_Loss:0.8062962293624878, Valid_Loss:1.231097936630249, Valid_ACC:0.6055999398231506
Epoch 313, CIFAR-10 Batch 1:  Train_Loss:0.814275860786438, Valid_Loss:1.2503242492675781, Valid_ACC:0.5951999425888062
Epoch 313, CIFAR-10 Batch 2:  Train_Loss:0.8196917176246643, Valid_Loss:1.2328684329986572, Valid_ACC:0.603399932384491
Epoch 313, CIFAR-10 Batch 3:  Train_Loss:0.7962687611579895, Valid_Loss:1.2461885213851929, Valid_ACC:0.5951998829841614
Epoch 313, CIFAR-10 Batch 4:  Train_Loss:0.8048895001411438, Valid_Loss:1.2381892204284668, Valid_ACC:0.5997999310493469
Epoch 313, CIFAR-10 Batch 5:  Train_Loss:0.8155831694602966, Valid_Loss:1.2387337684631348, Valid_ACC:0.603399932384491
Epoch 314, CIFAR-10 Batch 1:  Train_Loss:0.8115582466125488, Valid_Loss:1.2455217838287354, Valid_ACC:0.5977999567985535
Epoch 314, CIFAR-10 Batch 2:  Train_Loss:0.8136617541313171, Valid_Loss:1.2390981912612915, Valid_ACC:0.5987999439239502
Epoch 314, CIFAR-10 Batch 3:  Train_Loss:0.7998096346855164, Valid_Loss:1.2486040592193604, Valid_ACC:0.5937999486923218
Epoch 314, CIFAR-10 Batch 4:  Train_Loss:0.810263991355896, Valid_Loss:1.236110806465149, Valid_ACC:0.6029999256134033
Epoch 314, CIFAR-10 Batch 5:  Train_Loss:0.8192589282989502, Valid_Loss:1.245566964149475, Valid_ACC:0.6013998985290527
Epoch 315, CIFAR-10 Batch 1:  Train_Loss:0.8068086504936218, Valid_Loss:1.2348482608795166, Valid_ACC:0.6023999452590942
Epoch 315, CIFAR-10 Batch 2:  Train_Loss:0.8273890018463135, Valid_Loss:1.2313684225082397, Valid_ACC:0.6047998666763306
Epoch 315, CIFAR-10 Batch 3:  Train_Loss:0.7759820222854614, Valid_Loss:1.2399888038635254, Valid_ACC:0.5993999242782593
Epoch 315, CIFAR-10 Batch 4:  Train_Loss:0.8130394220352173, Valid_Loss:1.2419623136520386, Valid_ACC:0.6001998782157898
Epoch 315, CIFAR-10 Batch 5:  Train_Loss:0.8188552856445312, Valid_Loss:1.2428696155548096, Valid_ACC:0.602199912071228
Epoch 316, CIFAR-10 Batch 1:  Train_Loss:0.7955179810523987, Valid_Loss:1.2299357652664185, Valid_ACC:0.6043998599052429
Epoch 316, CIFAR-10 Batch 2:  Train_Loss:0.8229783773422241, Valid_Loss:1.2347580194473267, Valid_ACC:0.6029999256134033
Epoch 316, CIFAR-10 Batch 3:  Train_Loss:0.7956715822219849, Valid_Loss:1.250622034072876, Valid_ACC:0.5975998640060425
Epoch 316, CIFAR-10 Batch 4:  Train_Loss:0.8110713362693787, Valid_Loss:1.242055892944336, Valid_ACC:0.5951998829841614
Epoch 316, CIFAR-10 Batch 5:  Train_Loss:0.8173089027404785, Valid_Loss:1.245240569114685, Valid_ACC:0.602199912071228
Epoch 317, CIFAR-10 Batch 1:  Train_Loss:0.8212352395057678, Valid_Loss:1.2441009283065796, Valid_ACC:0.597399890422821
Epoch 317, CIFAR-10 Batch 2:  Train_Loss:0.8316608667373657, Valid_Loss:1.244746208190918, Valid_ACC:0.5983999371528625
Epoch 317, CIFAR-10 Batch 3:  Train_Loss:0.796735942363739, Valid_Loss:1.246063232421875, Valid_ACC:0.5947999358177185
Epoch 317, CIFAR-10 Batch 4:  Train_Loss:0.8149814009666443, Valid_Loss:1.2324036359786987, Valid_ACC:0.6043999195098877
Epoch 317, CIFAR-10 Batch 5:  Train_Loss:0.8095777034759521, Valid_Loss:1.2337228059768677, Valid_ACC:0.6031998991966248
Epoch 318, CIFAR-10 Batch 1:  Train_Loss:0.8046396970748901, Valid_Loss:1.2267488241195679, Valid_ACC:0.6125999093055725
Epoch 318, CIFAR-10 Batch 2:  Train_Loss:0.8334705233573914, Valid_Loss:1.237694263458252, Valid_ACC:0.6023999452590942
Epoch 318, CIFAR-10 Batch 3:  Train_Loss:0.7905134558677673, Valid_Loss:1.2539818286895752, Valid_ACC:0.5969999432563782
Epoch 318, CIFAR-10 Batch 4:  Train_Loss:0.818232536315918, Valid_Loss:1.2406160831451416, Valid_ACC:0.5965999364852905
Epoch 318, CIFAR-10 Batch 5:  Train_Loss:0.8070840835571289, Valid_Loss:1.23866868019104, Valid_ACC:0.6005998849868774
Epoch 319, CIFAR-10 Batch 1:  Train_Loss:0.8029961585998535, Valid_Loss:1.2409698963165283, Valid_ACC:0.602199912071228
Epoch 319, CIFAR-10 Batch 2:  Train_Loss:0.8129302859306335, Valid_Loss:1.2312006950378418, Valid_ACC:0.6005998849868774
Epoch 319, CIFAR-10 Batch 3:  Train_Loss:0.7835052609443665, Valid_Loss:1.2392743825912476, Valid_ACC:0.5979998707771301
Epoch 319, CIFAR-10 Batch 4:  Train_Loss:0.8295841217041016, Valid_Loss:1.2493609189987183, Valid_ACC:0.5985998511314392
Epoch 319, CIFAR-10 Batch 5:  Train_Loss:0.8068509101867676, Valid_Loss:1.24095618724823, Valid_ACC:0.6007999181747437
Epoch 320, CIFAR-10 Batch 1:  Train_Loss:0.8006469011306763, Valid_Loss:1.2444339990615845, Valid_ACC:0.5991998910903931
Epoch 320, CIFAR-10 Batch 2:  Train_Loss:0.8199554085731506, Valid_Loss:1.2390402555465698, Valid_ACC:0.5993998646736145
Epoch 320, CIFAR-10 Batch 3:  Train_Loss:0.7802972197532654, Valid_Loss:1.245147943496704, Valid_ACC:0.596799910068512
Epoch 320, CIFAR-10 Batch 4:  Train_Loss:0.7980937361717224, Valid_Loss:1.2299087047576904, Valid_ACC:0.6057998538017273
Epoch 320, CIFAR-10 Batch 5:  Train_Loss:0.8122327327728271, Valid_Loss:1.2509992122650146, Valid_ACC:0.5989999175071716
Epoch 321, CIFAR-10 Batch 1:  Train_Loss:0.8004547953605652, Valid_Loss:1.2331756353378296, Valid_ACC:0.603399932384491
Epoch 321, CIFAR-10 Batch 2:  Train_Loss:0.8134084343910217, Valid_Loss:1.2351160049438477, Valid_ACC:0.6043999195098877
Epoch 321, CIFAR-10 Batch 3:  Train_Loss:0.7775782942771912, Valid_Loss:1.2457451820373535, Valid_ACC:0.596799910068512
Epoch 321, CIFAR-10 Batch 4:  Train_Loss:0.8261857628822327, Valid_Loss:1.2472974061965942, Valid_ACC:0.6037998795509338
Epoch 321, CIFAR-10 Batch 5:  Train_Loss:0.799244225025177, Valid_Loss:1.2393085956573486, Valid_ACC:0.5965999364852905
Epoch 322, CIFAR-10 Batch 1:  Train_Loss:0.8055449724197388, Valid_Loss:1.259446382522583, Valid_ACC:0.5911999344825745
Epoch 322, CIFAR-10 Batch 2:  Train_Loss:0.8069126009941101, Valid_Loss:1.2343966960906982, Valid_ACC:0.6019999980926514
Epoch 322, CIFAR-10 Batch 3:  Train_Loss:0.7751513123512268, Valid_Loss:1.2399879693984985, Valid_ACC:0.6039999723434448
Epoch 322, CIFAR-10 Batch 4:  Train_Loss:0.8113795518875122, Valid_Loss:1.2370116710662842, Valid_ACC:0.6039998531341553
Epoch 322, CIFAR-10 Batch 5:  Train_Loss:0.7947794795036316, Valid_Loss:1.2408391237258911, Valid_ACC:0.6021999716758728
Epoch 323, CIFAR-10 Batch 1:  Train_Loss:0.8007591366767883, Valid_Loss:1.23543119430542, Valid_ACC:0.6013998985290527
Epoch 323, CIFAR-10 Batch 2:  Train_Loss:0.8059975504875183, Valid_Loss:1.2316614389419556, Valid_ACC:0.6005998849868774
Epoch 323, CIFAR-10 Batch 3:  Train_Loss:0.7686455249786377, Valid_Loss:1.2361798286437988, Valid_ACC:0.6001999378204346
Epoch 323, CIFAR-10 Batch 4:  Train_Loss:0.8352662324905396, Valid_Loss:1.2548547983169556, Valid_ACC:0.5963999032974243
Epoch 323, CIFAR-10 Batch 5:  Train_Loss:0.8127226233482361, Valid_Loss:1.2588609457015991, Valid_ACC:0.5931999087333679
Epoch 324, CIFAR-10 Batch 1:  Train_Loss:0.7957039475440979, Valid_Loss:1.236914038658142, Valid_ACC:0.6023998856544495
Epoch 324, CIFAR-10 Batch 2:  Train_Loss:0.8279984593391418, Valid_Loss:1.2416067123413086, Valid_ACC:0.5981999039649963
Epoch 324, CIFAR-10 Batch 3:  Train_Loss:0.8055680990219116, Valid_Loss:1.2502117156982422, Valid_ACC:0.5959998369216919
Epoch 324, CIFAR-10 Batch 4:  Train_Loss:0.8164964914321899, Valid_Loss:1.2434409856796265, Valid_ACC:0.5991999506950378
Epoch 324, CIFAR-10 Batch 5:  Train_Loss:0.8327319622039795, Valid_Loss:1.264317512512207, Valid_ACC:0.5933998823165894
Epoch 325, CIFAR-10 Batch 1:  Train_Loss:0.7960853576660156, Valid_Loss:1.2314884662628174, Valid_ACC:0.606999933719635
Epoch 325, CIFAR-10 Batch 2:  Train_Loss:0.8158268928527832, Valid_Loss:1.230255365371704, Valid_ACC:0.6013998985290527
Epoch 325, CIFAR-10 Batch 3:  Train_Loss:0.7850920557975769, Valid_Loss:1.238348364830017, Valid_ACC:0.6007998585700989
Epoch 325, CIFAR-10 Batch 4:  Train_Loss:0.8084263801574707, Valid_Loss:1.2364201545715332, Valid_ACC:0.6009998917579651
Epoch 325, CIFAR-10 Batch 5:  Train_Loss:0.8302923440933228, Valid_Loss:1.257171630859375, Valid_ACC:0.5973999500274658
Epoch 326, CIFAR-10 Batch 1:  Train_Loss:0.7822203636169434, Valid_Loss:1.2319114208221436, Valid_ACC:0.6023999452590942
Epoch 326, CIFAR-10 Batch 2:  Train_Loss:0.8151270747184753, Valid_Loss:1.2332754135131836, Valid_ACC:0.6015998721122742
Epoch 326, CIFAR-10 Batch 3:  Train_Loss:0.783315122127533, Valid_Loss:1.2470200061798096, Valid_ACC:0.5999999046325684
Epoch 326, CIFAR-10 Batch 4:  Train_Loss:0.8153578639030457, Valid_Loss:1.238656997680664, Valid_ACC:0.5981999039649963
Epoch 326, CIFAR-10 Batch 5:  Train_Loss:0.8012948036193848, Valid_Loss:1.2450926303863525, Valid_ACC:0.596799910068512
Epoch 327, CIFAR-10 Batch 1:  Train_Loss:0.7866575121879578, Valid_Loss:1.2285070419311523, Valid_ACC:0.6061999201774597
Epoch 327, CIFAR-10 Batch 2:  Train_Loss:0.8017855882644653, Valid_Loss:1.2306396961212158, Valid_ACC:0.6059998869895935
Epoch 327, CIFAR-10 Batch 3:  Train_Loss:0.7862658500671387, Valid_Loss:1.2416738271713257, Valid_ACC:0.5957999229431152
Epoch 327, CIFAR-10 Batch 4:  Train_Loss:0.7953523397445679, Valid_Loss:1.2288519144058228, Valid_ACC:0.6071999669075012
Epoch 327, CIFAR-10 Batch 5:  Train_Loss:0.7909667491912842, Valid_Loss:1.2323150634765625, Valid_ACC:0.6019998788833618
Epoch 328, CIFAR-10 Batch 1:  Train_Loss:0.7928137183189392, Valid_Loss:1.2278664112091064, Valid_ACC:0.6083999872207642
Epoch 328, CIFAR-10 Batch 2:  Train_Loss:0.8243651986122131, Valid_Loss:1.235288143157959, Valid_ACC:0.5997999310493469
Epoch 328, CIFAR-10 Batch 3:  Train_Loss:0.7662473320960999, Valid_Loss:1.236489176750183, Valid_ACC:0.6035999059677124
Epoch 328, CIFAR-10 Batch 4:  Train_Loss:0.8362220525741577, Valid_Loss:1.2562103271484375, Valid_ACC:0.593799889087677
Epoch 328, CIFAR-10 Batch 5:  Train_Loss:0.8064884543418884, Valid_Loss:1.2427113056182861, Valid_ACC:0.6025999188423157
Epoch 329, CIFAR-10 Batch 1:  Train_Loss:0.7980299592018127, Valid_Loss:1.2513766288757324, Valid_ACC:0.5951999425888062
Epoch 329, CIFAR-10 Batch 2:  Train_Loss:0.8170506358146667, Valid_Loss:1.2421562671661377, Valid_ACC:0.5989998579025269
Epoch 329, CIFAR-10 Batch 3:  Train_Loss:0.7830120325088501, Valid_Loss:1.2413538694381714, Valid_ACC:0.6017999053001404
Epoch 329, CIFAR-10 Batch 4:  Train_Loss:0.8443963527679443, Valid_Loss:1.2639334201812744, Valid_ACC:0.5961999893188477
Epoch 329, CIFAR-10 Batch 5:  Train_Loss:0.793122410774231, Valid_Loss:1.241079568862915, Valid_ACC:0.601599931716919
Epoch 330, CIFAR-10 Batch 1:  Train_Loss:0.7840895652770996, Valid_Loss:1.2360801696777344, Valid_ACC:0.6019999384880066
Epoch 330, CIFAR-10 Batch 2:  Train_Loss:0.7897614240646362, Valid_Loss:1.2314271926879883, Valid_ACC:0.6007999777793884
Epoch 330, CIFAR-10 Batch 3:  Train_Loss:0.7742612361907959, Valid_Loss:1.231126308441162, Valid_ACC:0.6013998985290527
Epoch 330, CIFAR-10 Batch 4:  Train_Loss:0.8137798309326172, Valid_Loss:1.2371324300765991, Valid_ACC:0.6041999459266663
Epoch 330, CIFAR-10 Batch 5:  Train_Loss:0.8162833452224731, Valid_Loss:1.2566907405853271, Valid_ACC:0.5941999554634094
Epoch 331, CIFAR-10 Batch 1:  Train_Loss:0.7983372211456299, Valid_Loss:1.254534125328064, Valid_ACC:0.5941999554634094
Epoch 331, CIFAR-10 Batch 2:  Train_Loss:0.8109176158905029, Valid_Loss:1.2489309310913086, Valid_ACC:0.5955999493598938
Epoch 331, CIFAR-10 Batch 3:  Train_Loss:0.7668817043304443, Valid_Loss:1.2329695224761963, Valid_ACC:0.6017999053001404
Epoch 331, CIFAR-10 Batch 4:  Train_Loss:0.7973785400390625, Valid_Loss:1.2319989204406738, Valid_ACC:0.6017999053001404
Epoch 331, CIFAR-10 Batch 5:  Train_Loss:0.7884426116943359, Valid_Loss:1.2409461736679077, Valid_ACC:0.5999999046325684
Epoch 332, CIFAR-10 Batch 1:  Train_Loss:0.7791469097137451, Valid_Loss:1.2275997400283813, Valid_ACC:0.6091999411582947
Epoch 332, CIFAR-10 Batch 2:  Train_Loss:0.79229736328125, Valid_Loss:1.2294883728027344, Valid_ACC:0.602199912071228
Epoch 332, CIFAR-10 Batch 3:  Train_Loss:0.763481080532074, Valid_Loss:1.2365233898162842, Valid_ACC:0.605199933052063
Epoch 332, CIFAR-10 Batch 4:  Train_Loss:0.8116011619567871, Valid_Loss:1.2417662143707275, Valid_ACC:0.5953999757766724
Epoch 332, CIFAR-10 Batch 5:  Train_Loss:0.8041434288024902, Valid_Loss:1.2570189237594604, Valid_ACC:0.597399890422821
Epoch 333, CIFAR-10 Batch 1:  Train_Loss:0.7895530462265015, Valid_Loss:1.2278581857681274, Valid_ACC:0.6033998727798462
Epoch 333, CIFAR-10 Batch 2:  Train_Loss:0.7858940362930298, Valid_Loss:1.2345941066741943, Valid_ACC:0.5995999574661255
Epoch 333, CIFAR-10 Batch 3:  Train_Loss:0.7892977595329285, Valid_Loss:1.2353856563568115, Valid_ACC:0.5979999303817749
Epoch 333, CIFAR-10 Batch 4:  Train_Loss:0.7845834493637085, Valid_Loss:1.222203254699707, Valid_ACC:0.6037998795509338
Epoch 333, CIFAR-10 Batch 5:  Train_Loss:0.8036065697669983, Valid_Loss:1.2387646436691284, Valid_ACC:0.6039999723434448
Epoch 334, CIFAR-10 Batch 1:  Train_Loss:0.7803798913955688, Valid_Loss:1.2421963214874268, Valid_ACC:0.5977999567985535
Epoch 334, CIFAR-10 Batch 2:  Train_Loss:0.7891495823860168, Valid_Loss:1.226104497909546, Valid_ACC:0.6047998666763306
Epoch 334, CIFAR-10 Batch 3:  Train_Loss:0.7739216089248657, Valid_Loss:1.239540696144104, Valid_ACC:0.6005999445915222
Epoch 334, CIFAR-10 Batch 4:  Train_Loss:0.834388792514801, Valid_Loss:1.253843903541565, Valid_ACC:0.6007999181747437
Epoch 334, CIFAR-10 Batch 5:  Train_Loss:0.8198217153549194, Valid_Loss:1.2597273588180542, Valid_ACC:0.5961999297142029
Epoch 335, CIFAR-10 Batch 1:  Train_Loss:0.7987668514251709, Valid_Loss:1.2403565645217896, Valid_ACC:0.5953999161720276
Epoch 335, CIFAR-10 Batch 2:  Train_Loss:0.7951158881187439, Valid_Loss:1.2362163066864014, Valid_ACC:0.6027998924255371
Epoch 335, CIFAR-10 Batch 3:  Train_Loss:0.763339638710022, Valid_Loss:1.2321571111679077, Valid_ACC:0.602199912071228
Epoch 335, CIFAR-10 Batch 4:  Train_Loss:0.8243231773376465, Valid_Loss:1.2422914505004883, Valid_ACC:0.5997998714447021
Epoch 335, CIFAR-10 Batch 5:  Train_Loss:0.8122140169143677, Valid_Loss:1.2526946067810059, Valid_ACC:0.5997999906539917
Epoch 336, CIFAR-10 Batch 1:  Train_Loss:0.7807526588439941, Valid_Loss:1.2341887950897217, Valid_ACC:0.6043999195098877
Epoch 336, CIFAR-10 Batch 2:  Train_Loss:0.8045212030410767, Valid_Loss:1.2460895776748657, Valid_ACC:0.5961998701095581
Epoch 336, CIFAR-10 Batch 3:  Train_Loss:0.7768540382385254, Valid_Loss:1.2400928735733032, Valid_ACC:0.6023998856544495
Epoch 336, CIFAR-10 Batch 4:  Train_Loss:0.7992657423019409, Valid_Loss:1.2299307584762573, Valid_ACC:0.6033998727798462
Epoch 336, CIFAR-10 Batch 5:  Train_Loss:0.8029677867889404, Valid_Loss:1.247280240058899, Valid_ACC:0.598599910736084
Epoch 337, CIFAR-10 Batch 1:  Train_Loss:0.7909478545188904, Valid_Loss:1.233138918876648, Valid_ACC:0.6063998937606812
Epoch 337, CIFAR-10 Batch 2:  Train_Loss:0.8028362989425659, Valid_Loss:1.2353531122207642, Valid_ACC:0.6009999513626099
Epoch 337, CIFAR-10 Batch 3:  Train_Loss:0.7661406993865967, Valid_Loss:1.2371317148208618, Valid_ACC:0.5995998978614807
Epoch 337, CIFAR-10 Batch 4:  Train_Loss:0.7949360609054565, Valid_Loss:1.2324974536895752, Valid_ACC:0.6027998328208923
Epoch 337, CIFAR-10 Batch 5:  Train_Loss:0.7923519611358643, Valid_Loss:1.2322289943695068, Valid_ACC:0.6051998734474182
Epoch 338, CIFAR-10 Batch 1:  Train_Loss:0.7973151803016663, Valid_Loss:1.2478621006011963, Valid_ACC:0.5987998843193054
Epoch 338, CIFAR-10 Batch 2:  Train_Loss:0.8126429319381714, Valid_Loss:1.2387906312942505, Valid_ACC:0.5995999574661255
Epoch 338, CIFAR-10 Batch 3:  Train_Loss:0.7694929838180542, Valid_Loss:1.2428313493728638, Valid_ACC:0.5991998910903931
Epoch 338, CIFAR-10 Batch 4:  Train_Loss:0.7907811403274536, Valid_Loss:1.2314308881759644, Valid_ACC:0.6045998930931091
Epoch 338, CIFAR-10 Batch 5:  Train_Loss:0.8078611493110657, Valid_Loss:1.2473092079162598, Valid_ACC:0.6029999256134033
Epoch 339, CIFAR-10 Batch 1:  Train_Loss:0.8101233243942261, Valid_Loss:1.2665393352508545, Valid_ACC:0.5931999087333679
Epoch 339, CIFAR-10 Batch 2:  Train_Loss:0.8262367248535156, Valid_Loss:1.2501063346862793, Valid_ACC:0.5921999216079712
Epoch 339, CIFAR-10 Batch 3:  Train_Loss:0.7891608476638794, Valid_Loss:1.246808648109436, Valid_ACC:0.598599910736084
Epoch 339, CIFAR-10 Batch 4:  Train_Loss:0.7876818180084229, Valid_Loss:1.2322680950164795, Valid_ACC:0.6001999378204346
Epoch 339, CIFAR-10 Batch 5:  Train_Loss:0.8172600269317627, Valid_Loss:1.2686270475387573, Valid_ACC:0.5907999277114868
Epoch 340, CIFAR-10 Batch 1:  Train_Loss:0.8085028529167175, Valid_Loss:1.2612874507904053, Valid_ACC:0.5889999270439148
Epoch 340, CIFAR-10 Batch 2:  Train_Loss:0.8357508182525635, Valid_Loss:1.264259696006775, Valid_ACC:0.5939999222755432
Epoch 340, CIFAR-10 Batch 3:  Train_Loss:0.782005786895752, Valid_Loss:1.2417501211166382, Valid_ACC:0.5983999967575073
Epoch 340, CIFAR-10 Batch 4:  Train_Loss:0.7808220982551575, Valid_Loss:1.2300039529800415, Valid_ACC:0.6027998924255371
Epoch 340, CIFAR-10 Batch 5:  Train_Loss:0.7996065616607666, Valid_Loss:1.2354826927185059, Valid_ACC:0.6025999188423157
Epoch 341, CIFAR-10 Batch 1:  Train_Loss:0.8352184891700745, Valid_Loss:1.2860095500946045, Valid_ACC:0.5841999053955078
Epoch 341, CIFAR-10 Batch 2:  Train_Loss:0.803175687789917, Valid_Loss:1.232813835144043, Valid_ACC:0.6051998734474182
Epoch 341, CIFAR-10 Batch 3:  Train_Loss:0.8202428221702576, Valid_Loss:1.2678776979446411, Valid_ACC:0.5925999879837036
Epoch 341, CIFAR-10 Batch 4:  Train_Loss:0.7908787131309509, Valid_Loss:1.2379732131958008, Valid_ACC:0.5995999574661255
Epoch 341, CIFAR-10 Batch 5:  Train_Loss:0.7928174734115601, Valid_Loss:1.2356960773468018, Valid_ACC:0.601599931716919
Epoch 342, CIFAR-10 Batch 1:  Train_Loss:0.7886908054351807, Valid_Loss:1.2309399843215942, Valid_ACC:0.6057999134063721
Epoch 342, CIFAR-10 Batch 2:  Train_Loss:0.7987104058265686, Valid_Loss:1.234020709991455, Valid_ACC:0.6035999059677124
Epoch 342, CIFAR-10 Batch 3:  Train_Loss:0.811813235282898, Valid_Loss:1.273740530014038, Valid_ACC:0.589199960231781
Epoch 342, CIFAR-10 Batch 4:  Train_Loss:0.8162469863891602, Valid_Loss:1.2502959966659546, Valid_ACC:0.5935999155044556
Epoch 342, CIFAR-10 Batch 5:  Train_Loss:0.8041254281997681, Valid_Loss:1.2445719242095947, Valid_ACC:0.598599910736084
Epoch 343, CIFAR-10 Batch 1:  Train_Loss:0.7889647483825684, Valid_Loss:1.2345670461654663, Valid_ACC:0.601599931716919
Epoch 343, CIFAR-10 Batch 2:  Train_Loss:0.8036344051361084, Valid_Loss:1.2323369979858398, Valid_ACC:0.6035999059677124
Epoch 343, CIFAR-10 Batch 3:  Train_Loss:0.7802062034606934, Valid_Loss:1.2455368041992188, Valid_ACC:0.5997999310493469
Epoch 343, CIFAR-10 Batch 4:  Train_Loss:0.7922688722610474, Valid_Loss:1.2433547973632812, Valid_ACC:0.5987999439239502
Epoch 343, CIFAR-10 Batch 5:  Train_Loss:0.8063093423843384, Valid_Loss:1.2412145137786865, Valid_ACC:0.5997999310493469
Epoch 344, CIFAR-10 Batch 1:  Train_Loss:0.7951540946960449, Valid_Loss:1.2480053901672363, Valid_ACC:0.6007999181747437
Epoch 344, CIFAR-10 Batch 2:  Train_Loss:0.8163098096847534, Valid_Loss:1.2454107999801636, Valid_ACC:0.5965999364852905
Epoch 344, CIFAR-10 Batch 3:  Train_Loss:0.758894681930542, Valid_Loss:1.2268540859222412, Valid_ACC:0.6059998869895935
Epoch 344, CIFAR-10 Batch 4:  Train_Loss:0.7816916704177856, Valid_Loss:1.2314181327819824, Valid_ACC:0.6019999980926514
Epoch 344, CIFAR-10 Batch 5:  Train_Loss:0.7875545024871826, Valid_Loss:1.2377004623413086, Valid_ACC:0.6067999005317688
Epoch 345, CIFAR-10 Batch 1:  Train_Loss:0.8060014843940735, Valid_Loss:1.2507917881011963, Valid_ACC:0.5981999635696411
Epoch 345, CIFAR-10 Batch 2:  Train_Loss:0.8021653890609741, Valid_Loss:1.236297607421875, Valid_ACC:0.6053998470306396
Epoch 345, CIFAR-10 Batch 3:  Train_Loss:0.7784909009933472, Valid_Loss:1.2409716844558716, Valid_ACC:0.5987998843193054
Epoch 345, CIFAR-10 Batch 4:  Train_Loss:0.8120514154434204, Valid_Loss:1.2492891550064087, Valid_ACC:0.5979999303817749
Epoch 345, CIFAR-10 Batch 5:  Train_Loss:0.8070500493049622, Valid_Loss:1.2471716403961182, Valid_ACC:0.5977998971939087
Epoch 346, CIFAR-10 Batch 1:  Train_Loss:0.7801542282104492, Valid_Loss:1.2257626056671143, Valid_ACC:0.6063998937606812
Epoch 346, CIFAR-10 Batch 2:  Train_Loss:0.7959674000740051, Valid_Loss:1.233614206314087, Valid_ACC:0.6035999059677124
Epoch 346, CIFAR-10 Batch 3:  Train_Loss:0.7995421886444092, Valid_Loss:1.2552872896194458, Valid_ACC:0.5943999290466309
Epoch 346, CIFAR-10 Batch 4:  Train_Loss:0.7853366732597351, Valid_Loss:1.2344605922698975, Valid_ACC:0.6009998917579651
Epoch 346, CIFAR-10 Batch 5:  Train_Loss:0.7951149940490723, Valid_Loss:1.2403666973114014, Valid_ACC:0.6023999452590942
Epoch 347, CIFAR-10 Batch 1:  Train_Loss:0.807972252368927, Valid_Loss:1.2689300775527954, Valid_ACC:0.5873998999595642
Epoch 347, CIFAR-10 Batch 2:  Train_Loss:0.7852463722229004, Valid_Loss:1.2278976440429688, Valid_ACC:0.6039999723434448
Epoch 347, CIFAR-10 Batch 3:  Train_Loss:0.7956537008285522, Valid_Loss:1.2543907165527344, Valid_ACC:0.5945999622344971
Epoch 347, CIFAR-10 Batch 4:  Train_Loss:0.7759379744529724, Valid_Loss:1.229480266571045, Valid_ACC:0.6055998802185059
Epoch 347, CIFAR-10 Batch 5:  Train_Loss:0.7946147918701172, Valid_Loss:1.2430965900421143, Valid_ACC:0.6037998795509338
Epoch 348, CIFAR-10 Batch 1:  Train_Loss:0.765512228012085, Valid_Loss:1.2310361862182617, Valid_ACC:0.6043998599052429
Epoch 348, CIFAR-10 Batch 2:  Train_Loss:0.7899065017700195, Valid_Loss:1.2379522323608398, Valid_ACC:0.5975999236106873
Epoch 348, CIFAR-10 Batch 3:  Train_Loss:0.7646181583404541, Valid_Loss:1.2330294847488403, Valid_ACC:0.6047999262809753
Epoch 348, CIFAR-10 Batch 4:  Train_Loss:0.7889635562896729, Valid_Loss:1.2328295707702637, Valid_ACC:0.6025999188423157
Epoch 348, CIFAR-10 Batch 5:  Train_Loss:0.790328323841095, Valid_Loss:1.2360234260559082, Valid_ACC:0.605199933052063
Epoch 349, CIFAR-10 Batch 1:  Train_Loss:0.7960912585258484, Valid_Loss:1.2538156509399414, Valid_ACC:0.5921999216079712
Epoch 349, CIFAR-10 Batch 2:  Train_Loss:0.7964892387390137, Valid_Loss:1.2338956594467163, Valid_ACC:0.6005998849868774
Epoch 349, CIFAR-10 Batch 3:  Train_Loss:0.778357982635498, Valid_Loss:1.2499020099639893, Valid_ACC:0.5959998965263367
Epoch 349, CIFAR-10 Batch 4:  Train_Loss:0.7829867601394653, Valid_Loss:1.234900951385498, Valid_ACC:0.6025998592376709
Epoch 349, CIFAR-10 Batch 5:  Train_Loss:0.7900522947311401, Valid_Loss:1.240920066833496, Valid_ACC:0.6025998592376709
Epoch 350, CIFAR-10 Batch 1:  Train_Loss:0.7875214219093323, Valid_Loss:1.2554621696472168, Valid_ACC:0.5953999161720276
Epoch 350, CIFAR-10 Batch 2:  Train_Loss:0.7900694608688354, Valid_Loss:1.2391976118087769, Valid_ACC:0.5981999635696411
Epoch 350, CIFAR-10 Batch 3:  Train_Loss:0.7710528373718262, Valid_Loss:1.2378532886505127, Valid_ACC:0.6003999710083008
Epoch 350, CIFAR-10 Batch 4:  Train_Loss:0.7799422144889832, Valid_Loss:1.2347959280014038, Valid_ACC:0.6039999127388
Epoch 350, CIFAR-10 Batch 5:  Train_Loss:0.7830241918563843, Valid_Loss:1.2319728136062622, Valid_ACC:0.6053999066352844
Epoch 351, CIFAR-10 Batch 1:  Train_Loss:0.7739566564559937, Valid_Loss:1.2416539192199707, Valid_ACC:0.602199912071228
Epoch 351, CIFAR-10 Batch 2:  Train_Loss:0.7809205055236816, Valid_Loss:1.2334154844284058, Valid_ACC:0.6013998985290527
Epoch 351, CIFAR-10 Batch 3:  Train_Loss:0.7598902583122253, Valid_Loss:1.2333123683929443, Valid_ACC:0.6001999378204346
Epoch 351, CIFAR-10 Batch 4:  Train_Loss:0.7920364737510681, Valid_Loss:1.2320363521575928, Valid_ACC:0.6029999256134033
Epoch 351, CIFAR-10 Batch 5:  Train_Loss:0.7755206823348999, Valid_Loss:1.2261697053909302, Valid_ACC:0.6069998741149902
Epoch 352, CIFAR-10 Batch 1:  Train_Loss:0.7817904949188232, Valid_Loss:1.228756070137024, Valid_ACC:0.6063998937606812
Epoch 352, CIFAR-10 Batch 2:  Train_Loss:0.7862065434455872, Valid_Loss:1.235278606414795, Valid_ACC:0.6063999533653259
Epoch 352, CIFAR-10 Batch 3:  Train_Loss:0.7724632024765015, Valid_Loss:1.2435047626495361, Valid_ACC:0.5949999094009399
Epoch 352, CIFAR-10 Batch 4:  Train_Loss:0.770015299320221, Valid_Loss:1.2246694564819336, Valid_ACC:0.6023999452590942
Epoch 352, CIFAR-10 Batch 5:  Train_Loss:0.7776200771331787, Valid_Loss:1.227508306503296, Valid_ACC:0.6071999073028564
Epoch 353, CIFAR-10 Batch 1:  Train_Loss:0.7724671363830566, Valid_Loss:1.2263376712799072, Valid_ACC:0.605199933052063
Epoch 353, CIFAR-10 Batch 2:  Train_Loss:0.7822712659835815, Valid_Loss:1.2280163764953613, Valid_ACC:0.6039998531341553
Epoch 353, CIFAR-10 Batch 3:  Train_Loss:0.7558315992355347, Valid_Loss:1.2407803535461426, Valid_ACC:0.6023998856544495
Epoch 353, CIFAR-10 Batch 4:  Train_Loss:0.7884830832481384, Valid_Loss:1.238837480545044, Valid_ACC:0.601599931716919
Epoch 353, CIFAR-10 Batch 5:  Train_Loss:0.7878775596618652, Valid_Loss:1.2395596504211426, Valid_ACC:0.6017999053001404
Epoch 354, CIFAR-10 Batch 1:  Train_Loss:0.8120641708374023, Valid_Loss:1.2953461408615112, Valid_ACC:0.5825998783111572
Epoch 354, CIFAR-10 Batch 2:  Train_Loss:0.8338639736175537, Valid_Loss:1.2695554494857788, Valid_ACC:0.5857999324798584
Epoch 354, CIFAR-10 Batch 3:  Train_Loss:0.7618066072463989, Valid_Loss:1.230080008506775, Valid_ACC:0.6041998863220215
Epoch 354, CIFAR-10 Batch 4:  Train_Loss:0.7840158343315125, Valid_Loss:1.2327394485473633, Valid_ACC:0.6031999588012695
Epoch 354, CIFAR-10 Batch 5:  Train_Loss:0.7864953875541687, Valid_Loss:1.242741346359253, Valid_ACC:0.6009999513626099
Epoch 355, CIFAR-10 Batch 1:  Train_Loss:0.778041660785675, Valid_Loss:1.236077070236206, Valid_ACC:0.6001998782157898
Epoch 355, CIFAR-10 Batch 2:  Train_Loss:0.7856599688529968, Valid_Loss:1.2286657094955444, Valid_ACC:0.6023999452590942
Epoch 355, CIFAR-10 Batch 3:  Train_Loss:0.7567037343978882, Valid_Loss:1.2305245399475098, Valid_ACC:0.6053998470306396
Epoch 355, CIFAR-10 Batch 4:  Train_Loss:0.7760365605354309, Valid_Loss:1.2259471416473389, Valid_ACC:0.6043999195098877
Epoch 355, CIFAR-10 Batch 5:  Train_Loss:0.7770112156867981, Valid_Loss:1.2336541414260864, Valid_ACC:0.6061999201774597
Epoch 356, CIFAR-10 Batch 1:  Train_Loss:0.7748380303382874, Valid_Loss:1.24393630027771, Valid_ACC:0.6017999053001404
Epoch 356, CIFAR-10 Batch 2:  Train_Loss:0.7890886068344116, Valid_Loss:1.2338744401931763, Valid_ACC:0.6011998653411865
Epoch 356, CIFAR-10 Batch 3:  Train_Loss:0.7574225068092346, Valid_Loss:1.233439326286316, Valid_ACC:0.5987999439239502
Epoch 356, CIFAR-10 Batch 4:  Train_Loss:0.7704687714576721, Valid_Loss:1.216362476348877, Valid_ACC:0.6045999526977539
Epoch 356, CIFAR-10 Batch 5:  Train_Loss:0.7832232713699341, Valid_Loss:1.2345203161239624, Valid_ACC:0.6079999208450317
Epoch 357, CIFAR-10 Batch 1:  Train_Loss:0.7679876089096069, Valid_Loss:1.2378098964691162, Valid_ACC:0.5989999175071716
Epoch 357, CIFAR-10 Batch 2:  Train_Loss:0.7953235507011414, Valid_Loss:1.23128080368042, Valid_ACC:0.6035999059677124
Epoch 357, CIFAR-10 Batch 3:  Train_Loss:0.7462249398231506, Valid_Loss:1.2350945472717285, Valid_ACC:0.6057999134063721
Epoch 357, CIFAR-10 Batch 4:  Train_Loss:0.7934504747390747, Valid_Loss:1.2395355701446533, Valid_ACC:0.6019998788833618
Epoch 357, CIFAR-10 Batch 5:  Train_Loss:0.7802435159683228, Valid_Loss:1.2497761249542236, Valid_ACC:0.6043999195098877
Epoch 358, CIFAR-10 Batch 1:  Train_Loss:0.7953448295593262, Valid_Loss:1.2464030981063843, Valid_ACC:0.6027998924255371
Epoch 358, CIFAR-10 Batch 2:  Train_Loss:0.8050370812416077, Valid_Loss:1.2382593154907227, Valid_ACC:0.6031998991966248
Epoch 358, CIFAR-10 Batch 3:  Train_Loss:0.7498964071273804, Valid_Loss:1.234494924545288, Valid_ACC:0.6037999391555786
Epoch 358, CIFAR-10 Batch 4:  Train_Loss:0.781901478767395, Valid_Loss:1.2261021137237549, Valid_ACC:0.6065999269485474
Epoch 358, CIFAR-10 Batch 5:  Train_Loss:0.7668160796165466, Valid_Loss:1.2325962781906128, Valid_ACC:0.6045998930931091
Epoch 359, CIFAR-10 Batch 1:  Train_Loss:0.7810490131378174, Valid_Loss:1.236860990524292, Valid_ACC:0.5981999039649963
Epoch 359, CIFAR-10 Batch 2:  Train_Loss:0.7811838388442993, Valid_Loss:1.2255078554153442, Valid_ACC:0.609799861907959
Epoch 359, CIFAR-10 Batch 3:  Train_Loss:0.7476300001144409, Valid_Loss:1.2345609664916992, Valid_ACC:0.6017999053001404
Epoch 359, CIFAR-10 Batch 4:  Train_Loss:0.7696192860603333, Valid_Loss:1.2247724533081055, Valid_ACC:0.600399911403656
Epoch 359, CIFAR-10 Batch 5:  Train_Loss:0.7878326177597046, Valid_Loss:1.241621971130371, Valid_ACC:0.602199912071228
Epoch 360, CIFAR-10 Batch 1:  Train_Loss:0.7852151393890381, Valid_Loss:1.234365463256836, Valid_ACC:0.5993999242782593
Epoch 360, CIFAR-10 Batch 2:  Train_Loss:0.7824707627296448, Valid_Loss:1.23103928565979, Valid_ACC:0.6029999256134033
Epoch 360, CIFAR-10 Batch 3:  Train_Loss:0.7583600282669067, Valid_Loss:1.2294080257415771, Valid_ACC:0.606999933719635
Epoch 360, CIFAR-10 Batch 4:  Train_Loss:0.7601470947265625, Valid_Loss:1.222660779953003, Valid_ACC:0.6077998876571655
Epoch 360, CIFAR-10 Batch 5:  Train_Loss:0.7686501145362854, Valid_Loss:1.2308282852172852, Valid_ACC:0.6065999269485474
Epoch 361, CIFAR-10 Batch 1:  Train_Loss:0.7768445611000061, Valid_Loss:1.2288049459457397, Valid_ACC:0.6029998660087585
Epoch 361, CIFAR-10 Batch 2:  Train_Loss:0.7809545993804932, Valid_Loss:1.2312549352645874, Valid_ACC:0.6045999526977539
Epoch 361, CIFAR-10 Batch 3:  Train_Loss:0.7668362259864807, Valid_Loss:1.2386326789855957, Valid_ACC:0.602199912071228
Epoch 361, CIFAR-10 Batch 4:  Train_Loss:0.7848536968231201, Valid_Loss:1.2353291511535645, Valid_ACC:0.6037998795509338
Epoch 361, CIFAR-10 Batch 5:  Train_Loss:0.7829184532165527, Valid_Loss:1.2344950437545776, Valid_ACC:0.6047999262809753
Epoch 362, CIFAR-10 Batch 1:  Train_Loss:0.7655611038208008, Valid_Loss:1.2291299104690552, Valid_ACC:0.610599935054779
Epoch 362, CIFAR-10 Batch 2:  Train_Loss:0.7876830101013184, Valid_Loss:1.2388365268707275, Valid_ACC:0.6035999059677124
Epoch 362, CIFAR-10 Batch 3:  Train_Loss:0.7436640858650208, Valid_Loss:1.2296600341796875, Valid_ACC:0.6067999005317688
Epoch 362, CIFAR-10 Batch 4:  Train_Loss:0.7610975503921509, Valid_Loss:1.2261415719985962, Valid_ACC:0.605199933052063
Epoch 362, CIFAR-10 Batch 5:  Train_Loss:0.7832319736480713, Valid_Loss:1.2398929595947266, Valid_ACC:0.600399911403656
Epoch 363, CIFAR-10 Batch 1:  Train_Loss:0.773647129535675, Valid_Loss:1.2389106750488281, Valid_ACC:0.605199933052063
Epoch 363, CIFAR-10 Batch 2:  Train_Loss:0.7727497220039368, Valid_Loss:1.2320760488510132, Valid_ACC:0.6025998592376709
Epoch 363, CIFAR-10 Batch 3:  Train_Loss:0.7609691619873047, Valid_Loss:1.2345950603485107, Valid_ACC:0.5995999574661255
Epoch 363, CIFAR-10 Batch 4:  Train_Loss:0.7618056535720825, Valid_Loss:1.223005771636963, Valid_ACC:0.6059999465942383
Epoch 363, CIFAR-10 Batch 5:  Train_Loss:0.7793564200401306, Valid_Loss:1.2360728979110718, Valid_ACC:0.6063999533653259
Epoch 364, CIFAR-10 Batch 1:  Train_Loss:0.7599055767059326, Valid_Loss:1.2297121286392212, Valid_ACC:0.6073998808860779
Epoch 364, CIFAR-10 Batch 2:  Train_Loss:0.7751840353012085, Valid_Loss:1.2301349639892578, Valid_ACC:0.6053999066352844
Epoch 364, CIFAR-10 Batch 3:  Train_Loss:0.76026850938797, Valid_Loss:1.2566863298416138, Valid_ACC:0.5997999310493469
Epoch 364, CIFAR-10 Batch 4:  Train_Loss:0.7842089533805847, Valid_Loss:1.2460213899612427, Valid_ACC:0.5971999764442444
Epoch 364, CIFAR-10 Batch 5:  Train_Loss:0.7761965990066528, Valid_Loss:1.237112283706665, Valid_ACC:0.605199933052063
Epoch 365, CIFAR-10 Batch 1:  Train_Loss:0.7592296600341797, Valid_Loss:1.2390227317810059, Valid_ACC:0.6043998599052429
Epoch 365, CIFAR-10 Batch 2:  Train_Loss:0.7850432395935059, Valid_Loss:1.2406566143035889, Valid_ACC:0.6001998782157898
Epoch 365, CIFAR-10 Batch 3:  Train_Loss:0.7479435205459595, Valid_Loss:1.2297370433807373, Valid_ACC:0.6027998924255371
Epoch 365, CIFAR-10 Batch 4:  Train_Loss:0.7645508646965027, Valid_Loss:1.2229610681533813, Valid_ACC:0.6071999073028564
Epoch 365, CIFAR-10 Batch 5:  Train_Loss:0.7832843065261841, Valid_Loss:1.2485235929489136, Valid_ACC:0.600399911403656
Epoch 366, CIFAR-10 Batch 1:  Train_Loss:0.7670668959617615, Valid_Loss:1.2370946407318115, Valid_ACC:0.6043999195098877
Epoch 366, CIFAR-10 Batch 2:  Train_Loss:0.7804685235023499, Valid_Loss:1.2362436056137085, Valid_ACC:0.6067999005317688
Epoch 366, CIFAR-10 Batch 3:  Train_Loss:0.7504813075065613, Valid_Loss:1.2377662658691406, Valid_ACC:0.6049998998641968
Epoch 366, CIFAR-10 Batch 4:  Train_Loss:0.770915150642395, Valid_Loss:1.2249172925949097, Valid_ACC:0.6113999485969543
Epoch 366, CIFAR-10 Batch 5:  Train_Loss:0.7631527185440063, Valid_Loss:1.226548433303833, Valid_ACC:0.6117998957633972
Epoch 367, CIFAR-10 Batch 1:  Train_Loss:0.7751775979995728, Valid_Loss:1.235611081123352, Valid_ACC:0.6077998876571655
Epoch 367, CIFAR-10 Batch 2:  Train_Loss:0.7765623331069946, Valid_Loss:1.2282663583755493, Valid_ACC:0.6063998937606812
Epoch 367, CIFAR-10 Batch 3:  Train_Loss:0.7397103309631348, Valid_Loss:1.227637767791748, Valid_ACC:0.6083999276161194
Epoch 367, CIFAR-10 Batch 4:  Train_Loss:0.7507598400115967, Valid_Loss:1.2202794551849365, Valid_ACC:0.6113998889923096
Epoch 367, CIFAR-10 Batch 5:  Train_Loss:0.762830376625061, Valid_Loss:1.2380006313323975, Valid_ACC:0.6075999140739441
Epoch 368, CIFAR-10 Batch 1:  Train_Loss:0.7652836441993713, Valid_Loss:1.23526132106781, Valid_ACC:0.6063998937606812
Epoch 368, CIFAR-10 Batch 2:  Train_Loss:0.7640179395675659, Valid_Loss:1.2273355722427368, Valid_ACC:0.6075998544692993
Epoch 368, CIFAR-10 Batch 3:  Train_Loss:0.7445502877235413, Valid_Loss:1.23243248462677, Valid_ACC:0.6039999127388
Epoch 368, CIFAR-10 Batch 4:  Train_Loss:0.7561658620834351, Valid_Loss:1.230043649673462, Valid_ACC:0.6063998937606812
Epoch 368, CIFAR-10 Batch 5:  Train_Loss:0.775769829750061, Valid_Loss:1.2542508840560913, Valid_ACC:0.6001999378204346
Epoch 369, CIFAR-10 Batch 1:  Train_Loss:0.7986454963684082, Valid_Loss:1.272135615348816, Valid_ACC:0.590799868106842
Epoch 369, CIFAR-10 Batch 2:  Train_Loss:0.8044872283935547, Valid_Loss:1.2511876821517944, Valid_ACC:0.598599910736084
Epoch 369, CIFAR-10 Batch 3:  Train_Loss:0.7595164775848389, Valid_Loss:1.2387083768844604, Valid_ACC:0.6047999262809753
Epoch 369, CIFAR-10 Batch 4:  Train_Loss:0.7858395576477051, Valid_Loss:1.2519322633743286, Valid_ACC:0.5975999236106873
Epoch 369, CIFAR-10 Batch 5:  Train_Loss:0.7763785719871521, Valid_Loss:1.257588505744934, Valid_ACC:0.5963999032974243
Epoch 370, CIFAR-10 Batch 1:  Train_Loss:0.7825769782066345, Valid_Loss:1.230415940284729, Valid_ACC:0.6071999073028564
Epoch 370, CIFAR-10 Batch 2:  Train_Loss:0.7943742871284485, Valid_Loss:1.2405939102172852, Valid_ACC:0.6017999053001404
Epoch 370, CIFAR-10 Batch 3:  Train_Loss:0.7746335864067078, Valid_Loss:1.2525877952575684, Valid_ACC:0.5945999026298523
Epoch 370, CIFAR-10 Batch 4:  Train_Loss:0.7857614159584045, Valid_Loss:1.2640056610107422, Valid_ACC:0.5947998762130737
Epoch 370, CIFAR-10 Batch 5:  Train_Loss:0.8373976945877075, Valid_Loss:1.3100125789642334, Valid_ACC:0.5851999521255493
Epoch 371, CIFAR-10 Batch 1:  Train_Loss:0.7852382063865662, Valid_Loss:1.258863091468811, Valid_ACC:0.5939999222755432
Epoch 371, CIFAR-10 Batch 2:  Train_Loss:0.7857998609542847, Valid_Loss:1.2406806945800781, Valid_ACC:0.6001999378204346
Epoch 371, CIFAR-10 Batch 3:  Train_Loss:0.7637755274772644, Valid_Loss:1.2369122505187988, Valid_ACC:0.6033998727798462
Epoch 371, CIFAR-10 Batch 4:  Train_Loss:0.7660421133041382, Valid_Loss:1.2323039770126343, Valid_ACC:0.6033999919891357
Epoch 371, CIFAR-10 Batch 5:  Train_Loss:0.7638512849807739, Valid_Loss:1.2327970266342163, Valid_ACC:0.6079999208450317
Epoch 372, CIFAR-10 Batch 1:  Train_Loss:0.7657411694526672, Valid_Loss:1.2232897281646729, Valid_ACC:0.6105998754501343
Epoch 372, CIFAR-10 Batch 2:  Train_Loss:0.774820864200592, Valid_Loss:1.2385317087173462, Valid_ACC:0.6005998849868774
Epoch 372, CIFAR-10 Batch 3:  Train_Loss:0.7584233283996582, Valid_Loss:1.2298210859298706, Valid_ACC:0.603399932384491
Epoch 372, CIFAR-10 Batch 4:  Train_Loss:0.7503862977027893, Valid_Loss:1.2252944707870483, Valid_ACC:0.60999995470047
Epoch 372, CIFAR-10 Batch 5:  Train_Loss:0.7684059739112854, Valid_Loss:1.2391268014907837, Valid_ACC:0.6039999127388
Epoch 373, CIFAR-10 Batch 1:  Train_Loss:0.7606778144836426, Valid_Loss:1.241576075553894, Valid_ACC:0.6039998531341553
Epoch 373, CIFAR-10 Batch 2:  Train_Loss:0.7587224245071411, Valid_Loss:1.2265865802764893, Valid_ACC:0.6079999208450317
Epoch 373, CIFAR-10 Batch 3:  Train_Loss:0.748895525932312, Valid_Loss:1.2300363779067993, Valid_ACC:0.6029999256134033
Epoch 373, CIFAR-10 Batch 4:  Train_Loss:0.7647755146026611, Valid_Loss:1.2363851070404053, Valid_ACC:0.601599931716919
Epoch 373, CIFAR-10 Batch 5:  Train_Loss:0.7813690304756165, Valid_Loss:1.2439266443252563, Valid_ACC:0.6059998869895935
Epoch 374, CIFAR-10 Batch 1:  Train_Loss:0.7858098149299622, Valid_Loss:1.263999581336975, Valid_ACC:0.5935999155044556
Epoch 374, CIFAR-10 Batch 2:  Train_Loss:0.7819054126739502, Valid_Loss:1.2442902326583862, Valid_ACC:0.6013998985290527
Epoch 374, CIFAR-10 Batch 3:  Train_Loss:0.7426782250404358, Valid_Loss:1.2306263446807861, Valid_ACC:0.6035999059677124
Epoch 374, CIFAR-10 Batch 4:  Train_Loss:0.7567693591117859, Valid_Loss:1.2298675775527954, Valid_ACC:0.6079999208450317
Epoch 374, CIFAR-10 Batch 5:  Train_Loss:0.7748093008995056, Valid_Loss:1.2539054155349731, Valid_ACC:0.5953999161720276
Epoch 375, CIFAR-10 Batch 1:  Train_Loss:0.7607961893081665, Valid_Loss:1.2375471591949463, Valid_ACC:0.6065998673439026
Epoch 375, CIFAR-10 Batch 2:  Train_Loss:0.7773246169090271, Valid_Loss:1.2441692352294922, Valid_ACC:0.601599931716919
Epoch 375, CIFAR-10 Batch 3:  Train_Loss:0.7612974643707275, Valid_Loss:1.23859703540802, Valid_ACC:0.6029999256134033
Epoch 375, CIFAR-10 Batch 4:  Train_Loss:0.7728772759437561, Valid_Loss:1.2354868650436401, Valid_ACC:0.6041999459266663
Epoch 375, CIFAR-10 Batch 5:  Train_Loss:0.7746986150741577, Valid_Loss:1.2588204145431519, Valid_ACC:0.5975999236106873
Epoch 376, CIFAR-10 Batch 1:  Train_Loss:0.7685273289680481, Valid_Loss:1.2632191181182861, Valid_ACC:0.5927999019622803
Epoch 376, CIFAR-10 Batch 2:  Train_Loss:0.789117693901062, Valid_Loss:1.2561252117156982, Valid_ACC:0.5971999168395996
Epoch 376, CIFAR-10 Batch 3:  Train_Loss:0.744339108467102, Valid_Loss:1.2322251796722412, Valid_ACC:0.6069998741149902
Epoch 376, CIFAR-10 Batch 4:  Train_Loss:0.7603651881217957, Valid_Loss:1.2202582359313965, Valid_ACC:0.6111999154090881
Epoch 376, CIFAR-10 Batch 5:  Train_Loss:0.7666615843772888, Valid_Loss:1.2530624866485596, Valid_ACC:0.6001999378204346
Epoch 377, CIFAR-10 Batch 1:  Train_Loss:0.7541782259941101, Valid_Loss:1.2395908832550049, Valid_ACC:0.6025998592376709
Epoch 377, CIFAR-10 Batch 2:  Train_Loss:0.7896326184272766, Valid_Loss:1.2531402111053467, Valid_ACC:0.5991998910903931
Epoch 377, CIFAR-10 Batch 3:  Train_Loss:0.7548907995223999, Valid_Loss:1.2456318140029907, Valid_ACC:0.6005999445915222
Epoch 377, CIFAR-10 Batch 4:  Train_Loss:0.7837409973144531, Valid_Loss:1.247499942779541, Valid_ACC:0.5989998579025269
Epoch 377, CIFAR-10 Batch 5:  Train_Loss:0.761014997959137, Valid_Loss:1.2409324645996094, Valid_ACC:0.6081998944282532
Epoch 378, CIFAR-10 Batch 1:  Train_Loss:0.7579333186149597, Valid_Loss:1.2328966856002808, Valid_ACC:0.6083999276161194
Epoch 378, CIFAR-10 Batch 2:  Train_Loss:0.7716699242591858, Valid_Loss:1.2384660243988037, Valid_ACC:0.6069998741149902
Epoch 378, CIFAR-10 Batch 3:  Train_Loss:0.7616724967956543, Valid_Loss:1.2353520393371582, Valid_ACC:0.6069998741149902
Epoch 378, CIFAR-10 Batch 4:  Train_Loss:0.7527763247489929, Valid_Loss:1.225696325302124, Valid_ACC:0.6057999134063721
Epoch 378, CIFAR-10 Batch 5:  Train_Loss:0.7527084350585938, Valid_Loss:1.232235312461853, Valid_ACC:0.6089998483657837
Epoch 379, CIFAR-10 Batch 1:  Train_Loss:0.75776606798172, Valid_Loss:1.2354412078857422, Valid_ACC:0.606999933719635
Epoch 379, CIFAR-10 Batch 2:  Train_Loss:0.7793204188346863, Valid_Loss:1.2404727935791016, Valid_ACC:0.6047998666763306
Epoch 379, CIFAR-10 Batch 3:  Train_Loss:0.7355637550354004, Valid_Loss:1.2236162424087524, Valid_ACC:0.6099998950958252
Epoch 379, CIFAR-10 Batch 4:  Train_Loss:0.7662549614906311, Valid_Loss:1.2365442514419556, Valid_ACC:0.6069998741149902
Epoch 379, CIFAR-10 Batch 5:  Train_Loss:0.7669458389282227, Valid_Loss:1.250434160232544, Valid_ACC:0.6011999249458313
Epoch 380, CIFAR-10 Batch 1:  Train_Loss:0.7476937770843506, Valid_Loss:1.2333698272705078, Valid_ACC:0.6043999195098877
Epoch 380, CIFAR-10 Batch 2:  Train_Loss:0.7678962349891663, Valid_Loss:1.2431385517120361, Valid_ACC:0.602199912071228
Epoch 380, CIFAR-10 Batch 3:  Train_Loss:0.7404828071594238, Valid_Loss:1.218004584312439, Valid_ACC:0.6109999418258667
Epoch 380, CIFAR-10 Batch 4:  Train_Loss:0.7464200854301453, Valid_Loss:1.2255995273590088, Valid_ACC:0.6109998822212219
Epoch 380, CIFAR-10 Batch 5:  Train_Loss:0.762263298034668, Valid_Loss:1.2432671785354614, Valid_ACC:0.6023998856544495
Epoch 381, CIFAR-10 Batch 1:  Train_Loss:0.7433940768241882, Valid_Loss:1.2246625423431396, Valid_ACC:0.6093999147415161
Epoch 381, CIFAR-10 Batch 2:  Train_Loss:0.7733066082000732, Valid_Loss:1.2318533658981323, Valid_ACC:0.6067999005317688
Epoch 381, CIFAR-10 Batch 3:  Train_Loss:0.7346676588058472, Valid_Loss:1.2326165437698364, Valid_ACC:0.6055998802185059
Epoch 381, CIFAR-10 Batch 4:  Train_Loss:0.7455344200134277, Valid_Loss:1.2278661727905273, Valid_ACC:0.605199933052063
Epoch 381, CIFAR-10 Batch 5:  Train_Loss:0.7546846270561218, Valid_Loss:1.243561029434204, Valid_ACC:0.60319983959198
Epoch 382, CIFAR-10 Batch 1:  Train_Loss:0.7488899827003479, Valid_Loss:1.2321065664291382, Valid_ACC:0.6075999140739441
Epoch 382, CIFAR-10 Batch 2:  Train_Loss:0.7619938254356384, Valid_Loss:1.2296370267868042, Valid_ACC:0.6055998802185059
Epoch 382, CIFAR-10 Batch 3:  Train_Loss:0.730470597743988, Valid_Loss:1.223583459854126, Valid_ACC:0.6093999147415161
Epoch 382, CIFAR-10 Batch 4:  Train_Loss:0.7549653053283691, Valid_Loss:1.2236428260803223, Valid_ACC:0.6065999269485474
Epoch 382, CIFAR-10 Batch 5:  Train_Loss:0.7473645210266113, Valid_Loss:1.2403979301452637, Valid_ACC:0.6011998653411865
Epoch 383, CIFAR-10 Batch 1:  Train_Loss:0.7534807324409485, Valid_Loss:1.2383403778076172, Valid_ACC:0.6019999384880066
Epoch 383, CIFAR-10 Batch 2:  Train_Loss:0.7554331421852112, Valid_Loss:1.2286922931671143, Valid_ACC:0.6089999079704285
Epoch 383, CIFAR-10 Batch 3:  Train_Loss:0.7362101674079895, Valid_Loss:1.235335350036621, Valid_ACC:0.6055999398231506
Epoch 383, CIFAR-10 Batch 4:  Train_Loss:0.7553653120994568, Valid_Loss:1.231058955192566, Valid_ACC:0.6067999601364136
Epoch 383, CIFAR-10 Batch 5:  Train_Loss:0.7319854497909546, Valid_Loss:1.222064733505249, Valid_ACC:0.6107999086380005
Epoch 384, CIFAR-10 Batch 1:  Train_Loss:0.7410691380500793, Valid_Loss:1.2234015464782715, Valid_ACC:0.6087998747825623
Epoch 384, CIFAR-10 Batch 2:  Train_Loss:0.7565284967422485, Valid_Loss:1.2308207750320435, Valid_ACC:0.602199912071228
Epoch 384, CIFAR-10 Batch 3:  Train_Loss:0.7461227774620056, Valid_Loss:1.225140929222107, Valid_ACC:0.606999933719635
Epoch 384, CIFAR-10 Batch 4:  Train_Loss:0.7495090961456299, Valid_Loss:1.2243387699127197, Valid_ACC:0.6097999215126038
Epoch 384, CIFAR-10 Batch 5:  Train_Loss:0.7365593314170837, Valid_Loss:1.2349915504455566, Valid_ACC:0.6097999215126038
Epoch 385, CIFAR-10 Batch 1:  Train_Loss:0.7379904985427856, Valid_Loss:1.2298109531402588, Valid_ACC:0.6075999140739441
Epoch 385, CIFAR-10 Batch 2:  Train_Loss:0.7537676095962524, Valid_Loss:1.2235567569732666, Valid_ACC:0.6103999614715576
Epoch 385, CIFAR-10 Batch 3:  Train_Loss:0.7249796986579895, Valid_Loss:1.2208629846572876, Valid_ACC:0.6121999621391296
Epoch 385, CIFAR-10 Batch 4:  Train_Loss:0.7623315453529358, Valid_Loss:1.2305299043655396, Valid_ACC:0.6103999614715576
Epoch 385, CIFAR-10 Batch 5:  Train_Loss:0.7605302929878235, Valid_Loss:1.2677069902420044, Valid_ACC:0.5941998958587646
Epoch 386, CIFAR-10 Batch 1:  Train_Loss:0.7592384815216064, Valid_Loss:1.2230782508850098, Valid_ACC:0.614799976348877
Epoch 386, CIFAR-10 Batch 2:  Train_Loss:0.7665022611618042, Valid_Loss:1.242213487625122, Valid_ACC:0.6041999459266663
Epoch 386, CIFAR-10 Batch 3:  Train_Loss:0.7330312728881836, Valid_Loss:1.2216975688934326, Valid_ACC:0.6089999675750732
Epoch 386, CIFAR-10 Batch 4:  Train_Loss:0.7597182989120483, Valid_Loss:1.230721354484558, Valid_ACC:0.6059999465942383
Epoch 386, CIFAR-10 Batch 5:  Train_Loss:0.7297855019569397, Valid_Loss:1.2450023889541626, Valid_ACC:0.6039999723434448
Epoch 387, CIFAR-10 Batch 1:  Train_Loss:0.7373758554458618, Valid_Loss:1.2271920442581177, Valid_ACC:0.6091998815536499
Epoch 387, CIFAR-10 Batch 2:  Train_Loss:0.751933753490448, Valid_Loss:1.2261402606964111, Valid_ACC:0.6089999675750732
Epoch 387, CIFAR-10 Batch 3:  Train_Loss:0.7275176644325256, Valid_Loss:1.2251899242401123, Valid_ACC:0.6109998822212219
Epoch 387, CIFAR-10 Batch 4:  Train_Loss:0.7501338720321655, Valid_Loss:1.2326576709747314, Valid_ACC:0.6059999465942383
Epoch 387, CIFAR-10 Batch 5:  Train_Loss:0.7451266050338745, Valid_Loss:1.2437260150909424, Valid_ACC:0.6001999378204346
Epoch 388, CIFAR-10 Batch 1:  Train_Loss:0.7482682466506958, Valid_Loss:1.2250219583511353, Valid_ACC:0.6111998558044434
Epoch 388, CIFAR-10 Batch 2:  Train_Loss:0.7577178478240967, Valid_Loss:1.2283694744110107, Valid_ACC:0.60999995470047
Epoch 388, CIFAR-10 Batch 3:  Train_Loss:0.7242919206619263, Valid_Loss:1.231191873550415, Valid_ACC:0.6097999215126038
Epoch 388, CIFAR-10 Batch 4:  Train_Loss:0.7539998292922974, Valid_Loss:1.2291793823242188, Valid_ACC:0.6049998998641968
Epoch 388, CIFAR-10 Batch 5:  Train_Loss:0.7418525218963623, Valid_Loss:1.2313098907470703, Valid_ACC:0.6065999269485474
Epoch 389, CIFAR-10 Batch 1:  Train_Loss:0.7358843684196472, Valid_Loss:1.2274184226989746, Valid_ACC:0.6077998876571655
Epoch 389, CIFAR-10 Batch 2:  Train_Loss:0.759315550327301, Valid_Loss:1.2299765348434448, Valid_ACC:0.6065998673439026
Epoch 389, CIFAR-10 Batch 3:  Train_Loss:0.7301763296127319, Valid_Loss:1.2204076051712036, Valid_ACC:0.6071999073028564
Epoch 389, CIFAR-10 Batch 4:  Train_Loss:0.7579854726791382, Valid_Loss:1.2347846031188965, Valid_ACC:0.6067999601364136
Epoch 389, CIFAR-10 Batch 5:  Train_Loss:0.7386147379875183, Valid_Loss:1.228058099746704, Valid_ACC:0.6141998767852783
Epoch 390, CIFAR-10 Batch 1:  Train_Loss:0.7333726286888123, Valid_Loss:1.2206025123596191, Valid_ACC:0.6117998957633972
Epoch 390, CIFAR-10 Batch 2:  Train_Loss:0.7441632747650146, Valid_Loss:1.2233691215515137, Valid_ACC:0.6077999472618103
Epoch 390, CIFAR-10 Batch 3:  Train_Loss:0.7383078932762146, Valid_Loss:1.22991943359375, Valid_ACC:0.6101998686790466
Epoch 390, CIFAR-10 Batch 4:  Train_Loss:0.7493802309036255, Valid_Loss:1.2317800521850586, Valid_ACC:0.6071999073028564
Epoch 390, CIFAR-10 Batch 5:  Train_Loss:0.7390683889389038, Valid_Loss:1.2478442192077637, Valid_ACC:0.5989998579025269
Epoch 391, CIFAR-10 Batch 1:  Train_Loss:0.7351155281066895, Valid_Loss:1.2203103303909302, Valid_ACC:0.6147998571395874
Epoch 391, CIFAR-10 Batch 2:  Train_Loss:0.7586591839790344, Valid_Loss:1.2316770553588867, Valid_ACC:0.6091998815536499
Epoch 391, CIFAR-10 Batch 3:  Train_Loss:0.7274684906005859, Valid_Loss:1.227719783782959, Valid_ACC:0.6091998815536499
Epoch 391, CIFAR-10 Batch 4:  Train_Loss:0.7359468340873718, Valid_Loss:1.221251130104065, Valid_ACC:0.608199954032898
Epoch 391, CIFAR-10 Batch 5:  Train_Loss:0.7465219497680664, Valid_Loss:1.2296255826950073, Valid_ACC:0.6065999269485474
Epoch 392, CIFAR-10 Batch 1:  Train_Loss:0.7327309250831604, Valid_Loss:1.2246395349502563, Valid_ACC:0.6099998950958252
Epoch 392, CIFAR-10 Batch 2:  Train_Loss:0.7485483288764954, Valid_Loss:1.2319921255111694, Valid_ACC:0.6091998815536499
Epoch 392, CIFAR-10 Batch 3:  Train_Loss:0.7520065903663635, Valid_Loss:1.2413963079452515, Valid_ACC:0.6009998917579651
Epoch 392, CIFAR-10 Batch 4:  Train_Loss:0.7507854700088501, Valid_Loss:1.2294293642044067, Valid_ACC:0.608799934387207
Epoch 392, CIFAR-10 Batch 5:  Train_Loss:0.7530661821365356, Valid_Loss:1.244255542755127, Valid_ACC:0.6059999465942383
Epoch 393, CIFAR-10 Batch 1:  Train_Loss:0.7217544317245483, Valid_Loss:1.221090316772461, Valid_ACC:0.6107999086380005
Epoch 393, CIFAR-10 Batch 2:  Train_Loss:0.7558037638664246, Valid_Loss:1.2315528392791748, Valid_ACC:0.6069998741149902
Epoch 393, CIFAR-10 Batch 3:  Train_Loss:0.7242563366889954, Valid_Loss:1.2286646366119385, Valid_ACC:0.6049998998641968
Epoch 393, CIFAR-10 Batch 4:  Train_Loss:0.7368537783622742, Valid_Loss:1.2238950729370117, Valid_ACC:0.6107999086380005
Epoch 393, CIFAR-10 Batch 5:  Train_Loss:0.7328425645828247, Valid_Loss:1.2275092601776123, Valid_ACC:0.6111999154090881
Epoch 394, CIFAR-10 Batch 1:  Train_Loss:0.7353706359863281, Valid_Loss:1.2256261110305786, Valid_ACC:0.606999933719635
Epoch 394, CIFAR-10 Batch 2:  Train_Loss:0.7578184008598328, Valid_Loss:1.2281384468078613, Valid_ACC:0.6095999479293823
Epoch 394, CIFAR-10 Batch 3:  Train_Loss:0.7318851351737976, Valid_Loss:1.2450758218765259, Valid_ACC:0.5993999242782593
Epoch 394, CIFAR-10 Batch 4:  Train_Loss:0.7509778738021851, Valid_Loss:1.2440704107284546, Valid_ACC:0.6035999059677124
Epoch 394, CIFAR-10 Batch 5:  Train_Loss:0.7533566355705261, Valid_Loss:1.246092677116394, Valid_ACC:0.6029999256134033
Epoch 395, CIFAR-10 Batch 1:  Train_Loss:0.740768551826477, Valid_Loss:1.2416703701019287, Valid_ACC:0.6025999784469604
Epoch 395, CIFAR-10 Batch 2:  Train_Loss:0.7644782662391663, Valid_Loss:1.2446507215499878, Valid_ACC:0.6003999710083008
Epoch 395, CIFAR-10 Batch 3:  Train_Loss:0.7317849397659302, Valid_Loss:1.2230618000030518, Valid_ACC:0.6089999079704285
Epoch 395, CIFAR-10 Batch 4:  Train_Loss:0.7350981831550598, Valid_Loss:1.226787805557251, Valid_ACC:0.60999995470047
Epoch 395, CIFAR-10 Batch 5:  Train_Loss:0.7435055375099182, Valid_Loss:1.2465953826904297, Valid_ACC:0.604999840259552
Epoch 396, CIFAR-10 Batch 1:  Train_Loss:0.7425042390823364, Valid_Loss:1.2440329790115356, Valid_ACC:0.6029999256134033
Epoch 396, CIFAR-10 Batch 2:  Train_Loss:0.762107253074646, Valid_Loss:1.2336843013763428, Valid_ACC:0.6083998680114746
Epoch 396, CIFAR-10 Batch 3:  Train_Loss:0.7342974543571472, Valid_Loss:1.2352232933044434, Valid_ACC:0.6049998998641968
Epoch 396, CIFAR-10 Batch 4:  Train_Loss:0.7533165216445923, Valid_Loss:1.2388280630111694, Valid_ACC:0.6023998856544495
Epoch 396, CIFAR-10 Batch 5:  Train_Loss:0.740639328956604, Valid_Loss:1.2460455894470215, Valid_ACC:0.6045999526977539
Epoch 397, CIFAR-10 Batch 1:  Train_Loss:0.7334945797920227, Valid_Loss:1.2412426471710205, Valid_ACC:0.6029999256134033
Epoch 397, CIFAR-10 Batch 2:  Train_Loss:0.7560261487960815, Valid_Loss:1.2240400314331055, Valid_ACC:0.6063998937606812
Epoch 397, CIFAR-10 Batch 3:  Train_Loss:0.7385722398757935, Valid_Loss:1.2446815967559814, Valid_ACC:0.6003998517990112
Epoch 397, CIFAR-10 Batch 4:  Train_Loss:0.757552444934845, Valid_Loss:1.2413573265075684, Valid_ACC:0.6035999059677124
Epoch 397, CIFAR-10 Batch 5:  Train_Loss:0.7467004060745239, Valid_Loss:1.2350144386291504, Valid_ACC:0.6067999005317688
Epoch 398, CIFAR-10 Batch 1:  Train_Loss:0.7451812624931335, Valid_Loss:1.2503483295440674, Valid_ACC:0.5997999310493469
Epoch 398, CIFAR-10 Batch 2:  Train_Loss:0.7906545400619507, Valid_Loss:1.2573649883270264, Valid_ACC:0.5989998579025269
Epoch 398, CIFAR-10 Batch 3:  Train_Loss:0.7327874898910522, Valid_Loss:1.2410032749176025, Valid_ACC:0.6101999282836914
Epoch 398, CIFAR-10 Batch 4:  Train_Loss:0.7838248014450073, Valid_Loss:1.244657039642334, Valid_ACC:0.6039998531341553
Epoch 398, CIFAR-10 Batch 5:  Train_Loss:0.730383038520813, Valid_Loss:1.2344151735305786, Valid_ACC:0.6085999011993408
Epoch 399, CIFAR-10 Batch 1:  Train_Loss:0.7295351624488831, Valid_Loss:1.228440284729004, Valid_ACC:0.6059998869895935
Epoch 399, CIFAR-10 Batch 2:  Train_Loss:0.7595294117927551, Valid_Loss:1.2477322816848755, Valid_ACC:0.6047998666763306
Epoch 399, CIFAR-10 Batch 3:  Train_Loss:0.7154297828674316, Valid_Loss:1.2238523960113525, Valid_ACC:0.6087998747825623
Epoch 399, CIFAR-10 Batch 4:  Train_Loss:0.7348794937133789, Valid_Loss:1.2246830463409424, Valid_ACC:0.6085999011993408
Epoch 399, CIFAR-10 Batch 5:  Train_Loss:0.7360661625862122, Valid_Loss:1.2394949197769165, Valid_ACC:0.6013998985290527
Epoch 400, CIFAR-10 Batch 1:  Train_Loss:0.7281026244163513, Valid_Loss:1.2259953022003174, Valid_ACC:0.6077998876571655
Epoch 400, CIFAR-10 Batch 2:  Train_Loss:0.7611165046691895, Valid_Loss:1.2348614931106567, Valid_ACC:0.6049998998641968
Epoch 400, CIFAR-10 Batch 3:  Train_Loss:0.7270622253417969, Valid_Loss:1.2313777208328247, Valid_ACC:0.6043999195098877
Epoch 400, CIFAR-10 Batch 4:  Train_Loss:0.7388832569122314, Valid_Loss:1.231566309928894, Valid_ACC:0.6087999939918518
Epoch 400, CIFAR-10 Batch 5:  Train_Loss:0.7450934648513794, Valid_Loss:1.2519679069519043, Valid_ACC:0.6011999249458313
Epoch 401, CIFAR-10 Batch 1:  Train_Loss:0.727409839630127, Valid_Loss:1.2203618288040161, Valid_ACC:0.6101999282836914
Epoch 401, CIFAR-10 Batch 2:  Train_Loss:0.7418172955513, Valid_Loss:1.2180743217468262, Valid_ACC:0.6139999032020569
Epoch 401, CIFAR-10 Batch 3:  Train_Loss:0.7161677479743958, Valid_Loss:1.2362735271453857, Valid_ACC:0.6073999404907227
Epoch 401, CIFAR-10 Batch 4:  Train_Loss:0.7405619621276855, Valid_Loss:1.2389166355133057, Valid_ACC:0.6059999465942383
Epoch 401, CIFAR-10 Batch 5:  Train_Loss:0.7939170002937317, Valid_Loss:1.285906195640564, Valid_ACC:0.5895998477935791
Epoch 402, CIFAR-10 Batch 1:  Train_Loss:0.7736544013023376, Valid_Loss:1.2815697193145752, Valid_ACC:0.5857998728752136
Epoch 402, CIFAR-10 Batch 2:  Train_Loss:0.7684792876243591, Valid_Loss:1.2384212017059326, Valid_ACC:0.6031999588012695
Epoch 402, CIFAR-10 Batch 3:  Train_Loss:0.7436604499816895, Valid_Loss:1.2492103576660156, Valid_ACC:0.5987999439239502
Epoch 402, CIFAR-10 Batch 4:  Train_Loss:0.7993654012680054, Valid_Loss:1.2838839292526245, Valid_ACC:0.5887999534606934
Epoch 402, CIFAR-10 Batch 5:  Train_Loss:0.81305330991745, Valid_Loss:1.2942683696746826, Valid_ACC:0.5891999006271362
Epoch 403, CIFAR-10 Batch 1:  Train_Loss:0.7524952292442322, Valid_Loss:1.2431347370147705, Valid_ACC:0.6041999459266663
Epoch 403, CIFAR-10 Batch 2:  Train_Loss:0.7786136865615845, Valid_Loss:1.2430304288864136, Valid_ACC:0.6031998991966248
Epoch 403, CIFAR-10 Batch 3:  Train_Loss:0.761696457862854, Valid_Loss:1.2624882459640503, Valid_ACC:0.5981999635696411
Epoch 403, CIFAR-10 Batch 4:  Train_Loss:0.746587336063385, Valid_Loss:1.2268421649932861, Valid_ACC:0.6039999127388
Epoch 403, CIFAR-10 Batch 5:  Train_Loss:0.7578824758529663, Valid_Loss:1.2573373317718506, Valid_ACC:0.600399911403656
Epoch 404, CIFAR-10 Batch 1:  Train_Loss:0.7432609796524048, Valid_Loss:1.2388582229614258, Valid_ACC:0.6039999127388
Epoch 404, CIFAR-10 Batch 2:  Train_Loss:0.7828661203384399, Valid_Loss:1.2455006837844849, Valid_ACC:0.598599910736084
Epoch 404, CIFAR-10 Batch 3:  Train_Loss:0.7482154965400696, Valid_Loss:1.2510987520217896, Valid_ACC:0.6035999655723572
Epoch 404, CIFAR-10 Batch 4:  Train_Loss:0.7356179356575012, Valid_Loss:1.2353019714355469, Valid_ACC:0.602199912071228
Epoch 404, CIFAR-10 Batch 5:  Train_Loss:0.7646737098693848, Valid_Loss:1.2740548849105835, Valid_ACC:0.6005998849868774
Epoch 405, CIFAR-10 Batch 1:  Train_Loss:0.7498473525047302, Valid_Loss:1.2565395832061768, Valid_ACC:0.5947999358177185
Epoch 405, CIFAR-10 Batch 2:  Train_Loss:0.7566190361976624, Valid_Loss:1.2351000308990479, Valid_ACC:0.6059998869895935
Epoch 405, CIFAR-10 Batch 3:  Train_Loss:0.7357697486877441, Valid_Loss:1.2328871488571167, Valid_ACC:0.6039999127388
Epoch 405, CIFAR-10 Batch 4:  Train_Loss:0.726516604423523, Valid_Loss:1.228729009628296, Valid_ACC:0.6045998930931091
Epoch 405, CIFAR-10 Batch 5:  Train_Loss:0.7489628791809082, Valid_Loss:1.260947823524475, Valid_ACC:0.599399983882904
Epoch 406, CIFAR-10 Batch 1:  Train_Loss:0.7585805654525757, Valid_Loss:1.266921877861023, Valid_ACC:0.5935999155044556
Epoch 406, CIFAR-10 Batch 2:  Train_Loss:0.7436679601669312, Valid_Loss:1.2266004085540771, Valid_ACC:0.6101999282836914
Epoch 406, CIFAR-10 Batch 3:  Train_Loss:0.7550325393676758, Valid_Loss:1.2601583003997803, Valid_ACC:0.5961999297142029
Epoch 406, CIFAR-10 Batch 4:  Train_Loss:0.7547968626022339, Valid_Loss:1.2620534896850586, Valid_ACC:0.5931999087333679
Epoch 406, CIFAR-10 Batch 5:  Train_Loss:0.7584733366966248, Valid_Loss:1.2628533840179443, Valid_ACC:0.6005999445915222
Epoch 407, CIFAR-10 Batch 1:  Train_Loss:0.7555078268051147, Valid_Loss:1.2365586757659912, Valid_ACC:0.6043999195098877
Epoch 407, CIFAR-10 Batch 2:  Train_Loss:0.8031489849090576, Valid_Loss:1.2622215747833252, Valid_ACC:0.5935999155044556
Epoch 407, CIFAR-10 Batch 3:  Train_Loss:0.7540209889411926, Valid_Loss:1.2471215724945068, Valid_ACC:0.5963999032974243
Epoch 407, CIFAR-10 Batch 4:  Train_Loss:0.7687683701515198, Valid_Loss:1.2557024955749512, Valid_ACC:0.5927999019622803
Epoch 407, CIFAR-10 Batch 5:  Train_Loss:0.7726049423217773, Valid_Loss:1.270747184753418, Valid_ACC:0.5949999094009399
Epoch 408, CIFAR-10 Batch 1:  Train_Loss:0.7891700267791748, Valid_Loss:1.2770795822143555, Valid_ACC:0.5901999473571777
Epoch 408, CIFAR-10 Batch 2:  Train_Loss:0.7628129124641418, Valid_Loss:1.2358219623565674, Valid_ACC:0.6059998869895935
Epoch 408, CIFAR-10 Batch 3:  Train_Loss:0.7680344581604004, Valid_Loss:1.2562310695648193, Valid_ACC:0.5993999242782593
Epoch 408, CIFAR-10 Batch 4:  Train_Loss:0.742357075214386, Valid_Loss:1.2428981065750122, Valid_ACC:0.6007999181747437
Epoch 408, CIFAR-10 Batch 5:  Train_Loss:0.7612255811691284, Valid_Loss:1.2611894607543945, Valid_ACC:0.5969998836517334
Epoch 409, CIFAR-10 Batch 1:  Train_Loss:0.7687546014785767, Valid_Loss:1.2586299180984497, Valid_ACC:0.5955999493598938
Epoch 409, CIFAR-10 Batch 2:  Train_Loss:0.792301595211029, Valid_Loss:1.2433502674102783, Valid_ACC:0.6023998856544495
Epoch 409, CIFAR-10 Batch 3:  Train_Loss:0.7383543252944946, Valid_Loss:1.2343064546585083, Valid_ACC:0.6035999059677124
Epoch 409, CIFAR-10 Batch 4:  Train_Loss:0.727344274520874, Valid_Loss:1.2257391214370728, Valid_ACC:0.6067999601364136
Epoch 409, CIFAR-10 Batch 5:  Train_Loss:0.7331349849700928, Valid_Loss:1.2393635511398315, Valid_ACC:0.6067999601364136
Epoch 410, CIFAR-10 Batch 1:  Train_Loss:0.756973385810852, Valid_Loss:1.26423180103302, Valid_ACC:0.5953999161720276
Epoch 410, CIFAR-10 Batch 2:  Train_Loss:0.7731298804283142, Valid_Loss:1.2416388988494873, Valid_ACC:0.6065999269485474
Epoch 410, CIFAR-10 Batch 3:  Train_Loss:0.7489789128303528, Valid_Loss:1.2564386129379272, Valid_ACC:0.5989999175071716
Epoch 410, CIFAR-10 Batch 4:  Train_Loss:0.7427811026573181, Valid_Loss:1.2429516315460205, Valid_ACC:0.6031998991966248
Epoch 410, CIFAR-10 Batch 5:  Train_Loss:0.7908318638801575, Valid_Loss:1.290080189704895, Valid_ACC:0.5901999473571777
Epoch 411, CIFAR-10 Batch 1:  Train_Loss:0.7622021436691284, Valid_Loss:1.2667571306228638, Valid_ACC:0.5937999486923218
Epoch 411, CIFAR-10 Batch 2:  Train_Loss:0.7672959566116333, Valid_Loss:1.2413405179977417, Valid_ACC:0.6019998788833618
Epoch 411, CIFAR-10 Batch 3:  Train_Loss:0.7532294988632202, Valid_Loss:1.256495475769043, Valid_ACC:0.597399890422821
Epoch 411, CIFAR-10 Batch 4:  Train_Loss:0.7424821257591248, Valid_Loss:1.238041639328003, Valid_ACC:0.6027999520301819
Epoch 411, CIFAR-10 Batch 5:  Train_Loss:0.7519247531890869, Valid_Loss:1.2606174945831299, Valid_ACC:0.5957999229431152
Epoch 412, CIFAR-10 Batch 1:  Train_Loss:0.7559955716133118, Valid_Loss:1.262954592704773, Valid_ACC:0.5933998823165894
Epoch 412, CIFAR-10 Batch 2:  Train_Loss:0.751960813999176, Valid_Loss:1.2346751689910889, Valid_ACC:0.6033998727798462
Epoch 412, CIFAR-10 Batch 3:  Train_Loss:0.7185124754905701, Valid_Loss:1.2348392009735107, Valid_ACC:0.6025999188423157
Epoch 412, CIFAR-10 Batch 4:  Train_Loss:0.7476917505264282, Valid_Loss:1.2513984441757202, Valid_ACC:0.5995998978614807
Epoch 412, CIFAR-10 Batch 5:  Train_Loss:0.7606896758079529, Valid_Loss:1.27447509765625, Valid_ACC:0.5911999344825745
Epoch 413, CIFAR-10 Batch 1:  Train_Loss:0.7475418448448181, Valid_Loss:1.255537986755371, Valid_ACC:0.5957998633384705
Epoch 413, CIFAR-10 Batch 2:  Train_Loss:0.7472397089004517, Valid_Loss:1.2257331609725952, Valid_ACC:0.6093999147415161
Epoch 413, CIFAR-10 Batch 3:  Train_Loss:0.7638868093490601, Valid_Loss:1.2599843740463257, Valid_ACC:0.5987999439239502
Epoch 413, CIFAR-10 Batch 4:  Train_Loss:0.7288140654563904, Valid_Loss:1.2349936962127686, Valid_ACC:0.605199933052063
Epoch 413, CIFAR-10 Batch 5:  Train_Loss:0.7379331588745117, Valid_Loss:1.2548630237579346, Valid_ACC:0.6025998592376709
Epoch 414, CIFAR-10 Batch 1:  Train_Loss:0.7641664743423462, Valid_Loss:1.2568082809448242, Valid_ACC:0.5929999351501465
Epoch 414, CIFAR-10 Batch 2:  Train_Loss:0.7511597871780396, Valid_Loss:1.228649616241455, Valid_ACC:0.6073999404907227
Epoch 414, CIFAR-10 Batch 3:  Train_Loss:0.742906928062439, Valid_Loss:1.2443974018096924, Valid_ACC:0.5979999303817749
Epoch 414, CIFAR-10 Batch 4:  Train_Loss:0.7429194450378418, Valid_Loss:1.254169225692749, Valid_ACC:0.6009998917579651
Epoch 414, CIFAR-10 Batch 5:  Train_Loss:0.7722412347793579, Valid_Loss:1.2734004259109497, Valid_ACC:0.5923999547958374
Epoch 415, CIFAR-10 Batch 1:  Train_Loss:0.7404070496559143, Valid_Loss:1.2390233278274536, Valid_ACC:0.6073998808860779
Epoch 415, CIFAR-10 Batch 2:  Train_Loss:0.74537193775177, Valid_Loss:1.2313494682312012, Valid_ACC:0.6095998287200928
Epoch 415, CIFAR-10 Batch 3:  Train_Loss:0.7241239547729492, Valid_Loss:1.2367637157440186, Valid_ACC:0.6039999723434448
Epoch 415, CIFAR-10 Batch 4:  Train_Loss:0.7505673766136169, Valid_Loss:1.2628964185714722, Valid_ACC:0.5949999094009399
Epoch 415, CIFAR-10 Batch 5:  Train_Loss:0.773784339427948, Valid_Loss:1.2788439989089966, Valid_ACC:0.5899998545646667
Epoch 416, CIFAR-10 Batch 1:  Train_Loss:0.7787654399871826, Valid_Loss:1.257590889930725, Valid_ACC:0.601599931716919
Epoch 416, CIFAR-10 Batch 2:  Train_Loss:0.7520366907119751, Valid_Loss:1.2466717958450317, Valid_ACC:0.597399890422821
Epoch 416, CIFAR-10 Batch 3:  Train_Loss:0.7658677101135254, Valid_Loss:1.2717504501342773, Valid_ACC:0.5937998294830322
Epoch 416, CIFAR-10 Batch 4:  Train_Loss:0.7416245341300964, Valid_Loss:1.246453046798706, Valid_ACC:0.5951998829841614
Epoch 416, CIFAR-10 Batch 5:  Train_Loss:0.7744235396385193, Valid_Loss:1.2775267362594604, Valid_ACC:0.5929999351501465
Epoch 417, CIFAR-10 Batch 1:  Train_Loss:0.7751900553703308, Valid_Loss:1.2503993511199951, Valid_ACC:0.5999999046325684
Epoch 417, CIFAR-10 Batch 2:  Train_Loss:0.7787498831748962, Valid_Loss:1.268420696258545, Valid_ACC:0.5915999412536621
Epoch 417, CIFAR-10 Batch 3:  Train_Loss:0.7630203366279602, Valid_Loss:1.273000717163086, Valid_ACC:0.591999888420105
Epoch 417, CIFAR-10 Batch 4:  Train_Loss:0.7228755354881287, Valid_Loss:1.2325938940048218, Valid_ACC:0.6047999262809753
Epoch 417, CIFAR-10 Batch 5:  Train_Loss:0.7568084001541138, Valid_Loss:1.2650179862976074, Valid_ACC:0.5931999087333679
Epoch 418, CIFAR-10 Batch 1:  Train_Loss:0.7680273652076721, Valid_Loss:1.2449902296066284, Valid_ACC:0.6023999452590942
Epoch 418, CIFAR-10 Batch 2:  Train_Loss:0.7694582939147949, Valid_Loss:1.2491061687469482, Valid_ACC:0.6043999195098877
Epoch 418, CIFAR-10 Batch 3:  Train_Loss:0.7584628462791443, Valid_Loss:1.2688140869140625, Valid_ACC:0.5903999209403992
Epoch 418, CIFAR-10 Batch 4:  Train_Loss:0.7512553930282593, Valid_Loss:1.2469333410263062, Valid_ACC:0.5981999039649963
Epoch 418, CIFAR-10 Batch 5:  Train_Loss:0.7706049680709839, Valid_Loss:1.2598727941513062, Valid_ACC:0.600399911403656
Epoch 419, CIFAR-10 Batch 1:  Train_Loss:0.7904159426689148, Valid_Loss:1.247704267501831, Valid_ACC:0.6009999513626099
Epoch 419, CIFAR-10 Batch 2:  Train_Loss:0.7549213171005249, Valid_Loss:1.2329031229019165, Valid_ACC:0.6031998991966248
Epoch 419, CIFAR-10 Batch 3:  Train_Loss:0.7149325013160706, Valid_Loss:1.224765658378601, Valid_ACC:0.6055998802185059
Epoch 419, CIFAR-10 Batch 4:  Train_Loss:0.7278029918670654, Valid_Loss:1.2236080169677734, Valid_ACC:0.6085999011993408
Epoch 419, CIFAR-10 Batch 5:  Train_Loss:0.7378900647163391, Valid_Loss:1.2492897510528564, Valid_ACC:0.6027998924255371
Epoch 420, CIFAR-10 Batch 1:  Train_Loss:0.7655526399612427, Valid_Loss:1.2462676763534546, Valid_ACC:0.6051998734474182
Epoch 420, CIFAR-10 Batch 2:  Train_Loss:0.7519571185112, Valid_Loss:1.2294334173202515, Valid_ACC:0.6071999073028564
Epoch 420, CIFAR-10 Batch 3:  Train_Loss:0.7240920662879944, Valid_Loss:1.2402540445327759, Valid_ACC:0.6039998531341553
Epoch 420, CIFAR-10 Batch 4:  Train_Loss:0.7479711174964905, Valid_Loss:1.2420152425765991, Valid_ACC:0.6025999188423157
Epoch 420, CIFAR-10 Batch 5:  Train_Loss:0.755524218082428, Valid_Loss:1.2611178159713745, Valid_ACC:0.5977998971939087
Epoch 421, CIFAR-10 Batch 1:  Train_Loss:0.765514612197876, Valid_Loss:1.2503957748413086, Valid_ACC:0.6007999181747437
Epoch 421, CIFAR-10 Batch 2:  Train_Loss:0.7681788206100464, Valid_Loss:1.2451566457748413, Valid_ACC:0.5963999032974243
Epoch 421, CIFAR-10 Batch 3:  Train_Loss:0.7587242126464844, Valid_Loss:1.2669661045074463, Valid_ACC:0.5931999087333679
Epoch 421, CIFAR-10 Batch 4:  Train_Loss:0.7336363792419434, Valid_Loss:1.2337247133255005, Valid_ACC:0.6065999269485474
Epoch 421, CIFAR-10 Batch 5:  Train_Loss:0.7596156597137451, Valid_Loss:1.2545660734176636, Valid_ACC:0.601599931716919
Epoch 422, CIFAR-10 Batch 1:  Train_Loss:0.757687509059906, Valid_Loss:1.237971544265747, Valid_ACC:0.6037999391555786
Epoch 422, CIFAR-10 Batch 2:  Train_Loss:0.7932860255241394, Valid_Loss:1.2744299173355103, Valid_ACC:0.5927999019622803
Epoch 422, CIFAR-10 Batch 3:  Train_Loss:0.7681350708007812, Valid_Loss:1.2546926736831665, Valid_ACC:0.5939999222755432
Epoch 422, CIFAR-10 Batch 4:  Train_Loss:0.7379106879234314, Valid_Loss:1.2268892526626587, Valid_ACC:0.6077998876571655
Epoch 422, CIFAR-10 Batch 5:  Train_Loss:0.7464846968650818, Valid_Loss:1.2433723211288452, Valid_ACC:0.6035999059677124
Epoch 423, CIFAR-10 Batch 1:  Train_Loss:0.7964500784873962, Valid_Loss:1.2659074068069458, Valid_ACC:0.5961999297142029
Epoch 423, CIFAR-10 Batch 2:  Train_Loss:0.7532837986946106, Valid_Loss:1.2399704456329346, Valid_ACC:0.6065999269485474
Epoch 423, CIFAR-10 Batch 3:  Train_Loss:0.745947003364563, Valid_Loss:1.2646725177764893, Valid_ACC:0.5941998958587646
Epoch 423, CIFAR-10 Batch 4:  Train_Loss:0.7622752785682678, Valid_Loss:1.2483153343200684, Valid_ACC:0.6005998849868774
Epoch 423, CIFAR-10 Batch 5:  Train_Loss:0.7434295415878296, Valid_Loss:1.241324782371521, Valid_ACC:0.6041999459266663
Epoch 424, CIFAR-10 Batch 1:  Train_Loss:0.7566211819648743, Valid_Loss:1.2393584251403809, Valid_ACC:0.6037999391555786
Epoch 424, CIFAR-10 Batch 2:  Train_Loss:0.7537923455238342, Valid_Loss:1.2348027229309082, Valid_ACC:0.6055998206138611
Epoch 424, CIFAR-10 Batch 3:  Train_Loss:0.7395604848861694, Valid_Loss:1.2427153587341309, Valid_ACC:0.6031998991966248
Epoch 424, CIFAR-10 Batch 4:  Train_Loss:0.7544606328010559, Valid_Loss:1.2511087656021118, Valid_ACC:0.5995999574661255
Epoch 424, CIFAR-10 Batch 5:  Train_Loss:0.7676975727081299, Valid_Loss:1.2408106327056885, Valid_ACC:0.6063999533653259
Epoch 425, CIFAR-10 Batch 1:  Train_Loss:0.7313176989555359, Valid_Loss:1.2263439893722534, Valid_ACC:0.6089999675750732
Epoch 425, CIFAR-10 Batch 2:  Train_Loss:0.7521488666534424, Valid_Loss:1.2227286100387573, Valid_ACC:0.608799934387207
Epoch 425, CIFAR-10 Batch 3:  Train_Loss:0.724165678024292, Valid_Loss:1.2382960319519043, Valid_ACC:0.6093999743461609
Epoch 425, CIFAR-10 Batch 4:  Train_Loss:0.7742860317230225, Valid_Loss:1.2721757888793945, Valid_ACC:0.5949999094009399
Epoch 425, CIFAR-10 Batch 5:  Train_Loss:0.7587623000144958, Valid_Loss:1.2492667436599731, Valid_ACC:0.6017999649047852
Epoch 426, CIFAR-10 Batch 1:  Train_Loss:0.7345575094223022, Valid_Loss:1.2211486101150513, Valid_ACC:0.6089999079704285
Epoch 426, CIFAR-10 Batch 2:  Train_Loss:0.7447139024734497, Valid_Loss:1.2262684106826782, Valid_ACC:0.6097999215126038
Epoch 426, CIFAR-10 Batch 3:  Train_Loss:0.716119647026062, Valid_Loss:1.2361506223678589, Valid_ACC:0.6083998680114746
Epoch 426, CIFAR-10 Batch 4:  Train_Loss:0.7334162592887878, Valid_Loss:1.2374085187911987, Valid_ACC:0.6031999588012695
Epoch 426, CIFAR-10 Batch 5:  Train_Loss:0.746849775314331, Valid_Loss:1.2529267072677612, Valid_ACC:0.6027998924255371
Epoch 427, CIFAR-10 Batch 1:  Train_Loss:0.7369040846824646, Valid_Loss:1.231778860092163, Valid_ACC:0.6045999526977539
Epoch 427, CIFAR-10 Batch 2:  Train_Loss:0.774990975856781, Valid_Loss:1.2480695247650146, Valid_ACC:0.5999999046325684
Epoch 427, CIFAR-10 Batch 3:  Train_Loss:0.7132039666175842, Valid_Loss:1.2261073589324951, Valid_ACC:0.6091998815536499
Epoch 427, CIFAR-10 Batch 4:  Train_Loss:0.744365394115448, Valid_Loss:1.2329941987991333, Valid_ACC:0.6031999588012695
Epoch 427, CIFAR-10 Batch 5:  Train_Loss:0.7641700506210327, Valid_Loss:1.2469590902328491, Valid_ACC:0.6035999059677124
Epoch 428, CIFAR-10 Batch 1:  Train_Loss:0.7328782677650452, Valid_Loss:1.2204511165618896, Valid_ACC:0.612799882888794
Epoch 428, CIFAR-10 Batch 2:  Train_Loss:0.7733600735664368, Valid_Loss:1.2453172206878662, Valid_ACC:0.6019999384880066
Epoch 428, CIFAR-10 Batch 3:  Train_Loss:0.7095996141433716, Valid_Loss:1.2315019369125366, Valid_ACC:0.6101998686790466
Epoch 428, CIFAR-10 Batch 4:  Train_Loss:0.7415632605552673, Valid_Loss:1.242297649383545, Valid_ACC:0.6017999053001404
Epoch 428, CIFAR-10 Batch 5:  Train_Loss:0.7667667269706726, Valid_Loss:1.2422667741775513, Valid_ACC:0.6049998998641968
Epoch 429, CIFAR-10 Batch 1:  Train_Loss:0.7210868000984192, Valid_Loss:1.2193148136138916, Valid_ACC:0.6099998354911804
Epoch 429, CIFAR-10 Batch 2:  Train_Loss:0.745143711566925, Valid_Loss:1.2230944633483887, Valid_ACC:0.6085999011993408
Epoch 429, CIFAR-10 Batch 3:  Train_Loss:0.6987365484237671, Valid_Loss:1.2230970859527588, Valid_ACC:0.6151999235153198
Epoch 429, CIFAR-10 Batch 4:  Train_Loss:0.7411980628967285, Valid_Loss:1.2546108961105347, Valid_ACC:0.596799910068512
Epoch 429, CIFAR-10 Batch 5:  Train_Loss:0.7476615905761719, Valid_Loss:1.2512986660003662, Valid_ACC:0.5991998910903931
Epoch 430, CIFAR-10 Batch 1:  Train_Loss:0.7252110242843628, Valid_Loss:1.215933084487915, Valid_ACC:0.6095998883247375
Epoch 430, CIFAR-10 Batch 2:  Train_Loss:0.7462292909622192, Valid_Loss:1.229317545890808, Valid_ACC:0.6085999011993408
Epoch 430, CIFAR-10 Batch 3:  Train_Loss:0.7098130583763123, Valid_Loss:1.2191424369812012, Valid_ACC:0.6101999282836914
Epoch 430, CIFAR-10 Batch 4:  Train_Loss:0.723135232925415, Valid_Loss:1.2262943983078003, Valid_ACC:0.605199933052063
Epoch 430, CIFAR-10 Batch 5:  Train_Loss:0.7294551134109497, Valid_Loss:1.2386198043823242, Valid_ACC:0.6039999127388
Epoch 431, CIFAR-10 Batch 1:  Train_Loss:0.7173534035682678, Valid_Loss:1.2176940441131592, Valid_ACC:0.6135998964309692
Epoch 431, CIFAR-10 Batch 2:  Train_Loss:0.7341827154159546, Valid_Loss:1.2198959589004517, Valid_ACC:0.6101998686790466
Epoch 431, CIFAR-10 Batch 3:  Train_Loss:0.7148211002349854, Valid_Loss:1.2220544815063477, Valid_ACC:0.6109999418258667
Epoch 431, CIFAR-10 Batch 4:  Train_Loss:0.7279180884361267, Valid_Loss:1.2352452278137207, Valid_ACC:0.6035999059677124
Epoch 431, CIFAR-10 Batch 5:  Train_Loss:0.7439605593681335, Valid_Loss:1.2448142766952515, Valid_ACC:0.6047998666763306
Epoch 432, CIFAR-10 Batch 1:  Train_Loss:0.7232285737991333, Valid_Loss:1.2231512069702148, Valid_ACC:0.6101999282836914
Epoch 432, CIFAR-10 Batch 2:  Train_Loss:0.7155534029006958, Valid_Loss:1.2136764526367188, Valid_ACC:0.6149998903274536
Epoch 432, CIFAR-10 Batch 3:  Train_Loss:0.7087810635566711, Valid_Loss:1.227898359298706, Valid_ACC:0.6101998686790466
Epoch 432, CIFAR-10 Batch 4:  Train_Loss:0.720329999923706, Valid_Loss:1.2329269647598267, Valid_ACC:0.6029999256134033
Epoch 432, CIFAR-10 Batch 5:  Train_Loss:0.732280433177948, Valid_Loss:1.2333877086639404, Valid_ACC:0.6047998666763306
Epoch 433, CIFAR-10 Batch 1:  Train_Loss:0.7180185317993164, Valid_Loss:1.221523404121399, Valid_ACC:0.6103999018669128
Epoch 433, CIFAR-10 Batch 2:  Train_Loss:0.7282054424285889, Valid_Loss:1.2219375371932983, Valid_ACC:0.6101999282836914
Epoch 433, CIFAR-10 Batch 3:  Train_Loss:0.693710207939148, Valid_Loss:1.2229620218276978, Valid_ACC:0.6071999073028564
Epoch 433, CIFAR-10 Batch 4:  Train_Loss:0.7168659567832947, Valid_Loss:1.229475498199463, Valid_ACC:0.6061998605728149
Epoch 433, CIFAR-10 Batch 5:  Train_Loss:0.7095025181770325, Valid_Loss:1.2263375520706177, Valid_ACC:0.6103999614715576
Epoch 434, CIFAR-10 Batch 1:  Train_Loss:0.7168145179748535, Valid_Loss:1.2197530269622803, Valid_ACC:0.6095998883247375
Epoch 434, CIFAR-10 Batch 2:  Train_Loss:0.7233642339706421, Valid_Loss:1.2125608921051025, Valid_ACC:0.6119999289512634
Epoch 434, CIFAR-10 Batch 3:  Train_Loss:0.707186758518219, Valid_Loss:1.226710557937622, Valid_ACC:0.608199954032898
Epoch 434, CIFAR-10 Batch 4:  Train_Loss:0.7097131609916687, Valid_Loss:1.2150120735168457, Valid_ACC:0.6113998889923096
Epoch 434, CIFAR-10 Batch 5:  Train_Loss:0.7086383700370789, Valid_Loss:1.23137629032135, Valid_ACC:0.6063998937606812
Epoch 435, CIFAR-10 Batch 1:  Train_Loss:0.7135353088378906, Valid_Loss:1.2155729532241821, Valid_ACC:0.6109999418258667
Epoch 435, CIFAR-10 Batch 2:  Train_Loss:0.7223725318908691, Valid_Loss:1.2198594808578491, Valid_ACC:0.6127999424934387
Epoch 435, CIFAR-10 Batch 3:  Train_Loss:0.6906478404998779, Valid_Loss:1.2185537815093994, Valid_ACC:0.6121999025344849
Epoch 435, CIFAR-10 Batch 4:  Train_Loss:0.7069919109344482, Valid_Loss:1.225296974182129, Valid_ACC:0.6073999404907227
Epoch 435, CIFAR-10 Batch 5:  Train_Loss:0.7242292165756226, Valid_Loss:1.2381459474563599, Valid_ACC:0.6075998544692993
Epoch 436, CIFAR-10 Batch 1:  Train_Loss:0.7080206871032715, Valid_Loss:1.2211158275604248, Valid_ACC:0.6073999404907227
Epoch 436, CIFAR-10 Batch 2:  Train_Loss:0.7165441513061523, Valid_Loss:1.2195796966552734, Valid_ACC:0.6085999608039856
Epoch 436, CIFAR-10 Batch 3:  Train_Loss:0.7035335302352905, Valid_Loss:1.2265336513519287, Valid_ACC:0.6113998889923096
Epoch 436, CIFAR-10 Batch 4:  Train_Loss:0.7280054092407227, Valid_Loss:1.2381536960601807, Valid_ACC:0.6053999066352844
Epoch 436, CIFAR-10 Batch 5:  Train_Loss:0.7205154895782471, Valid_Loss:1.239498257637024, Valid_ACC:0.605199933052063
Epoch 437, CIFAR-10 Batch 1:  Train_Loss:0.7055879235267639, Valid_Loss:1.2166497707366943, Valid_ACC:0.6111998558044434
Epoch 437, CIFAR-10 Batch 2:  Train_Loss:0.7189034223556519, Valid_Loss:1.2171508073806763, Valid_ACC:0.6123998761177063
Epoch 437, CIFAR-10 Batch 3:  Train_Loss:0.6930005550384521, Valid_Loss:1.2145850658416748, Valid_ACC:0.6117998957633972
Epoch 437, CIFAR-10 Batch 4:  Train_Loss:0.7068189978599548, Valid_Loss:1.2246220111846924, Valid_ACC:0.6065998673439026
Epoch 437, CIFAR-10 Batch 5:  Train_Loss:0.7140579223632812, Valid_Loss:1.2413749694824219, Valid_ACC:0.605199933052063
Epoch 438, CIFAR-10 Batch 1:  Train_Loss:0.7063159346580505, Valid_Loss:1.222899317741394, Valid_ACC:0.6101998686790466
Epoch 438, CIFAR-10 Batch 2:  Train_Loss:0.7204959392547607, Valid_Loss:1.2198936939239502, Valid_ACC:0.611599862575531
Epoch 438, CIFAR-10 Batch 3:  Train_Loss:0.6900936365127563, Valid_Loss:1.2300255298614502, Valid_ACC:0.6085999011993408
Epoch 438, CIFAR-10 Batch 4:  Train_Loss:0.7032519578933716, Valid_Loss:1.226467251777649, Valid_ACC:0.6083999276161194
Epoch 438, CIFAR-10 Batch 5:  Train_Loss:0.7219043970108032, Valid_Loss:1.241029143333435, Valid_ACC:0.6057999134063721
Epoch 439, CIFAR-10 Batch 1:  Train_Loss:0.7059561014175415, Valid_Loss:1.2200661897659302, Valid_ACC:0.6123998761177063
Epoch 439, CIFAR-10 Batch 2:  Train_Loss:0.7258409261703491, Valid_Loss:1.2198587656021118, Valid_ACC:0.6085999608039856
Epoch 439, CIFAR-10 Batch 3:  Train_Loss:0.6916942596435547, Valid_Loss:1.2222437858581543, Valid_ACC:0.6131999492645264
Epoch 439, CIFAR-10 Batch 4:  Train_Loss:0.7011727690696716, Valid_Loss:1.2215778827667236, Valid_ACC:0.611799955368042
Epoch 439, CIFAR-10 Batch 5:  Train_Loss:0.7058847546577454, Valid_Loss:1.2390658855438232, Valid_ACC:0.6069998741149902
Epoch 440, CIFAR-10 Batch 1:  Train_Loss:0.700966477394104, Valid_Loss:1.2166168689727783, Valid_ACC:0.6125999689102173
Epoch 440, CIFAR-10 Batch 2:  Train_Loss:0.7099235653877258, Valid_Loss:1.2139850854873657, Valid_ACC:0.6159998774528503
Epoch 440, CIFAR-10 Batch 3:  Train_Loss:0.7110294103622437, Valid_Loss:1.2396166324615479, Valid_ACC:0.6051998734474182
Epoch 440, CIFAR-10 Batch 4:  Train_Loss:0.7069854140281677, Valid_Loss:1.213549017906189, Valid_ACC:0.6141998767852783
Epoch 440, CIFAR-10 Batch 5:  Train_Loss:0.730769157409668, Valid_Loss:1.241384506225586, Valid_ACC:0.6047998666763306
Epoch 441, CIFAR-10 Batch 1:  Train_Loss:0.704292893409729, Valid_Loss:1.2135347127914429, Valid_ACC:0.6123998761177063
Epoch 441, CIFAR-10 Batch 2:  Train_Loss:0.7196862697601318, Valid_Loss:1.2195597887039185, Valid_ACC:0.6157999038696289
Epoch 441, CIFAR-10 Batch 3:  Train_Loss:0.7016111612319946, Valid_Loss:1.2299778461456299, Valid_ACC:0.6067999601364136
Epoch 441, CIFAR-10 Batch 4:  Train_Loss:0.7066544890403748, Valid_Loss:1.214085340499878, Valid_ACC:0.614599883556366
Epoch 441, CIFAR-10 Batch 5:  Train_Loss:0.7102715969085693, Valid_Loss:1.2196425199508667, Valid_ACC:0.6131998300552368
Epoch 442, CIFAR-10 Batch 1:  Train_Loss:0.6966840028762817, Valid_Loss:1.220377802848816, Valid_ACC:0.6119998693466187
Epoch 442, CIFAR-10 Batch 2:  Train_Loss:0.72014319896698, Valid_Loss:1.2151873111724854, Valid_ACC:0.610599935054779
Epoch 442, CIFAR-10 Batch 3:  Train_Loss:0.7217191457748413, Valid_Loss:1.245110273361206, Valid_ACC:0.6031999588012695
Epoch 442, CIFAR-10 Batch 4:  Train_Loss:0.7068528532981873, Valid_Loss:1.2170791625976562, Valid_ACC:0.6141998767852783
Epoch 442, CIFAR-10 Batch 5:  Train_Loss:0.7259043455123901, Valid_Loss:1.244094729423523, Valid_ACC:0.6041998863220215
Epoch 443, CIFAR-10 Batch 1:  Train_Loss:0.6991428732872009, Valid_Loss:1.2111995220184326, Valid_ACC:0.616399884223938
Epoch 443, CIFAR-10 Batch 2:  Train_Loss:0.7184157371520996, Valid_Loss:1.2123210430145264, Valid_ACC:0.614799976348877
Epoch 443, CIFAR-10 Batch 3:  Train_Loss:0.7102081179618835, Valid_Loss:1.2378404140472412, Valid_ACC:0.6077999472618103
Epoch 443, CIFAR-10 Batch 4:  Train_Loss:0.7016518712043762, Valid_Loss:1.2186099290847778, Valid_ACC:0.6095998883247375
Epoch 443, CIFAR-10 Batch 5:  Train_Loss:0.7019139528274536, Valid_Loss:1.2290093898773193, Valid_ACC:0.6089999079704285
Epoch 444, CIFAR-10 Batch 1:  Train_Loss:0.6985338926315308, Valid_Loss:1.229538917541504, Valid_ACC:0.6071999073028564
Epoch 444, CIFAR-10 Batch 2:  Train_Loss:0.7225480079650879, Valid_Loss:1.229005217552185, Valid_ACC:0.6049998998641968
Epoch 444, CIFAR-10 Batch 3:  Train_Loss:0.6922528147697449, Valid_Loss:1.2209370136260986, Valid_ACC:0.6113999485969543
Epoch 444, CIFAR-10 Batch 4:  Train_Loss:0.7030070424079895, Valid_Loss:1.22379469871521, Valid_ACC:0.6075999736785889
Epoch 444, CIFAR-10 Batch 5:  Train_Loss:0.700735330581665, Valid_Loss:1.2324011325836182, Valid_ACC:0.6081998944282532
Epoch 445, CIFAR-10 Batch 1:  Train_Loss:0.6971322298049927, Valid_Loss:1.2202415466308594, Valid_ACC:0.6083998680114746
Epoch 445, CIFAR-10 Batch 2:  Train_Loss:0.7179806232452393, Valid_Loss:1.224410057067871, Valid_ACC:0.6055999994277954
Epoch 445, CIFAR-10 Batch 3:  Train_Loss:0.6875243186950684, Valid_Loss:1.2316322326660156, Valid_ACC:0.6069998741149902
Epoch 445, CIFAR-10 Batch 4:  Train_Loss:0.7560988664627075, Valid_Loss:1.2433345317840576, Valid_ACC:0.6029999256134033
Epoch 445, CIFAR-10 Batch 5:  Train_Loss:0.7084332704544067, Valid_Loss:1.2315332889556885, Valid_ACC:0.6071999073028564
Epoch 446, CIFAR-10 Batch 1:  Train_Loss:0.7039012908935547, Valid_Loss:1.2325947284698486, Valid_ACC:0.598599910736084
Epoch 446, CIFAR-10 Batch 2:  Train_Loss:0.7237194776535034, Valid_Loss:1.2253129482269287, Valid_ACC:0.6091998815536499
Epoch 446, CIFAR-10 Batch 3:  Train_Loss:0.6944093108177185, Valid_Loss:1.222143292427063, Valid_ACC:0.6111999154090881
Epoch 446, CIFAR-10 Batch 4:  Train_Loss:0.704017162322998, Valid_Loss:1.2206518650054932, Valid_ACC:0.6035999059677124
Epoch 446, CIFAR-10 Batch 5:  Train_Loss:0.7147437930107117, Valid_Loss:1.2336077690124512, Valid_ACC:0.6075999736785889
Epoch 447, CIFAR-10 Batch 1:  Train_Loss:0.701164722442627, Valid_Loss:1.2169735431671143, Valid_ACC:0.6135998964309692
Epoch 447, CIFAR-10 Batch 2:  Train_Loss:0.6979228854179382, Valid_Loss:1.2128582000732422, Valid_ACC:0.6095999479293823
Epoch 447, CIFAR-10 Batch 3:  Train_Loss:0.6879383325576782, Valid_Loss:1.2227013111114502, Valid_ACC:0.6089999675750732
Epoch 447, CIFAR-10 Batch 4:  Train_Loss:0.7057291865348816, Valid_Loss:1.2246818542480469, Valid_ACC:0.6057999730110168
Epoch 447, CIFAR-10 Batch 5:  Train_Loss:0.7014576196670532, Valid_Loss:1.2237616777420044, Valid_ACC:0.6119999289512634
Epoch 448, CIFAR-10 Batch 1:  Train_Loss:0.6947351098060608, Valid_Loss:1.2147904634475708, Valid_ACC:0.6123998761177063
Epoch 448, CIFAR-10 Batch 2:  Train_Loss:0.7070873975753784, Valid_Loss:1.212416648864746, Valid_ACC:0.6123998761177063
Epoch 448, CIFAR-10 Batch 3:  Train_Loss:0.6959631443023682, Valid_Loss:1.2175674438476562, Valid_ACC:0.6107999086380005
Epoch 448, CIFAR-10 Batch 4:  Train_Loss:0.6935231685638428, Valid_Loss:1.2216209173202515, Valid_ACC:0.6093998551368713
Epoch 448, CIFAR-10 Batch 5:  Train_Loss:0.7025829553604126, Valid_Loss:1.228872537612915, Valid_ACC:0.6099998950958252
Epoch 449, CIFAR-10 Batch 1:  Train_Loss:0.6901867985725403, Valid_Loss:1.2176203727722168, Valid_ACC:0.6091998815536499
Epoch 449, CIFAR-10 Batch 2:  Train_Loss:0.6988458037376404, Valid_Loss:1.2128443717956543, Valid_ACC:0.6119999289512634
Epoch 449, CIFAR-10 Batch 3:  Train_Loss:0.6859930157661438, Valid_Loss:1.2187824249267578, Valid_ACC:0.6083999276161194
Epoch 449, CIFAR-10 Batch 4:  Train_Loss:0.706307053565979, Valid_Loss:1.2204086780548096, Valid_ACC:0.6085999011993408
Epoch 449, CIFAR-10 Batch 5:  Train_Loss:0.7222700715065002, Valid_Loss:1.2275539636611938, Valid_ACC:0.6097999215126038
Epoch 450, CIFAR-10 Batch 1:  Train_Loss:0.704216718673706, Valid_Loss:1.2316235303878784, Valid_ACC:0.6077998876571655
Epoch 450, CIFAR-10 Batch 2:  Train_Loss:0.7100374698638916, Valid_Loss:1.2244077920913696, Valid_ACC:0.605199933052063
Epoch 450, CIFAR-10 Batch 3:  Train_Loss:0.6838499903678894, Valid_Loss:1.221055507659912, Valid_ACC:0.6081998944282532
Epoch 450, CIFAR-10 Batch 4:  Train_Loss:0.727323591709137, Valid_Loss:1.2379785776138306, Valid_ACC:0.6045998930931091
Epoch 450, CIFAR-10 Batch 5:  Train_Loss:0.7303391695022583, Valid_Loss:1.2471675872802734, Valid_ACC:0.605199933052063
Epoch 451, CIFAR-10 Batch 1:  Train_Loss:0.694145917892456, Valid_Loss:1.2216914892196655, Valid_ACC:0.6131999492645264
Epoch 451, CIFAR-10 Batch 2:  Train_Loss:0.7112094759941101, Valid_Loss:1.2108796834945679, Valid_ACC:0.6175999045372009
Epoch 451, CIFAR-10 Batch 3:  Train_Loss:0.6986502408981323, Valid_Loss:1.2442374229431152, Valid_ACC:0.6035999059677124
Epoch 451, CIFAR-10 Batch 4:  Train_Loss:0.6977932453155518, Valid_Loss:1.2242848873138428, Valid_ACC:0.6101999282836914
Epoch 451, CIFAR-10 Batch 5:  Train_Loss:0.7039841413497925, Valid_Loss:1.2379294633865356, Valid_ACC:0.6071999073028564
Epoch 452, CIFAR-10 Batch 1:  Train_Loss:0.6913242936134338, Valid_Loss:1.221660852432251, Valid_ACC:0.6107999682426453
Epoch 452, CIFAR-10 Batch 2:  Train_Loss:0.6997313499450684, Valid_Loss:1.2165567874908447, Valid_ACC:0.6101999282836914
Epoch 452, CIFAR-10 Batch 3:  Train_Loss:0.6987707614898682, Valid_Loss:1.2343778610229492, Valid_ACC:0.6009999513626099
Epoch 452, CIFAR-10 Batch 4:  Train_Loss:0.698701024055481, Valid_Loss:1.214578628540039, Valid_ACC:0.6091998815536499
Epoch 452, CIFAR-10 Batch 5:  Train_Loss:0.6927276849746704, Valid_Loss:1.2190601825714111, Valid_ACC:0.6101999282836914
Epoch 453, CIFAR-10 Batch 1:  Train_Loss:0.693920910358429, Valid_Loss:1.2230901718139648, Valid_ACC:0.6079999208450317
Epoch 453, CIFAR-10 Batch 2:  Train_Loss:0.6904041767120361, Valid_Loss:1.214362382888794, Valid_ACC:0.6145999431610107
Epoch 453, CIFAR-10 Batch 3:  Train_Loss:0.7142837643623352, Valid_Loss:1.247878909111023, Valid_ACC:0.6033998727798462
Epoch 453, CIFAR-10 Batch 4:  Train_Loss:0.710059642791748, Valid_Loss:1.2233169078826904, Valid_ACC:0.6121999025344849
Epoch 453, CIFAR-10 Batch 5:  Train_Loss:0.7029173374176025, Valid_Loss:1.2365193367004395, Valid_ACC:0.606799840927124
Epoch 454, CIFAR-10 Batch 1:  Train_Loss:0.6941214203834534, Valid_Loss:1.2154897451400757, Valid_ACC:0.6135998368263245
Epoch 454, CIFAR-10 Batch 2:  Train_Loss:0.705909013748169, Valid_Loss:1.2115548849105835, Valid_ACC:0.6139999032020569
Epoch 454, CIFAR-10 Batch 3:  Train_Loss:0.6831045150756836, Valid_Loss:1.222428798675537, Valid_ACC:0.6103999018669128
Epoch 454, CIFAR-10 Batch 4:  Train_Loss:0.7141464948654175, Valid_Loss:1.2230026721954346, Valid_ACC:0.6061999201774597
Epoch 454, CIFAR-10 Batch 5:  Train_Loss:0.7030526995658875, Valid_Loss:1.2322642803192139, Valid_ACC:0.6091999411582947
Epoch 455, CIFAR-10 Batch 1:  Train_Loss:0.7107750177383423, Valid_Loss:1.232750654220581, Valid_ACC:0.6019999384880066
Epoch 455, CIFAR-10 Batch 2:  Train_Loss:0.7096059918403625, Valid_Loss:1.2253022193908691, Valid_ACC:0.606999933719635
Epoch 455, CIFAR-10 Batch 3:  Train_Loss:0.6858174800872803, Valid_Loss:1.2220314741134644, Valid_ACC:0.6111998558044434
Epoch 455, CIFAR-10 Batch 4:  Train_Loss:0.7014391422271729, Valid_Loss:1.2252668142318726, Valid_ACC:0.6103998422622681
Epoch 455, CIFAR-10 Batch 5:  Train_Loss:0.7086179852485657, Valid_Loss:1.2251306772232056, Valid_ACC:0.6107999682426453
Epoch 456, CIFAR-10 Batch 1:  Train_Loss:0.6990680694580078, Valid_Loss:1.2222251892089844, Valid_ACC:0.6071999073028564
Epoch 456, CIFAR-10 Batch 2:  Train_Loss:0.7108945250511169, Valid_Loss:1.2211395502090454, Valid_ACC:0.60999995470047
Epoch 456, CIFAR-10 Batch 3:  Train_Loss:0.697483241558075, Valid_Loss:1.2248008251190186, Valid_ACC:0.6091998815536499
Epoch 456, CIFAR-10 Batch 4:  Train_Loss:0.689116895198822, Valid_Loss:1.2223178148269653, Valid_ACC:0.6107999682426453
Epoch 456, CIFAR-10 Batch 5:  Train_Loss:0.7043750286102295, Valid_Loss:1.2260994911193848, Valid_ACC:0.6059999465942383
Epoch 457, CIFAR-10 Batch 1:  Train_Loss:0.6904335618019104, Valid_Loss:1.2102410793304443, Valid_ACC:0.61819988489151
Epoch 457, CIFAR-10 Batch 2:  Train_Loss:0.7011005878448486, Valid_Loss:1.2145487070083618, Valid_ACC:0.6135998964309692
Epoch 457, CIFAR-10 Batch 3:  Train_Loss:0.6839128136634827, Valid_Loss:1.2202844619750977, Valid_ACC:0.6109999418258667
Epoch 457, CIFAR-10 Batch 4:  Train_Loss:0.6867929697036743, Valid_Loss:1.220240831375122, Valid_ACC:0.6109998822212219
Epoch 457, CIFAR-10 Batch 5:  Train_Loss:0.7033588290214539, Valid_Loss:1.2228938341140747, Valid_ACC:0.6131999492645264
Epoch 458, CIFAR-10 Batch 1:  Train_Loss:0.6994802951812744, Valid_Loss:1.21999192237854, Valid_ACC:0.6111998558044434
Epoch 458, CIFAR-10 Batch 2:  Train_Loss:0.7197439074516296, Valid_Loss:1.2280596494674683, Valid_ACC:0.6101999282836914
Epoch 458, CIFAR-10 Batch 3:  Train_Loss:0.6839485764503479, Valid_Loss:1.2152273654937744, Valid_ACC:0.6107999086380005
Epoch 458, CIFAR-10 Batch 4:  Train_Loss:0.7062766551971436, Valid_Loss:1.2498759031295776, Valid_ACC:0.5961998701095581
Epoch 458, CIFAR-10 Batch 5:  Train_Loss:0.7420356273651123, Valid_Loss:1.259186863899231, Valid_ACC:0.5953999161720276
Epoch 459, CIFAR-10 Batch 1:  Train_Loss:0.7078173160552979, Valid_Loss:1.2157983779907227, Valid_ACC:0.6089999079704285
Epoch 459, CIFAR-10 Batch 2:  Train_Loss:0.7013669013977051, Valid_Loss:1.2109650373458862, Valid_ACC:0.6115999221801758
Epoch 459, CIFAR-10 Batch 3:  Train_Loss:0.6883625388145447, Valid_Loss:1.2179243564605713, Valid_ACC:0.6087998747825623
Epoch 459, CIFAR-10 Batch 4:  Train_Loss:0.7000380754470825, Valid_Loss:1.2404577732086182, Valid_ACC:0.6017999649047852
Epoch 459, CIFAR-10 Batch 5:  Train_Loss:0.6962150931358337, Valid_Loss:1.2353696823120117, Valid_ACC:0.6085999011993408
Epoch 460, CIFAR-10 Batch 1:  Train_Loss:0.7026643753051758, Valid_Loss:1.2164130210876465, Valid_ACC:0.615399956703186
Epoch 460, CIFAR-10 Batch 2:  Train_Loss:0.7000257968902588, Valid_Loss:1.2163021564483643, Valid_ACC:0.6093999147415161
Epoch 460, CIFAR-10 Batch 3:  Train_Loss:0.703307032585144, Valid_Loss:1.2261688709259033, Valid_ACC:0.6057999134063721
Epoch 460, CIFAR-10 Batch 4:  Train_Loss:0.6986743807792664, Valid_Loss:1.241456389427185, Valid_ACC:0.6007999181747437
Epoch 460, CIFAR-10 Batch 5:  Train_Loss:0.701988935470581, Valid_Loss:1.2334401607513428, Valid_ACC:0.6079999208450317
Epoch 461, CIFAR-10 Batch 1:  Train_Loss:0.6918056011199951, Valid_Loss:1.2073951959609985, Valid_ACC:0.6167999505996704
Epoch 461, CIFAR-10 Batch 2:  Train_Loss:0.7002284526824951, Valid_Loss:1.2094056606292725, Valid_ACC:0.6123998761177063
Epoch 461, CIFAR-10 Batch 3:  Train_Loss:0.6885831952095032, Valid_Loss:1.2093393802642822, Valid_ACC:0.6113998889923096
Epoch 461, CIFAR-10 Batch 4:  Train_Loss:0.677685558795929, Valid_Loss:1.2086412906646729, Valid_ACC:0.6147999167442322
Epoch 461, CIFAR-10 Batch 5:  Train_Loss:0.702114999294281, Valid_Loss:1.2191548347473145, Valid_ACC:0.6125999093055725
Epoch 462, CIFAR-10 Batch 1:  Train_Loss:0.689400315284729, Valid_Loss:1.2136954069137573, Valid_ACC:0.6107999086380005
Epoch 462, CIFAR-10 Batch 2:  Train_Loss:0.6872615814208984, Valid_Loss:1.212053894996643, Valid_ACC:0.6131998896598816
Epoch 462, CIFAR-10 Batch 3:  Train_Loss:0.6797527074813843, Valid_Loss:1.2186588048934937, Valid_ACC:0.6069998741149902
Epoch 462, CIFAR-10 Batch 4:  Train_Loss:0.6875922083854675, Valid_Loss:1.225567102432251, Valid_ACC:0.6085999011993408
Epoch 462, CIFAR-10 Batch 5:  Train_Loss:0.6846216917037964, Valid_Loss:1.212951898574829, Valid_ACC:0.6167999505996704
Epoch 463, CIFAR-10 Batch 1:  Train_Loss:0.6904209852218628, Valid_Loss:1.2157695293426514, Valid_ACC:0.6133999228477478
Epoch 463, CIFAR-10 Batch 2:  Train_Loss:0.6923052072525024, Valid_Loss:1.2135366201400757, Valid_ACC:0.6099998950958252
Epoch 463, CIFAR-10 Batch 3:  Train_Loss:0.6856844425201416, Valid_Loss:1.2096914052963257, Valid_ACC:0.6149998903274536
Epoch 463, CIFAR-10 Batch 4:  Train_Loss:0.686989963054657, Valid_Loss:1.2121104001998901, Valid_ACC:0.6091999411582947
Epoch 463, CIFAR-10 Batch 5:  Train_Loss:0.7111762762069702, Valid_Loss:1.2349003553390503, Valid_ACC:0.6049999594688416
Epoch 464, CIFAR-10 Batch 1:  Train_Loss:0.685438871383667, Valid_Loss:1.2113498449325562, Valid_ACC:0.6139999032020569
Epoch 464, CIFAR-10 Batch 2:  Train_Loss:0.6920664310455322, Valid_Loss:1.2095983028411865, Valid_ACC:0.6123998761177063
Epoch 464, CIFAR-10 Batch 3:  Train_Loss:0.6890296936035156, Valid_Loss:1.221247673034668, Valid_ACC:0.6119999289512634
Epoch 464, CIFAR-10 Batch 4:  Train_Loss:0.6772123575210571, Valid_Loss:1.219920039176941, Valid_ACC:0.6079999208450317
Epoch 464, CIFAR-10 Batch 5:  Train_Loss:0.6995648145675659, Valid_Loss:1.2245055437088013, Valid_ACC:0.613399863243103
Epoch 465, CIFAR-10 Batch 1:  Train_Loss:0.6833857297897339, Valid_Loss:1.2191202640533447, Valid_ACC:0.6085999011993408
Epoch 465, CIFAR-10 Batch 2:  Train_Loss:0.6936793327331543, Valid_Loss:1.2170052528381348, Valid_ACC:0.6075999736785889
Epoch 465, CIFAR-10 Batch 3:  Train_Loss:0.6922050714492798, Valid_Loss:1.2174891233444214, Valid_ACC:0.6073998808860779
Epoch 465, CIFAR-10 Batch 4:  Train_Loss:0.7185911536216736, Valid_Loss:1.2519280910491943, Valid_ACC:0.5963999032974243
Epoch 465, CIFAR-10 Batch 5:  Train_Loss:0.7129136919975281, Valid_Loss:1.2368957996368408, Valid_ACC:0.6053999066352844
Epoch 466, CIFAR-10 Batch 1:  Train_Loss:0.6963059306144714, Valid_Loss:1.2158310413360596, Valid_ACC:0.612799882888794
Epoch 466, CIFAR-10 Batch 2:  Train_Loss:0.6986364126205444, Valid_Loss:1.210726022720337, Valid_ACC:0.6107999086380005
Epoch 466, CIFAR-10 Batch 3:  Train_Loss:0.6844154596328735, Valid_Loss:1.2224544286727905, Valid_ACC:0.6079999208450317
Epoch 466, CIFAR-10 Batch 4:  Train_Loss:0.6870557069778442, Valid_Loss:1.2179938554763794, Valid_ACC:0.6075999140739441
Epoch 466, CIFAR-10 Batch 5:  Train_Loss:0.7020488977432251, Valid_Loss:1.2263318300247192, Valid_ACC:0.6113998889923096
Epoch 467, CIFAR-10 Batch 1:  Train_Loss:0.701160192489624, Valid_Loss:1.2354559898376465, Valid_ACC:0.6069998741149902
Epoch 467, CIFAR-10 Batch 2:  Train_Loss:0.6863127946853638, Valid_Loss:1.2076297998428345, Valid_ACC:0.6119998693466187
Epoch 467, CIFAR-10 Batch 3:  Train_Loss:0.683215320110321, Valid_Loss:1.210207462310791, Valid_ACC:0.6123998761177063
Epoch 467, CIFAR-10 Batch 4:  Train_Loss:0.6986621618270874, Valid_Loss:1.2144229412078857, Valid_ACC:0.6059998869895935
Epoch 467, CIFAR-10 Batch 5:  Train_Loss:0.6920363306999207, Valid_Loss:1.220044732093811, Valid_ACC:0.6087998747825623
Epoch 468, CIFAR-10 Batch 1:  Train_Loss:0.7147942781448364, Valid_Loss:1.2409533262252808, Valid_ACC:0.6009998917579651
Epoch 468, CIFAR-10 Batch 2:  Train_Loss:0.705530047416687, Valid_Loss:1.2367126941680908, Valid_ACC:0.605199933052063
Epoch 468, CIFAR-10 Batch 3:  Train_Loss:0.6720365285873413, Valid_Loss:1.21528959274292, Valid_ACC:0.6125998497009277
Epoch 468, CIFAR-10 Batch 4:  Train_Loss:0.6756556630134583, Valid_Loss:1.2088065147399902, Valid_ACC:0.6101999282836914
Epoch 468, CIFAR-10 Batch 5:  Train_Loss:0.7025704383850098, Valid_Loss:1.2380236387252808, Valid_ACC:0.6065998673439026
Epoch 469, CIFAR-10 Batch 1:  Train_Loss:0.6893093585968018, Valid_Loss:1.210166573524475, Valid_ACC:0.6157999634742737
Epoch 469, CIFAR-10 Batch 2:  Train_Loss:0.6905739903450012, Valid_Loss:1.2091999053955078, Valid_ACC:0.6101999282836914
Epoch 469, CIFAR-10 Batch 3:  Train_Loss:0.677299976348877, Valid_Loss:1.2067551612854004, Valid_ACC:0.6143999099731445
Epoch 469, CIFAR-10 Batch 4:  Train_Loss:0.6833398938179016, Valid_Loss:1.2070525884628296, Valid_ACC:0.613399863243103
Epoch 469, CIFAR-10 Batch 5:  Train_Loss:0.6984859108924866, Valid_Loss:1.2351834774017334, Valid_ACC:0.6059998869895935
Epoch 470, CIFAR-10 Batch 1:  Train_Loss:0.6808143258094788, Valid_Loss:1.2118761539459229, Valid_ACC:0.6117998361587524
Epoch 470, CIFAR-10 Batch 2:  Train_Loss:0.690883994102478, Valid_Loss:1.210314154624939, Valid_ACC:0.6109999418258667
Epoch 470, CIFAR-10 Batch 3:  Train_Loss:0.678405225276947, Valid_Loss:1.2200173139572144, Valid_ACC:0.6081998944282532
Epoch 470, CIFAR-10 Batch 4:  Train_Loss:0.6950901746749878, Valid_Loss:1.2181867361068726, Valid_ACC:0.6092000007629395
Epoch 470, CIFAR-10 Batch 5:  Train_Loss:0.6782612800598145, Valid_Loss:1.2087599039077759, Valid_ACC:0.6167999505996704
Epoch 471, CIFAR-10 Batch 1:  Train_Loss:0.6848043203353882, Valid_Loss:1.211508870124817, Valid_ACC:0.6149998903274536
Epoch 471, CIFAR-10 Batch 2:  Train_Loss:0.687606930732727, Valid_Loss:1.2048733234405518, Valid_ACC:0.6159999370574951
Epoch 471, CIFAR-10 Batch 3:  Train_Loss:0.6799271106719971, Valid_Loss:1.216331958770752, Valid_ACC:0.6109998822212219
Epoch 471, CIFAR-10 Batch 4:  Train_Loss:0.6739956140518188, Valid_Loss:1.2137641906738281, Valid_ACC:0.609799861907959
Epoch 471, CIFAR-10 Batch 5:  Train_Loss:0.692355215549469, Valid_Loss:1.230067253112793, Valid_ACC:0.611799955368042
Epoch 472, CIFAR-10 Batch 1:  Train_Loss:0.6943922638893127, Valid_Loss:1.2098411321640015, Valid_ACC:0.6135998964309692
Epoch 472, CIFAR-10 Batch 2:  Train_Loss:0.6991534233093262, Valid_Loss:1.2114644050598145, Valid_ACC:0.6143998503684998
Epoch 472, CIFAR-10 Batch 3:  Train_Loss:0.695673942565918, Valid_Loss:1.229267954826355, Valid_ACC:0.606999933719635
Epoch 472, CIFAR-10 Batch 4:  Train_Loss:0.7034966349601746, Valid_Loss:1.2231225967407227, Valid_ACC:0.60999995470047
Epoch 472, CIFAR-10 Batch 5:  Train_Loss:0.7262580394744873, Valid_Loss:1.2499195337295532, Valid_ACC:0.6009999513626099
Epoch 473, CIFAR-10 Batch 1:  Train_Loss:0.6938105821609497, Valid_Loss:1.2243587970733643, Valid_ACC:0.60999995470047
Epoch 473, CIFAR-10 Batch 2:  Train_Loss:0.695667564868927, Valid_Loss:1.2193540334701538, Valid_ACC:0.6117998957633972
Epoch 473, CIFAR-10 Batch 3:  Train_Loss:0.6893702149391174, Valid_Loss:1.233221173286438, Valid_ACC:0.6045998930931091
Epoch 473, CIFAR-10 Batch 4:  Train_Loss:0.688783586025238, Valid_Loss:1.220604658126831, Valid_ACC:0.6099998950958252
Epoch 473, CIFAR-10 Batch 5:  Train_Loss:0.694277822971344, Valid_Loss:1.2210930585861206, Valid_ACC:0.6093999147415161
Epoch 474, CIFAR-10 Batch 1:  Train_Loss:0.679707407951355, Valid_Loss:1.205880045890808, Valid_ACC:0.6155998706817627
Epoch 474, CIFAR-10 Batch 2:  Train_Loss:0.6886868476867676, Valid_Loss:1.2116577625274658, Valid_ACC:0.6183999180793762
Epoch 474, CIFAR-10 Batch 3:  Train_Loss:0.685160756111145, Valid_Loss:1.2241579294204712, Valid_ACC:0.6063998937606812
Epoch 474, CIFAR-10 Batch 4:  Train_Loss:0.6760438084602356, Valid_Loss:1.2152777910232544, Valid_ACC:0.6135998964309692
Epoch 474, CIFAR-10 Batch 5:  Train_Loss:0.7127123475074768, Valid_Loss:1.246375560760498, Valid_ACC:0.6049998998641968
Epoch 475, CIFAR-10 Batch 1:  Train_Loss:0.6914014220237732, Valid_Loss:1.2139331102371216, Valid_ACC:0.6137999296188354
Epoch 475, CIFAR-10 Batch 2:  Train_Loss:0.7055546641349792, Valid_Loss:1.2316992282867432, Valid_ACC:0.6041998863220215
Epoch 475, CIFAR-10 Batch 3:  Train_Loss:0.6783228516578674, Valid_Loss:1.210573434829712, Valid_ACC:0.6099998950958252
Epoch 475, CIFAR-10 Batch 4:  Train_Loss:0.6769821643829346, Valid_Loss:1.2138310670852661, Valid_ACC:0.6071999073028564
Epoch 475, CIFAR-10 Batch 5:  Train_Loss:0.6825181841850281, Valid_Loss:1.2219332456588745, Valid_ACC:0.6111999154090881
Epoch 476, CIFAR-10 Batch 1:  Train_Loss:0.6746635437011719, Valid_Loss:1.2006672620773315, Valid_ACC:0.6189998984336853
Epoch 476, CIFAR-10 Batch 2:  Train_Loss:0.6926676034927368, Valid_Loss:1.216430902481079, Valid_ACC:0.6115999221801758
Epoch 476, CIFAR-10 Batch 3:  Train_Loss:0.6872631311416626, Valid_Loss:1.2204238176345825, Valid_ACC:0.6067999601364136
Epoch 476, CIFAR-10 Batch 4:  Train_Loss:0.67972731590271, Valid_Loss:1.2170244455337524, Valid_ACC:0.6183998584747314
Epoch 476, CIFAR-10 Batch 5:  Train_Loss:0.7197313904762268, Valid_Loss:1.240916132926941, Valid_ACC:0.6071999073028564
Epoch 477, CIFAR-10 Batch 1:  Train_Loss:0.6910984516143799, Valid_Loss:1.2223567962646484, Valid_ACC:0.6095998883247375
Epoch 477, CIFAR-10 Batch 2:  Train_Loss:0.677280843257904, Valid_Loss:1.211364507675171, Valid_ACC:0.6139999032020569
Epoch 477, CIFAR-10 Batch 3:  Train_Loss:0.6925107836723328, Valid_Loss:1.2119228839874268, Valid_ACC:0.6129999160766602
Epoch 477, CIFAR-10 Batch 4:  Train_Loss:0.6805450320243835, Valid_Loss:1.212587833404541, Valid_ACC:0.6141999363899231
Epoch 477, CIFAR-10 Batch 5:  Train_Loss:0.6806896924972534, Valid_Loss:1.220250129699707, Valid_ACC:0.6119999289512634
Epoch 478, CIFAR-10 Batch 1:  Train_Loss:0.6777477264404297, Valid_Loss:1.2154276371002197, Valid_ACC:0.612799882888794
Epoch 478, CIFAR-10 Batch 2:  Train_Loss:0.6779909133911133, Valid_Loss:1.2114275693893433, Valid_ACC:0.6111999154090881
Epoch 478, CIFAR-10 Batch 3:  Train_Loss:0.6770665049552917, Valid_Loss:1.2130637168884277, Valid_ACC:0.6101999282836914
Epoch 478, CIFAR-10 Batch 4:  Train_Loss:0.6831453442573547, Valid_Loss:1.2161258459091187, Valid_ACC:0.6139999032020569
Epoch 478, CIFAR-10 Batch 5:  Train_Loss:0.6842188835144043, Valid_Loss:1.2205381393432617, Valid_ACC:0.6121998429298401
Epoch 479, CIFAR-10 Batch 1:  Train_Loss:0.6858949661254883, Valid_Loss:1.2144601345062256, Valid_ACC:0.613399863243103
Epoch 479, CIFAR-10 Batch 2:  Train_Loss:0.6803595423698425, Valid_Loss:1.210860252380371, Valid_ACC:0.6115999221801758
Epoch 479, CIFAR-10 Batch 3:  Train_Loss:0.6825968027114868, Valid_Loss:1.2218890190124512, Valid_ACC:0.606999933719635
Epoch 479, CIFAR-10 Batch 4:  Train_Loss:0.6747583150863647, Valid_Loss:1.2004845142364502, Valid_ACC:0.614599883556366
Epoch 479, CIFAR-10 Batch 5:  Train_Loss:0.69175124168396, Valid_Loss:1.2284075021743774, Valid_ACC:0.6081998944282532
Epoch 480, CIFAR-10 Batch 1:  Train_Loss:0.6912076473236084, Valid_Loss:1.2246177196502686, Valid_ACC:0.6055998802185059
Epoch 480, CIFAR-10 Batch 2:  Train_Loss:0.6807687282562256, Valid_Loss:1.21262788772583, Valid_ACC:0.6071999073028564
Epoch 480, CIFAR-10 Batch 3:  Train_Loss:0.6761840581893921, Valid_Loss:1.2077120542526245, Valid_ACC:0.6119998693466187
Epoch 480, CIFAR-10 Batch 4:  Train_Loss:0.6787055134773254, Valid_Loss:1.2050493955612183, Valid_ACC:0.6177998781204224
Epoch 480, CIFAR-10 Batch 5:  Train_Loss:0.6827325224876404, Valid_Loss:1.2179330587387085, Valid_ACC:0.6110000014305115
Epoch 481, CIFAR-10 Batch 1:  Train_Loss:0.6769619584083557, Valid_Loss:1.2102752923965454, Valid_ACC:0.6141999363899231
Epoch 481, CIFAR-10 Batch 2:  Train_Loss:0.7253645658493042, Valid_Loss:1.2334152460098267, Valid_ACC:0.6025999784469604
Epoch 481, CIFAR-10 Batch 3:  Train_Loss:0.6837636232376099, Valid_Loss:1.2148464918136597, Valid_ACC:0.6091998815536499
Epoch 481, CIFAR-10 Batch 4:  Train_Loss:0.6917454600334167, Valid_Loss:1.2095251083374023, Valid_ACC:0.6129999160766602
Epoch 481, CIFAR-10 Batch 5:  Train_Loss:0.6846896409988403, Valid_Loss:1.218393325805664, Valid_ACC:0.6131999492645264
Epoch 482, CIFAR-10 Batch 1:  Train_Loss:0.6974878311157227, Valid_Loss:1.2157633304595947, Valid_ACC:0.6091999411582947
Epoch 482, CIFAR-10 Batch 2:  Train_Loss:0.6760985851287842, Valid_Loss:1.2121384143829346, Valid_ACC:0.6113998889923096
Epoch 482, CIFAR-10 Batch 3:  Train_Loss:0.6726890802383423, Valid_Loss:1.2057640552520752, Valid_ACC:0.6143998503684998
Epoch 482, CIFAR-10 Batch 4:  Train_Loss:0.7009636759757996, Valid_Loss:1.2204227447509766, Valid_ACC:0.6039999723434448
Epoch 482, CIFAR-10 Batch 5:  Train_Loss:0.7088180780410767, Valid_Loss:1.2560698986053467, Valid_ACC:0.6003999710083008
Epoch 483, CIFAR-10 Batch 1:  Train_Loss:0.6859617233276367, Valid_Loss:1.208528995513916, Valid_ACC:0.6101998686790466
Epoch 483, CIFAR-10 Batch 2:  Train_Loss:0.6891476511955261, Valid_Loss:1.2150108814239502, Valid_ACC:0.6117998957633972
Epoch 483, CIFAR-10 Batch 3:  Train_Loss:0.6806182861328125, Valid_Loss:1.210667371749878, Valid_ACC:0.6079999208450317
Epoch 483, CIFAR-10 Batch 4:  Train_Loss:0.6778420209884644, Valid_Loss:1.2097848653793335, Valid_ACC:0.6149998903274536
Epoch 483, CIFAR-10 Batch 5:  Train_Loss:0.6880891919136047, Valid_Loss:1.224592685699463, Valid_ACC:0.6047998666763306
Epoch 484, CIFAR-10 Batch 1:  Train_Loss:0.6790072321891785, Valid_Loss:1.217320203781128, Valid_ACC:0.6041998863220215
Epoch 484, CIFAR-10 Batch 2:  Train_Loss:0.6758766770362854, Valid_Loss:1.218421459197998, Valid_ACC:0.6095998883247375
Epoch 484, CIFAR-10 Batch 3:  Train_Loss:0.6775717735290527, Valid_Loss:1.202826976776123, Valid_ACC:0.6119999289512634
Epoch 484, CIFAR-10 Batch 4:  Train_Loss:0.6721127033233643, Valid_Loss:1.2194697856903076, Valid_ACC:0.6093997955322266
Epoch 484, CIFAR-10 Batch 5:  Train_Loss:0.6864185929298401, Valid_Loss:1.230493426322937, Valid_ACC:0.6077998876571655
Epoch 485, CIFAR-10 Batch 1:  Train_Loss:0.6948291063308716, Valid_Loss:1.2415671348571777, Valid_ACC:0.6041998863220215
Epoch 485, CIFAR-10 Batch 2:  Train_Loss:0.6869757771492004, Valid_Loss:1.224959135055542, Valid_ACC:0.6073999404907227
Epoch 485, CIFAR-10 Batch 3:  Train_Loss:0.6776042580604553, Valid_Loss:1.213194489479065, Valid_ACC:0.6095998883247375
Epoch 485, CIFAR-10 Batch 4:  Train_Loss:0.6629528999328613, Valid_Loss:1.2054951190948486, Valid_ACC:0.6135998964309692
Epoch 485, CIFAR-10 Batch 5:  Train_Loss:0.7158377766609192, Valid_Loss:1.2692524194717407, Valid_ACC:0.5927999019622803
Epoch 486, CIFAR-10 Batch 1:  Train_Loss:0.6781625151634216, Valid_Loss:1.208363652229309, Valid_ACC:0.6123998761177063
Epoch 486, CIFAR-10 Batch 2:  Train_Loss:0.6909496784210205, Valid_Loss:1.227468490600586, Valid_ACC:0.6075999736785889
Epoch 486, CIFAR-10 Batch 3:  Train_Loss:0.6915651559829712, Valid_Loss:1.2090309858322144, Valid_ACC:0.6123998761177063
Epoch 486, CIFAR-10 Batch 4:  Train_Loss:0.6858255863189697, Valid_Loss:1.213128685951233, Valid_ACC:0.6175998449325562
Epoch 486, CIFAR-10 Batch 5:  Train_Loss:0.6814995408058167, Valid_Loss:1.2310407161712646, Valid_ACC:0.6079999208450317
Epoch 487, CIFAR-10 Batch 1:  Train_Loss:0.663827121257782, Valid_Loss:1.2045239210128784, Valid_ACC:0.6125999093055725
Epoch 487, CIFAR-10 Batch 2:  Train_Loss:0.6771184802055359, Valid_Loss:1.220177173614502, Valid_ACC:0.609799861907959
Epoch 487, CIFAR-10 Batch 3:  Train_Loss:0.6889619827270508, Valid_Loss:1.213498830795288, Valid_ACC:0.6113999485969543
Epoch 487, CIFAR-10 Batch 4:  Train_Loss:0.68528813123703, Valid_Loss:1.2305893898010254, Valid_ACC:0.6055999398231506
Epoch 487, CIFAR-10 Batch 5:  Train_Loss:0.6911908388137817, Valid_Loss:1.233292579650879, Valid_ACC:0.6081998944282532
Epoch 488, CIFAR-10 Batch 1:  Train_Loss:0.6643824577331543, Valid_Loss:1.2173558473587036, Valid_ACC:0.60999995470047
Epoch 488, CIFAR-10 Batch 2:  Train_Loss:0.6681322455406189, Valid_Loss:1.2141038179397583, Valid_ACC:0.6109998822212219
Epoch 488, CIFAR-10 Batch 3:  Train_Loss:0.6791181564331055, Valid_Loss:1.2223771810531616, Valid_ACC:0.6113998889923096
Epoch 488, CIFAR-10 Batch 4:  Train_Loss:0.6775782108306885, Valid_Loss:1.2183036804199219, Valid_ACC:0.6089999079704285
Epoch 488, CIFAR-10 Batch 5:  Train_Loss:0.6804358959197998, Valid_Loss:1.2202380895614624, Valid_ACC:0.6139998435974121
Epoch 489, CIFAR-10 Batch 1:  Train_Loss:0.6798471212387085, Valid_Loss:1.220415472984314, Valid_ACC:0.6091999411582947
Epoch 489, CIFAR-10 Batch 2:  Train_Loss:0.6739593744277954, Valid_Loss:1.217771053314209, Valid_ACC:0.6111999154090881
Epoch 489, CIFAR-10 Batch 3:  Train_Loss:0.6752671599388123, Valid_Loss:1.2195764780044556, Valid_ACC:0.6085999011993408
Epoch 489, CIFAR-10 Batch 4:  Train_Loss:0.683480441570282, Valid_Loss:1.2333992719650269, Valid_ACC:0.6017999053001404
Epoch 489, CIFAR-10 Batch 5:  Train_Loss:0.6821666359901428, Valid_Loss:1.2321984767913818, Valid_ACC:0.6053999662399292
Epoch 490, CIFAR-10 Batch 1:  Train_Loss:0.6653525829315186, Valid_Loss:1.2208878993988037, Valid_ACC:0.6107999086380005
Epoch 490, CIFAR-10 Batch 2:  Train_Loss:0.6778396368026733, Valid_Loss:1.2221710681915283, Valid_ACC:0.6091998815536499
Epoch 490, CIFAR-10 Batch 3:  Train_Loss:0.6965407133102417, Valid_Loss:1.2195219993591309, Valid_ACC:0.6081998944282532
Epoch 490, CIFAR-10 Batch 4:  Train_Loss:0.6878421902656555, Valid_Loss:1.2322527170181274, Valid_ACC:0.6035999059677124
Epoch 490, CIFAR-10 Batch 5:  Train_Loss:0.686535656452179, Valid_Loss:1.2254401445388794, Valid_ACC:0.60999995470047
Epoch 491, CIFAR-10 Batch 1:  Train_Loss:0.6782830357551575, Valid_Loss:1.231550693511963, Valid_ACC:0.6053999662399292
Epoch 491, CIFAR-10 Batch 2:  Train_Loss:0.680242657661438, Valid_Loss:1.2264577150344849, Valid_ACC:0.6063998937606812
Epoch 491, CIFAR-10 Batch 3:  Train_Loss:0.6764605045318604, Valid_Loss:1.2141971588134766, Valid_ACC:0.6131998896598816
Epoch 491, CIFAR-10 Batch 4:  Train_Loss:0.6689258217811584, Valid_Loss:1.2123732566833496, Valid_ACC:0.6119998693466187
Epoch 491, CIFAR-10 Batch 5:  Train_Loss:0.6712362766265869, Valid_Loss:1.21567702293396, Valid_ACC:0.6147999167442322
Epoch 492, CIFAR-10 Batch 1:  Train_Loss:0.6804392337799072, Valid_Loss:1.2196789979934692, Valid_ACC:0.613399863243103
Epoch 492, CIFAR-10 Batch 2:  Train_Loss:0.6760966777801514, Valid_Loss:1.2332040071487427, Valid_ACC:0.606999933719635
Epoch 492, CIFAR-10 Batch 3:  Train_Loss:0.6619136929512024, Valid_Loss:1.2061171531677246, Valid_ACC:0.6131999492645264
Epoch 492, CIFAR-10 Batch 4:  Train_Loss:0.6635041236877441, Valid_Loss:1.2042334079742432, Valid_ACC:0.6159998774528503
Epoch 492, CIFAR-10 Batch 5:  Train_Loss:0.6731995344161987, Valid_Loss:1.235601544380188, Valid_ACC:0.6103999614715576
Epoch 493, CIFAR-10 Batch 1:  Train_Loss:0.6643530130386353, Valid_Loss:1.2114698886871338, Valid_ACC:0.6139999032020569
Epoch 493, CIFAR-10 Batch 2:  Train_Loss:0.6794445514678955, Valid_Loss:1.2189931869506836, Valid_ACC:0.6091998815536499
Epoch 493, CIFAR-10 Batch 3:  Train_Loss:0.686303973197937, Valid_Loss:1.2332885265350342, Valid_ACC:0.6085999011993408
Epoch 493, CIFAR-10 Batch 4:  Train_Loss:0.693988561630249, Valid_Loss:1.240478277206421, Valid_ACC:0.6041998863220215
Epoch 493, CIFAR-10 Batch 5:  Train_Loss:0.6957830190658569, Valid_Loss:1.2520718574523926, Valid_ACC:0.6003999710083008
Epoch 494, CIFAR-10 Batch 1:  Train_Loss:0.6885454654693604, Valid_Loss:1.2405692338943481, Valid_ACC:0.6013999581336975
Epoch 494, CIFAR-10 Batch 2:  Train_Loss:0.6693815588951111, Valid_Loss:1.221482515335083, Valid_ACC:0.6119998693466187
Epoch 494, CIFAR-10 Batch 3:  Train_Loss:0.6837981939315796, Valid_Loss:1.2192492485046387, Valid_ACC:0.6099998950958252
Epoch 494, CIFAR-10 Batch 4:  Train_Loss:0.6811814308166504, Valid_Loss:1.227383017539978, Valid_ACC:0.6029998660087585
Epoch 494, CIFAR-10 Batch 5:  Train_Loss:0.7292153835296631, Valid_Loss:1.2893010377883911, Valid_ACC:0.5869998931884766
Epoch 495, CIFAR-10 Batch 1:  Train_Loss:0.7104979157447815, Valid_Loss:1.2371561527252197, Valid_ACC:0.605199933052063
Epoch 495, CIFAR-10 Batch 2:  Train_Loss:0.7057995200157166, Valid_Loss:1.243936538696289, Valid_ACC:0.6023999452590942
Epoch 495, CIFAR-10 Batch 3:  Train_Loss:0.6853298544883728, Valid_Loss:1.2366214990615845, Valid_ACC:0.6085999011993408
Epoch 495, CIFAR-10 Batch 4:  Train_Loss:0.6789827942848206, Valid_Loss:1.218732237815857, Valid_ACC:0.6121999025344849
Epoch 495, CIFAR-10 Batch 5:  Train_Loss:0.7062526941299438, Valid_Loss:1.2503554821014404, Valid_ACC:0.6011998653411865
Epoch 496, CIFAR-10 Batch 1:  Train_Loss:0.6729137301445007, Valid_Loss:1.2114920616149902, Valid_ACC:0.6117998957633972
Epoch 496, CIFAR-10 Batch 2:  Train_Loss:0.665618360042572, Valid_Loss:1.2178738117218018, Valid_ACC:0.6107998490333557
Epoch 496, CIFAR-10 Batch 3:  Train_Loss:0.6877169013023376, Valid_Loss:1.2400670051574707, Valid_ACC:0.6069998741149902
Epoch 496, CIFAR-10 Batch 4:  Train_Loss:0.6805652379989624, Valid_Loss:1.231346607208252, Valid_ACC:0.6085999011993408
Epoch 496, CIFAR-10 Batch 5:  Train_Loss:0.6853010654449463, Valid_Loss:1.2267454862594604, Valid_ACC:0.6099998354911804
Epoch 497, CIFAR-10 Batch 1:  Train_Loss:0.6789613366127014, Valid_Loss:1.2310059070587158, Valid_ACC:0.6079999208450317
Epoch 497, CIFAR-10 Batch 2:  Train_Loss:0.6714778542518616, Valid_Loss:1.210373878479004, Valid_ACC:0.6107999086380005
Epoch 497, CIFAR-10 Batch 3:  Train_Loss:0.672766923904419, Valid_Loss:1.2210863828659058, Valid_ACC:0.6113999485969543
Epoch 497, CIFAR-10 Batch 4:  Train_Loss:0.6686501502990723, Valid_Loss:1.2231602668762207, Valid_ACC:0.6103999018669128
Epoch 497, CIFAR-10 Batch 5:  Train_Loss:0.6779515147209167, Valid_Loss:1.2276595830917358, Valid_ACC:0.6117998957633972
Epoch 498, CIFAR-10 Batch 1:  Train_Loss:0.6758095026016235, Valid_Loss:1.2138550281524658, Valid_ACC:0.6141998767852783
Epoch 498, CIFAR-10 Batch 2:  Train_Loss:0.6680482625961304, Valid_Loss:1.2262585163116455, Valid_ACC:0.6103999018669128
Epoch 498, CIFAR-10 Batch 3:  Train_Loss:0.6780887246131897, Valid_Loss:1.2221685647964478, Valid_ACC:0.6111999154090881
Epoch 498, CIFAR-10 Batch 4:  Train_Loss:0.6896565556526184, Valid_Loss:1.2274192571640015, Valid_ACC:0.6085999011993408
Epoch 498, CIFAR-10 Batch 5:  Train_Loss:0.6864026784896851, Valid_Loss:1.2441658973693848, Valid_ACC:0.6011999845504761
Epoch 499, CIFAR-10 Batch 1:  Train_Loss:0.6740407347679138, Valid_Loss:1.2193195819854736, Valid_ACC:0.6099998950958252
Epoch 499, CIFAR-10 Batch 2:  Train_Loss:0.6712789535522461, Valid_Loss:1.2100927829742432, Valid_ACC:0.6157999038696289
Epoch 499, CIFAR-10 Batch 3:  Train_Loss:0.6736937165260315, Valid_Loss:1.219120979309082, Valid_ACC:0.608799934387207
Epoch 499, CIFAR-10 Batch 4:  Train_Loss:0.6736699938774109, Valid_Loss:1.2202882766723633, Valid_ACC:0.6097999215126038
Epoch 499, CIFAR-10 Batch 5:  Train_Loss:0.6925306916236877, Valid_Loss:1.228285551071167, Valid_ACC:0.6089999079704285
Epoch 500, CIFAR-10 Batch 1:  Train_Loss:0.680862307548523, Valid_Loss:1.231709361076355, Valid_ACC:0.6073999404907227
Epoch 500, CIFAR-10 Batch 2:  Train_Loss:0.6912720203399658, Valid_Loss:1.241061806678772, Valid_ACC:0.6037998795509338
Epoch 500, CIFAR-10 Batch 3:  Train_Loss:0.6637159585952759, Valid_Loss:1.2154208421707153, Valid_ACC:0.6089999079704285
Epoch 500, CIFAR-10 Batch 4:  Train_Loss:0.6706772446632385, Valid_Loss:1.2143454551696777, Valid_ACC:0.6155999302864075
Epoch 500, CIFAR-10 Batch 5:  Train_Loss:0.6897494792938232, Valid_Loss:1.2417901754379272, Valid_ACC:0.6071999073028564
Epoch 501, CIFAR-10 Batch 1:  Train_Loss:0.6703431606292725, Valid_Loss:1.2115147113800049, Valid_ACC:0.6145999431610107
Epoch 501, CIFAR-10 Batch 2:  Train_Loss:0.6856528520584106, Valid_Loss:1.2242237329483032, Valid_ACC:0.6097999215126038
Epoch 501, CIFAR-10 Batch 3:  Train_Loss:0.668287456035614, Valid_Loss:1.2168370485305786, Valid_ACC:0.6049998998641968
Epoch 501, CIFAR-10 Batch 4:  Train_Loss:0.6682254076004028, Valid_Loss:1.212881088256836, Valid_ACC:0.6109999418258667
Epoch 501, CIFAR-10 Batch 5:  Train_Loss:0.6728611588478088, Valid_Loss:1.2181541919708252, Valid_ACC:0.6117998957633972
Epoch 502, CIFAR-10 Batch 1:  Train_Loss:0.6815292239189148, Valid_Loss:1.2340561151504517, Valid_ACC:0.6045998930931091
Epoch 502, CIFAR-10 Batch 2:  Train_Loss:0.6813434362411499, Valid_Loss:1.2246792316436768, Valid_ACC:0.606999933719635
Epoch 502, CIFAR-10 Batch 3:  Train_Loss:0.7024656534194946, Valid_Loss:1.2474242448806763, Valid_ACC:0.6007999181747437
Epoch 502, CIFAR-10 Batch 4:  Train_Loss:0.6653106808662415, Valid_Loss:1.2069365978240967, Valid_ACC:0.6121999025344849
Epoch 502, CIFAR-10 Batch 5:  Train_Loss:0.7168034315109253, Valid_Loss:1.265061855316162, Valid_ACC:0.5939998626708984
Epoch 503, CIFAR-10 Batch 1:  Train_Loss:0.6967564225196838, Valid_Loss:1.2301626205444336, Valid_ACC:0.603399932384491
Epoch 503, CIFAR-10 Batch 2:  Train_Loss:0.7048045992851257, Valid_Loss:1.2385611534118652, Valid_ACC:0.6075999140739441
Epoch 503, CIFAR-10 Batch 3:  Train_Loss:0.6657037138938904, Valid_Loss:1.2142117023468018, Valid_ACC:0.6125999093055725
Epoch 503, CIFAR-10 Batch 4:  Train_Loss:0.6572874784469604, Valid_Loss:1.2132048606872559, Valid_ACC:0.6183999180793762
Epoch 503, CIFAR-10 Batch 5:  Train_Loss:0.674567699432373, Valid_Loss:1.2334654331207275, Valid_ACC:0.6053999662399292
Epoch 504, CIFAR-10 Batch 1:  Train_Loss:0.664602518081665, Valid_Loss:1.2171562910079956, Valid_ACC:0.6081998944282532
Epoch 504, CIFAR-10 Batch 2:  Train_Loss:0.6711805462837219, Valid_Loss:1.219110131263733, Valid_ACC:0.6131998896598816
Epoch 504, CIFAR-10 Batch 3:  Train_Loss:0.6810676455497742, Valid_Loss:1.2267117500305176, Valid_ACC:0.609799861907959
Epoch 504, CIFAR-10 Batch 4:  Train_Loss:0.6591037511825562, Valid_Loss:1.2204065322875977, Valid_ACC:0.6107999086380005
Epoch 504, CIFAR-10 Batch 5:  Train_Loss:0.6740107536315918, Valid_Loss:1.2218912839889526, Valid_ACC:0.6103999018669128
Epoch 505, CIFAR-10 Batch 1:  Train_Loss:0.6701550483703613, Valid_Loss:1.214080572128296, Valid_ACC:0.6111999154090881
Epoch 505, CIFAR-10 Batch 2:  Train_Loss:0.6697450280189514, Valid_Loss:1.2188209295272827, Valid_ACC:0.6093999743461609
Epoch 505, CIFAR-10 Batch 3:  Train_Loss:0.677034854888916, Valid_Loss:1.2121704816818237, Valid_ACC:0.610599935054779
Epoch 505, CIFAR-10 Batch 4:  Train_Loss:0.664350688457489, Valid_Loss:1.22735595703125, Valid_ACC:0.608799934387207
Epoch 505, CIFAR-10 Batch 5:  Train_Loss:0.6806879043579102, Valid_Loss:1.2373607158660889, Valid_ACC:0.6037999391555786
Epoch 506, CIFAR-10 Batch 1:  Train_Loss:0.662898063659668, Valid_Loss:1.2231611013412476, Valid_ACC:0.6117998957633972
Epoch 506, CIFAR-10 Batch 2:  Train_Loss:0.6662478446960449, Valid_Loss:1.2139835357666016, Valid_ACC:0.6119999289512634
Epoch 506, CIFAR-10 Batch 3:  Train_Loss:0.6634750962257385, Valid_Loss:1.2090743780136108, Valid_ACC:0.6131998896598816
Epoch 506, CIFAR-10 Batch 4:  Train_Loss:0.6535059809684753, Valid_Loss:1.2062727212905884, Valid_ACC:0.615399956703186
Epoch 506, CIFAR-10 Batch 5:  Train_Loss:0.6788622140884399, Valid_Loss:1.2190234661102295, Valid_ACC:0.6123999357223511
Epoch 507, CIFAR-10 Batch 1:  Train_Loss:0.6753090023994446, Valid_Loss:1.2153204679489136, Valid_ACC:0.6107999086380005
Epoch 507, CIFAR-10 Batch 2:  Train_Loss:0.6638498306274414, Valid_Loss:1.2195723056793213, Valid_ACC:0.6107999086380005
Epoch 507, CIFAR-10 Batch 3:  Train_Loss:0.6759693622589111, Valid_Loss:1.2255507707595825, Valid_ACC:0.6071999073028564
Epoch 507, CIFAR-10 Batch 4:  Train_Loss:0.6594852805137634, Valid_Loss:1.2083220481872559, Valid_ACC:0.6175999045372009
Epoch 507, CIFAR-10 Batch 5:  Train_Loss:0.6822648048400879, Valid_Loss:1.23781418800354, Valid_ACC:0.6053999066352844
Epoch 508, CIFAR-10 Batch 1:  Train_Loss:0.6677451133728027, Valid_Loss:1.209486484527588, Valid_ACC:0.6137998700141907
Epoch 508, CIFAR-10 Batch 2:  Train_Loss:0.6609640717506409, Valid_Loss:1.213234782218933, Valid_ACC:0.6117998957633972
Epoch 508, CIFAR-10 Batch 3:  Train_Loss:0.6790115833282471, Valid_Loss:1.2235782146453857, Valid_ACC:0.6063998937606812
Epoch 508, CIFAR-10 Batch 4:  Train_Loss:0.6528796553611755, Valid_Loss:1.2060166597366333, Valid_ACC:0.6135998964309692
Epoch 508, CIFAR-10 Batch 5:  Train_Loss:0.6856584548950195, Valid_Loss:1.241140365600586, Valid_ACC:0.6039999723434448
Epoch 509, CIFAR-10 Batch 1:  Train_Loss:0.6660577654838562, Valid_Loss:1.2193927764892578, Valid_ACC:0.6089999079704285
Epoch 509, CIFAR-10 Batch 2:  Train_Loss:0.6772668957710266, Valid_Loss:1.2263314723968506, Valid_ACC:0.6107999086380005
Epoch 509, CIFAR-10 Batch 3:  Train_Loss:0.6852460503578186, Valid_Loss:1.2223135232925415, Valid_ACC:0.6099998950958252
Epoch 509, CIFAR-10 Batch 4:  Train_Loss:0.6737529635429382, Valid_Loss:1.2277815341949463, Valid_ACC:0.6095998883247375
Epoch 509, CIFAR-10 Batch 5:  Train_Loss:0.7058942317962646, Valid_Loss:1.2403564453125, Valid_ACC:0.6025999188423157
Epoch 510, CIFAR-10 Batch 1:  Train_Loss:0.6732376217842102, Valid_Loss:1.2298376560211182, Valid_ACC:0.6111998558044434
Epoch 510, CIFAR-10 Batch 2:  Train_Loss:0.6764458417892456, Valid_Loss:1.2341694831848145, Valid_ACC:0.6057999134063721
Epoch 510, CIFAR-10 Batch 3:  Train_Loss:0.6786997318267822, Valid_Loss:1.225053071975708, Valid_ACC:0.6035999059677124
Epoch 510, CIFAR-10 Batch 4:  Train_Loss:0.6589752435684204, Valid_Loss:1.215464472770691, Valid_ACC:0.6143999099731445
Epoch 510, CIFAR-10 Batch 5:  Train_Loss:0.6683972477912903, Valid_Loss:1.2260123491287231, Valid_ACC:0.6083998680114746
Epoch 511, CIFAR-10 Batch 1:  Train_Loss:0.6489280462265015, Valid_Loss:1.2073113918304443, Valid_ACC:0.6131998896598816
Epoch 511, CIFAR-10 Batch 2:  Train_Loss:0.6586791276931763, Valid_Loss:1.2151585817337036, Valid_ACC:0.6123999357223511
Epoch 511, CIFAR-10 Batch 3:  Train_Loss:0.664899468421936, Valid_Loss:1.2259668111801147, Valid_ACC:0.6065999269485474
Epoch 511, CIFAR-10 Batch 4:  Train_Loss:0.6749469041824341, Valid_Loss:1.2243167161941528, Valid_ACC:0.6085999011993408
Epoch 511, CIFAR-10 Batch 5:  Train_Loss:0.7375310063362122, Valid_Loss:1.2763497829437256, Valid_ACC:0.590999960899353
Epoch 512, CIFAR-10 Batch 1:  Train_Loss:0.6931878924369812, Valid_Loss:1.2360261678695679, Valid_ACC:0.6077999472618103
Epoch 512, CIFAR-10 Batch 2:  Train_Loss:0.6781332492828369, Valid_Loss:1.2268987894058228, Valid_ACC:0.6101999282836914
Epoch 512, CIFAR-10 Batch 3:  Train_Loss:0.6868219375610352, Valid_Loss:1.225470781326294, Valid_ACC:0.6073998808860779
Epoch 512, CIFAR-10 Batch 4:  Train_Loss:0.6772054433822632, Valid_Loss:1.2356603145599365, Valid_ACC:0.6057999134063721
Epoch 512, CIFAR-10 Batch 5:  Train_Loss:0.6964297294616699, Valid_Loss:1.2549293041229248, Valid_ACC:0.6001999378204346
Epoch 513, CIFAR-10 Batch 1:  Train_Loss:0.6819592714309692, Valid_Loss:1.2406820058822632, Valid_ACC:0.6073998808860779
Epoch 513, CIFAR-10 Batch 2:  Train_Loss:0.6809354424476624, Valid_Loss:1.2279462814331055, Valid_ACC:0.6055998802185059
Epoch 513, CIFAR-10 Batch 3:  Train_Loss:0.6761904954910278, Valid_Loss:1.2155463695526123, Valid_ACC:0.6117998957633972
Epoch 513, CIFAR-10 Batch 4:  Train_Loss:0.6905057430267334, Valid_Loss:1.2240889072418213, Valid_ACC:0.608799934387207
Epoch 513, CIFAR-10 Batch 5:  Train_Loss:0.6960196495056152, Valid_Loss:1.241086721420288, Valid_ACC:0.6053999066352844
Epoch 514, CIFAR-10 Batch 1:  Train_Loss:0.7143038511276245, Valid_Loss:1.2670891284942627, Valid_ACC:0.5959999561309814
Epoch 514, CIFAR-10 Batch 2:  Train_Loss:0.698689877986908, Valid_Loss:1.2259562015533447, Valid_ACC:0.6091999411582947
Epoch 514, CIFAR-10 Batch 3:  Train_Loss:0.6992971301078796, Valid_Loss:1.2372424602508545, Valid_ACC:0.6021998524665833
Epoch 514, CIFAR-10 Batch 4:  Train_Loss:0.7006697654724121, Valid_Loss:1.2347536087036133, Valid_ACC:0.6023999452590942
Epoch 514, CIFAR-10 Batch 5:  Train_Loss:0.6859098076820374, Valid_Loss:1.2255256175994873, Valid_ACC:0.6115999221801758
Epoch 515, CIFAR-10 Batch 1:  Train_Loss:0.6865167617797852, Valid_Loss:1.2337746620178223, Valid_ACC:0.6059998869895935
Epoch 515, CIFAR-10 Batch 2:  Train_Loss:0.695087730884552, Valid_Loss:1.228501796722412, Valid_ACC:0.6099998950958252
Epoch 515, CIFAR-10 Batch 3:  Train_Loss:0.68852299451828, Valid_Loss:1.2446891069412231, Valid_ACC:0.600399911403656
Epoch 515, CIFAR-10 Batch 4:  Train_Loss:0.6867085695266724, Valid_Loss:1.2319140434265137, Valid_ACC:0.6041998863220215
Epoch 515, CIFAR-10 Batch 5:  Train_Loss:0.6905006766319275, Valid_Loss:1.2411736249923706, Valid_ACC:0.6017999649047852
Epoch 516, CIFAR-10 Batch 1:  Train_Loss:0.6903223395347595, Valid_Loss:1.247446894645691, Valid_ACC:0.6055999398231506
Epoch 516, CIFAR-10 Batch 2:  Train_Loss:0.701114296913147, Valid_Loss:1.2208170890808105, Valid_ACC:0.6105998754501343
Epoch 516, CIFAR-10 Batch 3:  Train_Loss:0.6814201474189758, Valid_Loss:1.234724521636963, Valid_ACC:0.6083999276161194
Epoch 516, CIFAR-10 Batch 4:  Train_Loss:0.7154718041419983, Valid_Loss:1.2530536651611328, Valid_ACC:0.5981999039649963
Epoch 516, CIFAR-10 Batch 5:  Train_Loss:0.7772201299667358, Valid_Loss:1.2909059524536133, Valid_ACC:0.5915998816490173
Epoch 517, CIFAR-10 Batch 1:  Train_Loss:0.7275300025939941, Valid_Loss:1.2486655712127686, Valid_ACC:0.6031998991966248
Epoch 517, CIFAR-10 Batch 2:  Train_Loss:0.6983360052108765, Valid_Loss:1.226240873336792, Valid_ACC:0.6103999018669128
Epoch 517, CIFAR-10 Batch 3:  Train_Loss:0.6889427900314331, Valid_Loss:1.2346827983856201, Valid_ACC:0.6050000190734863
Epoch 517, CIFAR-10 Batch 4:  Train_Loss:0.6631419658660889, Valid_Loss:1.2161046266555786, Valid_ACC:0.6101999282836914
Epoch 517, CIFAR-10 Batch 5:  Train_Loss:0.6838260293006897, Valid_Loss:1.2261079549789429, Valid_ACC:0.610599935054779
Epoch 518, CIFAR-10 Batch 1:  Train_Loss:0.6684396266937256, Valid_Loss:1.2184120416641235, Valid_ACC:0.6065998673439026
Epoch 518, CIFAR-10 Batch 2:  Train_Loss:0.7111667990684509, Valid_Loss:1.232993721961975, Valid_ACC:0.6077998876571655
Epoch 518, CIFAR-10 Batch 3:  Train_Loss:0.6914929151535034, Valid_Loss:1.2408329248428345, Valid_ACC:0.6053999662399292
Epoch 518, CIFAR-10 Batch 4:  Train_Loss:0.6929648518562317, Valid_Loss:1.247849702835083, Valid_ACC:0.5987998843193054
Epoch 518, CIFAR-10 Batch 5:  Train_Loss:0.7231414318084717, Valid_Loss:1.260493516921997, Valid_ACC:0.6031998991966248
Epoch 519, CIFAR-10 Batch 1:  Train_Loss:0.6982631087303162, Valid_Loss:1.2490174770355225, Valid_ACC:0.6019999384880066
Epoch 519, CIFAR-10 Batch 2:  Train_Loss:0.7019355297088623, Valid_Loss:1.231722116470337, Valid_ACC:0.6091999411582947
Epoch 519, CIFAR-10 Batch 3:  Train_Loss:0.6884218454360962, Valid_Loss:1.2343899011611938, Valid_ACC:0.6057999134063721
Epoch 519, CIFAR-10 Batch 4:  Train_Loss:0.6991139650344849, Valid_Loss:1.237626075744629, Valid_ACC:0.6007999181747437
Epoch 519, CIFAR-10 Batch 5:  Train_Loss:0.7013707756996155, Valid_Loss:1.2502466440200806, Valid_ACC:0.6035998463630676
Epoch 520, CIFAR-10 Batch 1:  Train_Loss:0.6950736045837402, Valid_Loss:1.2217073440551758, Valid_ACC:0.6103999018669128
Epoch 520, CIFAR-10 Batch 2:  Train_Loss:0.6857963800430298, Valid_Loss:1.2324490547180176, Valid_ACC:0.6065999269485474
Epoch 520, CIFAR-10 Batch 3:  Train_Loss:0.686409592628479, Valid_Loss:1.2329155206680298, Valid_ACC:0.6051998734474182
Epoch 520, CIFAR-10 Batch 4:  Train_Loss:0.6921858787536621, Valid_Loss:1.2371270656585693, Valid_ACC:0.6013998985290527
Epoch 520, CIFAR-10 Batch 5:  Train_Loss:0.7027600407600403, Valid_Loss:1.241207480430603, Valid_ACC:0.6073999404907227
Epoch 521, CIFAR-10 Batch 1:  Train_Loss:0.6877737045288086, Valid_Loss:1.2217860221862793, Valid_ACC:0.6091998815536499
Epoch 521, CIFAR-10 Batch 2:  Train_Loss:0.7039616107940674, Valid_Loss:1.2389733791351318, Valid_ACC:0.6047999262809753
Epoch 521, CIFAR-10 Batch 3:  Train_Loss:0.695436954498291, Valid_Loss:1.2360146045684814, Valid_ACC:0.6007999181747437
Epoch 521, CIFAR-10 Batch 4:  Train_Loss:0.6759429574012756, Valid_Loss:1.223364233970642, Valid_ACC:0.6069998741149902
Epoch 521, CIFAR-10 Batch 5:  Train_Loss:0.6906808614730835, Valid_Loss:1.2463456392288208, Valid_ACC:0.6019999384880066
Epoch 522, CIFAR-10 Batch 1:  Train_Loss:0.6856408715248108, Valid_Loss:1.2347006797790527, Valid_ACC:0.6057999134063721
Epoch 522, CIFAR-10 Batch 2:  Train_Loss:0.6827459335327148, Valid_Loss:1.2184288501739502, Valid_ACC:0.6137998700141907
Epoch 522, CIFAR-10 Batch 3:  Train_Loss:0.6728582382202148, Valid_Loss:1.2312345504760742, Valid_ACC:0.6055998802185059
Epoch 522, CIFAR-10 Batch 4:  Train_Loss:0.6813559532165527, Valid_Loss:1.230933427810669, Valid_ACC:0.6065999269485474
Epoch 522, CIFAR-10 Batch 5:  Train_Loss:0.7021363377571106, Valid_Loss:1.2387279272079468, Valid_ACC:0.6083999276161194
Epoch 523, CIFAR-10 Batch 1:  Train_Loss:0.720708966255188, Valid_Loss:1.2379086017608643, Valid_ACC:0.6101998686790466
Epoch 523, CIFAR-10 Batch 2:  Train_Loss:0.7193455696105957, Valid_Loss:1.2605854272842407, Valid_ACC:0.6005999445915222
Epoch 523, CIFAR-10 Batch 3:  Train_Loss:0.710602879524231, Valid_Loss:1.232956886291504, Valid_ACC:0.602199912071228
Epoch 523, CIFAR-10 Batch 4:  Train_Loss:0.6860833764076233, Valid_Loss:1.2254060506820679, Valid_ACC:0.608599841594696
Epoch 523, CIFAR-10 Batch 5:  Train_Loss:0.6975305080413818, Valid_Loss:1.2468163967132568, Valid_ACC:0.6003998517990112
Epoch 524, CIFAR-10 Batch 1:  Train_Loss:0.745709240436554, Valid_Loss:1.2479976415634155, Valid_ACC:0.6013998985290527
Epoch 524, CIFAR-10 Batch 2:  Train_Loss:0.699431300163269, Valid_Loss:1.2475978136062622, Valid_ACC:0.5995998978614807
Epoch 524, CIFAR-10 Batch 3:  Train_Loss:0.7104191184043884, Valid_Loss:1.2560557126998901, Valid_ACC:0.5959999561309814
Epoch 524, CIFAR-10 Batch 4:  Train_Loss:0.6956944465637207, Valid_Loss:1.2298758029937744, Valid_ACC:0.608799934387207
Epoch 524, CIFAR-10 Batch 5:  Train_Loss:0.7148642539978027, Valid_Loss:1.2340949773788452, Valid_ACC:0.610599935054779
Epoch 525, CIFAR-10 Batch 1:  Train_Loss:0.7845977544784546, Valid_Loss:1.2901352643966675, Valid_ACC:0.5887999534606934
Epoch 525, CIFAR-10 Batch 2:  Train_Loss:0.7059102058410645, Valid_Loss:1.2326762676239014, Valid_ACC:0.6083999276161194
Epoch 525, CIFAR-10 Batch 3:  Train_Loss:0.6888698935508728, Valid_Loss:1.2348203659057617, Valid_ACC:0.6029999256134033
Epoch 525, CIFAR-10 Batch 4:  Train_Loss:0.6778081059455872, Valid_Loss:1.2284412384033203, Valid_ACC:0.6071999073028564
Epoch 525, CIFAR-10 Batch 5:  Train_Loss:0.6795571446418762, Valid_Loss:1.226898193359375, Valid_ACC:0.6099998950958252
Epoch 526, CIFAR-10 Batch 1:  Train_Loss:0.6756646037101746, Valid_Loss:1.2097512483596802, Valid_ACC:0.6149998903274536
Epoch 526, CIFAR-10 Batch 2:  Train_Loss:0.6643590331077576, Valid_Loss:1.2140429019927979, Valid_ACC:0.6141999363899231
Epoch 526, CIFAR-10 Batch 3:  Train_Loss:0.6831657290458679, Valid_Loss:1.2319189310073853, Valid_ACC:0.6085999608039856
Epoch 526, CIFAR-10 Batch 4:  Train_Loss:0.6601736545562744, Valid_Loss:1.212701439857483, Valid_ACC:0.6129999160766602
Epoch 526, CIFAR-10 Batch 5:  Train_Loss:0.6754984855651855, Valid_Loss:1.2276395559310913, Valid_ACC:0.6091998815536499
Epoch 527, CIFAR-10 Batch 1:  Train_Loss:0.6712514758110046, Valid_Loss:1.2210204601287842, Valid_ACC:0.6095998883247375
Epoch 527, CIFAR-10 Batch 2:  Train_Loss:0.6585513353347778, Valid_Loss:1.2176964282989502, Valid_ACC:0.6115999221801758
Epoch 527, CIFAR-10 Batch 3:  Train_Loss:0.6555906534194946, Valid_Loss:1.2123388051986694, Valid_ACC:0.6105998754501343
Epoch 527, CIFAR-10 Batch 4:  Train_Loss:0.6569649577140808, Valid_Loss:1.2237468957901, Valid_ACC:0.6091998815536499
Epoch 527, CIFAR-10 Batch 5:  Train_Loss:0.6789044737815857, Valid_Loss:1.23189115524292, Valid_ACC:0.6097999811172485
Epoch 528, CIFAR-10 Batch 1:  Train_Loss:0.6999202966690063, Valid_Loss:1.2394667863845825, Valid_ACC:0.6031999588012695
Epoch 528, CIFAR-10 Batch 2:  Train_Loss:0.6728695631027222, Valid_Loss:1.2296665906906128, Valid_ACC:0.6101998686790466
Epoch 528, CIFAR-10 Batch 3:  Train_Loss:0.6679577231407166, Valid_Loss:1.220890998840332, Valid_ACC:0.6091998815536499
Epoch 528, CIFAR-10 Batch 4:  Train_Loss:0.6940045952796936, Valid_Loss:1.2397241592407227, Valid_ACC:0.6063998937606812
Epoch 528, CIFAR-10 Batch 5:  Train_Loss:0.6774768829345703, Valid_Loss:1.2363636493682861, Valid_ACC:0.6065999269485474
Epoch 529, CIFAR-10 Batch 1:  Train_Loss:0.6845453977584839, Valid_Loss:1.2334409952163696, Valid_ACC:0.6057999134063721
Epoch 529, CIFAR-10 Batch 2:  Train_Loss:0.6779686212539673, Valid_Loss:1.2272124290466309, Valid_ACC:0.6103999018669128
Epoch 529, CIFAR-10 Batch 3:  Train_Loss:0.6631572246551514, Valid_Loss:1.2226295471191406, Valid_ACC:0.609799861907959
Epoch 529, CIFAR-10 Batch 4:  Train_Loss:0.6685323715209961, Valid_Loss:1.2330693006515503, Valid_ACC:0.6067999005317688
Epoch 529, CIFAR-10 Batch 5:  Train_Loss:0.6934787034988403, Valid_Loss:1.236533761024475, Valid_ACC:0.6069999933242798
Epoch 530, CIFAR-10 Batch 1:  Train_Loss:0.6728204488754272, Valid_Loss:1.2286747694015503, Valid_ACC:0.6089999079704285
Epoch 530, CIFAR-10 Batch 2:  Train_Loss:0.6813884973526001, Valid_Loss:1.2327312231063843, Valid_ACC:0.6077998876571655
Epoch 530, CIFAR-10 Batch 3:  Train_Loss:0.6737610101699829, Valid_Loss:1.2305502891540527, Valid_ACC:0.6045998930931091
Epoch 530, CIFAR-10 Batch 4:  Train_Loss:0.7102254033088684, Valid_Loss:1.2506436109542847, Valid_ACC:0.5995998978614807
Epoch 530, CIFAR-10 Batch 5:  Train_Loss:0.7148552536964417, Valid_Loss:1.2519501447677612, Valid_ACC:0.6065999269485474
Epoch 531, CIFAR-10 Batch 1:  Train_Loss:0.6903978586196899, Valid_Loss:1.236794114112854, Valid_ACC:0.6079999208450317
Epoch 531, CIFAR-10 Batch 2:  Train_Loss:0.6991510391235352, Valid_Loss:1.243212342262268, Valid_ACC:0.5995999574661255
Epoch 531, CIFAR-10 Batch 3:  Train_Loss:0.6871997117996216, Valid_Loss:1.2366981506347656, Valid_ACC:0.6071999669075012
Epoch 531, CIFAR-10 Batch 4:  Train_Loss:0.6876230835914612, Valid_Loss:1.2307403087615967, Valid_ACC:0.6035999059677124
Epoch 531, CIFAR-10 Batch 5:  Train_Loss:0.6745169162750244, Valid_Loss:1.2335540056228638, Valid_ACC:0.6077998876571655
Epoch 532, CIFAR-10 Batch 1:  Train_Loss:0.7174786329269409, Valid_Loss:1.240430235862732, Valid_ACC:0.6067999005317688
Epoch 532, CIFAR-10 Batch 2:  Train_Loss:0.6642997860908508, Valid_Loss:1.217802882194519, Valid_ACC:0.6091998815536499
Epoch 532, CIFAR-10 Batch 3:  Train_Loss:0.7012733221054077, Valid_Loss:1.2367695569992065, Valid_ACC:0.6009998917579651
Epoch 532, CIFAR-10 Batch 4:  Train_Loss:0.6810659170150757, Valid_Loss:1.2223442792892456, Valid_ACC:0.6077999472618103
Epoch 532, CIFAR-10 Batch 5:  Train_Loss:0.6663120985031128, Valid_Loss:1.2164989709854126, Valid_ACC:0.6141999363899231
Epoch 533, CIFAR-10 Batch 1:  Train_Loss:0.6995266675949097, Valid_Loss:1.2417726516723633, Valid_ACC:0.6067999005317688
Epoch 533, CIFAR-10 Batch 2:  Train_Loss:0.6821669340133667, Valid_Loss:1.2390892505645752, Valid_ACC:0.6055998802185059
Epoch 533, CIFAR-10 Batch 3:  Train_Loss:0.6954227685928345, Valid_Loss:1.2466883659362793, Valid_ACC:0.5995998978614807
Epoch 533, CIFAR-10 Batch 4:  Train_Loss:0.6738235950469971, Valid_Loss:1.22142493724823, Valid_ACC:0.6123998761177063
Epoch 533, CIFAR-10 Batch 5:  Train_Loss:0.6963348984718323, Valid_Loss:1.2372233867645264, Valid_ACC:0.6109998226165771
Epoch 534, CIFAR-10 Batch 1:  Train_Loss:0.719109833240509, Valid_Loss:1.242157220840454, Valid_ACC:0.6095999479293823
Epoch 534, CIFAR-10 Batch 2:  Train_Loss:0.6991680860519409, Valid_Loss:1.2457963228225708, Valid_ACC:0.6027998924255371
Epoch 534, CIFAR-10 Batch 3:  Train_Loss:0.675931453704834, Valid_Loss:1.2318065166473389, Valid_ACC:0.6083998680114746
Epoch 534, CIFAR-10 Batch 4:  Train_Loss:0.6689557433128357, Valid_Loss:1.2220591306686401, Valid_ACC:0.6073998808860779
Epoch 534, CIFAR-10 Batch 5:  Train_Loss:0.6703141927719116, Valid_Loss:1.222224235534668, Valid_ACC:0.6103999614715576
Epoch 535, CIFAR-10 Batch 1:  Train_Loss:0.7212437987327576, Valid_Loss:1.2486538887023926, Valid_ACC:0.6049998998641968
Epoch 535, CIFAR-10 Batch 2:  Train_Loss:0.6620044708251953, Valid_Loss:1.2161924839019775, Valid_ACC:0.6111999154090881
Epoch 535, CIFAR-10 Batch 3:  Train_Loss:0.6655331254005432, Valid_Loss:1.219287395477295, Valid_ACC:0.6119999289512634
Epoch 535, CIFAR-10 Batch 4:  Train_Loss:0.6551588177680969, Valid_Loss:1.2136127948760986, Valid_ACC:0.614599883556366
Epoch 535, CIFAR-10 Batch 5:  Train_Loss:0.6879547238349915, Valid_Loss:1.2358782291412354, Valid_ACC:0.608799934387207
Epoch 536, CIFAR-10 Batch 1:  Train_Loss:0.7034440040588379, Valid_Loss:1.234686255455017, Valid_ACC:0.6119999289512634
Epoch 536, CIFAR-10 Batch 2:  Train_Loss:0.6669248342514038, Valid_Loss:1.2169138193130493, Valid_ACC:0.6129999160766602
Epoch 536, CIFAR-10 Batch 3:  Train_Loss:0.6833536624908447, Valid_Loss:1.2308918237686157, Valid_ACC:0.6017999053001404
Epoch 536, CIFAR-10 Batch 4:  Train_Loss:0.6683142185211182, Valid_Loss:1.2173179388046265, Valid_ACC:0.6109999418258667
Epoch 536, CIFAR-10 Batch 5:  Train_Loss:0.6735507249832153, Valid_Loss:1.2113513946533203, Valid_ACC:0.6165999174118042
Epoch 537, CIFAR-10 Batch 1:  Train_Loss:0.7058792114257812, Valid_Loss:1.2357481718063354, Valid_ACC:0.6059998869895935
Epoch 537, CIFAR-10 Batch 2:  Train_Loss:0.6792170405387878, Valid_Loss:1.2351120710372925, Valid_ACC:0.6061999201774597
Epoch 537, CIFAR-10 Batch 3:  Train_Loss:0.6731924414634705, Valid_Loss:1.2344911098480225, Valid_ACC:0.6059999465942383
Epoch 537, CIFAR-10 Batch 4:  Train_Loss:0.6802982091903687, Valid_Loss:1.227437973022461, Valid_ACC:0.608799934387207
Epoch 537, CIFAR-10 Batch 5:  Train_Loss:0.6909925937652588, Valid_Loss:1.2322615385055542, Valid_ACC:0.6119999289512634
Epoch 538, CIFAR-10 Batch 1:  Train_Loss:0.7012928128242493, Valid_Loss:1.2431881427764893, Valid_ACC:0.6071999073028564
Epoch 538, CIFAR-10 Batch 2:  Train_Loss:0.7135906219482422, Valid_Loss:1.2487151622772217, Valid_ACC:0.6023998856544495
Epoch 538, CIFAR-10 Batch 3:  Train_Loss:0.6882652640342712, Valid_Loss:1.2435379028320312, Valid_ACC:0.6013998985290527
Epoch 538, CIFAR-10 Batch 4:  Train_Loss:0.7011255025863647, Valid_Loss:1.2339937686920166, Valid_ACC:0.6065999269485474
Epoch 538, CIFAR-10 Batch 5:  Train_Loss:0.6970723867416382, Valid_Loss:1.2181780338287354, Valid_ACC:0.6109998822212219
Epoch 539, CIFAR-10 Batch 1:  Train_Loss:0.7066309452056885, Valid_Loss:1.2325960397720337, Valid_ACC:0.6125999093055725
Epoch 539, CIFAR-10 Batch 2:  Train_Loss:0.704129695892334, Valid_Loss:1.250860571861267, Valid_ACC:0.6035999059677124
Epoch 539, CIFAR-10 Batch 3:  Train_Loss:0.6783650517463684, Valid_Loss:1.2208244800567627, Valid_ACC:0.6125999093055725
Epoch 539, CIFAR-10 Batch 4:  Train_Loss:0.673515796661377, Valid_Loss:1.2208998203277588, Valid_ACC:0.6125999689102173
Epoch 539, CIFAR-10 Batch 5:  Train_Loss:0.6791700124740601, Valid_Loss:1.2162582874298096, Valid_ACC:0.615199863910675
Epoch 540, CIFAR-10 Batch 1:  Train_Loss:0.7034236788749695, Valid_Loss:1.2395442724227905, Valid_ACC:0.6043999195098877
Epoch 540, CIFAR-10 Batch 2:  Train_Loss:0.6976824998855591, Valid_Loss:1.249656319618225, Valid_ACC:0.6037998795509338
Epoch 540, CIFAR-10 Batch 3:  Train_Loss:0.6678040027618408, Valid_Loss:1.2262409925460815, Valid_ACC:0.6055998802185059
Epoch 540, CIFAR-10 Batch 4:  Train_Loss:0.6775012612342834, Valid_Loss:1.233203411102295, Valid_ACC:0.6077999472618103
Epoch 540, CIFAR-10 Batch 5:  Train_Loss:0.6651881337165833, Valid_Loss:1.2161622047424316, Valid_ACC:0.6159998774528503
Epoch 541, CIFAR-10 Batch 1:  Train_Loss:0.7262626886367798, Valid_Loss:1.239490270614624, Valid_ACC:0.608199954032898
Epoch 541, CIFAR-10 Batch 2:  Train_Loss:0.6815471649169922, Valid_Loss:1.2315651178359985, Valid_ACC:0.602199912071228
Epoch 541, CIFAR-10 Batch 3:  Train_Loss:0.6869531273841858, Valid_Loss:1.2277768850326538, Valid_ACC:0.6067999601364136
Epoch 541, CIFAR-10 Batch 4:  Train_Loss:0.6744141578674316, Valid_Loss:1.2230842113494873, Valid_ACC:0.6095998883247375
Epoch 541, CIFAR-10 Batch 5:  Train_Loss:0.690526008605957, Valid_Loss:1.2336264848709106, Valid_ACC:0.6097999215126038
Epoch 542, CIFAR-10 Batch 1:  Train_Loss:0.6893511414527893, Valid_Loss:1.2288627624511719, Valid_ACC:0.6111999154090881
Epoch 542, CIFAR-10 Batch 2:  Train_Loss:0.6956322193145752, Valid_Loss:1.240190863609314, Valid_ACC:0.6081998944282532
Epoch 542, CIFAR-10 Batch 3:  Train_Loss:0.6762107610702515, Valid_Loss:1.2274668216705322, Valid_ACC:0.6095999479293823
Epoch 542, CIFAR-10 Batch 4:  Train_Loss:0.6629813313484192, Valid_Loss:1.2157323360443115, Valid_ACC:0.6107998490333557
Epoch 542, CIFAR-10 Batch 5:  Train_Loss:0.6779171228408813, Valid_Loss:1.2303190231323242, Valid_ACC:0.6053999066352844
Epoch 543, CIFAR-10 Batch 1:  Train_Loss:0.6786724328994751, Valid_Loss:1.220528483390808, Valid_ACC:0.60999995470047
Epoch 543, CIFAR-10 Batch 2:  Train_Loss:0.6869174838066101, Valid_Loss:1.2396445274353027, Valid_ACC:0.6007999181747437
Epoch 543, CIFAR-10 Batch 3:  Train_Loss:0.6776360273361206, Valid_Loss:1.2310168743133545, Valid_ACC:0.6059998869895935
Epoch 543, CIFAR-10 Batch 4:  Train_Loss:0.6727900505065918, Valid_Loss:1.217439889907837, Valid_ACC:0.6131998896598816
Epoch 543, CIFAR-10 Batch 5:  Train_Loss:0.6725364923477173, Valid_Loss:1.2198530435562134, Valid_ACC:0.6141999363899231
Epoch 544, CIFAR-10 Batch 1:  Train_Loss:0.6605746746063232, Valid_Loss:1.210134744644165, Valid_ACC:0.6167999505996704
Epoch 544, CIFAR-10 Batch 2:  Train_Loss:0.6835206151008606, Valid_Loss:1.2334882020950317, Valid_ACC:0.6071998476982117
Epoch 544, CIFAR-10 Batch 3:  Train_Loss:0.6538177132606506, Valid_Loss:1.2184123992919922, Valid_ACC:0.6083999276161194
Epoch 544, CIFAR-10 Batch 4:  Train_Loss:0.6695187091827393, Valid_Loss:1.222275972366333, Valid_ACC:0.6091999411582947
Epoch 544, CIFAR-10 Batch 5:  Train_Loss:0.705076277256012, Valid_Loss:1.2353016138076782, Valid_ACC:0.6073998808860779
Epoch 545, CIFAR-10 Batch 1:  Train_Loss:0.6617543697357178, Valid_Loss:1.2075836658477783, Valid_ACC:0.6205999255180359
Epoch 545, CIFAR-10 Batch 2:  Train_Loss:0.6772002577781677, Valid_Loss:1.2208162546157837, Valid_ACC:0.6093999147415161
Epoch 545, CIFAR-10 Batch 3:  Train_Loss:0.682796835899353, Valid_Loss:1.2279396057128906, Valid_ACC:0.610599935054779
Epoch 545, CIFAR-10 Batch 4:  Train_Loss:0.6640930771827698, Valid_Loss:1.2152972221374512, Valid_ACC:0.6101999282836914
Epoch 545, CIFAR-10 Batch 5:  Train_Loss:0.66961669921875, Valid_Loss:1.2171392440795898, Valid_ACC:0.6117998957633972
Epoch 546, CIFAR-10 Batch 1:  Train_Loss:0.658930778503418, Valid_Loss:1.2112599611282349, Valid_ACC:0.6143999695777893
Epoch 546, CIFAR-10 Batch 2:  Train_Loss:0.6596460938453674, Valid_Loss:1.2130801677703857, Valid_ACC:0.6125998497009277
Epoch 546, CIFAR-10 Batch 3:  Train_Loss:0.6715276837348938, Valid_Loss:1.2357628345489502, Valid_ACC:0.6075999140739441
Epoch 546, CIFAR-10 Batch 4:  Train_Loss:0.6687362194061279, Valid_Loss:1.2252588272094727, Valid_ACC:0.6113999485969543
Epoch 546, CIFAR-10 Batch 5:  Train_Loss:0.6962145566940308, Valid_Loss:1.242106318473816, Valid_ACC:0.607999861240387
Epoch 547, CIFAR-10 Batch 1:  Train_Loss:0.6625350117683411, Valid_Loss:1.20842444896698, Valid_ACC:0.6129999160766602
Epoch 547, CIFAR-10 Batch 2:  Train_Loss:0.6699480414390564, Valid_Loss:1.2342838048934937, Valid_ACC:0.6077998876571655
Epoch 547, CIFAR-10 Batch 3:  Train_Loss:0.6662184000015259, Valid_Loss:1.2175263166427612, Valid_ACC:0.612799882888794
Epoch 547, CIFAR-10 Batch 4:  Train_Loss:0.6686599254608154, Valid_Loss:1.2190806865692139, Valid_ACC:0.6131998896598816
Epoch 547, CIFAR-10 Batch 5:  Train_Loss:0.6778777241706848, Valid_Loss:1.232094407081604, Valid_ACC:0.6073999404907227
Epoch 548, CIFAR-10 Batch 1:  Train_Loss:0.7007798552513123, Valid_Loss:1.233736276626587, Valid_ACC:0.6073998808860779
Epoch 548, CIFAR-10 Batch 2:  Train_Loss:0.6835827827453613, Valid_Loss:1.228540301322937, Valid_ACC:0.6065999269485474
Epoch 548, CIFAR-10 Batch 3:  Train_Loss:0.6581138372421265, Valid_Loss:1.2072902917861938, Valid_ACC:0.6101998686790466
Epoch 548, CIFAR-10 Batch 4:  Train_Loss:0.6585001945495605, Valid_Loss:1.2145377397537231, Valid_ACC:0.6129999160766602
Epoch 548, CIFAR-10 Batch 5:  Train_Loss:0.6656625866889954, Valid_Loss:1.223666787147522, Valid_ACC:0.6071999669075012
Epoch 549, CIFAR-10 Batch 1:  Train_Loss:0.6673258543014526, Valid_Loss:1.2191548347473145, Valid_ACC:0.6153998970985413
Epoch 549, CIFAR-10 Batch 2:  Train_Loss:0.6651901006698608, Valid_Loss:1.2231223583221436, Valid_ACC:0.6121999025344849
Epoch 549, CIFAR-10 Batch 3:  Train_Loss:0.6591535806655884, Valid_Loss:1.218115210533142, Valid_ACC:0.6093999147415161
Epoch 549, CIFAR-10 Batch 4:  Train_Loss:0.6715784072875977, Valid_Loss:1.2245956659317017, Valid_ACC:0.6121999025344849
Epoch 549, CIFAR-10 Batch 5:  Train_Loss:0.671597957611084, Valid_Loss:1.2143478393554688, Valid_ACC:0.6131999492645264
Epoch 550, CIFAR-10 Batch 1:  Train_Loss:0.6533167958259583, Valid_Loss:1.2056972980499268, Valid_ACC:0.6161998510360718
Epoch 550, CIFAR-10 Batch 2:  Train_Loss:0.6929041743278503, Valid_Loss:1.234278917312622, Valid_ACC:0.6085999011993408
Epoch 550, CIFAR-10 Batch 3:  Train_Loss:0.6576486825942993, Valid_Loss:1.2168790102005005, Valid_ACC:0.6129998564720154
Epoch 550, CIFAR-10 Batch 4:  Train_Loss:0.6655081510543823, Valid_Loss:1.2107250690460205, Valid_ACC:0.6151999235153198
Epoch 550, CIFAR-10 Batch 5:  Train_Loss:0.6752504110336304, Valid_Loss:1.2384577989578247, Valid_ACC:0.6061999797821045
Epoch 551, CIFAR-10 Batch 1:  Train_Loss:0.6532586812973022, Valid_Loss:1.2133259773254395, Valid_ACC:0.6109999418258667
Epoch 551, CIFAR-10 Batch 2:  Train_Loss:0.6481141448020935, Valid_Loss:1.2120391130447388, Valid_ACC:0.6189998984336853
Epoch 551, CIFAR-10 Batch 3:  Train_Loss:0.6511433124542236, Valid_Loss:1.2144125699996948, Valid_ACC:0.6095998883247375
Epoch 551, CIFAR-10 Batch 4:  Train_Loss:0.6542841792106628, Valid_Loss:1.2146625518798828, Valid_ACC:0.6127999424934387
Epoch 551, CIFAR-10 Batch 5:  Train_Loss:0.6607886552810669, Valid_Loss:1.219909906387329, Valid_ACC:0.6103999018669128
Epoch 552, CIFAR-10 Batch 1:  Train_Loss:0.6508586406707764, Valid_Loss:1.2086504697799683, Valid_ACC:0.612799882888794
Epoch 552, CIFAR-10 Batch 2:  Train_Loss:0.6688063144683838, Valid_Loss:1.2300195693969727, Valid_ACC:0.608199954032898
Epoch 552, CIFAR-10 Batch 3:  Train_Loss:0.645823061466217, Valid_Loss:1.2082436084747314, Valid_ACC:0.6157999038696289
Epoch 552, CIFAR-10 Batch 4:  Train_Loss:0.6601754426956177, Valid_Loss:1.2086073160171509, Valid_ACC:0.6149998903274536
Epoch 552, CIFAR-10 Batch 5:  Train_Loss:0.6589412689208984, Valid_Loss:1.2180509567260742, Valid_ACC:0.6141998767852783
Epoch 553, CIFAR-10 Batch 1:  Train_Loss:0.651841402053833, Valid_Loss:1.2108553647994995, Valid_ACC:0.6159998774528503
Epoch 553, CIFAR-10 Batch 2:  Train_Loss:0.6513428092002869, Valid_Loss:1.206852674484253, Valid_ACC:0.6135998368263245
Epoch 553, CIFAR-10 Batch 3:  Train_Loss:0.6483359336853027, Valid_Loss:1.2133854627609253, Valid_ACC:0.614599883556366
Epoch 553, CIFAR-10 Batch 4:  Train_Loss:0.6449704170227051, Valid_Loss:1.211851954460144, Valid_ACC:0.6155999302864075
Epoch 553, CIFAR-10 Batch 5:  Train_Loss:0.65641188621521, Valid_Loss:1.209808588027954, Valid_ACC:0.6149998903274536
Epoch 554, CIFAR-10 Batch 1:  Train_Loss:0.6590409278869629, Valid_Loss:1.2191994190216064, Valid_ACC:0.6139999628067017
Epoch 554, CIFAR-10 Batch 2:  Train_Loss:0.659711480140686, Valid_Loss:1.2196528911590576, Valid_ACC:0.6097999811172485
Epoch 554, CIFAR-10 Batch 3:  Train_Loss:0.660082221031189, Valid_Loss:1.2306437492370605, Valid_ACC:0.611799955368042
Epoch 554, CIFAR-10 Batch 4:  Train_Loss:0.6516082286834717, Valid_Loss:1.2105908393859863, Valid_ACC:0.6171999573707581
Epoch 554, CIFAR-10 Batch 5:  Train_Loss:0.6601992845535278, Valid_Loss:1.217481017112732, Valid_ACC:0.6123999357223511
Epoch 555, CIFAR-10 Batch 1:  Train_Loss:0.651179313659668, Valid_Loss:1.2052292823791504, Valid_ACC:0.6149998903274536
Epoch 555, CIFAR-10 Batch 2:  Train_Loss:0.6481856107711792, Valid_Loss:1.2169814109802246, Valid_ACC:0.6131998896598816
Epoch 555, CIFAR-10 Batch 3:  Train_Loss:0.6492680311203003, Valid_Loss:1.224274754524231, Valid_ACC:0.6081998944282532
Epoch 555, CIFAR-10 Batch 4:  Train_Loss:0.6455848813056946, Valid_Loss:1.2132443189620972, Valid_ACC:0.6131998896598816
Epoch 555, CIFAR-10 Batch 5:  Train_Loss:0.6784235239028931, Valid_Loss:1.2265369892120361, Valid_ACC:0.6113998889923096
Epoch 556, CIFAR-10 Batch 1:  Train_Loss:0.660567581653595, Valid_Loss:1.2123676538467407, Valid_ACC:0.61819988489151
Epoch 556, CIFAR-10 Batch 2:  Train_Loss:0.6399247050285339, Valid_Loss:1.213444471359253, Valid_ACC:0.6159999370574951
Epoch 556, CIFAR-10 Batch 3:  Train_Loss:0.6560264825820923, Valid_Loss:1.2099593877792358, Valid_ACC:0.6135998964309692
Epoch 556, CIFAR-10 Batch 4:  Train_Loss:0.6445035338401794, Valid_Loss:1.208360195159912, Valid_ACC:0.6137999296188354
Epoch 556, CIFAR-10 Batch 5:  Train_Loss:0.6713180541992188, Valid_Loss:1.2288838624954224, Valid_ACC:0.6071999073028564
Epoch 557, CIFAR-10 Batch 1:  Train_Loss:0.6432433724403381, Valid_Loss:1.1970771551132202, Valid_ACC:0.6209999322891235
Epoch 557, CIFAR-10 Batch 2:  Train_Loss:0.6426885724067688, Valid_Loss:1.2129734754562378, Valid_ACC:0.611799955368042
Epoch 557, CIFAR-10 Batch 3:  Train_Loss:0.659349799156189, Valid_Loss:1.2201157808303833, Valid_ACC:0.607999861240387
Epoch 557, CIFAR-10 Batch 4:  Train_Loss:0.6494304537773132, Valid_Loss:1.212146282196045, Valid_ACC:0.6139999032020569
Epoch 557, CIFAR-10 Batch 5:  Train_Loss:0.6667681336402893, Valid_Loss:1.215064287185669, Valid_ACC:0.6147998571395874
Epoch 558, CIFAR-10 Batch 1:  Train_Loss:0.6475876569747925, Valid_Loss:1.2026591300964355, Valid_ACC:0.6181999444961548
Epoch 558, CIFAR-10 Batch 2:  Train_Loss:0.6506555080413818, Valid_Loss:1.214282512664795, Valid_ACC:0.6093999147415161
Epoch 558, CIFAR-10 Batch 3:  Train_Loss:0.6641452312469482, Valid_Loss:1.2260911464691162, Valid_ACC:0.6091998815536499
Epoch 558, CIFAR-10 Batch 4:  Train_Loss:0.6611109375953674, Valid_Loss:1.2143970727920532, Valid_ACC:0.612799882888794
Epoch 558, CIFAR-10 Batch 5:  Train_Loss:0.6838357448577881, Valid_Loss:1.2292124032974243, Valid_ACC:0.608799934387207
Epoch 559, CIFAR-10 Batch 1:  Train_Loss:0.6677863597869873, Valid_Loss:1.2249830961227417, Valid_ACC:0.6111999750137329
Epoch 559, CIFAR-10 Batch 2:  Train_Loss:0.6564815640449524, Valid_Loss:1.2313573360443115, Valid_ACC:0.6075999736785889
Epoch 559, CIFAR-10 Batch 3:  Train_Loss:0.6469017267227173, Valid_Loss:1.2207366228103638, Valid_ACC:0.6123998761177063
Epoch 559, CIFAR-10 Batch 4:  Train_Loss:0.6478556990623474, Valid_Loss:1.1962209939956665, Valid_ACC:0.6155998706817627
Epoch 559, CIFAR-10 Batch 5:  Train_Loss:0.6865001916885376, Valid_Loss:1.22767972946167, Valid_ACC:0.6127999424934387
Epoch 560, CIFAR-10 Batch 1:  Train_Loss:0.648580014705658, Valid_Loss:1.2087888717651367, Valid_ACC:0.6153998970985413
Epoch 560, CIFAR-10 Batch 2:  Train_Loss:0.6461451053619385, Valid_Loss:1.2069969177246094, Valid_ACC:0.6143999099731445
Epoch 560, CIFAR-10 Batch 3:  Train_Loss:0.646030843257904, Valid_Loss:1.204288125038147, Valid_ACC:0.6099998950958252
Epoch 560, CIFAR-10 Batch 4:  Train_Loss:0.6480845212936401, Valid_Loss:1.208404302597046, Valid_ACC:0.6103999018669128
Epoch 560, CIFAR-10 Batch 5:  Train_Loss:0.6828295588493347, Valid_Loss:1.2309720516204834, Valid_ACC:0.6091998815536499
Epoch 561, CIFAR-10 Batch 1:  Train_Loss:0.6624460220336914, Valid_Loss:1.2243452072143555, Valid_ACC:0.6095999479293823
Epoch 561, CIFAR-10 Batch 2:  Train_Loss:0.6498770117759705, Valid_Loss:1.225818395614624, Valid_ACC:0.6063998937606812
Epoch 561, CIFAR-10 Batch 3:  Train_Loss:0.6619861125946045, Valid_Loss:1.220380425453186, Valid_ACC:0.6103999614715576
Epoch 561, CIFAR-10 Batch 4:  Train_Loss:0.6443008184432983, Valid_Loss:1.2075449228286743, Valid_ACC:0.6157999038696289
Epoch 561, CIFAR-10 Batch 5:  Train_Loss:0.6560226678848267, Valid_Loss:1.2146046161651611, Valid_ACC:0.613599956035614
Epoch 562, CIFAR-10 Batch 1:  Train_Loss:0.6550494432449341, Valid_Loss:1.2130560874938965, Valid_ACC:0.6149998903274536
Epoch 562, CIFAR-10 Batch 2:  Train_Loss:0.6499475836753845, Valid_Loss:1.2172679901123047, Valid_ACC:0.6119999289512634
Epoch 562, CIFAR-10 Batch 3:  Train_Loss:0.6523866653442383, Valid_Loss:1.2168673276901245, Valid_ACC:0.6107999086380005
Epoch 562, CIFAR-10 Batch 4:  Train_Loss:0.6385459899902344, Valid_Loss:1.1970958709716797, Valid_ACC:0.6189998984336853
Epoch 562, CIFAR-10 Batch 5:  Train_Loss:0.6817582845687866, Valid_Loss:1.2331877946853638, Valid_ACC:0.6093999147415161
Epoch 563, CIFAR-10 Batch 1:  Train_Loss:0.6585091948509216, Valid_Loss:1.2220168113708496, Valid_ACC:0.6063999533653259
Epoch 563, CIFAR-10 Batch 2:  Train_Loss:0.6515839099884033, Valid_Loss:1.2237517833709717, Valid_ACC:0.6081998944282532
Epoch 563, CIFAR-10 Batch 3:  Train_Loss:0.6520327925682068, Valid_Loss:1.2125482559204102, Valid_ACC:0.6125998497009277
Epoch 563, CIFAR-10 Batch 4:  Train_Loss:0.6569187045097351, Valid_Loss:1.2154806852340698, Valid_ACC:0.6131999492645264
Epoch 563, CIFAR-10 Batch 5:  Train_Loss:0.6821918487548828, Valid_Loss:1.2320772409439087, Valid_ACC:0.6059998869895935
Epoch 564, CIFAR-10 Batch 1:  Train_Loss:0.6923266649246216, Valid_Loss:1.246694564819336, Valid_ACC:0.5987999439239502
Epoch 564, CIFAR-10 Batch 2:  Train_Loss:0.6832721829414368, Valid_Loss:1.2391847372055054, Valid_ACC:0.6065999269485474
Epoch 564, CIFAR-10 Batch 3:  Train_Loss:0.666185736656189, Valid_Loss:1.218059778213501, Valid_ACC:0.6093999147415161
Epoch 564, CIFAR-10 Batch 4:  Train_Loss:0.6515388488769531, Valid_Loss:1.2180204391479492, Valid_ACC:0.6125999093055725
Epoch 564, CIFAR-10 Batch 5:  Train_Loss:0.7316964864730835, Valid_Loss:1.2647558450698853, Valid_ACC:0.6005998849868774
Epoch 565, CIFAR-10 Batch 1:  Train_Loss:0.6678411364555359, Valid_Loss:1.2129571437835693, Valid_ACC:0.6143999695777893
Epoch 565, CIFAR-10 Batch 2:  Train_Loss:0.6628884673118591, Valid_Loss:1.2223641872406006, Valid_ACC:0.6075999140739441
Epoch 565, CIFAR-10 Batch 3:  Train_Loss:0.6504504084587097, Valid_Loss:1.212611198425293, Valid_ACC:0.6121999025344849
Epoch 565, CIFAR-10 Batch 4:  Train_Loss:0.6482537984848022, Valid_Loss:1.204249382019043, Valid_ACC:0.6213998794555664
Epoch 565, CIFAR-10 Batch 5:  Train_Loss:0.6727924942970276, Valid_Loss:1.226457953453064, Valid_ACC:0.6123999357223511
Epoch 566, CIFAR-10 Batch 1:  Train_Loss:0.6509127616882324, Valid_Loss:1.210275411605835, Valid_ACC:0.6107999086380005
Epoch 566, CIFAR-10 Batch 2:  Train_Loss:0.6416589617729187, Valid_Loss:1.2107980251312256, Valid_ACC:0.6137999296188354
Epoch 566, CIFAR-10 Batch 3:  Train_Loss:0.6460193395614624, Valid_Loss:1.2093596458435059, Valid_ACC:0.6089999675750732
Epoch 566, CIFAR-10 Batch 4:  Train_Loss:0.6427944302558899, Valid_Loss:1.2198899984359741, Valid_ACC:0.6095998883247375
Epoch 566, CIFAR-10 Batch 5:  Train_Loss:0.6489356756210327, Valid_Loss:1.2104125022888184, Valid_ACC:0.6157998442649841
Epoch 567, CIFAR-10 Batch 1:  Train_Loss:0.6594845056533813, Valid_Loss:1.2256563901901245, Valid_ACC:0.6071998476982117
Epoch 567, CIFAR-10 Batch 2:  Train_Loss:0.6717637181282043, Valid_Loss:1.231121301651001, Valid_ACC:0.6059999465942383
Epoch 567, CIFAR-10 Batch 3:  Train_Loss:0.6595855355262756, Valid_Loss:1.2249540090560913, Valid_ACC:0.6097999811172485
Epoch 567, CIFAR-10 Batch 4:  Train_Loss:0.6425797343254089, Valid_Loss:1.2095283269882202, Valid_ACC:0.6123999357223511
Epoch 567, CIFAR-10 Batch 5:  Train_Loss:0.6589943766593933, Valid_Loss:1.221306562423706, Valid_ACC:0.6125998497009277
Epoch 568, CIFAR-10 Batch 1:  Train_Loss:0.6614998579025269, Valid_Loss:1.2174700498580933, Valid_ACC:0.6121999025344849
Epoch 568, CIFAR-10 Batch 2:  Train_Loss:0.6540515422821045, Valid_Loss:1.2213249206542969, Valid_ACC:0.6111999750137329
Epoch 568, CIFAR-10 Batch 3:  Train_Loss:0.6560919284820557, Valid_Loss:1.2136403322219849, Valid_ACC:0.6113999485969543
Epoch 568, CIFAR-10 Batch 4:  Train_Loss:0.6529092192649841, Valid_Loss:1.2160730361938477, Valid_ACC:0.6075998544692993
Epoch 568, CIFAR-10 Batch 5:  Train_Loss:0.6767842769622803, Valid_Loss:1.2347474098205566, Valid_ACC:0.6057999134063721
Epoch 569, CIFAR-10 Batch 1:  Train_Loss:0.6591547131538391, Valid_Loss:1.219251275062561, Valid_ACC:0.6119998693466187
Epoch 569, CIFAR-10 Batch 2:  Train_Loss:0.6618660688400269, Valid_Loss:1.2308446168899536, Valid_ACC:0.606999933719635
Epoch 569, CIFAR-10 Batch 3:  Train_Loss:0.6539520025253296, Valid_Loss:1.2131006717681885, Valid_ACC:0.6079999208450317
Epoch 569, CIFAR-10 Batch 4:  Train_Loss:0.6576083302497864, Valid_Loss:1.2214257717132568, Valid_ACC:0.612799882888794
Epoch 569, CIFAR-10 Batch 5:  Train_Loss:0.6748173236846924, Valid_Loss:1.2292163372039795, Valid_ACC:0.6121999025344849
Epoch 570, CIFAR-10 Batch 1:  Train_Loss:0.6541287899017334, Valid_Loss:1.213244915008545, Valid_ACC:0.6115999221801758
Epoch 570, CIFAR-10 Batch 2:  Train_Loss:0.6589831113815308, Valid_Loss:1.22707200050354, Valid_ACC:0.6079999208450317
Epoch 570, CIFAR-10 Batch 3:  Train_Loss:0.6480175852775574, Valid_Loss:1.2194772958755493, Valid_ACC:0.610599935054779
Epoch 570, CIFAR-10 Batch 4:  Train_Loss:0.646118700504303, Valid_Loss:1.2013152837753296, Valid_ACC:0.6157999038696289
Epoch 570, CIFAR-10 Batch 5:  Train_Loss:0.6723415851593018, Valid_Loss:1.237586259841919, Valid_ACC:0.6103998422622681
Epoch 571, CIFAR-10 Batch 1:  Train_Loss:0.6639373302459717, Valid_Loss:1.2251088619232178, Valid_ACC:0.6073999404907227
Epoch 571, CIFAR-10 Batch 2:  Train_Loss:0.6675155758857727, Valid_Loss:1.2252434492111206, Valid_ACC:0.6117998957633972
Epoch 571, CIFAR-10 Batch 3:  Train_Loss:0.6664659976959229, Valid_Loss:1.2309868335723877, Valid_ACC:0.6113999485969543
Epoch 571, CIFAR-10 Batch 4:  Train_Loss:0.647911012172699, Valid_Loss:1.204951524734497, Valid_ACC:0.6173999309539795
Epoch 571, CIFAR-10 Batch 5:  Train_Loss:0.6425881385803223, Valid_Loss:1.2197755575180054, Valid_ACC:0.6114000082015991
Epoch 572, CIFAR-10 Batch 1:  Train_Loss:0.6572878956794739, Valid_Loss:1.22305428981781, Valid_ACC:0.6079999208450317
Epoch 572, CIFAR-10 Batch 2:  Train_Loss:0.6412259340286255, Valid_Loss:1.208531141281128, Valid_ACC:0.6151999235153198
Epoch 572, CIFAR-10 Batch 3:  Train_Loss:0.6467615962028503, Valid_Loss:1.2215138673782349, Valid_ACC:0.6103999018669128
Epoch 572, CIFAR-10 Batch 4:  Train_Loss:0.6467949151992798, Valid_Loss:1.2140485048294067, Valid_ACC:0.6129998564720154
Epoch 572, CIFAR-10 Batch 5:  Train_Loss:0.677078366279602, Valid_Loss:1.2315312623977661, Valid_ACC:0.6099998950958252
Epoch 573, CIFAR-10 Batch 1:  Train_Loss:0.6582541465759277, Valid_Loss:1.2147303819656372, Valid_ACC:0.6095999479293823
Epoch 573, CIFAR-10 Batch 2:  Train_Loss:0.6559428572654724, Valid_Loss:1.2286930084228516, Valid_ACC:0.6045999526977539
Epoch 573, CIFAR-10 Batch 3:  Train_Loss:0.6716294288635254, Valid_Loss:1.2348155975341797, Valid_ACC:0.6101999282836914
Epoch 573, CIFAR-10 Batch 4:  Train_Loss:0.6566193103790283, Valid_Loss:1.2190313339233398, Valid_ACC:0.6099998950958252
Epoch 573, CIFAR-10 Batch 5:  Train_Loss:0.6532644033432007, Valid_Loss:1.2163729667663574, Valid_ACC:0.613399863243103
Epoch 574, CIFAR-10 Batch 1:  Train_Loss:0.6517630815505981, Valid_Loss:1.2062060832977295, Valid_ACC:0.6161998510360718
Epoch 574, CIFAR-10 Batch 2:  Train_Loss:0.6716963648796082, Valid_Loss:1.2321473360061646, Valid_ACC:0.6091999411582947
Epoch 574, CIFAR-10 Batch 3:  Train_Loss:0.6534388661384583, Valid_Loss:1.2078652381896973, Valid_ACC:0.6179999113082886
Epoch 574, CIFAR-10 Batch 4:  Train_Loss:0.6700879335403442, Valid_Loss:1.2183676958084106, Valid_ACC:0.6117998957633972
Epoch 574, CIFAR-10 Batch 5:  Train_Loss:0.6662914752960205, Valid_Loss:1.2165439128875732, Valid_ACC:0.611799955368042
Epoch 575, CIFAR-10 Batch 1:  Train_Loss:0.6532198190689087, Valid_Loss:1.2071729898452759, Valid_ACC:0.6103999018669128
Epoch 575, CIFAR-10 Batch 2:  Train_Loss:0.6535851955413818, Valid_Loss:1.2191418409347534, Valid_ACC:0.6107999086380005
Epoch 575, CIFAR-10 Batch 3:  Train_Loss:0.6443920135498047, Valid_Loss:1.2217174768447876, Valid_ACC:0.6103999018669128
Epoch 575, CIFAR-10 Batch 4:  Train_Loss:0.6409928202629089, Valid_Loss:1.2028250694274902, Valid_ACC:0.6159999370574951
Epoch 575, CIFAR-10 Batch 5:  Train_Loss:0.6655558943748474, Valid_Loss:1.2280118465423584, Valid_ACC:0.6077999472618103
Epoch 576, CIFAR-10 Batch 1:  Train_Loss:0.6448040008544922, Valid_Loss:1.2080371379852295, Valid_ACC:0.6137999296188354
Epoch 576, CIFAR-10 Batch 2:  Train_Loss:0.6388861536979675, Valid_Loss:1.213213324546814, Valid_ACC:0.6143999099731445
Epoch 576, CIFAR-10 Batch 3:  Train_Loss:0.6429709792137146, Valid_Loss:1.2059829235076904, Valid_ACC:0.614599883556366
Epoch 576, CIFAR-10 Batch 4:  Train_Loss:0.647779107093811, Valid_Loss:1.2132922410964966, Valid_ACC:0.612799882888794
Epoch 576, CIFAR-10 Batch 5:  Train_Loss:0.6625825762748718, Valid_Loss:1.2196201086044312, Valid_ACC:0.6081998944282532
Epoch 577, CIFAR-10 Batch 1:  Train_Loss:0.6804813742637634, Valid_Loss:1.2357953786849976, Valid_ACC:0.6039999127388
Epoch 577, CIFAR-10 Batch 2:  Train_Loss:0.640178918838501, Valid_Loss:1.2089420557022095, Valid_ACC:0.6153998970985413
Epoch 577, CIFAR-10 Batch 3:  Train_Loss:0.6404847502708435, Valid_Loss:1.2117029428482056, Valid_ACC:0.6141999363899231
Epoch 577, CIFAR-10 Batch 4:  Train_Loss:0.6517742276191711, Valid_Loss:1.2151463031768799, Valid_ACC:0.6105998754501343
Epoch 577, CIFAR-10 Batch 5:  Train_Loss:0.697992742061615, Valid_Loss:1.2487781047821045, Valid_ACC:0.6059999465942383
Epoch 578, CIFAR-10 Batch 1:  Train_Loss:0.6415964365005493, Valid_Loss:1.2051202058792114, Valid_ACC:0.6155998706817627
Epoch 578, CIFAR-10 Batch 2:  Train_Loss:0.6390311121940613, Valid_Loss:1.213414192199707, Valid_ACC:0.6121999025344849
Epoch 578, CIFAR-10 Batch 3:  Train_Loss:0.6553745865821838, Valid_Loss:1.2201131582260132, Valid_ACC:0.607999861240387
Epoch 578, CIFAR-10 Batch 4:  Train_Loss:0.6467599868774414, Valid_Loss:1.2207396030426025, Valid_ACC:0.610599935054779
Epoch 578, CIFAR-10 Batch 5:  Train_Loss:0.6577191948890686, Valid_Loss:1.220044732093811, Valid_ACC:0.607999861240387
Epoch 579, CIFAR-10 Batch 1:  Train_Loss:0.648905336856842, Valid_Loss:1.2052556276321411, Valid_ACC:0.611799955368042
Epoch 579, CIFAR-10 Batch 2:  Train_Loss:0.6492302417755127, Valid_Loss:1.2101258039474487, Valid_ACC:0.6129999160766602
Epoch 579, CIFAR-10 Batch 3:  Train_Loss:0.6390382051467896, Valid_Loss:1.2077239751815796, Valid_ACC:0.6101999282836914
Epoch 579, CIFAR-10 Batch 4:  Train_Loss:0.6430847644805908, Valid_Loss:1.211177110671997, Valid_ACC:0.6121999025344849
Epoch 579, CIFAR-10 Batch 5:  Train_Loss:0.7366551160812378, Valid_Loss:1.2647603750228882, Valid_ACC:0.5979999303817749
Epoch 580, CIFAR-10 Batch 1:  Train_Loss:0.6573423743247986, Valid_Loss:1.2217004299163818, Valid_ACC:0.6085999011993408
Epoch 580, CIFAR-10 Batch 2:  Train_Loss:0.6610118746757507, Valid_Loss:1.2246735095977783, Valid_ACC:0.6053998470306396
Epoch 580, CIFAR-10 Batch 3:  Train_Loss:0.641866147518158, Valid_Loss:1.211059331893921, Valid_ACC:0.6081998944282532
Epoch 580, CIFAR-10 Batch 4:  Train_Loss:0.6410822868347168, Valid_Loss:1.2004649639129639, Valid_ACC:0.6175999641418457
Epoch 580, CIFAR-10 Batch 5:  Train_Loss:0.6600147485733032, Valid_Loss:1.2181159257888794, Valid_ACC:0.6149998903274536
Epoch 581, CIFAR-10 Batch 1:  Train_Loss:0.6537560224533081, Valid_Loss:1.2094719409942627, Valid_ACC:0.6145999431610107
Epoch 581, CIFAR-10 Batch 2:  Train_Loss:0.632098913192749, Valid_Loss:1.2133829593658447, Valid_ACC:0.615399956703186
Epoch 581, CIFAR-10 Batch 3:  Train_Loss:0.6532158851623535, Valid_Loss:1.2281322479248047, Valid_ACC:0.6169999241828918
Epoch 581, CIFAR-10 Batch 4:  Train_Loss:0.6594138145446777, Valid_Loss:1.215618371963501, Valid_ACC:0.6137999296188354
Epoch 581, CIFAR-10 Batch 5:  Train_Loss:0.6641463041305542, Valid_Loss:1.2362862825393677, Valid_ACC:0.6091998219490051
Epoch 582, CIFAR-10 Batch 1:  Train_Loss:0.6395244002342224, Valid_Loss:1.2080882787704468, Valid_ACC:0.6173999309539795
Epoch 582, CIFAR-10 Batch 2:  Train_Loss:0.6527782678604126, Valid_Loss:1.2164924144744873, Valid_ACC:0.6153998970985413
Epoch 582, CIFAR-10 Batch 3:  Train_Loss:0.6402894258499146, Valid_Loss:1.2084169387817383, Valid_ACC:0.6151999235153198
Epoch 582, CIFAR-10 Batch 4:  Train_Loss:0.6520810127258301, Valid_Loss:1.2069649696350098, Valid_ACC:0.6179999709129333
Epoch 582, CIFAR-10 Batch 5:  Train_Loss:0.6581305861473083, Valid_Loss:1.2231518030166626, Valid_ACC:0.6167999505996704
Epoch 583, CIFAR-10 Batch 1:  Train_Loss:0.6804711222648621, Valid_Loss:1.22847318649292, Valid_ACC:0.6077999472618103
Epoch 583, CIFAR-10 Batch 2:  Train_Loss:0.6587852239608765, Valid_Loss:1.220979928970337, Valid_ACC:0.6093998551368713
Epoch 583, CIFAR-10 Batch 3:  Train_Loss:0.6441019773483276, Valid_Loss:1.205954670906067, Valid_ACC:0.6111999154090881
Epoch 583, CIFAR-10 Batch 4:  Train_Loss:0.6475767493247986, Valid_Loss:1.2111542224884033, Valid_ACC:0.6119999289512634
Epoch 583, CIFAR-10 Batch 5:  Train_Loss:0.6794411540031433, Valid_Loss:1.2386541366577148, Valid_ACC:0.6041998863220215
Epoch 584, CIFAR-10 Batch 1:  Train_Loss:0.6657630801200867, Valid_Loss:1.2262555360794067, Valid_ACC:0.6077998876571655
Epoch 584, CIFAR-10 Batch 2:  Train_Loss:0.6552115678787231, Valid_Loss:1.2301204204559326, Valid_ACC:0.6057999134063721
Epoch 584, CIFAR-10 Batch 3:  Train_Loss:0.6420630216598511, Valid_Loss:1.2059218883514404, Valid_ACC:0.6141998767852783
Epoch 584, CIFAR-10 Batch 4:  Train_Loss:0.650450587272644, Valid_Loss:1.213700532913208, Valid_ACC:0.6175999045372009
Epoch 584, CIFAR-10 Batch 5:  Train_Loss:0.6428149938583374, Valid_Loss:1.211228609085083, Valid_ACC:0.6143999099731445
Epoch 585, CIFAR-10 Batch 1:  Train_Loss:0.68019700050354, Valid_Loss:1.2467175722122192, Valid_ACC:0.6017999053001404
Epoch 585, CIFAR-10 Batch 2:  Train_Loss:0.6412872076034546, Valid_Loss:1.2165566682815552, Valid_ACC:0.6151999235153198
Epoch 585, CIFAR-10 Batch 3:  Train_Loss:0.6530743837356567, Valid_Loss:1.2152175903320312, Valid_ACC:0.6187999248504639
Epoch 585, CIFAR-10 Batch 4:  Train_Loss:0.6427485346794128, Valid_Loss:1.2104297876358032, Valid_ACC:0.6133999228477478
Epoch 585, CIFAR-10 Batch 5:  Train_Loss:0.6471997499465942, Valid_Loss:1.2136632204055786, Valid_ACC:0.6147999167442322
Epoch 586, CIFAR-10 Batch 1:  Train_Loss:0.6422361135482788, Valid_Loss:1.211964726448059, Valid_ACC:0.6127999424934387
Epoch 586, CIFAR-10 Batch 2:  Train_Loss:0.6426937580108643, Valid_Loss:1.2183893918991089, Valid_ACC:0.6113999485969543
Epoch 586, CIFAR-10 Batch 3:  Train_Loss:0.6524579524993896, Valid_Loss:1.2196526527404785, Valid_ACC:0.6167998909950256
Epoch 586, CIFAR-10 Batch 4:  Train_Loss:0.6722730994224548, Valid_Loss:1.2328962087631226, Valid_ACC:0.6065998673439026
Epoch 586, CIFAR-10 Batch 5:  Train_Loss:0.6487415432929993, Valid_Loss:1.2105096578598022, Valid_ACC:0.6167998909950256
Epoch 587, CIFAR-10 Batch 1:  Train_Loss:0.6717996001243591, Valid_Loss:1.2276606559753418, Valid_ACC:0.6111999154090881
Epoch 587, CIFAR-10 Batch 2:  Train_Loss:0.6638956069946289, Valid_Loss:1.2307093143463135, Valid_ACC:0.6097999215126038
Epoch 587, CIFAR-10 Batch 3:  Train_Loss:0.6396262645721436, Valid_Loss:1.2110919952392578, Valid_ACC:0.613599956035614
Epoch 587, CIFAR-10 Batch 4:  Train_Loss:0.6495481729507446, Valid_Loss:1.2081923484802246, Valid_ACC:0.6099998950958252
Epoch 587, CIFAR-10 Batch 5:  Train_Loss:0.6516623497009277, Valid_Loss:1.2114312648773193, Valid_ACC:0.6125998497009277
Epoch 588, CIFAR-10 Batch 1:  Train_Loss:0.6421646475791931, Valid_Loss:1.2104947566986084, Valid_ACC:0.6131998896598816
Epoch 588, CIFAR-10 Batch 2:  Train_Loss:0.6363067626953125, Valid_Loss:1.2044681310653687, Valid_ACC:0.6149998903274536
Epoch 588, CIFAR-10 Batch 3:  Train_Loss:0.6675373315811157, Valid_Loss:1.2390468120574951, Valid_ACC:0.6045998930931091
Epoch 588, CIFAR-10 Batch 4:  Train_Loss:0.6338042616844177, Valid_Loss:1.1998000144958496, Valid_ACC:0.6161999702453613
Epoch 588, CIFAR-10 Batch 5:  Train_Loss:0.6539754867553711, Valid_Loss:1.2135648727416992, Valid_ACC:0.6123999357223511
Epoch 589, CIFAR-10 Batch 1:  Train_Loss:0.6889216303825378, Valid_Loss:1.2462533712387085, Valid_ACC:0.603399932384491
Epoch 589, CIFAR-10 Batch 2:  Train_Loss:0.67835932970047, Valid_Loss:1.2391066551208496, Valid_ACC:0.6061999201774597
Epoch 589, CIFAR-10 Batch 3:  Train_Loss:0.6775740385055542, Valid_Loss:1.2322980165481567, Valid_ACC:0.6055999398231506
Epoch 589, CIFAR-10 Batch 4:  Train_Loss:0.6740655899047852, Valid_Loss:1.228543758392334, Valid_ACC:0.6111999750137329
Epoch 589, CIFAR-10 Batch 5:  Train_Loss:0.6698165535926819, Valid_Loss:1.232507348060608, Valid_ACC:0.6085999608039856
Epoch 590, CIFAR-10 Batch 1:  Train_Loss:0.6561681628227234, Valid_Loss:1.2092080116271973, Valid_ACC:0.619399905204773
Epoch 590, CIFAR-10 Batch 2:  Train_Loss:0.6587123274803162, Valid_Loss:1.2240173816680908, Valid_ACC:0.611799955368042
Epoch 590, CIFAR-10 Batch 3:  Train_Loss:0.6712868809700012, Valid_Loss:1.224097728729248, Valid_ACC:0.6053999662399292
Epoch 590, CIFAR-10 Batch 4:  Train_Loss:0.6564344167709351, Valid_Loss:1.2209997177124023, Valid_ACC:0.6087998747825623
Epoch 590, CIFAR-10 Batch 5:  Train_Loss:0.6588180661201477, Valid_Loss:1.222530722618103, Valid_ACC:0.6089998483657837
Epoch 591, CIFAR-10 Batch 1:  Train_Loss:0.6870418190956116, Valid_Loss:1.2375273704528809, Valid_ACC:0.5995999574661255
Epoch 591, CIFAR-10 Batch 2:  Train_Loss:0.6578153967857361, Valid_Loss:1.2312746047973633, Valid_ACC:0.6039999127388
Epoch 591, CIFAR-10 Batch 3:  Train_Loss:0.658145010471344, Valid_Loss:1.2170441150665283, Valid_ACC:0.6043999195098877
Epoch 591, CIFAR-10 Batch 4:  Train_Loss:0.664459228515625, Valid_Loss:1.2197264432907104, Valid_ACC:0.6107999086380005
Epoch 591, CIFAR-10 Batch 5:  Train_Loss:0.663490355014801, Valid_Loss:1.2310607433319092, Valid_ACC:0.6053999066352844
Epoch 592, CIFAR-10 Batch 1:  Train_Loss:0.6637891530990601, Valid_Loss:1.2262593507766724, Valid_ACC:0.6075998544692993
Epoch 592, CIFAR-10 Batch 2:  Train_Loss:0.6446190476417542, Valid_Loss:1.213585376739502, Valid_ACC:0.6157999038696289
Epoch 592, CIFAR-10 Batch 3:  Train_Loss:0.6645581722259521, Valid_Loss:1.2272777557373047, Valid_ACC:0.6131999492645264
Epoch 592, CIFAR-10 Batch 4:  Train_Loss:0.6632198691368103, Valid_Loss:1.2320325374603271, Valid_ACC:0.6055999398231506
Epoch 592, CIFAR-10 Batch 5:  Train_Loss:0.6800543665885925, Valid_Loss:1.2525005340576172, Valid_ACC:0.596799910068512
Epoch 593, CIFAR-10 Batch 1:  Train_Loss:0.6662027835845947, Valid_Loss:1.2209279537200928, Valid_ACC:0.6061998605728149
Epoch 593, CIFAR-10 Batch 2:  Train_Loss:0.6470779776573181, Valid_Loss:1.2227678298950195, Valid_ACC:0.6073998808860779
Epoch 593, CIFAR-10 Batch 3:  Train_Loss:0.6507397890090942, Valid_Loss:1.2236719131469727, Valid_ACC:0.6077998876571655
Epoch 593, CIFAR-10 Batch 4:  Train_Loss:0.6639222502708435, Valid_Loss:1.2163646221160889, Valid_ACC:0.6095999479293823
Epoch 593, CIFAR-10 Batch 5:  Train_Loss:0.6491201519966125, Valid_Loss:1.2157937288284302, Valid_ACC:0.6089999079704285
Epoch 594, CIFAR-10 Batch 1:  Train_Loss:0.6564522385597229, Valid_Loss:1.219804048538208, Valid_ACC:0.606999933719635
Epoch 594, CIFAR-10 Batch 2:  Train_Loss:0.6381176114082336, Valid_Loss:1.220453143119812, Valid_ACC:0.6105998754501343
Epoch 594, CIFAR-10 Batch 3:  Train_Loss:0.6248936057090759, Valid_Loss:1.2066384553909302, Valid_ACC:0.6153998970985413
Epoch 594, CIFAR-10 Batch 4:  Train_Loss:0.6410991549491882, Valid_Loss:1.210024118423462, Valid_ACC:0.611599862575531
Epoch 594, CIFAR-10 Batch 5:  Train_Loss:0.6583130955696106, Valid_Loss:1.2260736227035522, Valid_ACC:0.6093999147415161
Epoch 595, CIFAR-10 Batch 1:  Train_Loss:0.6374624967575073, Valid_Loss:1.213436245918274, Valid_ACC:0.6161999106407166
Epoch 595, CIFAR-10 Batch 2:  Train_Loss:0.6528817415237427, Valid_Loss:1.2274596691131592, Valid_ACC:0.606999933719635
Epoch 595, CIFAR-10 Batch 3:  Train_Loss:0.6362601518630981, Valid_Loss:1.2178449630737305, Valid_ACC:0.6111999154090881
Epoch 595, CIFAR-10 Batch 4:  Train_Loss:0.6675530672073364, Valid_Loss:1.2334071397781372, Valid_ACC:0.6043999195098877
Epoch 595, CIFAR-10 Batch 5:  Train_Loss:0.655277669429779, Valid_Loss:1.2226004600524902, Valid_ACC:0.6105998754501343
Epoch 596, CIFAR-10 Batch 1:  Train_Loss:0.6736184358596802, Valid_Loss:1.2341920137405396, Valid_ACC:0.6113998889923096
Epoch 596, CIFAR-10 Batch 2:  Train_Loss:0.6779018044471741, Valid_Loss:1.2380526065826416, Valid_ACC:0.6073998808860779
Epoch 596, CIFAR-10 Batch 3:  Train_Loss:0.6531063318252563, Valid_Loss:1.217516303062439, Valid_ACC:0.6119998693466187
Epoch 596, CIFAR-10 Batch 4:  Train_Loss:0.6386240124702454, Valid_Loss:1.2099289894104004, Valid_ACC:0.6113998889923096
Epoch 596, CIFAR-10 Batch 5:  Train_Loss:0.6471827030181885, Valid_Loss:1.2188267707824707, Valid_ACC:0.6057999134063721
Epoch 597, CIFAR-10 Batch 1:  Train_Loss:0.6561416387557983, Valid_Loss:1.2195367813110352, Valid_ACC:0.610599935054779
Epoch 597, CIFAR-10 Batch 2:  Train_Loss:0.6692025661468506, Valid_Loss:1.231416940689087, Valid_ACC:0.6091999411582947
Epoch 597, CIFAR-10 Batch 3:  Train_Loss:0.6499594449996948, Valid_Loss:1.2198965549468994, Valid_ACC:0.6107999682426453
Epoch 597, CIFAR-10 Batch 4:  Train_Loss:0.6316014528274536, Valid_Loss:1.2005705833435059, Valid_ACC:0.6133999228477478
Epoch 597, CIFAR-10 Batch 5:  Train_Loss:0.6617181301116943, Valid_Loss:1.2314146757125854, Valid_ACC:0.6107998490333557
Epoch 598, CIFAR-10 Batch 1:  Train_Loss:0.6594224572181702, Valid_Loss:1.217400074005127, Valid_ACC:0.6149998903274536
Epoch 598, CIFAR-10 Batch 2:  Train_Loss:0.6395906209945679, Valid_Loss:1.205031156539917, Valid_ACC:0.6153998374938965
Epoch 598, CIFAR-10 Batch 3:  Train_Loss:0.6550623178482056, Valid_Loss:1.2246110439300537, Valid_ACC:0.6085999011993408
Epoch 598, CIFAR-10 Batch 4:  Train_Loss:0.6390187740325928, Valid_Loss:1.2016880512237549, Valid_ACC:0.6113998889923096
Epoch 598, CIFAR-10 Batch 5:  Train_Loss:0.6423341631889343, Valid_Loss:1.206246256828308, Valid_ACC:0.6201999187469482
Epoch 599, CIFAR-10 Batch 1:  Train_Loss:0.6476069688796997, Valid_Loss:1.2110918760299683, Valid_ACC:0.6139999032020569
Epoch 599, CIFAR-10 Batch 2:  Train_Loss:0.6337482929229736, Valid_Loss:1.2160075902938843, Valid_ACC:0.6095999479293823
Epoch 599, CIFAR-10 Batch 3:  Train_Loss:0.6614219546318054, Valid_Loss:1.2275259494781494, Valid_ACC:0.608199954032898
Epoch 599, CIFAR-10 Batch 4:  Train_Loss:0.645524263381958, Valid_Loss:1.2175922393798828, Valid_ACC:0.6097999215126038
Epoch 599, CIFAR-10 Batch 5:  Train_Loss:0.6405824422836304, Valid_Loss:1.2086079120635986, Valid_ACC:0.6113999485969543
Epoch 600, CIFAR-10 Batch 1:  Train_Loss:0.6545844674110413, Valid_Loss:1.2145450115203857, Valid_ACC:0.6109998822212219
Epoch 600, CIFAR-10 Batch 2:  Train_Loss:0.6374882459640503, Valid_Loss:1.2199416160583496, Valid_ACC:0.6157999038696289
Epoch 600, CIFAR-10 Batch 3:  Train_Loss:0.643142819404602, Valid_Loss:1.212294101715088, Valid_ACC:0.6107999086380005
Epoch 600, CIFAR-10 Batch 4:  Train_Loss:0.6433823704719543, Valid_Loss:1.2189468145370483, Valid_ACC:0.6115999221801758
Epoch 600, CIFAR-10 Batch 5:  Train_Loss:0.6757724285125732, Valid_Loss:1.2350521087646484, Valid_ACC:0.6027998924255371
Epoch 601, CIFAR-10 Batch 1:  Train_Loss:0.6630130410194397, Valid_Loss:1.2210255861282349, Valid_ACC:0.6073999404907227
Epoch 601, CIFAR-10 Batch 2:  Train_Loss:0.6287265419960022, Valid_Loss:1.2049002647399902, Valid_ACC:0.6143999099731445
Epoch 601, CIFAR-10 Batch 3:  Train_Loss:0.6379382014274597, Valid_Loss:1.2083649635314941, Valid_ACC:0.6103999018669128
Epoch 601, CIFAR-10 Batch 4:  Train_Loss:0.6380507946014404, Valid_Loss:1.2072337865829468, Valid_ACC:0.6121999025344849
Epoch 601, CIFAR-10 Batch 5:  Train_Loss:0.6475061774253845, Valid_Loss:1.2221852540969849, Valid_ACC:0.6091998815536499
Epoch 602, CIFAR-10 Batch 1:  Train_Loss:0.6665035486221313, Valid_Loss:1.2301234006881714, Valid_ACC:0.6065999269485474
Epoch 602, CIFAR-10 Batch 2:  Train_Loss:0.6439016461372375, Valid_Loss:1.2226340770721436, Valid_ACC:0.608799934387207
Epoch 602, CIFAR-10 Batch 3:  Train_Loss:0.6614165306091309, Valid_Loss:1.2251986265182495, Valid_ACC:0.6073999404907227
Epoch 602, CIFAR-10 Batch 4:  Train_Loss:0.6500776410102844, Valid_Loss:1.2152920961380005, Valid_ACC:0.6125999093055725
Epoch 602, CIFAR-10 Batch 5:  Train_Loss:0.6954877376556396, Valid_Loss:1.2600584030151367, Valid_ACC:0.5983998775482178
Epoch 603, CIFAR-10 Batch 1:  Train_Loss:0.6631125211715698, Valid_Loss:1.2351022958755493, Valid_ACC:0.6035999655723572
Epoch 603, CIFAR-10 Batch 2:  Train_Loss:0.6704803705215454, Valid_Loss:1.2396403551101685, Valid_ACC:0.6059998869895935
Epoch 603, CIFAR-10 Batch 3:  Train_Loss:0.6548402309417725, Valid_Loss:1.222670316696167, Valid_ACC:0.6111999154090881
Epoch 603, CIFAR-10 Batch 4:  Train_Loss:0.6529461145401001, Valid_Loss:1.2147198915481567, Valid_ACC:0.6099998950958252
Epoch 603, CIFAR-10 Batch 5:  Train_Loss:0.6439233422279358, Valid_Loss:1.2217698097229004, Valid_ACC:0.6103999018669128
Epoch 604, CIFAR-10 Batch 1:  Train_Loss:0.6705217957496643, Valid_Loss:1.2357940673828125, Valid_ACC:0.6065999269485474
Epoch 604, CIFAR-10 Batch 2:  Train_Loss:0.6561154127120972, Valid_Loss:1.2267314195632935, Valid_ACC:0.6129999160766602
Epoch 604, CIFAR-10 Batch 3:  Train_Loss:0.6289511322975159, Valid_Loss:1.215132713317871, Valid_ACC:0.6143999099731445
Epoch 604, CIFAR-10 Batch 4:  Train_Loss:0.6489821672439575, Valid_Loss:1.2225115299224854, Valid_ACC:0.6055999398231506
Epoch 604, CIFAR-10 Batch 5:  Train_Loss:0.6606558561325073, Valid_Loss:1.2224735021591187, Valid_ACC:0.6091999411582947
Epoch 605, CIFAR-10 Batch 1:  Train_Loss:0.653091311454773, Valid_Loss:1.222553014755249, Valid_ACC:0.6075999140739441
Epoch 605, CIFAR-10 Batch 2:  Train_Loss:0.6572681069374084, Valid_Loss:1.2339988946914673, Valid_ACC:0.6091998815536499
Epoch 605, CIFAR-10 Batch 3:  Train_Loss:0.6538901925086975, Valid_Loss:1.2326264381408691, Valid_ACC:0.6095999479293823
Epoch 605, CIFAR-10 Batch 4:  Train_Loss:0.6421098113059998, Valid_Loss:1.2176644802093506, Valid_ACC:0.6105998754501343
Epoch 605, CIFAR-10 Batch 5:  Train_Loss:0.6441221833229065, Valid_Loss:1.2246434688568115, Valid_ACC:0.6059998869895935
Epoch 606, CIFAR-10 Batch 1:  Train_Loss:0.6467049717903137, Valid_Loss:1.2191641330718994, Valid_ACC:0.6095999479293823
Epoch 606, CIFAR-10 Batch 2:  Train_Loss:0.6501482725143433, Valid_Loss:1.231706142425537, Valid_ACC:0.6051998734474182
Epoch 606, CIFAR-10 Batch 3:  Train_Loss:0.6502590179443359, Valid_Loss:1.235222339630127, Valid_ACC:0.608799934387207
Epoch 606, CIFAR-10 Batch 4:  Train_Loss:0.6332738995552063, Valid_Loss:1.210313081741333, Valid_ACC:0.611599862575531
Epoch 606, CIFAR-10 Batch 5:  Train_Loss:0.643832802772522, Valid_Loss:1.2251522541046143, Valid_ACC:0.6093999147415161
Epoch 607, CIFAR-10 Batch 1:  Train_Loss:0.6463008522987366, Valid_Loss:1.2150284051895142, Valid_ACC:0.6123998165130615
Epoch 607, CIFAR-10 Batch 2:  Train_Loss:0.6703486442565918, Valid_Loss:1.2442054748535156, Valid_ACC:0.601599931716919
Epoch 607, CIFAR-10 Batch 3:  Train_Loss:0.6630639433860779, Valid_Loss:1.2267367839813232, Valid_ACC:0.6093999147415161
Epoch 607, CIFAR-10 Batch 4:  Train_Loss:0.6608095765113831, Valid_Loss:1.22982656955719, Valid_ACC:0.6065999269485474
Epoch 607, CIFAR-10 Batch 5:  Train_Loss:0.6689260601997375, Valid_Loss:1.2297272682189941, Valid_ACC:0.608799934387207
Epoch 608, CIFAR-10 Batch 1:  Train_Loss:0.6418125629425049, Valid_Loss:1.2105592489242554, Valid_ACC:0.6131998896598816
Epoch 608, CIFAR-10 Batch 2:  Train_Loss:0.659920871257782, Valid_Loss:1.231128454208374, Valid_ACC:0.6065999269485474
Epoch 608, CIFAR-10 Batch 3:  Train_Loss:0.6416175365447998, Valid_Loss:1.2106434106826782, Valid_ACC:0.6125999093055725
Epoch 608, CIFAR-10 Batch 4:  Train_Loss:0.6468320488929749, Valid_Loss:1.2173722982406616, Valid_ACC:0.6103999614715576
Epoch 608, CIFAR-10 Batch 5:  Train_Loss:0.6446820497512817, Valid_Loss:1.2200878858566284, Valid_ACC:0.6121999025344849
Epoch 609, CIFAR-10 Batch 1:  Train_Loss:0.6582401990890503, Valid_Loss:1.216421127319336, Valid_ACC:0.6115999221801758
Epoch 609, CIFAR-10 Batch 2:  Train_Loss:0.6836225986480713, Valid_Loss:1.2377067804336548, Valid_ACC:0.6055998802185059
Epoch 609, CIFAR-10 Batch 3:  Train_Loss:0.6491104960441589, Valid_Loss:1.2159698009490967, Valid_ACC:0.6105998754501343
Epoch 609, CIFAR-10 Batch 4:  Train_Loss:0.6434338092803955, Valid_Loss:1.2133947610855103, Valid_ACC:0.609799861907959
Epoch 609, CIFAR-10 Batch 5:  Train_Loss:0.6604624390602112, Valid_Loss:1.225148320198059, Valid_ACC:0.6089999079704285
Epoch 610, CIFAR-10 Batch 1:  Train_Loss:0.6673397421836853, Valid_Loss:1.232282042503357, Valid_ACC:0.6035999059677124
Epoch 610, CIFAR-10 Batch 2:  Train_Loss:0.651650607585907, Valid_Loss:1.2329437732696533, Valid_ACC:0.6091999411582947
Epoch 610, CIFAR-10 Batch 3:  Train_Loss:0.6520519256591797, Valid_Loss:1.2207112312316895, Valid_ACC:0.6125999093055725
Epoch 610, CIFAR-10 Batch 4:  Train_Loss:0.6574411988258362, Valid_Loss:1.2225086688995361, Valid_ACC:0.6149998903274536
Epoch 610, CIFAR-10 Batch 5:  Train_Loss:0.6710475087165833, Valid_Loss:1.2478656768798828, Valid_ACC:0.602199912071228
Epoch 611, CIFAR-10 Batch 1:  Train_Loss:0.6402804851531982, Valid_Loss:1.2099368572235107, Valid_ACC:0.6113998889923096
Epoch 611, CIFAR-10 Batch 2:  Train_Loss:0.6369271874427795, Valid_Loss:1.2201855182647705, Valid_ACC:0.612799882888794
Epoch 611, CIFAR-10 Batch 3:  Train_Loss:0.6489021182060242, Valid_Loss:1.222324252128601, Valid_ACC:0.6131998896598816
Epoch 611, CIFAR-10 Batch 4:  Train_Loss:0.6496742367744446, Valid_Loss:1.2206010818481445, Valid_ACC:0.608799934387207
Epoch 611, CIFAR-10 Batch 5:  Train_Loss:0.6518864631652832, Valid_Loss:1.2375283241271973, Valid_ACC:0.6053999066352844
Epoch 612, CIFAR-10 Batch 1:  Train_Loss:0.6523115634918213, Valid_Loss:1.2157118320465088, Valid_ACC:0.6153998970985413
Epoch 612, CIFAR-10 Batch 2:  Train_Loss:0.6592944860458374, Valid_Loss:1.2212698459625244, Valid_ACC:0.6115999221801758
Epoch 612, CIFAR-10 Batch 3:  Train_Loss:0.6403940320014954, Valid_Loss:1.2171227931976318, Valid_ACC:0.611599862575531
Epoch 612, CIFAR-10 Batch 4:  Train_Loss:0.6334492564201355, Valid_Loss:1.2137856483459473, Valid_ACC:0.6083998680114746
Epoch 612, CIFAR-10 Batch 5:  Train_Loss:0.6492627263069153, Valid_Loss:1.2266297340393066, Valid_ACC:0.6077999472618103
Epoch 613, CIFAR-10 Batch 1:  Train_Loss:0.6465623378753662, Valid_Loss:1.220432162284851, Valid_ACC:0.6065999269485474
Epoch 613, CIFAR-10 Batch 2:  Train_Loss:0.6740031242370605, Valid_Loss:1.2351932525634766, Valid_ACC:0.6063999533653259
Epoch 613, CIFAR-10 Batch 3:  Train_Loss:0.6871501207351685, Valid_Loss:1.2522833347320557, Valid_ACC:0.6009998917579651
Epoch 613, CIFAR-10 Batch 4:  Train_Loss:0.6507946252822876, Valid_Loss:1.218833088874817, Valid_ACC:0.610599935054779
Epoch 613, CIFAR-10 Batch 5:  Train_Loss:0.6530591249465942, Valid_Loss:1.2312037944793701, Valid_ACC:0.606999933719635
Epoch 614, CIFAR-10 Batch 1:  Train_Loss:0.666832447052002, Valid_Loss:1.2321910858154297, Valid_ACC:0.6057999134063721
Epoch 614, CIFAR-10 Batch 2:  Train_Loss:0.6451615691184998, Valid_Loss:1.2212738990783691, Valid_ACC:0.6123999357223511
Epoch 614, CIFAR-10 Batch 3:  Train_Loss:0.6475147008895874, Valid_Loss:1.2169421911239624, Valid_ACC:0.6079999208450317
Epoch 614, CIFAR-10 Batch 4:  Train_Loss:0.6219152808189392, Valid_Loss:1.208005428314209, Valid_ACC:0.6129999160766602
Epoch 614, CIFAR-10 Batch 5:  Train_Loss:0.6438591480255127, Valid_Loss:1.222090482711792, Valid_ACC:0.6097999215126038
Epoch 615, CIFAR-10 Batch 1:  Train_Loss:0.6522751450538635, Valid_Loss:1.2104918956756592, Valid_ACC:0.616399884223938
Epoch 615, CIFAR-10 Batch 2:  Train_Loss:0.6347767114639282, Valid_Loss:1.2164689302444458, Valid_ACC:0.6119999289512634
Epoch 615, CIFAR-10 Batch 3:  Train_Loss:0.6508772373199463, Valid_Loss:1.2265865802764893, Valid_ACC:0.6079999208450317
Epoch 615, CIFAR-10 Batch 4:  Train_Loss:0.6256023049354553, Valid_Loss:1.2146499156951904, Valid_ACC:0.6097999215126038
Epoch 615, CIFAR-10 Batch 5:  Train_Loss:0.6576173305511475, Valid_Loss:1.2364797592163086, Valid_ACC:0.5971999168395996
Epoch 616, CIFAR-10 Batch 1:  Train_Loss:0.6538573503494263, Valid_Loss:1.2175804376602173, Valid_ACC:0.609799861907959
Epoch 616, CIFAR-10 Batch 2:  Train_Loss:0.6467334628105164, Valid_Loss:1.2313330173492432, Valid_ACC:0.6047999262809753
Epoch 616, CIFAR-10 Batch 3:  Train_Loss:0.6671593189239502, Valid_Loss:1.2317612171173096, Valid_ACC:0.607999861240387
Epoch 616, CIFAR-10 Batch 4:  Train_Loss:0.6357007026672363, Valid_Loss:1.205942153930664, Valid_ACC:0.614599883556366
Epoch 616, CIFAR-10 Batch 5:  Train_Loss:0.6358628273010254, Valid_Loss:1.2228608131408691, Valid_ACC:0.6121999025344849
Epoch 617, CIFAR-10 Batch 1:  Train_Loss:0.6391767859458923, Valid_Loss:1.2131119966506958, Valid_ACC:0.6127999424934387
Epoch 617, CIFAR-10 Batch 2:  Train_Loss:0.6401664018630981, Valid_Loss:1.223569393157959, Valid_ACC:0.609799861907959
Epoch 617, CIFAR-10 Batch 3:  Train_Loss:0.6723732352256775, Valid_Loss:1.229383945465088, Valid_ACC:0.6115999221801758
Epoch 617, CIFAR-10 Batch 4:  Train_Loss:0.6466944217681885, Valid_Loss:1.2176878452301025, Valid_ACC:0.6109999418258667
Epoch 617, CIFAR-10 Batch 5:  Train_Loss:0.6461034417152405, Valid_Loss:1.2193715572357178, Valid_ACC:0.606999933719635
Epoch 618, CIFAR-10 Batch 1:  Train_Loss:0.6425694823265076, Valid_Loss:1.2093485593795776, Valid_ACC:0.6119999289512634
Epoch 618, CIFAR-10 Batch 2:  Train_Loss:0.6223752498626709, Valid_Loss:1.2079840898513794, Valid_ACC:0.6113998889923096
Epoch 618, CIFAR-10 Batch 3:  Train_Loss:0.6469618082046509, Valid_Loss:1.2267630100250244, Valid_ACC:0.6065999269485474
Epoch 618, CIFAR-10 Batch 4:  Train_Loss:0.657041072845459, Valid_Loss:1.23016357421875, Valid_ACC:0.6059998869895935
Epoch 618, CIFAR-10 Batch 5:  Train_Loss:0.6603453159332275, Valid_Loss:1.234114170074463, Valid_ACC:0.6045998334884644
Epoch 619, CIFAR-10 Batch 1:  Train_Loss:0.6433038115501404, Valid_Loss:1.2063319683074951, Valid_ACC:0.6141999363899231
Epoch 619, CIFAR-10 Batch 2:  Train_Loss:0.6462739109992981, Valid_Loss:1.2196797132492065, Valid_ACC:0.6147999167442322
Epoch 619, CIFAR-10 Batch 3:  Train_Loss:0.6634109020233154, Valid_Loss:1.2468799352645874, Valid_ACC:0.603399932384491
Epoch 619, CIFAR-10 Batch 4:  Train_Loss:0.6370366811752319, Valid_Loss:1.2113919258117676, Valid_ACC:0.6111999750137329
Epoch 619, CIFAR-10 Batch 5:  Train_Loss:0.6325824856758118, Valid_Loss:1.2256734371185303, Valid_ACC:0.6079999208450317
Epoch 620, CIFAR-10 Batch 1:  Train_Loss:0.6365795135498047, Valid_Loss:1.2111568450927734, Valid_ACC:0.6113998889923096
Epoch 620, CIFAR-10 Batch 2:  Train_Loss:0.6312175989151001, Valid_Loss:1.2161755561828613, Valid_ACC:0.6095999479293823
Epoch 620, CIFAR-10 Batch 3:  Train_Loss:0.6407105326652527, Valid_Loss:1.208372712135315, Valid_ACC:0.614599883556366
Epoch 620, CIFAR-10 Batch 4:  Train_Loss:0.6487898826599121, Valid_Loss:1.2160148620605469, Valid_ACC:0.6121999025344849
Epoch 620, CIFAR-10 Batch 5:  Train_Loss:0.6846187710762024, Valid_Loss:1.239911437034607, Valid_ACC:0.6011999249458313
Epoch 621, CIFAR-10 Batch 1:  Train_Loss:0.6273485422134399, Valid_Loss:1.1926507949829102, Valid_ACC:0.618399977684021
Epoch 621, CIFAR-10 Batch 2:  Train_Loss:0.6323361396789551, Valid_Loss:1.2124619483947754, Valid_ACC:0.6125999093055725
Epoch 621, CIFAR-10 Batch 3:  Train_Loss:0.6455727219581604, Valid_Loss:1.218005895614624, Valid_ACC:0.6117998361587524
Epoch 621, CIFAR-10 Batch 4:  Train_Loss:0.6593366861343384, Valid_Loss:1.2388509511947632, Valid_ACC:0.6051998734474182
Epoch 621, CIFAR-10 Batch 5:  Train_Loss:0.6555824279785156, Valid_Loss:1.2301695346832275, Valid_ACC:0.608599841594696
Epoch 622, CIFAR-10 Batch 1:  Train_Loss:0.6469742059707642, Valid_Loss:1.2223132848739624, Valid_ACC:0.6091998815536499
Epoch 622, CIFAR-10 Batch 2:  Train_Loss:0.6501739621162415, Valid_Loss:1.223729133605957, Valid_ACC:0.6095999479293823
Epoch 622, CIFAR-10 Batch 3:  Train_Loss:0.6629970073699951, Valid_Loss:1.2239915132522583, Valid_ACC:0.6099998950958252
Epoch 622, CIFAR-10 Batch 4:  Train_Loss:0.6509397625923157, Valid_Loss:1.22286856174469, Valid_ACC:0.6075999140739441
Epoch 622, CIFAR-10 Batch 5:  Train_Loss:0.6763813495635986, Valid_Loss:1.2384579181671143, Valid_ACC:0.6075999140739441
Epoch 623, CIFAR-10 Batch 1:  Train_Loss:0.6548800468444824, Valid_Loss:1.2281417846679688, Valid_ACC:0.6075999140739441
Epoch 623, CIFAR-10 Batch 2:  Train_Loss:0.6402480006217957, Valid_Loss:1.22883939743042, Valid_ACC:0.6037998795509338
Epoch 623, CIFAR-10 Batch 3:  Train_Loss:0.6416876912117004, Valid_Loss:1.2200310230255127, Valid_ACC:0.6099998950958252
Epoch 623, CIFAR-10 Batch 4:  Train_Loss:0.6370865106582642, Valid_Loss:1.2121617794036865, Valid_ACC:0.6129999160766602
Epoch 623, CIFAR-10 Batch 5:  Train_Loss:0.6659982204437256, Valid_Loss:1.2505440711975098, Valid_ACC:0.6019998788833618
Epoch 624, CIFAR-10 Batch 1:  Train_Loss:0.6518198847770691, Valid_Loss:1.2142404317855835, Valid_ACC:0.6065999269485474
Epoch 624, CIFAR-10 Batch 2:  Train_Loss:0.6368501782417297, Valid_Loss:1.2276742458343506, Valid_ACC:0.6037998795509338
Epoch 624, CIFAR-10 Batch 3:  Train_Loss:0.6302903294563293, Valid_Loss:1.2133052349090576, Valid_ACC:0.6133999228477478
Epoch 624, CIFAR-10 Batch 4:  Train_Loss:0.6506772041320801, Valid_Loss:1.2300658226013184, Valid_ACC:0.6033998727798462
Epoch 624, CIFAR-10 Batch 5:  Train_Loss:0.6571430563926697, Valid_Loss:1.2381311655044556, Valid_ACC:0.602199912071228
Epoch 625, CIFAR-10 Batch 1:  Train_Loss:0.6437303423881531, Valid_Loss:1.216700792312622, Valid_ACC:0.608799934387207
Epoch 625, CIFAR-10 Batch 2:  Train_Loss:0.6313114762306213, Valid_Loss:1.2165659666061401, Valid_ACC:0.6129999756813049
Epoch 625, CIFAR-10 Batch 3:  Train_Loss:0.6448500156402588, Valid_Loss:1.2217053174972534, Valid_ACC:0.6153998970985413
Epoch 625, CIFAR-10 Batch 4:  Train_Loss:0.648388147354126, Valid_Loss:1.2302443981170654, Valid_ACC:0.6043999195098877
Epoch 625, CIFAR-10 Batch 5:  Train_Loss:0.6336137056350708, Valid_Loss:1.2314549684524536, Valid_ACC:0.6059999465942383
Epoch 626, CIFAR-10 Batch 1:  Train_Loss:0.647042989730835, Valid_Loss:1.2315025329589844, Valid_ACC:0.6047999262809753
Epoch 626, CIFAR-10 Batch 2:  Train_Loss:0.6223207116127014, Valid_Loss:1.213790774345398, Valid_ACC:0.6119998693466187
Epoch 626, CIFAR-10 Batch 3:  Train_Loss:0.6375990509986877, Valid_Loss:1.2181864976882935, Valid_ACC:0.6083998680114746
Epoch 626, CIFAR-10 Batch 4:  Train_Loss:0.6407326459884644, Valid_Loss:1.223330020904541, Valid_ACC:0.6055998802185059
Epoch 626, CIFAR-10 Batch 5:  Train_Loss:0.6406158804893494, Valid_Loss:1.2257150411605835, Valid_ACC:0.6113998889923096
Epoch 627, CIFAR-10 Batch 1:  Train_Loss:0.6376069784164429, Valid_Loss:1.21128511428833, Valid_ACC:0.612799882888794
Epoch 627, CIFAR-10 Batch 2:  Train_Loss:0.6206896305084229, Valid_Loss:1.2074536085128784, Valid_ACC:0.6183999180793762
Epoch 627, CIFAR-10 Batch 3:  Train_Loss:0.6340548992156982, Valid_Loss:1.2083951234817505, Valid_ACC:0.614799976348877
Epoch 627, CIFAR-10 Batch 4:  Train_Loss:0.6300591230392456, Valid_Loss:1.2133674621582031, Valid_ACC:0.6099998950958252
Epoch 627, CIFAR-10 Batch 5:  Train_Loss:0.6367354989051819, Valid_Loss:1.2303091287612915, Valid_ACC:0.6101998686790466
Epoch 628, CIFAR-10 Batch 1:  Train_Loss:0.6557854413986206, Valid_Loss:1.2362115383148193, Valid_ACC:0.600399911403656
Epoch 628, CIFAR-10 Batch 2:  Train_Loss:0.6253566145896912, Valid_Loss:1.2249701023101807, Valid_ACC:0.6123998761177063
Epoch 628, CIFAR-10 Batch 3:  Train_Loss:0.6302347779273987, Valid_Loss:1.2110081911087036, Valid_ACC:0.6087998151779175
Epoch 628, CIFAR-10 Batch 4:  Train_Loss:0.6292429566383362, Valid_Loss:1.2145835161209106, Valid_ACC:0.6093999147415161
Epoch 628, CIFAR-10 Batch 5:  Train_Loss:0.660473108291626, Valid_Loss:1.2340439558029175, Valid_ACC:0.6055998802185059
Epoch 629, CIFAR-10 Batch 1:  Train_Loss:0.6376318335533142, Valid_Loss:1.2135918140411377, Valid_ACC:0.6111999154090881
Epoch 629, CIFAR-10 Batch 2:  Train_Loss:0.6182061433792114, Valid_Loss:1.2110884189605713, Valid_ACC:0.6129999160766602
Epoch 629, CIFAR-10 Batch 3:  Train_Loss:0.6649461984634399, Valid_Loss:1.2358946800231934, Valid_ACC:0.6077998876571655
Epoch 629, CIFAR-10 Batch 4:  Train_Loss:0.6495952010154724, Valid_Loss:1.2202279567718506, Valid_ACC:0.6137999296188354
Epoch 629, CIFAR-10 Batch 5:  Train_Loss:0.65018230676651, Valid_Loss:1.2291678190231323, Valid_ACC:0.612799882888794
Epoch 630, CIFAR-10 Batch 1:  Train_Loss:0.6389358639717102, Valid_Loss:1.2086302042007446, Valid_ACC:0.6141998767852783
Epoch 630, CIFAR-10 Batch 2:  Train_Loss:0.6315266489982605, Valid_Loss:1.2161285877227783, Valid_ACC:0.6169999241828918
Epoch 630, CIFAR-10 Batch 3:  Train_Loss:0.631155788898468, Valid_Loss:1.2164150476455688, Valid_ACC:0.608799934387207
Epoch 630, CIFAR-10 Batch 4:  Train_Loss:0.6266428232192993, Valid_Loss:1.2138595581054688, Valid_ACC:0.6125999093055725
Epoch 630, CIFAR-10 Batch 5:  Train_Loss:0.6466533541679382, Valid_Loss:1.233627200126648, Valid_ACC:0.6045998930931091
Epoch 631, CIFAR-10 Batch 1:  Train_Loss:0.6569418907165527, Valid_Loss:1.2349478006362915, Valid_ACC:0.6065998673439026
Epoch 631, CIFAR-10 Batch 2:  Train_Loss:0.6503856182098389, Valid_Loss:1.2406004667282104, Valid_ACC:0.6025999188423157
Epoch 631, CIFAR-10 Batch 3:  Train_Loss:0.6241129040718079, Valid_Loss:1.2145905494689941, Valid_ACC:0.6175999045372009
Epoch 631, CIFAR-10 Batch 4:  Train_Loss:0.6304330825805664, Valid_Loss:1.2197517156600952, Valid_ACC:0.6097999215126038
Epoch 631, CIFAR-10 Batch 5:  Train_Loss:0.6455475687980652, Valid_Loss:1.2271827459335327, Valid_ACC:0.6093999147415161
Epoch 632, CIFAR-10 Batch 1:  Train_Loss:0.6645632982254028, Valid_Loss:1.2353637218475342, Valid_ACC:0.605199933052063
Epoch 632, CIFAR-10 Batch 2:  Train_Loss:0.6413670778274536, Valid_Loss:1.235141634941101, Valid_ACC:0.6043999195098877
Epoch 632, CIFAR-10 Batch 3:  Train_Loss:0.6350367069244385, Valid_Loss:1.2107634544372559, Valid_ACC:0.6145999431610107
Epoch 632, CIFAR-10 Batch 4:  Train_Loss:0.6513246297836304, Valid_Loss:1.230164647102356, Valid_ACC:0.6055999398231506
Epoch 632, CIFAR-10 Batch 5:  Train_Loss:0.6824324727058411, Valid_Loss:1.2485336065292358, Valid_ACC:0.6013998985290527
Epoch 633, CIFAR-10 Batch 1:  Train_Loss:0.6483409404754639, Valid_Loss:1.2164413928985596, Valid_ACC:0.6147999167442322
Epoch 633, CIFAR-10 Batch 2:  Train_Loss:0.6137665510177612, Valid_Loss:1.204717993736267, Valid_ACC:0.6153998970985413
Epoch 633, CIFAR-10 Batch 3:  Train_Loss:0.6427340507507324, Valid_Loss:1.219624400138855, Valid_ACC:0.6101998686790466
Epoch 633, CIFAR-10 Batch 4:  Train_Loss:0.6438709497451782, Valid_Loss:1.2257192134857178, Valid_ACC:0.6091998815536499
Epoch 633, CIFAR-10 Batch 5:  Train_Loss:0.6601747274398804, Valid_Loss:1.2341148853302002, Valid_ACC:0.6059999465942383
Epoch 634, CIFAR-10 Batch 1:  Train_Loss:0.6479736566543579, Valid_Loss:1.2219045162200928, Valid_ACC:0.6089998483657837
Epoch 634, CIFAR-10 Batch 2:  Train_Loss:0.6362269520759583, Valid_Loss:1.2145018577575684, Valid_ACC:0.6091998815536499
Epoch 634, CIFAR-10 Batch 3:  Train_Loss:0.6449906826019287, Valid_Loss:1.2236138582229614, Valid_ACC:0.6119998693466187
Epoch 634, CIFAR-10 Batch 4:  Train_Loss:0.6402589678764343, Valid_Loss:1.2134521007537842, Valid_ACC:0.6111999154090881
Epoch 634, CIFAR-10 Batch 5:  Train_Loss:0.6698036193847656, Valid_Loss:1.2278907299041748, Valid_ACC:0.6063998937606812
Epoch 635, CIFAR-10 Batch 1:  Train_Loss:0.6404412984848022, Valid_Loss:1.218330979347229, Valid_ACC:0.6123999357223511
Epoch 635, CIFAR-10 Batch 2:  Train_Loss:0.6434748768806458, Valid_Loss:1.235766887664795, Valid_ACC:0.6055998206138611
Epoch 635, CIFAR-10 Batch 3:  Train_Loss:0.670558750629425, Valid_Loss:1.2477846145629883, Valid_ACC:0.6027998924255371
Epoch 635, CIFAR-10 Batch 4:  Train_Loss:0.6608781814575195, Valid_Loss:1.2208294868469238, Valid_ACC:0.6129999160766602
Epoch 635, CIFAR-10 Batch 5:  Train_Loss:0.6507106423377991, Valid_Loss:1.2265970706939697, Valid_ACC:0.6103999018669128
Epoch 636, CIFAR-10 Batch 1:  Train_Loss:0.6410334706306458, Valid_Loss:1.2086398601531982, Valid_ACC:0.6177998781204224
Epoch 636, CIFAR-10 Batch 2:  Train_Loss:0.6433650255203247, Valid_Loss:1.2248411178588867, Valid_ACC:0.6095999479293823
Epoch 636, CIFAR-10 Batch 3:  Train_Loss:0.6438035368919373, Valid_Loss:1.2087762355804443, Valid_ACC:0.6121999025344849
Epoch 636, CIFAR-10 Batch 4:  Train_Loss:0.6288824081420898, Valid_Loss:1.2070889472961426, Valid_ACC:0.614599883556366
Epoch 636, CIFAR-10 Batch 5:  Train_Loss:0.6417185068130493, Valid_Loss:1.2197107076644897, Valid_ACC:0.6089999079704285
Epoch 637, CIFAR-10 Batch 1:  Train_Loss:0.6387917399406433, Valid_Loss:1.213320016860962, Valid_ACC:0.6143999099731445
Epoch 637, CIFAR-10 Batch 2:  Train_Loss:0.6393465995788574, Valid_Loss:1.2193188667297363, Valid_ACC:0.6083998680114746
Epoch 637, CIFAR-10 Batch 3:  Train_Loss:0.6365147829055786, Valid_Loss:1.2264273166656494, Valid_ACC:0.6101999282836914
Epoch 637, CIFAR-10 Batch 4:  Train_Loss:0.623641312122345, Valid_Loss:1.2035934925079346, Valid_ACC:0.6139999032020569
Epoch 637, CIFAR-10 Batch 5:  Train_Loss:0.6455340385437012, Valid_Loss:1.2209001779556274, Valid_ACC:0.6085999011993408
Epoch 638, CIFAR-10 Batch 1:  Train_Loss:0.6459228992462158, Valid_Loss:1.2166428565979004, Valid_ACC:0.6127999424934387
Epoch 638, CIFAR-10 Batch 2:  Train_Loss:0.6407057046890259, Valid_Loss:1.2123689651489258, Valid_ACC:0.6133999228477478
Epoch 638, CIFAR-10 Batch 3:  Train_Loss:0.6372624039649963, Valid_Loss:1.2175910472869873, Valid_ACC:0.6113999485969543
Epoch 638, CIFAR-10 Batch 4:  Train_Loss:0.6212751269340515, Valid_Loss:1.2090474367141724, Valid_ACC:0.6141998767852783
Epoch 638, CIFAR-10 Batch 5:  Train_Loss:0.6408208608627319, Valid_Loss:1.219075083732605, Valid_ACC:0.609799861907959
Epoch 639, CIFAR-10 Batch 1:  Train_Loss:0.6375128030776978, Valid_Loss:1.210333228111267, Valid_ACC:0.6131999492645264
Epoch 639, CIFAR-10 Batch 2:  Train_Loss:0.624556303024292, Valid_Loss:1.2165637016296387, Valid_ACC:0.6095998883247375
Epoch 639, CIFAR-10 Batch 3:  Train_Loss:0.6340417265892029, Valid_Loss:1.215856909751892, Valid_ACC:0.6139999032020569
Epoch 639, CIFAR-10 Batch 4:  Train_Loss:0.6232829093933105, Valid_Loss:1.2053463459014893, Valid_ACC:0.6113998889923096
Epoch 639, CIFAR-10 Batch 5:  Train_Loss:0.6447272896766663, Valid_Loss:1.2290139198303223, Valid_ACC:0.608799934387207
Epoch 640, CIFAR-10 Batch 1:  Train_Loss:0.6436892151832581, Valid_Loss:1.2109832763671875, Valid_ACC:0.6161999702453613
Epoch 640, CIFAR-10 Batch 2:  Train_Loss:0.6572219133377075, Valid_Loss:1.2259016036987305, Valid_ACC:0.6103998422622681
Epoch 640, CIFAR-10 Batch 3:  Train_Loss:0.6482132077217102, Valid_Loss:1.2303887605667114, Valid_ACC:0.6119999289512634
Epoch 640, CIFAR-10 Batch 4:  Train_Loss:0.6279580593109131, Valid_Loss:1.2159771919250488, Valid_ACC:0.6115999221801758
Epoch 640, CIFAR-10 Batch 5:  Train_Loss:0.6392251253128052, Valid_Loss:1.2179772853851318, Valid_ACC:0.6125999093055725
Epoch 641, CIFAR-10 Batch 1:  Train_Loss:0.6651092171669006, Valid_Loss:1.2353284358978271, Valid_ACC:0.6067999601364136
Epoch 641, CIFAR-10 Batch 2:  Train_Loss:0.6168272495269775, Valid_Loss:1.2059417963027954, Valid_ACC:0.6187999248504639
Epoch 641, CIFAR-10 Batch 3:  Train_Loss:0.6342363357543945, Valid_Loss:1.2162114381790161, Valid_ACC:0.6115999221801758
Epoch 641, CIFAR-10 Batch 4:  Train_Loss:0.6180959939956665, Valid_Loss:1.2103923559188843, Valid_ACC:0.616399884223938
Epoch 641, CIFAR-10 Batch 5:  Train_Loss:0.6536105275154114, Valid_Loss:1.2293015718460083, Valid_ACC:0.6071999073028564
Epoch 642, CIFAR-10 Batch 1:  Train_Loss:0.6382843852043152, Valid_Loss:1.207526683807373, Valid_ACC:0.6169999241828918
Epoch 642, CIFAR-10 Batch 2:  Train_Loss:0.6293840408325195, Valid_Loss:1.2202942371368408, Valid_ACC:0.6085999011993408
Epoch 642, CIFAR-10 Batch 3:  Train_Loss:0.6453322172164917, Valid_Loss:1.218508243560791, Valid_ACC:0.611599862575531
Epoch 642, CIFAR-10 Batch 4:  Train_Loss:0.6305599212646484, Valid_Loss:1.2022358179092407, Valid_ACC:0.6145999431610107
Epoch 642, CIFAR-10 Batch 5:  Train_Loss:0.6572760343551636, Valid_Loss:1.2359951734542847, Valid_ACC:0.6041998863220215
Epoch 643, CIFAR-10 Batch 1:  Train_Loss:0.6289137005805969, Valid_Loss:1.2186574935913086, Valid_ACC:0.6075999140739441
Epoch 643, CIFAR-10 Batch 2:  Train_Loss:0.6382441520690918, Valid_Loss:1.220299243927002, Valid_ACC:0.6127999424934387
Epoch 643, CIFAR-10 Batch 3:  Train_Loss:0.654519259929657, Valid_Loss:1.2270737886428833, Valid_ACC:0.6047999262809753
Epoch 643, CIFAR-10 Batch 4:  Train_Loss:0.6447462439537048, Valid_Loss:1.226317048072815, Valid_ACC:0.608199954032898
Epoch 643, CIFAR-10 Batch 5:  Train_Loss:0.6796216368675232, Valid_Loss:1.23239004611969, Valid_ACC:0.606999933719635
Epoch 644, CIFAR-10 Batch 1:  Train_Loss:0.6682043075561523, Valid_Loss:1.235811471939087, Valid_ACC:0.6043999195098877
Epoch 644, CIFAR-10 Batch 2:  Train_Loss:0.6332457065582275, Valid_Loss:1.2147295475006104, Valid_ACC:0.6107999086380005
Epoch 644, CIFAR-10 Batch 3:  Train_Loss:0.6319466829299927, Valid_Loss:1.2085360288619995, Valid_ACC:0.6133999228477478
Epoch 644, CIFAR-10 Batch 4:  Train_Loss:0.6385897994041443, Valid_Loss:1.2266671657562256, Valid_ACC:0.6033998727798462
Epoch 644, CIFAR-10 Batch 5:  Train_Loss:0.6514372825622559, Valid_Loss:1.2216565608978271, Valid_ACC:0.608199954032898
Epoch 645, CIFAR-10 Batch 1:  Train_Loss:0.6596821546554565, Valid_Loss:1.2224520444869995, Valid_ACC:0.6041998863220215
Epoch 645, CIFAR-10 Batch 2:  Train_Loss:0.6699281930923462, Valid_Loss:1.23392653465271, Valid_ACC:0.6097999215126038
Epoch 645, CIFAR-10 Batch 3:  Train_Loss:0.6429039835929871, Valid_Loss:1.2174866199493408, Valid_ACC:0.6111999154090881
Epoch 645, CIFAR-10 Batch 4:  Train_Loss:0.6352466344833374, Valid_Loss:1.213597297668457, Valid_ACC:0.6077998876571655
Epoch 645, CIFAR-10 Batch 5:  Train_Loss:0.657470703125, Valid_Loss:1.2306880950927734, Valid_ACC:0.6055999398231506
Epoch 646, CIFAR-10 Batch 1:  Train_Loss:0.6472729444503784, Valid_Loss:1.218538522720337, Valid_ACC:0.6113999485969543
Epoch 646, CIFAR-10 Batch 2:  Train_Loss:0.6299185752868652, Valid_Loss:1.211121916770935, Valid_ACC:0.6147999167442322
Epoch 646, CIFAR-10 Batch 3:  Train_Loss:0.6537028551101685, Valid_Loss:1.2312273979187012, Valid_ACC:0.6075999140739441
Epoch 646, CIFAR-10 Batch 4:  Train_Loss:0.6279094219207764, Valid_Loss:1.2155869007110596, Valid_ACC:0.6091998815536499
Epoch 646, CIFAR-10 Batch 5:  Train_Loss:0.6388064622879028, Valid_Loss:1.2178689241409302, Valid_ACC:0.6081998944282532
Epoch 647, CIFAR-10 Batch 1:  Train_Loss:0.6683756709098816, Valid_Loss:1.2231996059417725, Valid_ACC:0.6057999134063721
Epoch 647, CIFAR-10 Batch 2:  Train_Loss:0.6391827464103699, Valid_Loss:1.2229499816894531, Valid_ACC:0.6149998903274536
Epoch 647, CIFAR-10 Batch 3:  Train_Loss:0.638590395450592, Valid_Loss:1.2153825759887695, Valid_ACC:0.6053999662399292
Epoch 647, CIFAR-10 Batch 4:  Train_Loss:0.6286060214042664, Valid_Loss:1.2123122215270996, Valid_ACC:0.6107999086380005
Epoch 647, CIFAR-10 Batch 5:  Train_Loss:0.6562033295631409, Valid_Loss:1.2324409484863281, Valid_ACC:0.6057999730110168
Epoch 648, CIFAR-10 Batch 1:  Train_Loss:0.6546661853790283, Valid_Loss:1.2222847938537598, Valid_ACC:0.6063999533653259
Epoch 648, CIFAR-10 Batch 2:  Train_Loss:0.6267678737640381, Valid_Loss:1.212238073348999, Valid_ACC:0.6109999418258667
Epoch 648, CIFAR-10 Batch 3:  Train_Loss:0.6429824829101562, Valid_Loss:1.2136013507843018, Valid_ACC:0.6081998944282532
Epoch 648, CIFAR-10 Batch 4:  Train_Loss:0.646028995513916, Valid_Loss:1.2257874011993408, Valid_ACC:0.6059998869895935
Epoch 648, CIFAR-10 Batch 5:  Train_Loss:0.6731495261192322, Valid_Loss:1.234857439994812, Valid_ACC:0.6023998856544495
Epoch 649, CIFAR-10 Batch 1:  Train_Loss:0.6459589600563049, Valid_Loss:1.2155922651290894, Valid_ACC:0.6129999160766602
Epoch 649, CIFAR-10 Batch 2:  Train_Loss:0.6375882625579834, Valid_Loss:1.2289223670959473, Valid_ACC:0.6071999073028564
Epoch 649, CIFAR-10 Batch 3:  Train_Loss:0.6429420709609985, Valid_Loss:1.2232699394226074, Valid_ACC:0.6079999208450317
Epoch 649, CIFAR-10 Batch 4:  Train_Loss:0.6338305473327637, Valid_Loss:1.2193323373794556, Valid_ACC:0.6043999195098877
Epoch 649, CIFAR-10 Batch 5:  Train_Loss:0.6702665090560913, Valid_Loss:1.2346763610839844, Valid_ACC:0.6085999011993408
Epoch 650, CIFAR-10 Batch 1:  Train_Loss:0.6455232501029968, Valid_Loss:1.2070670127868652, Valid_ACC:0.6161999106407166
Epoch 650, CIFAR-10 Batch 2:  Train_Loss:0.6243302226066589, Valid_Loss:1.2147343158721924, Valid_ACC:0.6109999418258667
Epoch 650, CIFAR-10 Batch 3:  Train_Loss:0.6392501592636108, Valid_Loss:1.211216688156128, Valid_ACC:0.6135998368263245
Epoch 650, CIFAR-10 Batch 4:  Train_Loss:0.6408900022506714, Valid_Loss:1.2276116609573364, Valid_ACC:0.6103999018669128
Epoch 650, CIFAR-10 Batch 5:  Train_Loss:0.6536428332328796, Valid_Loss:1.2266230583190918, Valid_ACC:0.6069998741149902
Epoch 651, CIFAR-10 Batch 1:  Train_Loss:0.6590961217880249, Valid_Loss:1.220118761062622, Valid_ACC:0.6119999289512634
Epoch 651, CIFAR-10 Batch 2:  Train_Loss:0.6637580990791321, Valid_Loss:1.239152431488037, Valid_ACC:0.6077998876571655
Epoch 651, CIFAR-10 Batch 3:  Train_Loss:0.6366385221481323, Valid_Loss:1.2138466835021973, Valid_ACC:0.6111999154090881
Epoch 651, CIFAR-10 Batch 4:  Train_Loss:0.6260759234428406, Valid_Loss:1.2098033428192139, Valid_ACC:0.608199954032898
Epoch 651, CIFAR-10 Batch 5:  Train_Loss:0.6381619572639465, Valid_Loss:1.2275880575180054, Valid_ACC:0.6081998944282532
Epoch 652, CIFAR-10 Batch 1:  Train_Loss:0.6553922891616821, Valid_Loss:1.2336678504943848, Valid_ACC:0.6069998741149902
Epoch 652, CIFAR-10 Batch 2:  Train_Loss:0.6491512060165405, Valid_Loss:1.2324943542480469, Valid_ACC:0.6039998531341553
Epoch 652, CIFAR-10 Batch 3:  Train_Loss:0.656975507736206, Valid_Loss:1.2223118543624878, Valid_ACC:0.6115999221801758
Epoch 652, CIFAR-10 Batch 4:  Train_Loss:0.641079843044281, Valid_Loss:1.2216655015945435, Valid_ACC:0.6113998889923096
Epoch 652, CIFAR-10 Batch 5:  Train_Loss:0.6645522117614746, Valid_Loss:1.232825517654419, Valid_ACC:0.6033998727798462
Epoch 653, CIFAR-10 Batch 1:  Train_Loss:0.6385594010353088, Valid_Loss:1.2059284448623657, Valid_ACC:0.6150000095367432
Epoch 653, CIFAR-10 Batch 2:  Train_Loss:0.6294587254524231, Valid_Loss:1.2125650644302368, Valid_ACC:0.6125999093055725
Epoch 653, CIFAR-10 Batch 3:  Train_Loss:0.6473836898803711, Valid_Loss:1.2180575132369995, Valid_ACC:0.6093999147415161
Epoch 653, CIFAR-10 Batch 4:  Train_Loss:0.6382509469985962, Valid_Loss:1.223097801208496, Valid_ACC:0.6099998950958252
Epoch 653, CIFAR-10 Batch 5:  Train_Loss:0.6469897031784058, Valid_Loss:1.2240740060806274, Valid_ACC:0.6065999269485474
Epoch 654, CIFAR-10 Batch 1:  Train_Loss:0.660417377948761, Valid_Loss:1.2171636819839478, Valid_ACC:0.6139999032020569
Epoch 654, CIFAR-10 Batch 2:  Train_Loss:0.6184437274932861, Valid_Loss:1.2115795612335205, Valid_ACC:0.6085999608039856
Epoch 654, CIFAR-10 Batch 3:  Train_Loss:0.6315140724182129, Valid_Loss:1.2063277959823608, Valid_ACC:0.6115999221801758
Epoch 654, CIFAR-10 Batch 4:  Train_Loss:0.6183308362960815, Valid_Loss:1.2073334455490112, Valid_ACC:0.6121999025344849
Epoch 654, CIFAR-10 Batch 5:  Train_Loss:0.6491055488586426, Valid_Loss:1.2252607345581055, Valid_ACC:0.6053999662399292
Epoch 655, CIFAR-10 Batch 1:  Train_Loss:0.6373683214187622, Valid_Loss:1.2152498960494995, Valid_ACC:0.6103999018669128
Epoch 655, CIFAR-10 Batch 2:  Train_Loss:0.6257126927375793, Valid_Loss:1.216036319732666, Valid_ACC:0.606999933719635
Epoch 655, CIFAR-10 Batch 3:  Train_Loss:0.629517138004303, Valid_Loss:1.2026721239089966, Valid_ACC:0.6151999235153198
Epoch 655, CIFAR-10 Batch 4:  Train_Loss:0.6380126476287842, Valid_Loss:1.2136541604995728, Valid_ACC:0.6121999025344849
Epoch 655, CIFAR-10 Batch 5:  Train_Loss:0.6669156551361084, Valid_Loss:1.2451467514038086, Valid_ACC:0.603399932384491
Epoch 656, CIFAR-10 Batch 1:  Train_Loss:0.6272337436676025, Valid_Loss:1.205958366394043, Valid_ACC:0.6117998957633972
Epoch 656, CIFAR-10 Batch 2:  Train_Loss:0.620566725730896, Valid_Loss:1.2147295475006104, Valid_ACC:0.6143999099731445
Epoch 656, CIFAR-10 Batch 3:  Train_Loss:0.6224092245101929, Valid_Loss:1.2196279764175415, Valid_ACC:0.6101999282836914
Epoch 656, CIFAR-10 Batch 4:  Train_Loss:0.6063787341117859, Valid_Loss:1.2066980600357056, Valid_ACC:0.6119999289512634
Epoch 656, CIFAR-10 Batch 5:  Train_Loss:0.6342534422874451, Valid_Loss:1.2253223657608032, Valid_ACC:0.6097999215126038
Epoch 657, CIFAR-10 Batch 1:  Train_Loss:0.6401809453964233, Valid_Loss:1.203706979751587, Valid_ACC:0.6173999309539795
Epoch 657, CIFAR-10 Batch 2:  Train_Loss:0.623516321182251, Valid_Loss:1.2048604488372803, Valid_ACC:0.6159999370574951
Epoch 657, CIFAR-10 Batch 3:  Train_Loss:0.6400859355926514, Valid_Loss:1.2211523056030273, Valid_ACC:0.6107999086380005
Epoch 657, CIFAR-10 Batch 4:  Train_Loss:0.6409035921096802, Valid_Loss:1.220041275024414, Valid_ACC:0.611599862575531
Epoch 657, CIFAR-10 Batch 5:  Train_Loss:0.684274435043335, Valid_Loss:1.2454218864440918, Valid_ACC:0.5997998714447021
Epoch 658, CIFAR-10 Batch 1:  Train_Loss:0.6466546654701233, Valid_Loss:1.211186408996582, Valid_ACC:0.6139999032020569
Epoch 658, CIFAR-10 Batch 2:  Train_Loss:0.6064015030860901, Valid_Loss:1.210951566696167, Valid_ACC:0.6115999221801758
Epoch 658, CIFAR-10 Batch 3:  Train_Loss:0.631502628326416, Valid_Loss:1.2042092084884644, Valid_ACC:0.6147999167442322
Epoch 658, CIFAR-10 Batch 4:  Train_Loss:0.6195064783096313, Valid_Loss:1.205771803855896, Valid_ACC:0.6111998558044434
Epoch 658, CIFAR-10 Batch 5:  Train_Loss:0.6462662816047668, Valid_Loss:1.231041669845581, Valid_ACC:0.6079999208450317
Epoch 659, CIFAR-10 Batch 1:  Train_Loss:0.6274105310440063, Valid_Loss:1.201341152191162, Valid_ACC:0.6155999302864075
Epoch 659, CIFAR-10 Batch 2:  Train_Loss:0.6236074566841125, Valid_Loss:1.2164087295532227, Valid_ACC:0.6123999357223511
Epoch 659, CIFAR-10 Batch 3:  Train_Loss:0.6630409955978394, Valid_Loss:1.2329548597335815, Valid_ACC:0.6093999147415161
Epoch 659, CIFAR-10 Batch 4:  Train_Loss:0.6251923441886902, Valid_Loss:1.2142530679702759, Valid_ACC:0.6093999147415161
Epoch 659, CIFAR-10 Batch 5:  Train_Loss:0.6374098062515259, Valid_Loss:1.2112314701080322, Valid_ACC:0.6121999025344849
Epoch 660, CIFAR-10 Batch 1:  Train_Loss:0.6426537036895752, Valid_Loss:1.2166216373443604, Valid_ACC:0.6133999228477478
Epoch 660, CIFAR-10 Batch 2:  Train_Loss:0.616508424282074, Valid_Loss:1.2175395488739014, Valid_ACC:0.6111999154090881
Epoch 660, CIFAR-10 Batch 3:  Train_Loss:0.6262383460998535, Valid_Loss:1.2002907991409302, Valid_ACC:0.6119999289512634
Epoch 660, CIFAR-10 Batch 4:  Train_Loss:0.6150004863739014, Valid_Loss:1.204118251800537, Valid_ACC:0.6123999357223511
Epoch 660, CIFAR-10 Batch 5:  Train_Loss:0.6354635953903198, Valid_Loss:1.2303334474563599, Valid_ACC:0.6083998680114746
Epoch 661, CIFAR-10 Batch 1:  Train_Loss:0.6413745880126953, Valid_Loss:1.2126442193984985, Valid_ACC:0.6143999099731445
Epoch 661, CIFAR-10 Batch 2:  Train_Loss:0.6084794402122498, Valid_Loss:1.209794521331787, Valid_ACC:0.6147999167442322
Epoch 661, CIFAR-10 Batch 3:  Train_Loss:0.6244139075279236, Valid_Loss:1.2106274366378784, Valid_ACC:0.612799882888794
Epoch 661, CIFAR-10 Batch 4:  Train_Loss:0.6152968406677246, Valid_Loss:1.2069424390792847, Valid_ACC:0.6137999296188354
Epoch 661, CIFAR-10 Batch 5:  Train_Loss:0.6389273405075073, Valid_Loss:1.2261157035827637, Valid_ACC:0.6059998869895935
Epoch 662, CIFAR-10 Batch 1:  Train_Loss:0.6473268270492554, Valid_Loss:1.2244638204574585, Valid_ACC:0.6085999011993408
Epoch 662, CIFAR-10 Batch 2:  Train_Loss:0.6067110300064087, Valid_Loss:1.2156521081924438, Valid_ACC:0.6161998510360718
Epoch 662, CIFAR-10 Batch 3:  Train_Loss:0.6291872262954712, Valid_Loss:1.2136796712875366, Valid_ACC:0.6103999018669128
Epoch 662, CIFAR-10 Batch 4:  Train_Loss:0.6153899431228638, Valid_Loss:1.2035231590270996, Valid_ACC:0.6143999099731445
Epoch 662, CIFAR-10 Batch 5:  Train_Loss:0.633111298084259, Valid_Loss:1.2255229949951172, Valid_ACC:0.6075999140739441
Epoch 663, CIFAR-10 Batch 1:  Train_Loss:0.6256420612335205, Valid_Loss:1.203323483467102, Valid_ACC:0.6183998584747314
Epoch 663, CIFAR-10 Batch 2:  Train_Loss:0.6095529198646545, Valid_Loss:1.21488618850708, Valid_ACC:0.6121998429298401
Epoch 663, CIFAR-10 Batch 3:  Train_Loss:0.6244271993637085, Valid_Loss:1.2098079919815063, Valid_ACC:0.6119999289512634
Epoch 663, CIFAR-10 Batch 4:  Train_Loss:0.6181010007858276, Valid_Loss:1.215554118156433, Valid_ACC:0.6087998747825623
Epoch 663, CIFAR-10 Batch 5:  Train_Loss:0.6317435503005981, Valid_Loss:1.227526068687439, Valid_ACC:0.6065998673439026
Epoch 664, CIFAR-10 Batch 1:  Train_Loss:0.6254326105117798, Valid_Loss:1.2049428224563599, Valid_ACC:0.6159999370574951
Epoch 664, CIFAR-10 Batch 2:  Train_Loss:0.6108300685882568, Valid_Loss:1.2140578031539917, Valid_ACC:0.6099998950958252
Epoch 664, CIFAR-10 Batch 3:  Train_Loss:0.6234502196311951, Valid_Loss:1.2235819101333618, Valid_ACC:0.6127999424934387
Epoch 664, CIFAR-10 Batch 4:  Train_Loss:0.6188948750495911, Valid_Loss:1.2060729265213013, Valid_ACC:0.6161998510360718
Epoch 664, CIFAR-10 Batch 5:  Train_Loss:0.6386628150939941, Valid_Loss:1.2235229015350342, Valid_ACC:0.606999933719635
Epoch 665, CIFAR-10 Batch 1:  Train_Loss:0.635613203048706, Valid_Loss:1.20737624168396, Valid_ACC:0.616599977016449
Epoch 665, CIFAR-10 Batch 2:  Train_Loss:0.6172910332679749, Valid_Loss:1.21639084815979, Valid_ACC:0.6139999032020569
Epoch 665, CIFAR-10 Batch 3:  Train_Loss:0.6263198852539062, Valid_Loss:1.205596685409546, Valid_ACC:0.6155999302864075
Epoch 665, CIFAR-10 Batch 4:  Train_Loss:0.6198818683624268, Valid_Loss:1.2121232748031616, Valid_ACC:0.6155999898910522
Epoch 665, CIFAR-10 Batch 5:  Train_Loss:0.6389939785003662, Valid_Loss:1.2207562923431396, Valid_ACC:0.607999861240387
Epoch 666, CIFAR-10 Batch 1:  Train_Loss:0.6368510127067566, Valid_Loss:1.208627462387085, Valid_ACC:0.6159999370574951
Epoch 666, CIFAR-10 Batch 2:  Train_Loss:0.6178865432739258, Valid_Loss:1.214768409729004, Valid_ACC:0.6131998896598816
Epoch 666, CIFAR-10 Batch 3:  Train_Loss:0.6117874383926392, Valid_Loss:1.2103042602539062, Valid_ACC:0.6131999492645264
Epoch 666, CIFAR-10 Batch 4:  Train_Loss:0.6175019145011902, Valid_Loss:1.206108570098877, Valid_ACC:0.6095999479293823
Epoch 666, CIFAR-10 Batch 5:  Train_Loss:0.6259005665779114, Valid_Loss:1.2327134609222412, Valid_ACC:0.6101999282836914
Epoch 667, CIFAR-10 Batch 1:  Train_Loss:0.6381182074546814, Valid_Loss:1.2102380990982056, Valid_ACC:0.6169999241828918
Epoch 667, CIFAR-10 Batch 2:  Train_Loss:0.6160247921943665, Valid_Loss:1.211055040359497, Valid_ACC:0.61819988489151
Epoch 667, CIFAR-10 Batch 3:  Train_Loss:0.6251940727233887, Valid_Loss:1.2164299488067627, Valid_ACC:0.6109999418258667
Epoch 667, CIFAR-10 Batch 4:  Train_Loss:0.615993857383728, Valid_Loss:1.2137346267700195, Valid_ACC:0.6107999086380005
Epoch 667, CIFAR-10 Batch 5:  Train_Loss:0.6290150284767151, Valid_Loss:1.2265880107879639, Valid_ACC:0.6097999215126038
Epoch 668, CIFAR-10 Batch 1:  Train_Loss:0.6306301951408386, Valid_Loss:1.21417236328125, Valid_ACC:0.6195999383926392
Epoch 668, CIFAR-10 Batch 2:  Train_Loss:0.6307522654533386, Valid_Loss:1.2133615016937256, Valid_ACC:0.6145999431610107
Epoch 668, CIFAR-10 Batch 3:  Train_Loss:0.6294775009155273, Valid_Loss:1.2159157991409302, Valid_ACC:0.6145998239517212
Epoch 668, CIFAR-10 Batch 4:  Train_Loss:0.6255744099617004, Valid_Loss:1.2095857858657837, Valid_ACC:0.6093999147415161
Epoch 668, CIFAR-10 Batch 5:  Train_Loss:0.652719259262085, Valid_Loss:1.2426742315292358, Valid_ACC:0.601599931716919
Epoch 669, CIFAR-10 Batch 1:  Train_Loss:0.6372799277305603, Valid_Loss:1.21364426612854, Valid_ACC:0.6113998889923096
Epoch 669, CIFAR-10 Batch 2:  Train_Loss:0.616952657699585, Valid_Loss:1.20676851272583, Valid_ACC:0.6109999418258667
Epoch 669, CIFAR-10 Batch 3:  Train_Loss:0.6309892535209656, Valid_Loss:1.225581407546997, Valid_ACC:0.6111999750137329
Epoch 669, CIFAR-10 Batch 4:  Train_Loss:0.6315240263938904, Valid_Loss:1.212129831314087, Valid_ACC:0.6125998497009277
Epoch 669, CIFAR-10 Batch 5:  Train_Loss:0.6385779976844788, Valid_Loss:1.2323071956634521, Valid_ACC:0.6083999276161194
Epoch 670, CIFAR-10 Batch 1:  Train_Loss:0.6242066025733948, Valid_Loss:1.208925485610962, Valid_ACC:0.6143999099731445
Epoch 670, CIFAR-10 Batch 2:  Train_Loss:0.6299024820327759, Valid_Loss:1.230392575263977, Valid_ACC:0.6093999147415161
Epoch 670, CIFAR-10 Batch 3:  Train_Loss:0.6391581296920776, Valid_Loss:1.2145500183105469, Valid_ACC:0.6125999093055725
Epoch 670, CIFAR-10 Batch 4:  Train_Loss:0.6207153797149658, Valid_Loss:1.2082124948501587, Valid_ACC:0.6097999811172485
Epoch 670, CIFAR-10 Batch 5:  Train_Loss:0.6284700632095337, Valid_Loss:1.2215168476104736, Valid_ACC:0.6109999418258667
Epoch 671, CIFAR-10 Batch 1:  Train_Loss:0.6455360651016235, Valid_Loss:1.2126230001449585, Valid_ACC:0.6151999235153198
Epoch 671, CIFAR-10 Batch 2:  Train_Loss:0.6211520433425903, Valid_Loss:1.21767258644104, Valid_ACC:0.6079999208450317
Epoch 671, CIFAR-10 Batch 3:  Train_Loss:0.6276516318321228, Valid_Loss:1.2024767398834229, Valid_ACC:0.616399884223938
Epoch 671, CIFAR-10 Batch 4:  Train_Loss:0.6171709299087524, Valid_Loss:1.217193841934204, Valid_ACC:0.6119999885559082
Epoch 671, CIFAR-10 Batch 5:  Train_Loss:0.6109765768051147, Valid_Loss:1.2061338424682617, Valid_ACC:0.6125998497009277
Epoch 672, CIFAR-10 Batch 1:  Train_Loss:0.6350299715995789, Valid_Loss:1.2132258415222168, Valid_ACC:0.6107999086380005
Epoch 672, CIFAR-10 Batch 2:  Train_Loss:0.6186175346374512, Valid_Loss:1.2232153415679932, Valid_ACC:0.6061999797821045
Epoch 672, CIFAR-10 Batch 3:  Train_Loss:0.6134585738182068, Valid_Loss:1.209538221359253, Valid_ACC:0.6119999289512634
Epoch 672, CIFAR-10 Batch 4:  Train_Loss:0.6218153238296509, Valid_Loss:1.2139474153518677, Valid_ACC:0.6101999282836914
Epoch 672, CIFAR-10 Batch 5:  Train_Loss:0.6599528789520264, Valid_Loss:1.2472740411758423, Valid_ACC:0.6017999649047852
Epoch 673, CIFAR-10 Batch 1:  Train_Loss:0.6435456871986389, Valid_Loss:1.2150061130523682, Valid_ACC:0.6109998822212219
Epoch 673, CIFAR-10 Batch 2:  Train_Loss:0.6137703061103821, Valid_Loss:1.2131918668746948, Valid_ACC:0.6135998964309692
Epoch 673, CIFAR-10 Batch 3:  Train_Loss:0.6213493347167969, Valid_Loss:1.2082653045654297, Valid_ACC:0.616399884223938
Epoch 673, CIFAR-10 Batch 4:  Train_Loss:0.6164461970329285, Valid_Loss:1.201960802078247, Valid_ACC:0.6139999628067017
Epoch 673, CIFAR-10 Batch 5:  Train_Loss:0.653834342956543, Valid_Loss:1.2273377180099487, Valid_ACC:0.6087998747825623
Epoch 674, CIFAR-10 Batch 1:  Train_Loss:0.632136881351471, Valid_Loss:1.1984821557998657, Valid_ACC:0.619399905204773
Epoch 674, CIFAR-10 Batch 2:  Train_Loss:0.6068277359008789, Valid_Loss:1.208512544631958, Valid_ACC:0.6149998903274536
Epoch 674, CIFAR-10 Batch 3:  Train_Loss:0.6295772790908813, Valid_Loss:1.2155288457870483, Valid_ACC:0.6077998876571655
Epoch 674, CIFAR-10 Batch 4:  Train_Loss:0.6205205321311951, Valid_Loss:1.207364797592163, Valid_ACC:0.6143999099731445
Epoch 674, CIFAR-10 Batch 5:  Train_Loss:0.6254565119743347, Valid_Loss:1.2146118879318237, Valid_ACC:0.6125999093055725
Epoch 675, CIFAR-10 Batch 1:  Train_Loss:0.6378762722015381, Valid_Loss:1.2163403034210205, Valid_ACC:0.6175999641418457
Epoch 675, CIFAR-10 Batch 2:  Train_Loss:0.6167125701904297, Valid_Loss:1.2226734161376953, Valid_ACC:0.6107999086380005
Epoch 675, CIFAR-10 Batch 3:  Train_Loss:0.6086390018463135, Valid_Loss:1.2038822174072266, Valid_ACC:0.6195998787879944
Epoch 675, CIFAR-10 Batch 4:  Train_Loss:0.6071746945381165, Valid_Loss:1.1980955600738525, Valid_ACC:0.6149998903274536
Epoch 675, CIFAR-10 Batch 5:  Train_Loss:0.6324986219406128, Valid_Loss:1.2198965549468994, Valid_ACC:0.6063999533653259
Epoch 676, CIFAR-10 Batch 1:  Train_Loss:0.6349559426307678, Valid_Loss:1.2132145166397095, Valid_ACC:0.6205998659133911
Epoch 676, CIFAR-10 Batch 2:  Train_Loss:0.6094273328781128, Valid_Loss:1.2124850749969482, Valid_ACC:0.6115999221801758
Epoch 676, CIFAR-10 Batch 3:  Train_Loss:0.6315460205078125, Valid_Loss:1.2141610383987427, Valid_ACC:0.6109999418258667
Epoch 676, CIFAR-10 Batch 4:  Train_Loss:0.6113417148590088, Valid_Loss:1.208388328552246, Valid_ACC:0.6159999370574951
Epoch 676, CIFAR-10 Batch 5:  Train_Loss:0.6244063973426819, Valid_Loss:1.21161687374115, Valid_ACC:0.6105998754501343
Epoch 677, CIFAR-10 Batch 1:  Train_Loss:0.6285399794578552, Valid_Loss:1.2128093242645264, Valid_ACC:0.6163999438285828
Epoch 677, CIFAR-10 Batch 2:  Train_Loss:0.6157749891281128, Valid_Loss:1.2139806747436523, Valid_ACC:0.6097999215126038
Epoch 677, CIFAR-10 Batch 3:  Train_Loss:0.6354870796203613, Valid_Loss:1.2086868286132812, Valid_ACC:0.6109998822212219
Epoch 677, CIFAR-10 Batch 4:  Train_Loss:0.6310979723930359, Valid_Loss:1.2301268577575684, Valid_ACC:0.6083998680114746
Epoch 677, CIFAR-10 Batch 5:  Train_Loss:0.6357582211494446, Valid_Loss:1.2175376415252686, Valid_ACC:0.6129999160766602
Epoch 678, CIFAR-10 Batch 1:  Train_Loss:0.641706109046936, Valid_Loss:1.2133970260620117, Valid_ACC:0.612799882888794
Epoch 678, CIFAR-10 Batch 2:  Train_Loss:0.6353034377098083, Valid_Loss:1.2362864017486572, Valid_ACC:0.6079999208450317
Epoch 678, CIFAR-10 Batch 3:  Train_Loss:0.6210141181945801, Valid_Loss:1.2196391820907593, Valid_ACC:0.6113998889923096
Epoch 678, CIFAR-10 Batch 4:  Train_Loss:0.6247325539588928, Valid_Loss:1.22227144241333, Valid_ACC:0.6037999391555786
Epoch 678, CIFAR-10 Batch 5:  Train_Loss:0.6358784437179565, Valid_Loss:1.227009892463684, Valid_ACC:0.6071999073028564
Epoch 679, CIFAR-10 Batch 1:  Train_Loss:0.6329960227012634, Valid_Loss:1.2167823314666748, Valid_ACC:0.6077999472618103
Epoch 679, CIFAR-10 Batch 2:  Train_Loss:0.6163267493247986, Valid_Loss:1.2254358530044556, Valid_ACC:0.6085999011993408
Epoch 679, CIFAR-10 Batch 3:  Train_Loss:0.6464446783065796, Valid_Loss:1.2343921661376953, Valid_ACC:0.6091998815536499
Epoch 679, CIFAR-10 Batch 4:  Train_Loss:0.6164805293083191, Valid_Loss:1.2093262672424316, Valid_ACC:0.6105998754501343
Epoch 679, CIFAR-10 Batch 5:  Train_Loss:0.6227691173553467, Valid_Loss:1.2144174575805664, Valid_ACC:0.6115999221801758
Epoch 680, CIFAR-10 Batch 1:  Train_Loss:0.6427334547042847, Valid_Loss:1.2210373878479004, Valid_ACC:0.6125999093055725
Epoch 680, CIFAR-10 Batch 2:  Train_Loss:0.6222654581069946, Valid_Loss:1.2188998460769653, Valid_ACC:0.6137998700141907
Epoch 680, CIFAR-10 Batch 3:  Train_Loss:0.6260380148887634, Valid_Loss:1.2157231569290161, Valid_ACC:0.6139998435974121
Epoch 680, CIFAR-10 Batch 4:  Train_Loss:0.617946982383728, Valid_Loss:1.2190948724746704, Valid_ACC:0.606999933719635
Epoch 680, CIFAR-10 Batch 5:  Train_Loss:0.6258570551872253, Valid_Loss:1.2206085920333862, Valid_ACC:0.6125999093055725
Epoch 681, CIFAR-10 Batch 1:  Train_Loss:0.6325345039367676, Valid_Loss:1.2137632369995117, Valid_ACC:0.6143999099731445
Epoch 681, CIFAR-10 Batch 2:  Train_Loss:0.6202131509780884, Valid_Loss:1.220877766609192, Valid_ACC:0.6071999669075012
Epoch 681, CIFAR-10 Batch 3:  Train_Loss:0.6138617396354675, Valid_Loss:1.2064247131347656, Valid_ACC:0.6151999235153198
Epoch 681, CIFAR-10 Batch 4:  Train_Loss:0.6106468439102173, Valid_Loss:1.204889178276062, Valid_ACC:0.6105998754501343
Epoch 681, CIFAR-10 Batch 5:  Train_Loss:0.6262872815132141, Valid_Loss:1.215776801109314, Valid_ACC:0.6107999086380005
Epoch 682, CIFAR-10 Batch 1:  Train_Loss:0.6268547773361206, Valid_Loss:1.2123117446899414, Valid_ACC:0.6185998916625977
Epoch 682, CIFAR-10 Batch 2:  Train_Loss:0.6122356653213501, Valid_Loss:1.2124919891357422, Valid_ACC:0.612799882888794
Epoch 682, CIFAR-10 Batch 3:  Train_Loss:0.6185453534126282, Valid_Loss:1.214904546737671, Valid_ACC:0.6109998822212219
Epoch 682, CIFAR-10 Batch 4:  Train_Loss:0.6057307720184326, Valid_Loss:1.200213074684143, Valid_ACC:0.6155998706817627
Epoch 682, CIFAR-10 Batch 5:  Train_Loss:0.6311787366867065, Valid_Loss:1.2161227464675903, Valid_ACC:0.6101999282836914
Epoch 683, CIFAR-10 Batch 1:  Train_Loss:0.6391735076904297, Valid_Loss:1.208088755607605, Valid_ACC:0.6179999113082886
Epoch 683, CIFAR-10 Batch 2:  Train_Loss:0.6252524256706238, Valid_Loss:1.218813419342041, Valid_ACC:0.611799955368042
Epoch 683, CIFAR-10 Batch 3:  Train_Loss:0.6164658069610596, Valid_Loss:1.2155463695526123, Valid_ACC:0.6149999499320984
Epoch 683, CIFAR-10 Batch 4:  Train_Loss:0.6242413520812988, Valid_Loss:1.2075906991958618, Valid_ACC:0.6115999221801758
Epoch 683, CIFAR-10 Batch 5:  Train_Loss:0.6348931193351746, Valid_Loss:1.234236717224121, Valid_ACC:0.6091998815536499
Epoch 684, CIFAR-10 Batch 1:  Train_Loss:0.6322402358055115, Valid_Loss:1.2120628356933594, Valid_ACC:0.6109999418258667
Epoch 684, CIFAR-10 Batch 2:  Train_Loss:0.624433159828186, Valid_Loss:1.2226225137710571, Valid_ACC:0.6119999289512634
Epoch 684, CIFAR-10 Batch 3:  Train_Loss:0.6296827793121338, Valid_Loss:1.2099409103393555, Valid_ACC:0.6121999025344849
Epoch 684, CIFAR-10 Batch 4:  Train_Loss:0.6187129020690918, Valid_Loss:1.2149684429168701, Valid_ACC:0.6109999418258667
Epoch 684, CIFAR-10 Batch 5:  Train_Loss:0.6316667795181274, Valid_Loss:1.2284009456634521, Valid_ACC:0.6073999404907227
Epoch 685, CIFAR-10 Batch 1:  Train_Loss:0.6336534023284912, Valid_Loss:1.2147036790847778, Valid_ACC:0.6097999215126038
Epoch 685, CIFAR-10 Batch 2:  Train_Loss:0.6167392134666443, Valid_Loss:1.224998116493225, Valid_ACC:0.6109999418258667
Epoch 685, CIFAR-10 Batch 3:  Train_Loss:0.6219068169593811, Valid_Loss:1.2153708934783936, Valid_ACC:0.608199954032898
Epoch 685, CIFAR-10 Batch 4:  Train_Loss:0.6088709831237793, Valid_Loss:1.2103960514068604, Valid_ACC:0.6143999099731445
Epoch 685, CIFAR-10 Batch 5:  Train_Loss:0.6164305210113525, Valid_Loss:1.2278043031692505, Valid_ACC:0.6101998686790466
Epoch 686, CIFAR-10 Batch 1:  Train_Loss:0.6201834082603455, Valid_Loss:1.2163336277008057, Valid_ACC:0.6117998957633972
Epoch 686, CIFAR-10 Batch 2:  Train_Loss:0.621257483959198, Valid_Loss:1.2160762548446655, Valid_ACC:0.6149998903274536
Epoch 686, CIFAR-10 Batch 3:  Train_Loss:0.6396905779838562, Valid_Loss:1.2325916290283203, Valid_ACC:0.6095998883247375
Epoch 686, CIFAR-10 Batch 4:  Train_Loss:0.6424531936645508, Valid_Loss:1.2230653762817383, Valid_ACC:0.6111999750137329
Epoch 686, CIFAR-10 Batch 5:  Train_Loss:0.6224287748336792, Valid_Loss:1.2311537265777588, Valid_ACC:0.6077999472618103
Epoch 687, CIFAR-10 Batch 1:  Train_Loss:0.6581594347953796, Valid_Loss:1.2329442501068115, Valid_ACC:0.6095999479293823
Epoch 687, CIFAR-10 Batch 2:  Train_Loss:0.6181962490081787, Valid_Loss:1.217302680015564, Valid_ACC:0.609799861907959
Epoch 687, CIFAR-10 Batch 3:  Train_Loss:0.6456966400146484, Valid_Loss:1.2183310985565186, Valid_ACC:0.610599935054779
Epoch 687, CIFAR-10 Batch 4:  Train_Loss:0.6025925874710083, Valid_Loss:1.2058818340301514, Valid_ACC:0.6143999099731445
Epoch 687, CIFAR-10 Batch 5:  Train_Loss:0.6524534225463867, Valid_Loss:1.245732069015503, Valid_ACC:0.5989999771118164
Epoch 688, CIFAR-10 Batch 1:  Train_Loss:0.6281578540802002, Valid_Loss:1.2215770483016968, Valid_ACC:0.6089999079704285
Epoch 688, CIFAR-10 Batch 2:  Train_Loss:0.6253249645233154, Valid_Loss:1.2292816638946533, Valid_ACC:0.6041998863220215
Epoch 688, CIFAR-10 Batch 3:  Train_Loss:0.6312640905380249, Valid_Loss:1.2186052799224854, Valid_ACC:0.6081998944282532
Epoch 688, CIFAR-10 Batch 4:  Train_Loss:0.6336009502410889, Valid_Loss:1.2378742694854736, Valid_ACC:0.6035999059677124
Epoch 688, CIFAR-10 Batch 5:  Train_Loss:0.6433850526809692, Valid_Loss:1.2306222915649414, Valid_ACC:0.6091999411582947
Epoch 689, CIFAR-10 Batch 1:  Train_Loss:0.6483324766159058, Valid_Loss:1.2314409017562866, Valid_ACC:0.6079999208450317
Epoch 689, CIFAR-10 Batch 2:  Train_Loss:0.6279177665710449, Valid_Loss:1.2281957864761353, Valid_ACC:0.6065998673439026
Epoch 689, CIFAR-10 Batch 3:  Train_Loss:0.6526254415512085, Valid_Loss:1.2387336492538452, Valid_ACC:0.607999861240387
Epoch 689, CIFAR-10 Batch 4:  Train_Loss:0.6334173679351807, Valid_Loss:1.2210485935211182, Valid_ACC:0.6071999073028564
Epoch 689, CIFAR-10 Batch 5:  Train_Loss:0.6390526294708252, Valid_Loss:1.2280919551849365, Valid_ACC:0.6013998985290527
Epoch 690, CIFAR-10 Batch 1:  Train_Loss:0.6293141841888428, Valid_Loss:1.2172964811325073, Valid_ACC:0.6105998754501343
Epoch 690, CIFAR-10 Batch 2:  Train_Loss:0.6215954422950745, Valid_Loss:1.2314496040344238, Valid_ACC:0.6057999134063721
Epoch 690, CIFAR-10 Batch 3:  Train_Loss:0.6237727403640747, Valid_Loss:1.2179278135299683, Valid_ACC:0.6125999689102173
Epoch 690, CIFAR-10 Batch 4:  Train_Loss:0.6232503652572632, Valid_Loss:1.2243926525115967, Valid_ACC:0.6047999262809753
Epoch 690, CIFAR-10 Batch 5:  Train_Loss:0.6362475156784058, Valid_Loss:1.230625033378601, Valid_ACC:0.603399932384491
Epoch 691, CIFAR-10 Batch 1:  Train_Loss:0.6585202813148499, Valid_Loss:1.229132890701294, Valid_ACC:0.6103999614715576
Epoch 691, CIFAR-10 Batch 2:  Train_Loss:0.6365311741828918, Valid_Loss:1.2341859340667725, Valid_ACC:0.6045999526977539
Epoch 691, CIFAR-10 Batch 3:  Train_Loss:0.6298739314079285, Valid_Loss:1.2218854427337646, Valid_ACC:0.6097999215126038
Epoch 691, CIFAR-10 Batch 4:  Train_Loss:0.6335767507553101, Valid_Loss:1.2178207635879517, Valid_ACC:0.608799934387207
Epoch 691, CIFAR-10 Batch 5:  Train_Loss:0.6371794939041138, Valid_Loss:1.2317421436309814, Valid_ACC:0.606999933719635
Epoch 692, CIFAR-10 Batch 1:  Train_Loss:0.6342616081237793, Valid_Loss:1.2292414903640747, Valid_ACC:0.6111998558044434
Epoch 692, CIFAR-10 Batch 2:  Train_Loss:0.6233352422714233, Valid_Loss:1.231446623802185, Valid_ACC:0.6059998869895935
Epoch 692, CIFAR-10 Batch 3:  Train_Loss:0.618565559387207, Valid_Loss:1.2220818996429443, Valid_ACC:0.6095999479293823
Epoch 692, CIFAR-10 Batch 4:  Train_Loss:0.6210185289382935, Valid_Loss:1.2174774408340454, Valid_ACC:0.6081998944282532
Epoch 692, CIFAR-10 Batch 5:  Train_Loss:0.6390862464904785, Valid_Loss:1.2316588163375854, Valid_ACC:0.6003999710083008
Epoch 693, CIFAR-10 Batch 1:  Train_Loss:0.6521639227867126, Valid_Loss:1.2235593795776367, Valid_ACC:0.608799934387207
Epoch 693, CIFAR-10 Batch 2:  Train_Loss:0.6207422018051147, Valid_Loss:1.2276802062988281, Valid_ACC:0.6041999459266663
Epoch 693, CIFAR-10 Batch 3:  Train_Loss:0.6420978307723999, Valid_Loss:1.2321008443832397, Valid_ACC:0.6097999215126038
Epoch 693, CIFAR-10 Batch 4:  Train_Loss:0.6408858895301819, Valid_Loss:1.2316757440567017, Valid_ACC:0.6019998788833618
Epoch 693, CIFAR-10 Batch 5:  Train_Loss:0.6398325562477112, Valid_Loss:1.2304636240005493, Valid_ACC:0.6053999066352844
Epoch 694, CIFAR-10 Batch 1:  Train_Loss:0.628588080406189, Valid_Loss:1.2193232774734497, Valid_ACC:0.611799955368042
Epoch 694, CIFAR-10 Batch 2:  Train_Loss:0.629555344581604, Valid_Loss:1.2396084070205688, Valid_ACC:0.6083999276161194
Epoch 694, CIFAR-10 Batch 3:  Train_Loss:0.6248258352279663, Valid_Loss:1.2249901294708252, Valid_ACC:0.6103999018669128
Epoch 694, CIFAR-10 Batch 4:  Train_Loss:0.6232762932777405, Valid_Loss:1.221232533454895, Valid_ACC:0.6103999018669128
Epoch 694, CIFAR-10 Batch 5:  Train_Loss:0.6403860449790955, Valid_Loss:1.234025001525879, Valid_ACC:0.6037998795509338
Epoch 695, CIFAR-10 Batch 1:  Train_Loss:0.6376018524169922, Valid_Loss:1.226731300354004, Valid_ACC:0.6077998876571655
Epoch 695, CIFAR-10 Batch 2:  Train_Loss:0.6209741830825806, Valid_Loss:1.2233613729476929, Valid_ACC:0.6031999588012695
Epoch 695, CIFAR-10 Batch 3:  Train_Loss:0.6423503160476685, Valid_Loss:1.2321076393127441, Valid_ACC:0.6123998761177063
Epoch 695, CIFAR-10 Batch 4:  Train_Loss:0.6218850016593933, Valid_Loss:1.2149996757507324, Valid_ACC:0.6087998747825623
Epoch 695, CIFAR-10 Batch 5:  Train_Loss:0.6537684202194214, Valid_Loss:1.2419322729110718, Valid_ACC:0.6029998660087585
Epoch 696, CIFAR-10 Batch 1:  Train_Loss:0.6177328824996948, Valid_Loss:1.2048580646514893, Valid_ACC:0.6165999174118042
Epoch 696, CIFAR-10 Batch 2:  Train_Loss:0.6126709580421448, Valid_Loss:1.2197229862213135, Valid_ACC:0.6083999872207642
Epoch 696, CIFAR-10 Batch 3:  Train_Loss:0.6278465986251831, Valid_Loss:1.2248286008834839, Valid_ACC:0.6065999269485474
Epoch 696, CIFAR-10 Batch 4:  Train_Loss:0.6351330876350403, Valid_Loss:1.2383050918579102, Valid_ACC:0.5979999303817749
Epoch 696, CIFAR-10 Batch 5:  Train_Loss:0.6427364945411682, Valid_Loss:1.2318835258483887, Valid_ACC:0.6035999059677124
Epoch 697, CIFAR-10 Batch 1:  Train_Loss:0.6291581988334656, Valid_Loss:1.2236255407333374, Valid_ACC:0.6119998693466187
Epoch 697, CIFAR-10 Batch 2:  Train_Loss:0.6203339695930481, Valid_Loss:1.2379097938537598, Valid_ACC:0.6013998985290527
Epoch 697, CIFAR-10 Batch 3:  Train_Loss:0.6389009952545166, Valid_Loss:1.2318146228790283, Valid_ACC:0.6093999147415161
Epoch 697, CIFAR-10 Batch 4:  Train_Loss:0.6210265159606934, Valid_Loss:1.2199289798736572, Valid_ACC:0.6065999269485474
Epoch 697, CIFAR-10 Batch 5:  Train_Loss:0.6786476373672485, Valid_Loss:1.2563453912734985, Valid_ACC:0.5939999222755432
Epoch 698, CIFAR-10 Batch 1:  Train_Loss:0.6285255551338196, Valid_Loss:1.209267020225525, Valid_ACC:0.6163999438285828
Epoch 698, CIFAR-10 Batch 2:  Train_Loss:0.6271847486495972, Valid_Loss:1.239790678024292, Valid_ACC:0.6047998666763306
Epoch 698, CIFAR-10 Batch 3:  Train_Loss:0.6228763461112976, Valid_Loss:1.2255818843841553, Valid_ACC:0.6117998957633972
Epoch 698, CIFAR-10 Batch 4:  Train_Loss:0.6288256049156189, Valid_Loss:1.223994255065918, Valid_ACC:0.6077998876571655
Epoch 698, CIFAR-10 Batch 5:  Train_Loss:0.6461230516433716, Valid_Loss:1.2303659915924072, Valid_ACC:0.6109998226165771
Epoch 699, CIFAR-10 Batch 1:  Train_Loss:0.6267690658569336, Valid_Loss:1.2128791809082031, Valid_ACC:0.6175998449325562
Epoch 699, CIFAR-10 Batch 2:  Train_Loss:0.6227450370788574, Valid_Loss:1.2306679487228394, Valid_ACC:0.6011999249458313
Epoch 699, CIFAR-10 Batch 3:  Train_Loss:0.6201345920562744, Valid_Loss:1.2204070091247559, Valid_ACC:0.6141998767852783
Epoch 699, CIFAR-10 Batch 4:  Train_Loss:0.6242552995681763, Valid_Loss:1.225265622138977, Valid_ACC:0.6043999195098877
Epoch 699, CIFAR-10 Batch 5:  Train_Loss:0.6506752371788025, Valid_Loss:1.2464170455932617, Valid_ACC:0.5993999242782593
Epoch 700, CIFAR-10 Batch 1:  Train_Loss:0.6181650161743164, Valid_Loss:1.211874008178711, Valid_ACC:0.6195999383926392
Epoch 700, CIFAR-10 Batch 2:  Train_Loss:0.6299852728843689, Valid_Loss:1.2510156631469727, Valid_ACC:0.6001999378204346
Epoch 700, CIFAR-10 Batch 3:  Train_Loss:0.6157272458076477, Valid_Loss:1.2242894172668457, Valid_ACC:0.6109999418258667
Epoch 700, CIFAR-10 Batch 4:  Train_Loss:0.6338299512863159, Valid_Loss:1.2171351909637451, Valid_ACC:0.6109998822212219
Epoch 700, CIFAR-10 Batch 5:  Train_Loss:0.6447023749351501, Valid_Loss:1.23626708984375, Valid_ACC:0.605199933052063
Epoch 701, CIFAR-10 Batch 1:  Train_Loss:0.6141782402992249, Valid_Loss:1.210653305053711, Valid_ACC:0.6149999499320984
Epoch 701, CIFAR-10 Batch 2:  Train_Loss:0.617216944694519, Valid_Loss:1.2361650466918945, Valid_ACC:0.6031999588012695
Epoch 701, CIFAR-10 Batch 3:  Train_Loss:0.6267920732498169, Valid_Loss:1.228571891784668, Valid_ACC:0.6065998673439026
Epoch 701, CIFAR-10 Batch 4:  Train_Loss:0.6301754117012024, Valid_Loss:1.2236813306808472, Valid_ACC:0.6059998869895935
Epoch 701, CIFAR-10 Batch 5:  Train_Loss:0.6352666616439819, Valid_Loss:1.2353968620300293, Valid_ACC:0.6017998456954956
Epoch 702, CIFAR-10 Batch 1:  Train_Loss:0.6231474876403809, Valid_Loss:1.2051032781600952, Valid_ACC:0.6165998578071594
Epoch 702, CIFAR-10 Batch 2:  Train_Loss:0.6167000532150269, Valid_Loss:1.2190415859222412, Valid_ACC:0.6037999391555786
Epoch 702, CIFAR-10 Batch 3:  Train_Loss:0.6280853748321533, Valid_Loss:1.236238718032837, Valid_ACC:0.610599935054779
Epoch 702, CIFAR-10 Batch 4:  Train_Loss:0.6450359225273132, Valid_Loss:1.2250449657440186, Valid_ACC:0.6045999526977539
Epoch 702, CIFAR-10 Batch 5:  Train_Loss:0.6405619382858276, Valid_Loss:1.230456829071045, Valid_ACC:0.6067999005317688
Epoch 703, CIFAR-10 Batch 1:  Train_Loss:0.6339120268821716, Valid_Loss:1.2201229333877563, Valid_ACC:0.6103999018669128
Epoch 703, CIFAR-10 Batch 2:  Train_Loss:0.6204854249954224, Valid_Loss:1.2282674312591553, Valid_ACC:0.6063998937606812
Epoch 703, CIFAR-10 Batch 3:  Train_Loss:0.6369504332542419, Valid_Loss:1.2396876811981201, Valid_ACC:0.6023998856544495
Epoch 703, CIFAR-10 Batch 4:  Train_Loss:0.6471843123435974, Valid_Loss:1.2279865741729736, Valid_ACC:0.6023998856544495
Epoch 703, CIFAR-10 Batch 5:  Train_Loss:0.6595182418823242, Valid_Loss:1.2525500059127808, Valid_ACC:0.5969998836517334
Epoch 704, CIFAR-10 Batch 1:  Train_Loss:0.631661593914032, Valid_Loss:1.2195583581924438, Valid_ACC:0.6139999032020569
Epoch 704, CIFAR-10 Batch 2:  Train_Loss:0.6744136810302734, Valid_Loss:1.2811062335968018, Valid_ACC:0.5885999202728271
Epoch 704, CIFAR-10 Batch 3:  Train_Loss:0.63032066822052, Valid_Loss:1.232922077178955, Valid_ACC:0.609799861907959
Epoch 704, CIFAR-10 Batch 4:  Train_Loss:0.6380305290222168, Valid_Loss:1.2213510274887085, Valid_ACC:0.6035999655723572
Epoch 704, CIFAR-10 Batch 5:  Train_Loss:0.6426704525947571, Valid_Loss:1.228179931640625, Valid_ACC:0.6049998998641968
Epoch 705, CIFAR-10 Batch 1:  Train_Loss:0.6503918170928955, Valid_Loss:1.2232869863510132, Valid_ACC:0.6113998889923096
Epoch 705, CIFAR-10 Batch 2:  Train_Loss:0.6445446014404297, Valid_Loss:1.2478290796279907, Valid_ACC:0.5983998775482178
Epoch 705, CIFAR-10 Batch 3:  Train_Loss:0.6321125030517578, Valid_Loss:1.2279683351516724, Valid_ACC:0.6107999682426453
Epoch 705, CIFAR-10 Batch 4:  Train_Loss:0.6246079206466675, Valid_Loss:1.2145373821258545, Valid_ACC:0.6083998680114746
Epoch 705, CIFAR-10 Batch 5:  Train_Loss:0.6413360834121704, Valid_Loss:1.2314012050628662, Valid_ACC:0.6069998741149902
Epoch 706, CIFAR-10 Batch 1:  Train_Loss:0.6438312530517578, Valid_Loss:1.2102370262145996, Valid_ACC:0.6165999174118042
Epoch 706, CIFAR-10 Batch 2:  Train_Loss:0.6225448250770569, Valid_Loss:1.2321678400039673, Valid_ACC:0.6039998531341553
Epoch 706, CIFAR-10 Batch 3:  Train_Loss:0.6287909746170044, Valid_Loss:1.2270433902740479, Valid_ACC:0.611599862575531
Epoch 706, CIFAR-10 Batch 4:  Train_Loss:0.6276229619979858, Valid_Loss:1.2137563228607178, Valid_ACC:0.6101999282836914
Epoch 706, CIFAR-10 Batch 5:  Train_Loss:0.6681213974952698, Valid_Loss:1.247757077217102, Valid_ACC:0.6029998660087585
Epoch 707, CIFAR-10 Batch 1:  Train_Loss:0.6333987712860107, Valid_Loss:1.2097430229187012, Valid_ACC:0.6159999370574951
Epoch 707, CIFAR-10 Batch 2:  Train_Loss:0.6222075819969177, Valid_Loss:1.2161093950271606, Valid_ACC:0.608799934387207
Epoch 707, CIFAR-10 Batch 3:  Train_Loss:0.6151612997055054, Valid_Loss:1.2300931215286255, Valid_ACC:0.6117998957633972
Epoch 707, CIFAR-10 Batch 4:  Train_Loss:0.6351239681243896, Valid_Loss:1.2154690027236938, Valid_ACC:0.6105998754501343
Epoch 707, CIFAR-10 Batch 5:  Train_Loss:0.6353760957717896, Valid_Loss:1.2291293144226074, Valid_ACC:0.6067999005317688
Epoch 708, CIFAR-10 Batch 1:  Train_Loss:0.6544643640518188, Valid_Loss:1.2228113412857056, Valid_ACC:0.6061999201774597
Epoch 708, CIFAR-10 Batch 2:  Train_Loss:0.6181913614273071, Valid_Loss:1.227966547012329, Valid_ACC:0.6037998795509338
Epoch 708, CIFAR-10 Batch 3:  Train_Loss:0.6315489411354065, Valid_Loss:1.219868540763855, Valid_ACC:0.6149998307228088
Epoch 708, CIFAR-10 Batch 4:  Train_Loss:0.6291441917419434, Valid_Loss:1.2012158632278442, Valid_ACC:0.6137998700141907
Epoch 708, CIFAR-10 Batch 5:  Train_Loss:0.6279633641242981, Valid_Loss:1.2312743663787842, Valid_ACC:0.6049998998641968
Epoch 709, CIFAR-10 Batch 1:  Train_Loss:0.6326354146003723, Valid_Loss:1.214260220527649, Valid_ACC:0.6169999241828918
Epoch 709, CIFAR-10 Batch 2:  Train_Loss:0.6043458580970764, Valid_Loss:1.2202050685882568, Valid_ACC:0.6041999459266663
Epoch 709, CIFAR-10 Batch 3:  Train_Loss:0.6073011159896851, Valid_Loss:1.2224960327148438, Valid_ACC:0.6113999485969543
Epoch 709, CIFAR-10 Batch 4:  Train_Loss:0.625450074672699, Valid_Loss:1.2164381742477417, Valid_ACC:0.6067999601364136
Epoch 709, CIFAR-10 Batch 5:  Train_Loss:0.6373392939567566, Valid_Loss:1.230186939239502, Valid_ACC:0.6011998653411865
Epoch 710, CIFAR-10 Batch 1:  Train_Loss:0.6265714168548584, Valid_Loss:1.2109582424163818, Valid_ACC:0.6125998497009277
Epoch 710, CIFAR-10 Batch 2:  Train_Loss:0.6169189214706421, Valid_Loss:1.2199310064315796, Valid_ACC:0.6079999208450317
Epoch 710, CIFAR-10 Batch 3:  Train_Loss:0.6154053211212158, Valid_Loss:1.2149032354354858, Valid_ACC:0.6141998767852783
Epoch 710, CIFAR-10 Batch 4:  Train_Loss:0.6479874849319458, Valid_Loss:1.2252429723739624, Valid_ACC:0.6061999201774597
Epoch 710, CIFAR-10 Batch 5:  Train_Loss:0.6533294916152954, Valid_Loss:1.2470186948776245, Valid_ACC:0.6001999378204346
Epoch 711, CIFAR-10 Batch 1:  Train_Loss:0.6816623210906982, Valid_Loss:1.229171872138977, Valid_ACC:0.6083999872207642
Epoch 711, CIFAR-10 Batch 2:  Train_Loss:0.6415898203849792, Valid_Loss:1.2496843338012695, Valid_ACC:0.6027998924255371
Epoch 711, CIFAR-10 Batch 3:  Train_Loss:0.655007541179657, Valid_Loss:1.236245036125183, Valid_ACC:0.6029998660087585
Epoch 711, CIFAR-10 Batch 4:  Train_Loss:0.6522200107574463, Valid_Loss:1.2388817071914673, Valid_ACC:0.597399890422821
Epoch 711, CIFAR-10 Batch 5:  Train_Loss:0.6792848110198975, Valid_Loss:1.2440062761306763, Valid_ACC:0.6001999378204346
Epoch 712, CIFAR-10 Batch 1:  Train_Loss:0.6718831658363342, Valid_Loss:1.2260260581970215, Valid_ACC:0.6105998754501343
Epoch 712, CIFAR-10 Batch 2:  Train_Loss:0.6344931721687317, Valid_Loss:1.2380218505859375, Valid_ACC:0.6009998917579651
Epoch 712, CIFAR-10 Batch 3:  Train_Loss:0.632423996925354, Valid_Loss:1.2276917695999146, Valid_ACC:0.6085999608039856
Epoch 712, CIFAR-10 Batch 4:  Train_Loss:0.6265747547149658, Valid_Loss:1.2142491340637207, Valid_ACC:0.6063999533653259
Epoch 712, CIFAR-10 Batch 5:  Train_Loss:0.6363289952278137, Valid_Loss:1.2203277349472046, Valid_ACC:0.6099998950958252
Epoch 713, CIFAR-10 Batch 1:  Train_Loss:0.6518319845199585, Valid_Loss:1.2224783897399902, Valid_ACC:0.6161998510360718
Epoch 713, CIFAR-10 Batch 2:  Train_Loss:0.6204054355621338, Valid_Loss:1.2333357334136963, Valid_ACC:0.6049998998641968
Epoch 713, CIFAR-10 Batch 3:  Train_Loss:0.6299418210983276, Valid_Loss:1.2254971265792847, Valid_ACC:0.6083998680114746
Epoch 713, CIFAR-10 Batch 4:  Train_Loss:0.6339107155799866, Valid_Loss:1.2246735095977783, Valid_ACC:0.6059999465942383
Epoch 713, CIFAR-10 Batch 5:  Train_Loss:0.6424514055252075, Valid_Loss:1.228737711906433, Valid_ACC:0.6081998944282532
Epoch 714, CIFAR-10 Batch 1:  Train_Loss:0.6246734261512756, Valid_Loss:1.2085111141204834, Valid_ACC:0.6167998909950256
Epoch 714, CIFAR-10 Batch 2:  Train_Loss:0.6068321466445923, Valid_Loss:1.2229899168014526, Valid_ACC:0.6081998944282532
Epoch 714, CIFAR-10 Batch 3:  Train_Loss:0.616546094417572, Valid_Loss:1.2171528339385986, Valid_ACC:0.6139999032020569
Epoch 714, CIFAR-10 Batch 4:  Train_Loss:0.6356377005577087, Valid_Loss:1.2272554636001587, Valid_ACC:0.6059999465942383
Epoch 714, CIFAR-10 Batch 5:  Train_Loss:0.6286088228225708, Valid_Loss:1.2272617816925049, Valid_ACC:0.6057999134063721
Epoch 715, CIFAR-10 Batch 1:  Train_Loss:0.6587936878204346, Valid_Loss:1.2293232679367065, Valid_ACC:0.6149998903274536
Epoch 715, CIFAR-10 Batch 2:  Train_Loss:0.6564890146255493, Valid_Loss:1.276825189590454, Valid_ACC:0.5925999283790588
Epoch 715, CIFAR-10 Batch 3:  Train_Loss:0.6476090550422668, Valid_Loss:1.242494821548462, Valid_ACC:0.5991998910903931
Epoch 715, CIFAR-10 Batch 4:  Train_Loss:0.630014181137085, Valid_Loss:1.2201125621795654, Valid_ACC:0.6043999195098877
Epoch 715, CIFAR-10 Batch 5:  Train_Loss:0.6389198899269104, Valid_Loss:1.2304288148880005, Valid_ACC:0.6047998666763306
Epoch 716, CIFAR-10 Batch 1:  Train_Loss:0.6414112448692322, Valid_Loss:1.218303918838501, Valid_ACC:0.6171998977661133
Epoch 716, CIFAR-10 Batch 2:  Train_Loss:0.621033251285553, Valid_Loss:1.2242610454559326, Valid_ACC:0.60999995470047
Epoch 716, CIFAR-10 Batch 3:  Train_Loss:0.6262915134429932, Valid_Loss:1.2233426570892334, Valid_ACC:0.6131999492645264
Epoch 716, CIFAR-10 Batch 4:  Train_Loss:0.6290130019187927, Valid_Loss:1.2220959663391113, Valid_ACC:0.6091998815536499
Epoch 716, CIFAR-10 Batch 5:  Train_Loss:0.625560998916626, Valid_Loss:1.2254083156585693, Valid_ACC:0.609799861907959
Epoch 717, CIFAR-10 Batch 1:  Train_Loss:0.6224948167800903, Valid_Loss:1.2097147703170776, Valid_ACC:0.6201999187469482
Epoch 717, CIFAR-10 Batch 2:  Train_Loss:0.6232897043228149, Valid_Loss:1.2445714473724365, Valid_ACC:0.5989999175071716
Epoch 717, CIFAR-10 Batch 3:  Train_Loss:0.6270472407341003, Valid_Loss:1.2254925966262817, Valid_ACC:0.6125999093055725
Epoch 717, CIFAR-10 Batch 4:  Train_Loss:0.6181613802909851, Valid_Loss:1.2162474393844604, Valid_ACC:0.6107999086380005
Epoch 717, CIFAR-10 Batch 5:  Train_Loss:0.635265052318573, Valid_Loss:1.2365825176239014, Valid_ACC:0.6055998802185059
Epoch 718, CIFAR-10 Batch 1:  Train_Loss:0.6429740190505981, Valid_Loss:1.2196722030639648, Valid_ACC:0.6177998781204224
Epoch 718, CIFAR-10 Batch 2:  Train_Loss:0.6645617485046387, Valid_Loss:1.2868094444274902, Valid_ACC:0.5881999731063843
Epoch 718, CIFAR-10 Batch 3:  Train_Loss:0.6474521160125732, Valid_Loss:1.246394395828247, Valid_ACC:0.6061998605728149
Epoch 718, CIFAR-10 Batch 4:  Train_Loss:0.629584789276123, Valid_Loss:1.2321680784225464, Valid_ACC:0.6047998666763306
Epoch 718, CIFAR-10 Batch 5:  Train_Loss:0.679385244846344, Valid_Loss:1.2563328742980957, Valid_ACC:0.6023998856544495
Epoch 719, CIFAR-10 Batch 1:  Train_Loss:0.6353445053100586, Valid_Loss:1.2067257165908813, Valid_ACC:0.6121999025344849
Epoch 719, CIFAR-10 Batch 2:  Train_Loss:0.6197947859764099, Valid_Loss:1.237292766571045, Valid_ACC:0.6037999391555786
Epoch 719, CIFAR-10 Batch 3:  Train_Loss:0.6411752104759216, Valid_Loss:1.2335225343704224, Valid_ACC:0.6113998889923096
Epoch 719, CIFAR-10 Batch 4:  Train_Loss:0.6472566723823547, Valid_Loss:1.2365672588348389, Valid_ACC:0.6011999249458313
Epoch 719, CIFAR-10 Batch 5:  Train_Loss:0.6516017913818359, Valid_Loss:1.2467857599258423, Valid_ACC:0.602199912071228
Epoch 720, CIFAR-10 Batch 1:  Train_Loss:0.6385176181793213, Valid_Loss:1.2140353918075562, Valid_ACC:0.619999885559082
Epoch 720, CIFAR-10 Batch 2:  Train_Loss:0.6129047274589539, Valid_Loss:1.2292675971984863, Valid_ACC:0.6053998470306396
Epoch 720, CIFAR-10 Batch 3:  Train_Loss:0.6205602288246155, Valid_Loss:1.2329440116882324, Valid_ACC:0.6101999282836914
Epoch 720, CIFAR-10 Batch 4:  Train_Loss:0.6563160419464111, Valid_Loss:1.2485026121139526, Valid_ACC:0.5971999168395996
Epoch 720, CIFAR-10 Batch 5:  Train_Loss:0.6351792216300964, Valid_Loss:1.242652177810669, Valid_ACC:0.5983999371528625
Epoch 721, CIFAR-10 Batch 1:  Train_Loss:0.6381587386131287, Valid_Loss:1.214163899421692, Valid_ACC:0.6151999235153198
Epoch 721, CIFAR-10 Batch 2:  Train_Loss:0.6790943741798401, Valid_Loss:1.3012909889221191, Valid_ACC:0.5859999060630798
Epoch 721, CIFAR-10 Batch 3:  Train_Loss:0.658969521522522, Valid_Loss:1.251045823097229, Valid_ACC:0.6079999208450317
Epoch 721, CIFAR-10 Batch 4:  Train_Loss:0.6344394683837891, Valid_Loss:1.2328296899795532, Valid_ACC:0.6001999378204346
Epoch 721, CIFAR-10 Batch 5:  Train_Loss:0.6479959487915039, Valid_Loss:1.2405602931976318, Valid_ACC:0.5999998450279236
Epoch 722, CIFAR-10 Batch 1:  Train_Loss:0.6469613909721375, Valid_Loss:1.2280515432357788, Valid_ACC:0.6171998977661133
Epoch 722, CIFAR-10 Batch 2:  Train_Loss:0.6257685422897339, Valid_Loss:1.2459330558776855, Valid_ACC:0.6017999649047852
Epoch 722, CIFAR-10 Batch 3:  Train_Loss:0.6620731353759766, Valid_Loss:1.258769154548645, Valid_ACC:0.5979999303817749
Epoch 722, CIFAR-10 Batch 4:  Train_Loss:0.633766770362854, Valid_Loss:1.223469614982605, Valid_ACC:0.6097999215126038
Epoch 722, CIFAR-10 Batch 5:  Train_Loss:0.6330622434616089, Valid_Loss:1.236769437789917, Valid_ACC:0.6005999445915222
Epoch 723, CIFAR-10 Batch 1:  Train_Loss:0.6346134543418884, Valid_Loss:1.2232089042663574, Valid_ACC:0.6107999086380005
Epoch 723, CIFAR-10 Batch 2:  Train_Loss:0.646252453327179, Valid_Loss:1.2664802074432373, Valid_ACC:0.5973999500274658
Epoch 723, CIFAR-10 Batch 3:  Train_Loss:0.6586386561393738, Valid_Loss:1.2702378034591675, Valid_ACC:0.5979999303817749
Epoch 723, CIFAR-10 Batch 4:  Train_Loss:0.6355371475219727, Valid_Loss:1.228539228439331, Valid_ACC:0.6069999933242798
Epoch 723, CIFAR-10 Batch 5:  Train_Loss:0.6586799025535583, Valid_Loss:1.2417926788330078, Valid_ACC:0.5995999574661255
Epoch 724, CIFAR-10 Batch 1:  Train_Loss:0.635208785533905, Valid_Loss:1.2120004892349243, Valid_ACC:0.6123999357223511
Epoch 724, CIFAR-10 Batch 2:  Train_Loss:0.6494495868682861, Valid_Loss:1.2625097036361694, Valid_ACC:0.5975998640060425
Epoch 724, CIFAR-10 Batch 3:  Train_Loss:0.6245532631874084, Valid_Loss:1.2359733581542969, Valid_ACC:0.6083999276161194
Epoch 724, CIFAR-10 Batch 4:  Train_Loss:0.6180462837219238, Valid_Loss:1.2098637819290161, Valid_ACC:0.6099998950958252
Epoch 724, CIFAR-10 Batch 5:  Train_Loss:0.6254833936691284, Valid_Loss:1.2245677709579468, Valid_ACC:0.6049999594688416
Epoch 725, CIFAR-10 Batch 1:  Train_Loss:0.6555654406547546, Valid_Loss:1.22515869140625, Valid_ACC:0.613399863243103
Epoch 725, CIFAR-10 Batch 2:  Train_Loss:0.6294898986816406, Valid_Loss:1.2460789680480957, Valid_ACC:0.5983999371528625
Epoch 725, CIFAR-10 Batch 3:  Train_Loss:0.6236056089401245, Valid_Loss:1.226455569267273, Valid_ACC:0.6095999479293823
Epoch 725, CIFAR-10 Batch 4:  Train_Loss:0.6290398836135864, Valid_Loss:1.224746584892273, Valid_ACC:0.6041998863220215
Epoch 725, CIFAR-10 Batch 5:  Train_Loss:0.6634909510612488, Valid_Loss:1.246575117111206, Valid_ACC:0.5975999236106873
Epoch 726, CIFAR-10 Batch 1:  Train_Loss:0.6515429019927979, Valid_Loss:1.2336314916610718, Valid_ACC:0.6101999282836914
Epoch 726, CIFAR-10 Batch 2:  Train_Loss:0.6568288207054138, Valid_Loss:1.2644108533859253, Valid_ACC:0.5899999141693115
Epoch 726, CIFAR-10 Batch 3:  Train_Loss:0.6826761960983276, Valid_Loss:1.2601897716522217, Valid_ACC:0.596799910068512
Epoch 726, CIFAR-10 Batch 4:  Train_Loss:0.6652659177780151, Valid_Loss:1.2551337480545044, Valid_ACC:0.6019999384880066
Epoch 726, CIFAR-10 Batch 5:  Train_Loss:0.6582376956939697, Valid_Loss:1.2356288433074951, Valid_ACC:0.6011999249458313
Epoch 727, CIFAR-10 Batch 1:  Train_Loss:0.6300894618034363, Valid_Loss:1.2250010967254639, Valid_ACC:0.6189998984336853
Epoch 727, CIFAR-10 Batch 2:  Train_Loss:0.6774940490722656, Valid_Loss:1.2723966836929321, Valid_ACC:0.5907999277114868
Epoch 727, CIFAR-10 Batch 3:  Train_Loss:0.6313188076019287, Valid_Loss:1.2346162796020508, Valid_ACC:0.606999933719635
Epoch 727, CIFAR-10 Batch 4:  Train_Loss:0.6583386659622192, Valid_Loss:1.235700011253357, Valid_ACC:0.6071999073028564
Epoch 727, CIFAR-10 Batch 5:  Train_Loss:0.6641967296600342, Valid_Loss:1.2514442205429077, Valid_ACC:0.5957999229431152
Epoch 728, CIFAR-10 Batch 1:  Train_Loss:0.6669894456863403, Valid_Loss:1.2419551610946655, Valid_ACC:0.6137999296188354
Epoch 728, CIFAR-10 Batch 2:  Train_Loss:0.6488590240478516, Valid_Loss:1.2501194477081299, Valid_ACC:0.5989999175071716
Epoch 728, CIFAR-10 Batch 3:  Train_Loss:0.6405757665634155, Valid_Loss:1.228263258934021, Valid_ACC:0.6117998361587524
Epoch 728, CIFAR-10 Batch 4:  Train_Loss:0.648996889591217, Valid_Loss:1.233365535736084, Valid_ACC:0.6053999066352844
Epoch 728, CIFAR-10 Batch 5:  Train_Loss:0.66573566198349, Valid_Loss:1.2337299585342407, Valid_ACC:0.6011999845504761
Epoch 729, CIFAR-10 Batch 1:  Train_Loss:0.646384596824646, Valid_Loss:1.228684663772583, Valid_ACC:0.6159999370574951
Epoch 729, CIFAR-10 Batch 2:  Train_Loss:0.6262454390525818, Valid_Loss:1.2316428422927856, Valid_ACC:0.5995999574661255
Epoch 729, CIFAR-10 Batch 3:  Train_Loss:0.6204515695571899, Valid_Loss:1.222637414932251, Valid_ACC:0.6125999689102173
Epoch 729, CIFAR-10 Batch 4:  Train_Loss:0.6696292757987976, Valid_Loss:1.2455073595046997, Valid_ACC:0.600399911403656
Epoch 729, CIFAR-10 Batch 5:  Train_Loss:0.6792624592781067, Valid_Loss:1.2597870826721191, Valid_ACC:0.5939999222755432
Epoch 730, CIFAR-10 Batch 1:  Train_Loss:0.6709094047546387, Valid_Loss:1.2356950044631958, Valid_ACC:0.6149998903274536
Epoch 730, CIFAR-10 Batch 2:  Train_Loss:0.6826008558273315, Valid_Loss:1.2364829778671265, Valid_ACC:0.6011999249458313
Epoch 730, CIFAR-10 Batch 3:  Train_Loss:0.6565449237823486, Valid_Loss:1.2240532636642456, Valid_ACC:0.6087998747825623
Epoch 730, CIFAR-10 Batch 4:  Train_Loss:0.669043242931366, Valid_Loss:1.2343111038208008, Valid_ACC:0.6049998998641968
Epoch 730, CIFAR-10 Batch 5:  Train_Loss:0.6435670256614685, Valid_Loss:1.223785161972046, Valid_ACC:0.6055998802185059
Epoch 731, CIFAR-10 Batch 1:  Train_Loss:0.6521697640419006, Valid_Loss:1.2219164371490479, Valid_ACC:0.611799955368042
Epoch 731, CIFAR-10 Batch 2:  Train_Loss:0.6454823017120361, Valid_Loss:1.2357056140899658, Valid_ACC:0.5993999242782593
Epoch 731, CIFAR-10 Batch 3:  Train_Loss:0.6540008187294006, Valid_Loss:1.2155168056488037, Valid_ACC:0.6137999296188354
Epoch 731, CIFAR-10 Batch 4:  Train_Loss:0.6441947221755981, Valid_Loss:1.229570984840393, Valid_ACC:0.6059999465942383
Epoch 731, CIFAR-10 Batch 5:  Train_Loss:0.6347323656082153, Valid_Loss:1.2195162773132324, Valid_ACC:0.606999933719635
Epoch 732, CIFAR-10 Batch 1:  Train_Loss:0.6189483404159546, Valid_Loss:1.204955816268921, Valid_ACC:0.6213998794555664
Epoch 732, CIFAR-10 Batch 2:  Train_Loss:0.6304305791854858, Valid_Loss:1.2404206991195679, Valid_ACC:0.6019998788833618
Epoch 732, CIFAR-10 Batch 3:  Train_Loss:0.6265830993652344, Valid_Loss:1.2311110496520996, Valid_ACC:0.6123998761177063
Epoch 732, CIFAR-10 Batch 4:  Train_Loss:0.6423596739768982, Valid_Loss:1.2341781854629517, Valid_ACC:0.6041999459266663
Epoch 732, CIFAR-10 Batch 5:  Train_Loss:0.6678348183631897, Valid_Loss:1.238912582397461, Valid_ACC:0.5955999493598938
Epoch 733, CIFAR-10 Batch 1:  Train_Loss:0.6409599781036377, Valid_Loss:1.2246525287628174, Valid_ACC:0.6147999167442322
Epoch 733, CIFAR-10 Batch 2:  Train_Loss:0.6295185089111328, Valid_Loss:1.2444597482681274, Valid_ACC:0.597399890422821
Epoch 733, CIFAR-10 Batch 3:  Train_Loss:0.6302458047866821, Valid_Loss:1.2239925861358643, Valid_ACC:0.6099998950958252
Epoch 733, CIFAR-10 Batch 4:  Train_Loss:0.6724944710731506, Valid_Loss:1.2476692199707031, Valid_ACC:0.5999999046325684
Epoch 733, CIFAR-10 Batch 5:  Train_Loss:0.6499272584915161, Valid_Loss:1.229595422744751, Valid_ACC:0.603399932384491
Epoch 734, CIFAR-10 Batch 1:  Train_Loss:0.6409066915512085, Valid_Loss:1.222590446472168, Valid_ACC:0.6159998774528503
Epoch 734, CIFAR-10 Batch 2:  Train_Loss:0.6177922487258911, Valid_Loss:1.206386685371399, Valid_ACC:0.6093999147415161
Epoch 734, CIFAR-10 Batch 3:  Train_Loss:0.6253743767738342, Valid_Loss:1.2122400999069214, Valid_ACC:0.6135998964309692
Epoch 734, CIFAR-10 Batch 4:  Train_Loss:0.6449174284934998, Valid_Loss:1.2333568334579468, Valid_ACC:0.6063998937606812
Epoch 734, CIFAR-10 Batch 5:  Train_Loss:0.6673897504806519, Valid_Loss:1.2506872415542603, Valid_ACC:0.5961999297142029
Epoch 735, CIFAR-10 Batch 1:  Train_Loss:0.6610268950462341, Valid_Loss:1.2332249879837036, Valid_ACC:0.6101998686790466
Epoch 735, CIFAR-10 Batch 2:  Train_Loss:0.6343984603881836, Valid_Loss:1.2278451919555664, Valid_ACC:0.6041998863220215
Epoch 735, CIFAR-10 Batch 3:  Train_Loss:0.6378989219665527, Valid_Loss:1.2195372581481934, Valid_ACC:0.6105998754501343
Epoch 735, CIFAR-10 Batch 4:  Train_Loss:0.6580921411514282, Valid_Loss:1.2394250631332397, Valid_ACC:0.6035999059677124
Epoch 735, CIFAR-10 Batch 5:  Train_Loss:0.6511216163635254, Valid_Loss:1.2370555400848389, Valid_ACC:0.6053999662399292
Epoch 736, CIFAR-10 Batch 1:  Train_Loss:0.63815838098526, Valid_Loss:1.2304779291152954, Valid_ACC:0.6057999134063721
Epoch 736, CIFAR-10 Batch 2:  Train_Loss:0.6302609443664551, Valid_Loss:1.227827787399292, Valid_ACC:0.602199912071228
Epoch 736, CIFAR-10 Batch 3:  Train_Loss:0.6289166212081909, Valid_Loss:1.2210867404937744, Valid_ACC:0.60999995470047
Epoch 736, CIFAR-10 Batch 4:  Train_Loss:0.6261336207389832, Valid_Loss:1.2136508226394653, Valid_ACC:0.6107998490333557
Epoch 736, CIFAR-10 Batch 5:  Train_Loss:0.6272799968719482, Valid_Loss:1.2265379428863525, Valid_ACC:0.612799882888794
Epoch 737, CIFAR-10 Batch 1:  Train_Loss:0.6536759734153748, Valid_Loss:1.2262840270996094, Valid_ACC:0.6157999038696289
Epoch 737, CIFAR-10 Batch 2:  Train_Loss:0.6286311149597168, Valid_Loss:1.234844446182251, Valid_ACC:0.6089999079704285
Epoch 737, CIFAR-10 Batch 3:  Train_Loss:0.6183301210403442, Valid_Loss:1.205947995185852, Valid_ACC:0.6217999458312988
Epoch 737, CIFAR-10 Batch 4:  Train_Loss:0.6300434470176697, Valid_Loss:1.220836877822876, Valid_ACC:0.6113998889923096
Epoch 737, CIFAR-10 Batch 5:  Train_Loss:0.6460890173912048, Valid_Loss:1.232280969619751, Valid_ACC:0.6081998944282532
Epoch 738, CIFAR-10 Batch 1:  Train_Loss:0.6369603872299194, Valid_Loss:1.2260133028030396, Valid_ACC:0.615399956703186
Epoch 738, CIFAR-10 Batch 2:  Train_Loss:0.6222495436668396, Valid_Loss:1.2157008647918701, Valid_ACC:0.6075999736785889
Epoch 738, CIFAR-10 Batch 3:  Train_Loss:0.6136640310287476, Valid_Loss:1.2045003175735474, Valid_ACC:0.6123998761177063
Epoch 738, CIFAR-10 Batch 4:  Train_Loss:0.6409181356430054, Valid_Loss:1.229809284210205, Valid_ACC:0.6099998950958252
Epoch 738, CIFAR-10 Batch 5:  Train_Loss:0.6284726858139038, Valid_Loss:1.2211956977844238, Valid_ACC:0.6085999608039856
Epoch 739, CIFAR-10 Batch 1:  Train_Loss:0.6159419417381287, Valid_Loss:1.2166054248809814, Valid_ACC:0.6177998781204224
Epoch 739, CIFAR-10 Batch 2:  Train_Loss:0.6099490523338318, Valid_Loss:1.2232455015182495, Valid_ACC:0.6071999669075012
Epoch 739, CIFAR-10 Batch 3:  Train_Loss:0.6120104789733887, Valid_Loss:1.2075111865997314, Valid_ACC:0.6149998903274536
Epoch 739, CIFAR-10 Batch 4:  Train_Loss:0.6313768625259399, Valid_Loss:1.222805142402649, Valid_ACC:0.6077998876571655
Epoch 739, CIFAR-10 Batch 5:  Train_Loss:0.6502795815467834, Valid_Loss:1.2316515445709229, Valid_ACC:0.6045999526977539
Epoch 740, CIFAR-10 Batch 1:  Train_Loss:0.6397290229797363, Valid_Loss:1.2234694957733154, Valid_ACC:0.6161999106407166
Epoch 740, CIFAR-10 Batch 2:  Train_Loss:0.6201072335243225, Valid_Loss:1.230147361755371, Valid_ACC:0.6043998599052429
Epoch 740, CIFAR-10 Batch 3:  Train_Loss:0.6081011295318604, Valid_Loss:1.2068012952804565, Valid_ACC:0.6123999357223511
Epoch 740, CIFAR-10 Batch 4:  Train_Loss:0.6338961124420166, Valid_Loss:1.2258856296539307, Valid_ACC:0.6057999134063721
Epoch 740, CIFAR-10 Batch 5:  Train_Loss:0.6382395625114441, Valid_Loss:1.2284836769104004, Valid_ACC:0.6055999398231506
Epoch 741, CIFAR-10 Batch 1:  Train_Loss:0.6365249156951904, Valid_Loss:1.2144516706466675, Valid_ACC:0.6133999228477478
Epoch 741, CIFAR-10 Batch 2:  Train_Loss:0.6241304278373718, Valid_Loss:1.2249109745025635, Valid_ACC:0.6049998998641968
Epoch 741, CIFAR-10 Batch 3:  Train_Loss:0.62694251537323, Valid_Loss:1.2202857732772827, Valid_ACC:0.6095998883247375
Epoch 741, CIFAR-10 Batch 4:  Train_Loss:0.6272276639938354, Valid_Loss:1.219747543334961, Valid_ACC:0.6113999485969543
Epoch 741, CIFAR-10 Batch 5:  Train_Loss:0.6250027418136597, Valid_Loss:1.2192035913467407, Valid_ACC:0.6089998483657837
Epoch 742, CIFAR-10 Batch 1:  Train_Loss:0.6338696479797363, Valid_Loss:1.2116403579711914, Valid_ACC:0.6155998706817627
Epoch 742, CIFAR-10 Batch 2:  Train_Loss:0.6314765214920044, Valid_Loss:1.2244641780853271, Valid_ACC:0.6067999005317688
Epoch 742, CIFAR-10 Batch 3:  Train_Loss:0.6275957226753235, Valid_Loss:1.215603232383728, Valid_ACC:0.6157999038696289
Epoch 742, CIFAR-10 Batch 4:  Train_Loss:0.6147299408912659, Valid_Loss:1.2095054388046265, Valid_ACC:0.6125999093055725
Epoch 742, CIFAR-10 Batch 5:  Train_Loss:0.6312227249145508, Valid_Loss:1.235546588897705, Valid_ACC:0.6045999526977539
Epoch 743, CIFAR-10 Batch 1:  Train_Loss:0.6553424000740051, Valid_Loss:1.2267221212387085, Valid_ACC:0.6111999154090881
Epoch 743, CIFAR-10 Batch 2:  Train_Loss:0.6034033298492432, Valid_Loss:1.2208330631256104, Valid_ACC:0.6089999079704285
Epoch 743, CIFAR-10 Batch 3:  Train_Loss:0.6074185967445374, Valid_Loss:1.2113085985183716, Valid_ACC:0.6139999032020569
Epoch 743, CIFAR-10 Batch 4:  Train_Loss:0.6286083459854126, Valid_Loss:1.21327543258667, Valid_ACC:0.6103999018669128
Epoch 743, CIFAR-10 Batch 5:  Train_Loss:0.6328935027122498, Valid_Loss:1.2324693202972412, Valid_ACC:0.6057999134063721
Epoch 744, CIFAR-10 Batch 1:  Train_Loss:0.6287744641304016, Valid_Loss:1.2166999578475952, Valid_ACC:0.6113998889923096
Epoch 744, CIFAR-10 Batch 2:  Train_Loss:0.612730085849762, Valid_Loss:1.2233811616897583, Valid_ACC:0.6107999682426453
Epoch 744, CIFAR-10 Batch 3:  Train_Loss:0.6303045749664307, Valid_Loss:1.229385256767273, Valid_ACC:0.6095999479293823
Epoch 744, CIFAR-10 Batch 4:  Train_Loss:0.6296315789222717, Valid_Loss:1.218740701675415, Valid_ACC:0.6111998558044434
Epoch 744, CIFAR-10 Batch 5:  Train_Loss:0.6297300457954407, Valid_Loss:1.2309885025024414, Valid_ACC:0.6061999201774597
Epoch 745, CIFAR-10 Batch 1:  Train_Loss:0.637911319732666, Valid_Loss:1.211963415145874, Valid_ACC:0.6189999580383301
Epoch 745, CIFAR-10 Batch 2:  Train_Loss:0.6199271082878113, Valid_Loss:1.2285633087158203, Valid_ACC:0.6029999256134033
Epoch 745, CIFAR-10 Batch 3:  Train_Loss:0.6346250772476196, Valid_Loss:1.22273588180542, Valid_ACC:0.6119998693466187
Epoch 745, CIFAR-10 Batch 4:  Train_Loss:0.6309512853622437, Valid_Loss:1.2172226905822754, Valid_ACC:0.6025998592376709
Epoch 745, CIFAR-10 Batch 5:  Train_Loss:0.650097131729126, Valid_Loss:1.2465859651565552, Valid_ACC:0.6009999513626099
Epoch 746, CIFAR-10 Batch 1:  Train_Loss:0.6214805841445923, Valid_Loss:1.2071088552474976, Valid_ACC:0.619999885559082
Epoch 746, CIFAR-10 Batch 2:  Train_Loss:0.6355551481246948, Valid_Loss:1.2461984157562256, Valid_ACC:0.6031999588012695
Epoch 746, CIFAR-10 Batch 3:  Train_Loss:0.6255175471305847, Valid_Loss:1.2144615650177002, Valid_ACC:0.612799882888794
Epoch 746, CIFAR-10 Batch 4:  Train_Loss:0.6173831224441528, Valid_Loss:1.2119539976119995, Valid_ACC:0.6113998889923096
Epoch 746, CIFAR-10 Batch 5:  Train_Loss:0.6390033960342407, Valid_Loss:1.2258663177490234, Valid_ACC:0.609799861907959
Epoch 747, CIFAR-10 Batch 1:  Train_Loss:0.6328831315040588, Valid_Loss:1.2109484672546387, Valid_ACC:0.6141998767852783
Epoch 747, CIFAR-10 Batch 2:  Train_Loss:0.6173644661903381, Valid_Loss:1.2259637117385864, Valid_ACC:0.6047999262809753
Epoch 747, CIFAR-10 Batch 3:  Train_Loss:0.642213761806488, Valid_Loss:1.232335090637207, Valid_ACC:0.6097999215126038
Epoch 747, CIFAR-10 Batch 4:  Train_Loss:0.6356092095375061, Valid_Loss:1.2250118255615234, Valid_ACC:0.6077999472618103
Epoch 747, CIFAR-10 Batch 5:  Train_Loss:0.6701550483703613, Valid_Loss:1.2633705139160156, Valid_ACC:0.5945999026298523
Epoch 748, CIFAR-10 Batch 1:  Train_Loss:0.629765510559082, Valid_Loss:1.2219241857528687, Valid_ACC:0.6121999025344849
Epoch 748, CIFAR-10 Batch 2:  Train_Loss:0.6254226565361023, Valid_Loss:1.2308117151260376, Valid_ACC:0.6029999256134033
Epoch 748, CIFAR-10 Batch 3:  Train_Loss:0.6253728866577148, Valid_Loss:1.2163597345352173, Valid_ACC:0.616599977016449
Epoch 748, CIFAR-10 Batch 4:  Train_Loss:0.6091349124908447, Valid_Loss:1.2092831134796143, Valid_ACC:0.6139999032020569
Epoch 748, CIFAR-10 Batch 5:  Train_Loss:0.639853835105896, Valid_Loss:1.2317349910736084, Valid_ACC:0.6001998782157898
Epoch 749, CIFAR-10 Batch 1:  Train_Loss:0.6261117458343506, Valid_Loss:1.2046931982040405, Valid_ACC:0.6225999593734741
Epoch 749, CIFAR-10 Batch 2:  Train_Loss:0.6113839149475098, Valid_Loss:1.2272697687149048, Valid_ACC:0.6039999127388
Epoch 749, CIFAR-10 Batch 3:  Train_Loss:0.6192166209220886, Valid_Loss:1.2204777002334595, Valid_ACC:0.6143999695777893
Epoch 749, CIFAR-10 Batch 4:  Train_Loss:0.6078213453292847, Valid_Loss:1.2067815065383911, Valid_ACC:0.6125999093055725
Epoch 749, CIFAR-10 Batch 5:  Train_Loss:0.6201983094215393, Valid_Loss:1.205122947692871, Valid_ACC:0.6183998584747314
Epoch 750, CIFAR-10 Batch 1:  Train_Loss:0.6447579264640808, Valid_Loss:1.2189669609069824, Valid_ACC:0.6161999106407166
Epoch 750, CIFAR-10 Batch 2:  Train_Loss:0.5993014574050903, Valid_Loss:1.2050038576126099, Valid_ACC:0.6109999418258667
Epoch 750, CIFAR-10 Batch 3:  Train_Loss:0.6101583242416382, Valid_Loss:1.2133996486663818, Valid_ACC:0.6101999282836914
Epoch 750, CIFAR-10 Batch 4:  Train_Loss:0.603030800819397, Valid_Loss:1.2056193351745605, Valid_ACC:0.6143999099731445
Epoch 750, CIFAR-10 Batch 5:  Train_Loss:0.6297029256820679, Valid_Loss:1.2275954484939575, Valid_ACC:0.6073999404907227
Epoch 751, CIFAR-10 Batch 1:  Train_Loss:0.6510531902313232, Valid_Loss:1.22873854637146, Valid_ACC:0.6129999160766602
Epoch 751, CIFAR-10 Batch 2:  Train_Loss:0.5997836589813232, Valid_Loss:1.2066574096679688, Valid_ACC:0.6089999079704285
Epoch 751, CIFAR-10 Batch 3:  Train_Loss:0.6215366125106812, Valid_Loss:1.226600170135498, Valid_ACC:0.6085999011993408
Epoch 751, CIFAR-10 Batch 4:  Train_Loss:0.615128755569458, Valid_Loss:1.2081105709075928, Valid_ACC:0.6123999357223511
Epoch 751, CIFAR-10 Batch 5:  Train_Loss:0.614389955997467, Valid_Loss:1.2218017578125, Valid_ACC:0.6085999011993408
Epoch 752, CIFAR-10 Batch 1:  Train_Loss:0.6119939088821411, Valid_Loss:1.196764349937439, Valid_ACC:0.6179999113082886
Epoch 752, CIFAR-10 Batch 2:  Train_Loss:0.6003459692001343, Valid_Loss:1.2257031202316284, Valid_ACC:0.6091998815536499
Epoch 752, CIFAR-10 Batch 3:  Train_Loss:0.6117403507232666, Valid_Loss:1.2175735235214233, Valid_ACC:0.6083999276161194
Epoch 752, CIFAR-10 Batch 4:  Train_Loss:0.6134265065193176, Valid_Loss:1.2103315591812134, Valid_ACC:0.6095999479293823
Epoch 752, CIFAR-10 Batch 5:  Train_Loss:0.6095455288887024, Valid_Loss:1.2008278369903564, Valid_ACC:0.6151999235153198
Epoch 753, CIFAR-10 Batch 1:  Train_Loss:0.6133264303207397, Valid_Loss:1.1999006271362305, Valid_ACC:0.6157999038696289
Epoch 753, CIFAR-10 Batch 2:  Train_Loss:0.6071826815605164, Valid_Loss:1.2110133171081543, Valid_ACC:0.6113998889923096
Epoch 753, CIFAR-10 Batch 3:  Train_Loss:0.618679404258728, Valid_Loss:1.2306537628173828, Valid_ACC:0.6113999485969543
Epoch 753, CIFAR-10 Batch 4:  Train_Loss:0.6286616325378418, Valid_Loss:1.232696771621704, Valid_ACC:0.6031998991966248
Epoch 753, CIFAR-10 Batch 5:  Train_Loss:0.6309670805931091, Valid_Loss:1.2388594150543213, Valid_ACC:0.6027998924255371
Epoch 754, CIFAR-10 Batch 1:  Train_Loss:0.6141694784164429, Valid_Loss:1.2009087800979614, Valid_ACC:0.6189999580383301
Epoch 754, CIFAR-10 Batch 2:  Train_Loss:0.6060072183609009, Valid_Loss:1.2099659442901611, Valid_ACC:0.6121999025344849
Epoch 754, CIFAR-10 Batch 3:  Train_Loss:0.6184935569763184, Valid_Loss:1.2220375537872314, Valid_ACC:0.6141999363899231
Epoch 754, CIFAR-10 Batch 4:  Train_Loss:0.5982505679130554, Valid_Loss:1.2005395889282227, Valid_ACC:0.6177998781204224
Epoch 754, CIFAR-10 Batch 5:  Train_Loss:0.6117427349090576, Valid_Loss:1.2145392894744873, Valid_ACC:0.6109998822212219
Epoch 755, CIFAR-10 Batch 1:  Train_Loss:0.6165537238121033, Valid_Loss:1.2014681100845337, Valid_ACC:0.621199905872345
Epoch 755, CIFAR-10 Batch 2:  Train_Loss:0.6022456288337708, Valid_Loss:1.2226340770721436, Valid_ACC:0.6095998883247375
Epoch 755, CIFAR-10 Batch 3:  Train_Loss:0.6009697318077087, Valid_Loss:1.200727939605713, Valid_ACC:0.615399956703186
Epoch 755, CIFAR-10 Batch 4:  Train_Loss:0.6035770773887634, Valid_Loss:1.2045750617980957, Valid_ACC:0.6147999167442322
Epoch 755, CIFAR-10 Batch 5:  Train_Loss:0.6081267595291138, Valid_Loss:1.2107218503952026, Valid_ACC:0.6119999289512634
Epoch 756, CIFAR-10 Batch 1:  Train_Loss:0.6276664137840271, Valid_Loss:1.21366548538208, Valid_ACC:0.6131998896598816
Epoch 756, CIFAR-10 Batch 2:  Train_Loss:0.6117108464241028, Valid_Loss:1.2446308135986328, Valid_ACC:0.6061999201774597
Epoch 756, CIFAR-10 Batch 3:  Train_Loss:0.605138897895813, Valid_Loss:1.2215644121170044, Valid_ACC:0.6095998883247375
Epoch 756, CIFAR-10 Batch 4:  Train_Loss:0.6075626611709595, Valid_Loss:1.220043420791626, Valid_ACC:0.6103999018669128
Epoch 756, CIFAR-10 Batch 5:  Train_Loss:0.6046941876411438, Valid_Loss:1.213753581047058, Valid_ACC:0.610599935054779
Epoch 757, CIFAR-10 Batch 1:  Train_Loss:0.6175986528396606, Valid_Loss:1.1952307224273682, Valid_ACC:0.620199978351593
Epoch 757, CIFAR-10 Batch 2:  Train_Loss:0.6129637956619263, Valid_Loss:1.2205920219421387, Valid_ACC:0.6079999208450317
Epoch 757, CIFAR-10 Batch 3:  Train_Loss:0.5993150472640991, Valid_Loss:1.2050423622131348, Valid_ACC:0.6197999119758606
Epoch 757, CIFAR-10 Batch 4:  Train_Loss:0.6066487431526184, Valid_Loss:1.201310396194458, Valid_ACC:0.6169998645782471
Epoch 757, CIFAR-10 Batch 5:  Train_Loss:0.6239722967147827, Valid_Loss:1.2259392738342285, Valid_ACC:0.6121999025344849
Epoch 758, CIFAR-10 Batch 1:  Train_Loss:0.6176517605781555, Valid_Loss:1.2126460075378418, Valid_ACC:0.6105998754501343
Epoch 758, CIFAR-10 Batch 2:  Train_Loss:0.6017184257507324, Valid_Loss:1.2193560600280762, Valid_ACC:0.6093999147415161
Epoch 758, CIFAR-10 Batch 3:  Train_Loss:0.6231638789176941, Valid_Loss:1.219571590423584, Valid_ACC:0.6141999363899231
Epoch 758, CIFAR-10 Batch 4:  Train_Loss:0.6210609078407288, Valid_Loss:1.210524082183838, Valid_ACC:0.6117998957633972
Epoch 758, CIFAR-10 Batch 5:  Train_Loss:0.6488683223724365, Valid_Loss:1.2401636838912964, Valid_ACC:0.6013999581336975
Epoch 759, CIFAR-10 Batch 1:  Train_Loss:0.6159546971321106, Valid_Loss:1.2023471593856812, Valid_ACC:0.61819988489151
Epoch 759, CIFAR-10 Batch 2:  Train_Loss:0.6076452136039734, Valid_Loss:1.2236979007720947, Valid_ACC:0.6083998680114746
Epoch 759, CIFAR-10 Batch 3:  Train_Loss:0.6027718782424927, Valid_Loss:1.2105798721313477, Valid_ACC:0.609799861907959
Epoch 759, CIFAR-10 Batch 4:  Train_Loss:0.6049350500106812, Valid_Loss:1.2007211446762085, Valid_ACC:0.6173999309539795
Epoch 759, CIFAR-10 Batch 5:  Train_Loss:0.6150721311569214, Valid_Loss:1.21165931224823, Valid_ACC:0.6107998490333557
Epoch 760, CIFAR-10 Batch 1:  Train_Loss:0.6071999669075012, Valid_Loss:1.202925205230713, Valid_ACC:0.6185998916625977
Epoch 760, CIFAR-10 Batch 2:  Train_Loss:0.6015594005584717, Valid_Loss:1.2256883382797241, Valid_ACC:0.6067999601364136
Epoch 760, CIFAR-10 Batch 3:  Train_Loss:0.6152241826057434, Valid_Loss:1.2281025648117065, Valid_ACC:0.6075998544692993
Epoch 760, CIFAR-10 Batch 4:  Train_Loss:0.6023131012916565, Valid_Loss:1.2030918598175049, Valid_ACC:0.6131998896598816
Epoch 760, CIFAR-10 Batch 5:  Train_Loss:0.6033225059509277, Valid_Loss:1.2049102783203125, Valid_ACC:0.6141998767852783
Epoch 761, CIFAR-10 Batch 1:  Train_Loss:0.6226164698600769, Valid_Loss:1.2026422023773193, Valid_ACC:0.619399905204773
Epoch 761, CIFAR-10 Batch 2:  Train_Loss:0.5966986417770386, Valid_Loss:1.2111674547195435, Valid_ACC:0.6113998889923096
Epoch 761, CIFAR-10 Batch 3:  Train_Loss:0.6108682751655579, Valid_Loss:1.2194689512252808, Valid_ACC:0.6075999736785889
Epoch 761, CIFAR-10 Batch 4:  Train_Loss:0.6011539697647095, Valid_Loss:1.2008806467056274, Valid_ACC:0.6123999357223511
Epoch 761, CIFAR-10 Batch 5:  Train_Loss:0.6115195155143738, Valid_Loss:1.207554817199707, Valid_ACC:0.613399863243103
Epoch 762, CIFAR-10 Batch 1:  Train_Loss:0.6105723977088928, Valid_Loss:1.202502965927124, Valid_ACC:0.6179998517036438
Epoch 762, CIFAR-10 Batch 2:  Train_Loss:0.584640383720398, Valid_Loss:1.196882724761963, Valid_ACC:0.6131999492645264
Epoch 762, CIFAR-10 Batch 3:  Train_Loss:0.6043449640274048, Valid_Loss:1.2220609188079834, Valid_ACC:0.6097999215126038
Epoch 762, CIFAR-10 Batch 4:  Train_Loss:0.6006731390953064, Valid_Loss:1.2055957317352295, Valid_ACC:0.6151999235153198
Epoch 762, CIFAR-10 Batch 5:  Train_Loss:0.6144235134124756, Valid_Loss:1.224456787109375, Valid_ACC:0.6063998937606812
Epoch 763, CIFAR-10 Batch 1:  Train_Loss:0.6151538491249084, Valid_Loss:1.2051677703857422, Valid_ACC:0.6137999296188354
Epoch 763, CIFAR-10 Batch 2:  Train_Loss:0.6111561059951782, Valid_Loss:1.2293330430984497, Valid_ACC:0.6099998950958252
Epoch 763, CIFAR-10 Batch 3:  Train_Loss:0.5954754948616028, Valid_Loss:1.2064448595046997, Valid_ACC:0.6141998767852783
Epoch 763, CIFAR-10 Batch 4:  Train_Loss:0.5968303084373474, Valid_Loss:1.1992149353027344, Valid_ACC:0.6113998889923096
Epoch 763, CIFAR-10 Batch 5:  Train_Loss:0.6100295782089233, Valid_Loss:1.2072467803955078, Valid_ACC:0.6161998510360718
Epoch 764, CIFAR-10 Batch 1:  Train_Loss:0.6164905428886414, Valid_Loss:1.2017205953598022, Valid_ACC:0.6209998726844788
Epoch 764, CIFAR-10 Batch 2:  Train_Loss:0.6057190299034119, Valid_Loss:1.2248808145523071, Valid_ACC:0.6059998869895935
Epoch 764, CIFAR-10 Batch 3:  Train_Loss:0.6102373600006104, Valid_Loss:1.2071701288223267, Valid_ACC:0.6135998964309692
Epoch 764, CIFAR-10 Batch 4:  Train_Loss:0.6082727909088135, Valid_Loss:1.2039419412612915, Valid_ACC:0.6145999431610107
Epoch 764, CIFAR-10 Batch 5:  Train_Loss:0.6210890412330627, Valid_Loss:1.2200464010238647, Valid_ACC:0.6103999018669128
Epoch 765, CIFAR-10 Batch 1:  Train_Loss:0.6119402647018433, Valid_Loss:1.1977925300598145, Valid_ACC:0.6203998923301697
Epoch 765, CIFAR-10 Batch 2:  Train_Loss:0.5883809924125671, Valid_Loss:1.208044409751892, Valid_ACC:0.6129999160766602
Epoch 765, CIFAR-10 Batch 3:  Train_Loss:0.6058170199394226, Valid_Loss:1.213484525680542, Valid_ACC:0.6177998781204224
Epoch 765, CIFAR-10 Batch 4:  Train_Loss:0.598272979259491, Valid_Loss:1.2090227603912354, Valid_ACC:0.610599935054779
Epoch 765, CIFAR-10 Batch 5:  Train_Loss:0.6168007850646973, Valid_Loss:1.2202441692352295, Valid_ACC:0.6125999093055725
Epoch 766, CIFAR-10 Batch 1:  Train_Loss:0.6190147399902344, Valid_Loss:1.2052581310272217, Valid_ACC:0.6163999438285828
Epoch 766, CIFAR-10 Batch 2:  Train_Loss:0.5915465354919434, Valid_Loss:1.2127536535263062, Valid_ACC:0.6101998686790466
Epoch 766, CIFAR-10 Batch 3:  Train_Loss:0.5986886620521545, Valid_Loss:1.2019617557525635, Valid_ACC:0.6183999180793762
Epoch 766, CIFAR-10 Batch 4:  Train_Loss:0.6300411820411682, Valid_Loss:1.2271111011505127, Valid_ACC:0.6095998883247375
Epoch 766, CIFAR-10 Batch 5:  Train_Loss:0.6080432534217834, Valid_Loss:1.2126127481460571, Valid_ACC:0.6147999167442322
Epoch 767, CIFAR-10 Batch 1:  Train_Loss:0.6191778182983398, Valid_Loss:1.20805025100708, Valid_ACC:0.6191998720169067
Epoch 767, CIFAR-10 Batch 2:  Train_Loss:0.6090223789215088, Valid_Loss:1.2147382497787476, Valid_ACC:0.6121999025344849
Epoch 767, CIFAR-10 Batch 3:  Train_Loss:0.5938141345977783, Valid_Loss:1.2132521867752075, Valid_ACC:0.6119999289512634
Epoch 767, CIFAR-10 Batch 4:  Train_Loss:0.6206770539283752, Valid_Loss:1.2278399467468262, Valid_ACC:0.6047999262809753
Epoch 767, CIFAR-10 Batch 5:  Train_Loss:0.6293048858642578, Valid_Loss:1.2240021228790283, Valid_ACC:0.6067999005317688
Epoch 768, CIFAR-10 Batch 1:  Train_Loss:0.6152065992355347, Valid_Loss:1.2067052125930786, Valid_ACC:0.6175998449325562
Epoch 768, CIFAR-10 Batch 2:  Train_Loss:0.6206150054931641, Valid_Loss:1.2312774658203125, Valid_ACC:0.6107999682426453
Epoch 768, CIFAR-10 Batch 3:  Train_Loss:0.6017088890075684, Valid_Loss:1.2100939750671387, Valid_ACC:0.6191998720169067
Epoch 768, CIFAR-10 Batch 4:  Train_Loss:0.59508216381073, Valid_Loss:1.204492449760437, Valid_ACC:0.612799882888794
Epoch 768, CIFAR-10 Batch 5:  Train_Loss:0.6102814674377441, Valid_Loss:1.2052736282348633, Valid_ACC:0.6145998239517212
Epoch 769, CIFAR-10 Batch 1:  Train_Loss:0.6232062578201294, Valid_Loss:1.2091447114944458, Valid_ACC:0.6135998964309692
Epoch 769, CIFAR-10 Batch 2:  Train_Loss:0.59306800365448, Valid_Loss:1.210339903831482, Valid_ACC:0.6073998808860779
Epoch 769, CIFAR-10 Batch 3:  Train_Loss:0.5982481241226196, Valid_Loss:1.205971121788025, Valid_ACC:0.6165999174118042
Epoch 769, CIFAR-10 Batch 4:  Train_Loss:0.6015890836715698, Valid_Loss:1.2041239738464355, Valid_ACC:0.6179998517036438
Epoch 769, CIFAR-10 Batch 5:  Train_Loss:0.6139562726020813, Valid_Loss:1.2093504667282104, Valid_ACC:0.6111999750137329
Epoch 770, CIFAR-10 Batch 1:  Train_Loss:0.6192952990531921, Valid_Loss:1.2000478506088257, Valid_ACC:0.6231999397277832
Epoch 770, CIFAR-10 Batch 2:  Train_Loss:0.6273213624954224, Valid_Loss:1.2555004358291626, Valid_ACC:0.5987999439239502
Epoch 770, CIFAR-10 Batch 3:  Train_Loss:0.6037546992301941, Valid_Loss:1.1970081329345703, Valid_ACC:0.6157999038696289
Epoch 770, CIFAR-10 Batch 4:  Train_Loss:0.603236973285675, Valid_Loss:1.2033904790878296, Valid_ACC:0.6141999363899231
Epoch 770, CIFAR-10 Batch 5:  Train_Loss:0.6200589537620544, Valid_Loss:1.2191314697265625, Valid_ACC:0.6183999180793762
Epoch 771, CIFAR-10 Batch 1:  Train_Loss:0.620475709438324, Valid_Loss:1.2058565616607666, Valid_ACC:0.6173998713493347
Epoch 771, CIFAR-10 Batch 2:  Train_Loss:0.6069436073303223, Valid_Loss:1.2163947820663452, Valid_ACC:0.6091998815536499
Epoch 771, CIFAR-10 Batch 3:  Train_Loss:0.6037362217903137, Valid_Loss:1.2236864566802979, Valid_ACC:0.6105998754501343
Epoch 771, CIFAR-10 Batch 4:  Train_Loss:0.6062989234924316, Valid_Loss:1.2075608968734741, Valid_ACC:0.6187999248504639
Epoch 771, CIFAR-10 Batch 5:  Train_Loss:0.6093372702598572, Valid_Loss:1.207123041152954, Valid_ACC:0.615199863910675
Epoch 772, CIFAR-10 Batch 1:  Train_Loss:0.6143224239349365, Valid_Loss:1.198524832725525, Valid_ACC:0.6215998530387878
Epoch 772, CIFAR-10 Batch 2:  Train_Loss:0.6109750270843506, Valid_Loss:1.2085156440734863, Valid_ACC:0.6169999241828918
Epoch 772, CIFAR-10 Batch 3:  Train_Loss:0.6197832226753235, Valid_Loss:1.2332955598831177, Valid_ACC:0.6079999208450317
Epoch 772, CIFAR-10 Batch 4:  Train_Loss:0.6014626622200012, Valid_Loss:1.2036936283111572, Valid_ACC:0.6151999235153198
Epoch 772, CIFAR-10 Batch 5:  Train_Loss:0.6255208253860474, Valid_Loss:1.2109434604644775, Valid_ACC:0.6119999289512634
Epoch 773, CIFAR-10 Batch 1:  Train_Loss:0.6301649212837219, Valid_Loss:1.2205413579940796, Valid_ACC:0.6189998984336853
Epoch 773, CIFAR-10 Batch 2:  Train_Loss:0.603659451007843, Valid_Loss:1.2200899124145508, Valid_ACC:0.6099998950958252
Epoch 773, CIFAR-10 Batch 3:  Train_Loss:0.6014783978462219, Valid_Loss:1.213160514831543, Valid_ACC:0.6137998700141907
Epoch 773, CIFAR-10 Batch 4:  Train_Loss:0.6039890050888062, Valid_Loss:1.2129030227661133, Valid_ACC:0.608199954032898
Epoch 773, CIFAR-10 Batch 5:  Train_Loss:0.611703097820282, Valid_Loss:1.195614218711853, Valid_ACC:0.6169998645782471
Epoch 774, CIFAR-10 Batch 1:  Train_Loss:0.6180206537246704, Valid_Loss:1.202675223350525, Valid_ACC:0.6165999174118042
Epoch 774, CIFAR-10 Batch 2:  Train_Loss:0.5944418907165527, Valid_Loss:1.2022316455841064, Valid_ACC:0.6141999363899231
Epoch 774, CIFAR-10 Batch 3:  Train_Loss:0.6201257705688477, Valid_Loss:1.2301604747772217, Valid_ACC:0.6085999011993408
Epoch 774, CIFAR-10 Batch 4:  Train_Loss:0.595497727394104, Valid_Loss:1.2117260694503784, Valid_ACC:0.6121999025344849
Epoch 774, CIFAR-10 Batch 5:  Train_Loss:0.6213653087615967, Valid_Loss:1.1975176334381104, Valid_ACC:0.6147998571395874
Epoch 775, CIFAR-10 Batch 1:  Train_Loss:0.6312097907066345, Valid_Loss:1.2129122018814087, Valid_ACC:0.6107999086380005
Epoch 775, CIFAR-10 Batch 2:  Train_Loss:0.6024042963981628, Valid_Loss:1.219118356704712, Valid_ACC:0.6097999215126038
Epoch 775, CIFAR-10 Batch 3:  Train_Loss:0.6246818900108337, Valid_Loss:1.2385382652282715, Valid_ACC:0.6083998680114746
Epoch 775, CIFAR-10 Batch 4:  Train_Loss:0.6430169939994812, Valid_Loss:1.2400811910629272, Valid_ACC:0.601599931716919
Epoch 775, CIFAR-10 Batch 5:  Train_Loss:0.6115950345993042, Valid_Loss:1.2070990800857544, Valid_ACC:0.6131999492645264
Epoch 776, CIFAR-10 Batch 1:  Train_Loss:0.6133245229721069, Valid_Loss:1.1971263885498047, Valid_ACC:0.6161999106407166
Epoch 776, CIFAR-10 Batch 2:  Train_Loss:0.6102902889251709, Valid_Loss:1.227051019668579, Valid_ACC:0.6087998747825623
Epoch 776, CIFAR-10 Batch 3:  Train_Loss:0.608529806137085, Valid_Loss:1.217681646347046, Valid_ACC:0.6155998706817627
Epoch 776, CIFAR-10 Batch 4:  Train_Loss:0.6206943988800049, Valid_Loss:1.2316306829452515, Valid_ACC:0.6059998869895935
Epoch 776, CIFAR-10 Batch 5:  Train_Loss:0.6186262965202332, Valid_Loss:1.2100753784179688, Valid_ACC:0.6089999079704285
Epoch 777, CIFAR-10 Batch 1:  Train_Loss:0.6208933591842651, Valid_Loss:1.2073835134506226, Valid_ACC:0.6189999580383301
Epoch 777, CIFAR-10 Batch 2:  Train_Loss:0.58821040391922, Valid_Loss:1.205680251121521, Valid_ACC:0.614599883556366
Epoch 777, CIFAR-10 Batch 3:  Train_Loss:0.6177669763565063, Valid_Loss:1.2323675155639648, Valid_ACC:0.6103999614715576
Epoch 777, CIFAR-10 Batch 4:  Train_Loss:0.5979189872741699, Valid_Loss:1.2006279230117798, Valid_ACC:0.6147999167442322
Epoch 777, CIFAR-10 Batch 5:  Train_Loss:0.6032978296279907, Valid_Loss:1.2097558975219727, Valid_ACC:0.6153998970985413
Epoch 778, CIFAR-10 Batch 1:  Train_Loss:0.6034814119338989, Valid_Loss:1.191232442855835, Valid_ACC:0.619399905204773
Epoch 778, CIFAR-10 Batch 2:  Train_Loss:0.5876699686050415, Valid_Loss:1.2132900953292847, Valid_ACC:0.6145998239517212
Epoch 778, CIFAR-10 Batch 3:  Train_Loss:0.6371909379959106, Valid_Loss:1.2512633800506592, Valid_ACC:0.601599931716919
Epoch 778, CIFAR-10 Batch 4:  Train_Loss:0.6211907863616943, Valid_Loss:1.218910574913025, Valid_ACC:0.6095999479293823
Epoch 778, CIFAR-10 Batch 5:  Train_Loss:0.6226814389228821, Valid_Loss:1.2027579545974731, Valid_ACC:0.6151999235153198
Epoch 779, CIFAR-10 Batch 1:  Train_Loss:0.6221367120742798, Valid_Loss:1.2095867395401, Valid_ACC:0.6169999241828918
Epoch 779, CIFAR-10 Batch 2:  Train_Loss:0.6342050433158875, Valid_Loss:1.2539639472961426, Valid_ACC:0.5983999371528625
Epoch 779, CIFAR-10 Batch 3:  Train_Loss:0.5950158834457397, Valid_Loss:1.2270569801330566, Valid_ACC:0.6155998706817627
Epoch 779, CIFAR-10 Batch 4:  Train_Loss:0.5992878675460815, Valid_Loss:1.2057315111160278, Valid_ACC:0.6171998977661133
Epoch 779, CIFAR-10 Batch 5:  Train_Loss:0.613847017288208, Valid_Loss:1.209770917892456, Valid_ACC:0.6159998774528503
Epoch 780, CIFAR-10 Batch 1:  Train_Loss:0.6104167103767395, Valid_Loss:1.2111828327178955, Valid_ACC:0.6195998787879944
Epoch 780, CIFAR-10 Batch 2:  Train_Loss:0.6048743724822998, Valid_Loss:1.230668306350708, Valid_ACC:0.6107999086380005
Epoch 780, CIFAR-10 Batch 3:  Train_Loss:0.6138099431991577, Valid_Loss:1.2280024290084839, Valid_ACC:0.6155998706817627
Epoch 780, CIFAR-10 Batch 4:  Train_Loss:0.6150493025779724, Valid_Loss:1.2203398942947388, Valid_ACC:0.6091999411582947
Epoch 780, CIFAR-10 Batch 5:  Train_Loss:0.6097031831741333, Valid_Loss:1.210914134979248, Valid_ACC:0.6123999357223511
Epoch 781, CIFAR-10 Batch 1:  Train_Loss:0.6238502860069275, Valid_Loss:1.2132511138916016, Valid_ACC:0.6143999099731445
Epoch 781, CIFAR-10 Batch 2:  Train_Loss:0.6050801277160645, Valid_Loss:1.2129827737808228, Valid_ACC:0.6113998889923096
Epoch 781, CIFAR-10 Batch 3:  Train_Loss:0.633966863155365, Valid_Loss:1.250209093093872, Valid_ACC:0.6071999073028564
Epoch 781, CIFAR-10 Batch 4:  Train_Loss:0.6332231760025024, Valid_Loss:1.231501579284668, Valid_ACC:0.6083999276161194
Epoch 781, CIFAR-10 Batch 5:  Train_Loss:0.6240423321723938, Valid_Loss:1.2084739208221436, Valid_ACC:0.6151999235153198
Epoch 782, CIFAR-10 Batch 1:  Train_Loss:0.6236013174057007, Valid_Loss:1.2086855173110962, Valid_ACC:0.6143998503684998
Epoch 782, CIFAR-10 Batch 2:  Train_Loss:0.6073572635650635, Valid_Loss:1.2165486812591553, Valid_ACC:0.6121999621391296
Epoch 782, CIFAR-10 Batch 3:  Train_Loss:0.6280204057693481, Valid_Loss:1.247109055519104, Valid_ACC:0.6067999601364136
Epoch 782, CIFAR-10 Batch 4:  Train_Loss:0.6154661178588867, Valid_Loss:1.226083755493164, Valid_ACC:0.6069998741149902
Epoch 782, CIFAR-10 Batch 5:  Train_Loss:0.6245840191841125, Valid_Loss:1.2246280908584595, Valid_ACC:0.6043999195098877
Epoch 783, CIFAR-10 Batch 1:  Train_Loss:0.6103161573410034, Valid_Loss:1.1991493701934814, Valid_ACC:0.6159999370574951
Epoch 783, CIFAR-10 Batch 2:  Train_Loss:0.6068031191825867, Valid_Loss:1.221060037612915, Valid_ACC:0.6109998822212219
Epoch 783, CIFAR-10 Batch 3:  Train_Loss:0.5973324775695801, Valid_Loss:1.2164695262908936, Valid_ACC:0.6159999966621399
Epoch 783, CIFAR-10 Batch 4:  Train_Loss:0.597888708114624, Valid_Loss:1.2044299840927124, Valid_ACC:0.6147999167442322
Epoch 783, CIFAR-10 Batch 5:  Train_Loss:0.6090868711471558, Valid_Loss:1.211047649383545, Valid_ACC:0.6143998503684998
Epoch 784, CIFAR-10 Batch 1:  Train_Loss:0.6043180227279663, Valid_Loss:1.2011921405792236, Valid_ACC:0.6223998665809631
Epoch 784, CIFAR-10 Batch 2:  Train_Loss:0.5885437726974487, Valid_Loss:1.2001285552978516, Valid_ACC:0.6169998645782471
Epoch 784, CIFAR-10 Batch 3:  Train_Loss:0.5960721969604492, Valid_Loss:1.2147172689437866, Valid_ACC:0.619399905204773
Epoch 784, CIFAR-10 Batch 4:  Train_Loss:0.620940625667572, Valid_Loss:1.2134461402893066, Valid_ACC:0.6131998896598816
Epoch 784, CIFAR-10 Batch 5:  Train_Loss:0.5974768996238708, Valid_Loss:1.2045814990997314, Valid_ACC:0.6177999377250671
Epoch 785, CIFAR-10 Batch 1:  Train_Loss:0.6106103658676147, Valid_Loss:1.200343370437622, Valid_ACC:0.6203998923301697
Epoch 785, CIFAR-10 Batch 2:  Train_Loss:0.5962935090065002, Valid_Loss:1.198814868927002, Valid_ACC:0.6205999255180359
Epoch 785, CIFAR-10 Batch 3:  Train_Loss:0.6234614253044128, Valid_Loss:1.2347633838653564, Valid_ACC:0.6049999594688416
Epoch 785, CIFAR-10 Batch 4:  Train_Loss:0.6205273270606995, Valid_Loss:1.2270328998565674, Valid_ACC:0.6083999276161194
Epoch 785, CIFAR-10 Batch 5:  Train_Loss:0.645953893661499, Valid_Loss:1.2196404933929443, Valid_ACC:0.6065998673439026
Epoch 786, CIFAR-10 Batch 1:  Train_Loss:0.5995497703552246, Valid_Loss:1.1911239624023438, Valid_ACC:0.6193998456001282
Epoch 786, CIFAR-10 Batch 2:  Train_Loss:0.6331301331520081, Valid_Loss:1.2372461557388306, Valid_ACC:0.6043999195098877
Epoch 786, CIFAR-10 Batch 3:  Train_Loss:0.6064755916595459, Valid_Loss:1.2308776378631592, Valid_ACC:0.6083998680114746
Epoch 786, CIFAR-10 Batch 4:  Train_Loss:0.6116798520088196, Valid_Loss:1.2219939231872559, Valid_ACC:0.6117998361587524
Epoch 786, CIFAR-10 Batch 5:  Train_Loss:0.6038968563079834, Valid_Loss:1.2017771005630493, Valid_ACC:0.614799976348877
Epoch 787, CIFAR-10 Batch 1:  Train_Loss:0.6224318146705627, Valid_Loss:1.20645272731781, Valid_ACC:0.6161999106407166
Epoch 787, CIFAR-10 Batch 2:  Train_Loss:0.6011402606964111, Valid_Loss:1.2177221775054932, Valid_ACC:0.6155999302864075
Epoch 787, CIFAR-10 Batch 3:  Train_Loss:0.6147463917732239, Valid_Loss:1.2320858240127563, Valid_ACC:0.6121998429298401
Epoch 787, CIFAR-10 Batch 4:  Train_Loss:0.6037942171096802, Valid_Loss:1.2212637662887573, Valid_ACC:0.6053999066352844
Epoch 787, CIFAR-10 Batch 5:  Train_Loss:0.6307340860366821, Valid_Loss:1.2192302942276, Valid_ACC:0.6085999011993408
Epoch 788, CIFAR-10 Batch 1:  Train_Loss:0.605370044708252, Valid_Loss:1.197144865989685, Valid_ACC:0.6157998442649841
Epoch 788, CIFAR-10 Batch 2:  Train_Loss:0.6045340299606323, Valid_Loss:1.2395987510681152, Valid_ACC:0.6067999601364136
Epoch 788, CIFAR-10 Batch 3:  Train_Loss:0.6153379678726196, Valid_Loss:1.2247047424316406, Valid_ACC:0.6155999302864075
Epoch 788, CIFAR-10 Batch 4:  Train_Loss:0.5884580612182617, Valid_Loss:1.2053214311599731, Valid_ACC:0.613599956035614
Epoch 788, CIFAR-10 Batch 5:  Train_Loss:0.6167280077934265, Valid_Loss:1.200111746788025, Valid_ACC:0.6131998896598816
Epoch 789, CIFAR-10 Batch 1:  Train_Loss:0.5996288061141968, Valid_Loss:1.1974204778671265, Valid_ACC:0.6215999126434326
Epoch 789, CIFAR-10 Batch 2:  Train_Loss:0.5931493043899536, Valid_Loss:1.2130749225616455, Valid_ACC:0.6137998700141907
Epoch 789, CIFAR-10 Batch 3:  Train_Loss:0.6178028583526611, Valid_Loss:1.2296295166015625, Valid_ACC:0.6123999357223511
Epoch 789, CIFAR-10 Batch 4:  Train_Loss:0.612017035484314, Valid_Loss:1.2166357040405273, Valid_ACC:0.610599935054779
Epoch 789, CIFAR-10 Batch 5:  Train_Loss:0.6360040307044983, Valid_Loss:1.2250748872756958, Valid_ACC:0.6119999289512634
Epoch 790, CIFAR-10 Batch 1:  Train_Loss:0.6041885614395142, Valid_Loss:1.1949775218963623, Valid_ACC:0.6197999119758606
Epoch 790, CIFAR-10 Batch 2:  Train_Loss:0.5912266969680786, Valid_Loss:1.2040770053863525, Valid_ACC:0.6187999844551086
Epoch 790, CIFAR-10 Batch 3:  Train_Loss:0.5996314883232117, Valid_Loss:1.2255594730377197, Valid_ACC:0.6135998964309692
Epoch 790, CIFAR-10 Batch 4:  Train_Loss:0.6221498847007751, Valid_Loss:1.226349949836731, Valid_ACC:0.6123998761177063
Epoch 790, CIFAR-10 Batch 5:  Train_Loss:0.6081832051277161, Valid_Loss:1.201014518737793, Valid_ACC:0.6155999302864075
Epoch 791, CIFAR-10 Batch 1:  Train_Loss:0.6359133124351501, Valid_Loss:1.2096846103668213, Valid_ACC:0.6167998909950256
Epoch 791, CIFAR-10 Batch 2:  Train_Loss:0.6065135598182678, Valid_Loss:1.2033674716949463, Valid_ACC:0.6171998977661133
Epoch 791, CIFAR-10 Batch 3:  Train_Loss:0.6005405783653259, Valid_Loss:1.2146120071411133, Valid_ACC:0.6151999235153198
Epoch 791, CIFAR-10 Batch 4:  Train_Loss:0.6206942200660706, Valid_Loss:1.2138445377349854, Valid_ACC:0.6131998896598816
Epoch 791, CIFAR-10 Batch 5:  Train_Loss:0.6244493126869202, Valid_Loss:1.2173967361450195, Valid_ACC:0.6067999005317688
Epoch 792, CIFAR-10 Batch 1:  Train_Loss:0.6109145283699036, Valid_Loss:1.2132782936096191, Valid_ACC:0.6119998693466187
Epoch 792, CIFAR-10 Batch 2:  Train_Loss:0.6090406179428101, Valid_Loss:1.2088452577590942, Valid_ACC:0.6135998964309692
Epoch 792, CIFAR-10 Batch 3:  Train_Loss:0.6041927933692932, Valid_Loss:1.2108261585235596, Valid_ACC:0.6135998964309692
Epoch 792, CIFAR-10 Batch 4:  Train_Loss:0.6310038566589355, Valid_Loss:1.2235877513885498, Valid_ACC:0.608199954032898
Epoch 792, CIFAR-10 Batch 5:  Train_Loss:0.6110894680023193, Valid_Loss:1.2166568040847778, Valid_ACC:0.6141999363899231
Epoch 793, CIFAR-10 Batch 1:  Train_Loss:0.6186667680740356, Valid_Loss:1.207797884941101, Valid_ACC:0.6161998510360718
Epoch 793, CIFAR-10 Batch 2:  Train_Loss:0.6088300943374634, Valid_Loss:1.2178512811660767, Valid_ACC:0.610599935054779
Epoch 793, CIFAR-10 Batch 3:  Train_Loss:0.62674880027771, Valid_Loss:1.230433464050293, Valid_ACC:0.6107999086380005
Epoch 793, CIFAR-10 Batch 4:  Train_Loss:0.5983792543411255, Valid_Loss:1.207322359085083, Valid_ACC:0.6089999079704285
Epoch 793, CIFAR-10 Batch 5:  Train_Loss:0.609691321849823, Valid_Loss:1.212191104888916, Valid_ACC:0.6159999370574951
Epoch 794, CIFAR-10 Batch 1:  Train_Loss:0.6067681908607483, Valid_Loss:1.2012977600097656, Valid_ACC:0.6209999322891235
Epoch 794, CIFAR-10 Batch 2:  Train_Loss:0.6138786673545837, Valid_Loss:1.2216880321502686, Valid_ACC:0.610599935054779
Epoch 794, CIFAR-10 Batch 3:  Train_Loss:0.5989044904708862, Valid_Loss:1.2088888883590698, Valid_ACC:0.6137998104095459
Epoch 794, CIFAR-10 Batch 4:  Train_Loss:0.6232621073722839, Valid_Loss:1.213901400566101, Valid_ACC:0.6157999038696289
Epoch 794, CIFAR-10 Batch 5:  Train_Loss:0.6302892565727234, Valid_Loss:1.2109510898590088, Valid_ACC:0.6181999444961548
Epoch 795, CIFAR-10 Batch 1:  Train_Loss:0.6065575480461121, Valid_Loss:1.195151925086975, Valid_ACC:0.6225999593734741
Epoch 795, CIFAR-10 Batch 2:  Train_Loss:0.5912214517593384, Valid_Loss:1.2051243782043457, Valid_ACC:0.6123999357223511
Epoch 795, CIFAR-10 Batch 3:  Train_Loss:0.6048557758331299, Valid_Loss:1.2172181606292725, Valid_ACC:0.6117998361587524
Epoch 795, CIFAR-10 Batch 4:  Train_Loss:0.6230764985084534, Valid_Loss:1.2222988605499268, Valid_ACC:0.6085999011993408
Epoch 795, CIFAR-10 Batch 5:  Train_Loss:0.6376266479492188, Valid_Loss:1.233200192451477, Valid_ACC:0.6071999073028564
Epoch 796, CIFAR-10 Batch 1:  Train_Loss:0.6383726000785828, Valid_Loss:1.2205162048339844, Valid_ACC:0.6149999499320984
Epoch 796, CIFAR-10 Batch 2:  Train_Loss:0.5952886343002319, Valid_Loss:1.214145541191101, Valid_ACC:0.6097999215126038
Epoch 796, CIFAR-10 Batch 3:  Train_Loss:0.6200867891311646, Valid_Loss:1.2135419845581055, Valid_ACC:0.6135998964309692
Epoch 796, CIFAR-10 Batch 4:  Train_Loss:0.6512729525566101, Valid_Loss:1.243741512298584, Valid_ACC:0.6023998856544495
Epoch 796, CIFAR-10 Batch 5:  Train_Loss:0.6299605965614319, Valid_Loss:1.2308679819107056, Valid_ACC:0.6075999140739441
Epoch 797, CIFAR-10 Batch 1:  Train_Loss:0.6072103381156921, Valid_Loss:1.196305513381958, Valid_ACC:0.6141998767852783
Epoch 797, CIFAR-10 Batch 2:  Train_Loss:0.5945829749107361, Valid_Loss:1.204831838607788, Valid_ACC:0.6115999221801758
Epoch 797, CIFAR-10 Batch 3:  Train_Loss:0.6472488641738892, Valid_Loss:1.227048397064209, Valid_ACC:0.6097999215126038
Epoch 797, CIFAR-10 Batch 4:  Train_Loss:0.6547220945358276, Valid_Loss:1.2388771772384644, Valid_ACC:0.6071999073028564
Epoch 797, CIFAR-10 Batch 5:  Train_Loss:0.6541565656661987, Valid_Loss:1.2497639656066895, Valid_ACC:0.6027998924255371
Epoch 798, CIFAR-10 Batch 1:  Train_Loss:0.627991795539856, Valid_Loss:1.2191599607467651, Valid_ACC:0.6139999628067017
Epoch 798, CIFAR-10 Batch 2:  Train_Loss:0.6004171967506409, Valid_Loss:1.2021663188934326, Valid_ACC:0.6093999147415161
Epoch 798, CIFAR-10 Batch 3:  Train_Loss:0.6686745882034302, Valid_Loss:1.2524584531784058, Valid_ACC:0.5983998775482178
Epoch 798, CIFAR-10 Batch 4:  Train_Loss:0.6420154571533203, Valid_Loss:1.2295806407928467, Valid_ACC:0.6073998808860779
Epoch 798, CIFAR-10 Batch 5:  Train_Loss:0.618188738822937, Valid_Loss:1.2186250686645508, Valid_ACC:0.6111999750137329
Epoch 799, CIFAR-10 Batch 1:  Train_Loss:0.6408882737159729, Valid_Loss:1.2193433046340942, Valid_ACC:0.6143999099731445
Epoch 799, CIFAR-10 Batch 2:  Train_Loss:0.6183711290359497, Valid_Loss:1.2153230905532837, Valid_ACC:0.6147998571395874
Epoch 799, CIFAR-10 Batch 3:  Train_Loss:0.6441181302070618, Valid_Loss:1.2288953065872192, Valid_ACC:0.6027999520301819
Epoch 799, CIFAR-10 Batch 4:  Train_Loss:0.6191189289093018, Valid_Loss:1.2077101469039917, Valid_ACC:0.613399863243103
Epoch 799, CIFAR-10 Batch 5:  Train_Loss:0.6089229583740234, Valid_Loss:1.207811713218689, Valid_ACC:0.6125998497009277
Epoch 800, CIFAR-10 Batch 1:  Train_Loss:0.6086092591285706, Valid_Loss:1.1942389011383057, Valid_ACC:0.6227999329566956
Epoch 800, CIFAR-10 Batch 2:  Train_Loss:0.6042777299880981, Valid_Loss:1.2111964225769043, Valid_ACC:0.6101999282836914
Epoch 800, CIFAR-10 Batch 3:  Train_Loss:0.6189228296279907, Valid_Loss:1.2221139669418335, Valid_ACC:0.6119999289512634
Epoch 800, CIFAR-10 Batch 4:  Train_Loss:0.6242872476577759, Valid_Loss:1.2216465473175049, Valid_ACC:0.6091998815536499
Epoch 800, CIFAR-10 Batch 5:  Train_Loss:0.6271730065345764, Valid_Loss:1.2304068803787231, Valid_ACC:0.606999933719635
Epoch 801, CIFAR-10 Batch 1:  Train_Loss:0.621920645236969, Valid_Loss:1.2105944156646729, Valid_ACC:0.6171998977661133
Epoch 801, CIFAR-10 Batch 2:  Train_Loss:0.5974854826927185, Valid_Loss:1.2010310888290405, Valid_ACC:0.6107999086380005
Epoch 801, CIFAR-10 Batch 3:  Train_Loss:0.6243157982826233, Valid_Loss:1.2244813442230225, Valid_ACC:0.6185999512672424
Epoch 801, CIFAR-10 Batch 4:  Train_Loss:0.6125778555870056, Valid_Loss:1.2115108966827393, Valid_ACC:0.6129998564720154
Epoch 801, CIFAR-10 Batch 5:  Train_Loss:0.6245348453521729, Valid_Loss:1.2250621318817139, Valid_ACC:0.6073998808860779
Epoch 802, CIFAR-10 Batch 1:  Train_Loss:0.6106507778167725, Valid_Loss:1.197401523590088, Valid_ACC:0.6237999200820923
Epoch 802, CIFAR-10 Batch 2:  Train_Loss:0.5857216715812683, Valid_Loss:1.1988260746002197, Valid_ACC:0.6167998909950256
Epoch 802, CIFAR-10 Batch 3:  Train_Loss:0.5913639068603516, Valid_Loss:1.2085802555084229, Valid_ACC:0.616399884223938
Epoch 802, CIFAR-10 Batch 4:  Train_Loss:0.6019240617752075, Valid_Loss:1.1996315717697144, Valid_ACC:0.6141998767852783
Epoch 802, CIFAR-10 Batch 5:  Train_Loss:0.6065473556518555, Valid_Loss:1.2169426679611206, Valid_ACC:0.6151999235153198
Epoch 803, CIFAR-10 Batch 1:  Train_Loss:0.629345715045929, Valid_Loss:1.20906662940979, Valid_ACC:0.6215999126434326
Epoch 803, CIFAR-10 Batch 2:  Train_Loss:0.5895792245864868, Valid_Loss:1.2010579109191895, Valid_ACC:0.6139999032020569
Epoch 803, CIFAR-10 Batch 3:  Train_Loss:0.6000322103500366, Valid_Loss:1.2095942497253418, Valid_ACC:0.6173999309539795
Epoch 803, CIFAR-10 Batch 4:  Train_Loss:0.6138920783996582, Valid_Loss:1.2131279706954956, Valid_ACC:0.6125998497009277
Epoch 803, CIFAR-10 Batch 5:  Train_Loss:0.6150389313697815, Valid_Loss:1.2087887525558472, Valid_ACC:0.6141998767852783
Epoch 804, CIFAR-10 Batch 1:  Train_Loss:0.6213870048522949, Valid_Loss:1.219934344291687, Valid_ACC:0.613399863243103
Epoch 804, CIFAR-10 Batch 2:  Train_Loss:0.6022346019744873, Valid_Loss:1.2141932249069214, Valid_ACC:0.6139999032020569
Epoch 804, CIFAR-10 Batch 3:  Train_Loss:0.6307856440544128, Valid_Loss:1.2326250076293945, Valid_ACC:0.6107999682426453
Epoch 804, CIFAR-10 Batch 4:  Train_Loss:0.6463363170623779, Valid_Loss:1.2460386753082275, Valid_ACC:0.598599910736084
Epoch 804, CIFAR-10 Batch 5:  Train_Loss:0.6185281872749329, Valid_Loss:1.2128307819366455, Valid_ACC:0.6071999073028564
Epoch 805, CIFAR-10 Batch 1:  Train_Loss:0.6166005730628967, Valid_Loss:1.2054660320281982, Valid_ACC:0.6209999322891235
Epoch 805, CIFAR-10 Batch 2:  Train_Loss:0.650402843952179, Valid_Loss:1.2395765781402588, Valid_ACC:0.6075999140739441
Epoch 805, CIFAR-10 Batch 3:  Train_Loss:0.6527113318443298, Valid_Loss:1.232284426689148, Valid_ACC:0.6019999384880066
Epoch 805, CIFAR-10 Batch 4:  Train_Loss:0.6402525305747986, Valid_Loss:1.2246570587158203, Valid_ACC:0.6093999147415161
Epoch 805, CIFAR-10 Batch 5:  Train_Loss:0.6224517226219177, Valid_Loss:1.2187671661376953, Valid_ACC:0.6131998896598816
Epoch 806, CIFAR-10 Batch 1:  Train_Loss:0.6239449977874756, Valid_Loss:1.2086669206619263, Valid_ACC:0.6149998903274536
Epoch 806, CIFAR-10 Batch 2:  Train_Loss:0.5936560034751892, Valid_Loss:1.1973512172698975, Valid_ACC:0.6123998761177063
Epoch 806, CIFAR-10 Batch 3:  Train_Loss:0.628348708152771, Valid_Loss:1.229318380355835, Valid_ACC:0.6089998483657837
Epoch 806, CIFAR-10 Batch 4:  Train_Loss:0.6245183944702148, Valid_Loss:1.2109180688858032, Valid_ACC:0.608199954032898
Epoch 806, CIFAR-10 Batch 5:  Train_Loss:0.6082293391227722, Valid_Loss:1.204781174659729, Valid_ACC:0.6155998706817627
Epoch 807, CIFAR-10 Batch 1:  Train_Loss:0.6304440498352051, Valid_Loss:1.2147235870361328, Valid_ACC:0.6181999444961548
Epoch 807, CIFAR-10 Batch 2:  Train_Loss:0.6059386730194092, Valid_Loss:1.2055033445358276, Valid_ACC:0.6141998767852783
Epoch 807, CIFAR-10 Batch 3:  Train_Loss:0.6476975679397583, Valid_Loss:1.2451997995376587, Valid_ACC:0.6029999256134033
Epoch 807, CIFAR-10 Batch 4:  Train_Loss:0.6196705102920532, Valid_Loss:1.2206623554229736, Valid_ACC:0.6071999073028564
Epoch 807, CIFAR-10 Batch 5:  Train_Loss:0.623944878578186, Valid_Loss:1.2223985195159912, Valid_ACC:0.6071999073028564
Epoch 808, CIFAR-10 Batch 1:  Train_Loss:0.6187538504600525, Valid_Loss:1.2076711654663086, Valid_ACC:0.61819988489151
Epoch 808, CIFAR-10 Batch 2:  Train_Loss:0.6514050364494324, Valid_Loss:1.23014235496521, Valid_ACC:0.6089999079704285
Epoch 808, CIFAR-10 Batch 3:  Train_Loss:0.6307412385940552, Valid_Loss:1.233499526977539, Valid_ACC:0.6045998930931091
Epoch 808, CIFAR-10 Batch 4:  Train_Loss:0.6024349331855774, Valid_Loss:1.2011269330978394, Valid_ACC:0.612799882888794
Epoch 808, CIFAR-10 Batch 5:  Train_Loss:0.6114084124565125, Valid_Loss:1.2124618291854858, Valid_ACC:0.6091998815536499
Epoch 809, CIFAR-10 Batch 1:  Train_Loss:0.6236391067504883, Valid_Loss:1.2118339538574219, Valid_ACC:0.6165998578071594
Epoch 809, CIFAR-10 Batch 2:  Train_Loss:0.6145332455635071, Valid_Loss:1.2062609195709229, Valid_ACC:0.615199863910675
Epoch 809, CIFAR-10 Batch 3:  Train_Loss:0.6363523006439209, Valid_Loss:1.2279469966888428, Valid_ACC:0.6067999005317688
Epoch 809, CIFAR-10 Batch 4:  Train_Loss:0.6031285524368286, Valid_Loss:1.210169792175293, Valid_ACC:0.6091999411582947
Epoch 809, CIFAR-10 Batch 5:  Train_Loss:0.6122018098831177, Valid_Loss:1.2052428722381592, Valid_ACC:0.6141998767852783
Epoch 810, CIFAR-10 Batch 1:  Train_Loss:0.6475384831428528, Valid_Loss:1.2194691896438599, Valid_ACC:0.6163999438285828
Epoch 810, CIFAR-10 Batch 2:  Train_Loss:0.6044901013374329, Valid_Loss:1.206050157546997, Valid_ACC:0.6123999357223511
Epoch 810, CIFAR-10 Batch 3:  Train_Loss:0.6288338303565979, Valid_Loss:1.2255123853683472, Valid_ACC:0.6063998937606812
Epoch 810, CIFAR-10 Batch 4:  Train_Loss:0.6254919767379761, Valid_Loss:1.220208764076233, Valid_ACC:0.6033998727798462
Epoch 810, CIFAR-10 Batch 5:  Train_Loss:0.6058740019798279, Valid_Loss:1.2240655422210693, Valid_ACC:0.6129999160766602
Epoch 811, CIFAR-10 Batch 1:  Train_Loss:0.6101633310317993, Valid_Loss:1.2102580070495605, Valid_ACC:0.6191999316215515
Epoch 811, CIFAR-10 Batch 2:  Train_Loss:0.6163789629936218, Valid_Loss:1.2204809188842773, Valid_ACC:0.6107999086380005
Epoch 811, CIFAR-10 Batch 3:  Train_Loss:0.6231433749198914, Valid_Loss:1.217191457748413, Valid_ACC:0.6155999302864075
Epoch 811, CIFAR-10 Batch 4:  Train_Loss:0.6023595929145813, Valid_Loss:1.2059687376022339, Valid_ACC:0.6119999289512634
Epoch 811, CIFAR-10 Batch 5:  Train_Loss:0.5970117449760437, Valid_Loss:1.2121918201446533, Valid_ACC:0.614599883556366
Epoch 812, CIFAR-10 Batch 1:  Train_Loss:0.611138641834259, Valid_Loss:1.2062188386917114, Valid_ACC:0.6213998794555664
Epoch 812, CIFAR-10 Batch 2:  Train_Loss:0.5874201655387878, Valid_Loss:1.203535795211792, Valid_ACC:0.6115999221801758
Epoch 812, CIFAR-10 Batch 3:  Train_Loss:0.6117122173309326, Valid_Loss:1.210982084274292, Valid_ACC:0.614599883556366
Epoch 812, CIFAR-10 Batch 4:  Train_Loss:0.6009536385536194, Valid_Loss:1.2010607719421387, Valid_ACC:0.6171998977661133
Epoch 812, CIFAR-10 Batch 5:  Train_Loss:0.6121329069137573, Valid_Loss:1.2142106294631958, Valid_ACC:0.6167999505996704
Epoch 813, CIFAR-10 Batch 1:  Train_Loss:0.606736421585083, Valid_Loss:1.2054686546325684, Valid_ACC:0.6191998720169067
Epoch 813, CIFAR-10 Batch 2:  Train_Loss:0.6102952361106873, Valid_Loss:1.2115293741226196, Valid_ACC:0.6125999093055725
Epoch 813, CIFAR-10 Batch 3:  Train_Loss:0.6127296686172485, Valid_Loss:1.2148360013961792, Valid_ACC:0.6135998964309692
Epoch 813, CIFAR-10 Batch 4:  Train_Loss:0.6012367010116577, Valid_Loss:1.206968069076538, Valid_ACC:0.6097999215126038
Epoch 813, CIFAR-10 Batch 5:  Train_Loss:0.5951666831970215, Valid_Loss:1.196720004081726, Valid_ACC:0.6161999106407166
Epoch 814, CIFAR-10 Batch 1:  Train_Loss:0.5999962091445923, Valid_Loss:1.1999766826629639, Valid_ACC:0.6191998720169067
Epoch 814, CIFAR-10 Batch 2:  Train_Loss:0.5821611285209656, Valid_Loss:1.1923866271972656, Valid_ACC:0.6157999038696289
Epoch 814, CIFAR-10 Batch 3:  Train_Loss:0.5923706293106079, Valid_Loss:1.2051104307174683, Valid_ACC:0.6195999383926392
Epoch 814, CIFAR-10 Batch 4:  Train_Loss:0.6147039532661438, Valid_Loss:1.2138252258300781, Valid_ACC:0.616399884223938
Epoch 814, CIFAR-10 Batch 5:  Train_Loss:0.6111286878585815, Valid_Loss:1.2197428941726685, Valid_ACC:0.6137999296188354
Epoch 815, CIFAR-10 Batch 1:  Train_Loss:0.6094584465026855, Valid_Loss:1.197804570198059, Valid_ACC:0.6207998991012573
Epoch 815, CIFAR-10 Batch 2:  Train_Loss:0.5776420831680298, Valid_Loss:1.1983704566955566, Valid_ACC:0.6155999302864075
Epoch 815, CIFAR-10 Batch 3:  Train_Loss:0.5897455215454102, Valid_Loss:1.2051411867141724, Valid_ACC:0.6155999302864075
Epoch 815, CIFAR-10 Batch 4:  Train_Loss:0.6000931262969971, Valid_Loss:1.2087030410766602, Valid_ACC:0.6103999018669128
Epoch 815, CIFAR-10 Batch 5:  Train_Loss:0.6101734042167664, Valid_Loss:1.2109344005584717, Valid_ACC:0.6161999106407166
Epoch 816, CIFAR-10 Batch 1:  Train_Loss:0.6013017892837524, Valid_Loss:1.2034255266189575, Valid_ACC:0.6203998923301697
Epoch 816, CIFAR-10 Batch 2:  Train_Loss:0.5841655731201172, Valid_Loss:1.197588324546814, Valid_ACC:0.6131999492645264
Epoch 816, CIFAR-10 Batch 3:  Train_Loss:0.5908739566802979, Valid_Loss:1.210853099822998, Valid_ACC:0.6159998774528503
Epoch 816, CIFAR-10 Batch 4:  Train_Loss:0.6215969324111938, Valid_Loss:1.2234410047531128, Valid_ACC:0.6067999601364136
Epoch 816, CIFAR-10 Batch 5:  Train_Loss:0.6020697951316833, Valid_Loss:1.2099641561508179, Valid_ACC:0.6135998964309692
Epoch 817, CIFAR-10 Batch 1:  Train_Loss:0.6107909679412842, Valid_Loss:1.2019416093826294, Valid_ACC:0.6207999587059021
Epoch 817, CIFAR-10 Batch 2:  Train_Loss:0.5813875198364258, Valid_Loss:1.2019975185394287, Valid_ACC:0.6131999492645264
Epoch 817, CIFAR-10 Batch 3:  Train_Loss:0.5904210805892944, Valid_Loss:1.2075607776641846, Valid_ACC:0.6123998761177063
Epoch 817, CIFAR-10 Batch 4:  Train_Loss:0.590899646282196, Valid_Loss:1.2073935270309448, Valid_ACC:0.612799882888794
Epoch 817, CIFAR-10 Batch 5:  Train_Loss:0.6019182801246643, Valid_Loss:1.1983267068862915, Valid_ACC:0.6201998591423035
Epoch 818, CIFAR-10 Batch 1:  Train_Loss:0.6015377640724182, Valid_Loss:1.1992831230163574, Valid_ACC:0.6141998767852783
Epoch 818, CIFAR-10 Batch 2:  Train_Loss:0.5853980779647827, Valid_Loss:1.2023086547851562, Valid_ACC:0.6133999228477478
Epoch 818, CIFAR-10 Batch 3:  Train_Loss:0.5830689668655396, Valid_Loss:1.19686758518219, Valid_ACC:0.6203998923301697
Epoch 818, CIFAR-10 Batch 4:  Train_Loss:0.5933815836906433, Valid_Loss:1.2083202600479126, Valid_ACC:0.6135998964309692
Epoch 818, CIFAR-10 Batch 5:  Train_Loss:0.5992340445518494, Valid_Loss:1.2096446752548218, Valid_ACC:0.6133999228477478
Epoch 819, CIFAR-10 Batch 1:  Train_Loss:0.6035825610160828, Valid_Loss:1.2010595798492432, Valid_ACC:0.6139999032020569
Epoch 819, CIFAR-10 Batch 2:  Train_Loss:0.5916667580604553, Valid_Loss:1.1995769739151, Valid_ACC:0.6139999032020569
Epoch 819, CIFAR-10 Batch 3:  Train_Loss:0.6055132746696472, Valid_Loss:1.2125067710876465, Valid_ACC:0.6089999079704285
Epoch 819, CIFAR-10 Batch 4:  Train_Loss:0.5911365747451782, Valid_Loss:1.2030973434448242, Valid_ACC:0.6119998693466187
Epoch 819, CIFAR-10 Batch 5:  Train_Loss:0.5979028344154358, Valid_Loss:1.203760027885437, Valid_ACC:0.6141998767852783
Epoch 820, CIFAR-10 Batch 1:  Train_Loss:0.6096737384796143, Valid_Loss:1.206329345703125, Valid_ACC:0.6161999106407166
Epoch 820, CIFAR-10 Batch 2:  Train_Loss:0.5872582793235779, Valid_Loss:1.195799469947815, Valid_ACC:0.6143999099731445
Epoch 820, CIFAR-10 Batch 3:  Train_Loss:0.5887969136238098, Valid_Loss:1.2093355655670166, Valid_ACC:0.6189998984336853
Epoch 820, CIFAR-10 Batch 4:  Train_Loss:0.6137620210647583, Valid_Loss:1.2182302474975586, Valid_ACC:0.6101999282836914
Epoch 820, CIFAR-10 Batch 5:  Train_Loss:0.643210768699646, Valid_Loss:1.248767375946045, Valid_ACC:0.6027999520301819
Epoch 821, CIFAR-10 Batch 1:  Train_Loss:0.5980845093727112, Valid_Loss:1.1953388452529907, Valid_ACC:0.6197998523712158
Epoch 821, CIFAR-10 Batch 2:  Train_Loss:0.5938012599945068, Valid_Loss:1.2044134140014648, Valid_ACC:0.6125998497009277
Epoch 821, CIFAR-10 Batch 3:  Train_Loss:0.5872592926025391, Valid_Loss:1.195565938949585, Valid_ACC:0.619999885559082
Epoch 821, CIFAR-10 Batch 4:  Train_Loss:0.5885003805160522, Valid_Loss:1.2007901668548584, Valid_ACC:0.6151999235153198
Epoch 821, CIFAR-10 Batch 5:  Train_Loss:0.6029896140098572, Valid_Loss:1.2095280885696411, Valid_ACC:0.6153998970985413
Epoch 822, CIFAR-10 Batch 1:  Train_Loss:0.6012327075004578, Valid_Loss:1.1959823369979858, Valid_ACC:0.6183998584747314
Epoch 822, CIFAR-10 Batch 2:  Train_Loss:0.5885491967201233, Valid_Loss:1.205871343612671, Valid_ACC:0.6133999228477478
Epoch 822, CIFAR-10 Batch 3:  Train_Loss:0.599358856678009, Valid_Loss:1.211626648902893, Valid_ACC:0.6201998591423035
Epoch 822, CIFAR-10 Batch 4:  Train_Loss:0.5939168930053711, Valid_Loss:1.2073602676391602, Valid_ACC:0.6151999235153198
Epoch 822, CIFAR-10 Batch 5:  Train_Loss:0.6054556369781494, Valid_Loss:1.2038321495056152, Valid_ACC:0.6153998970985413
Epoch 823, CIFAR-10 Batch 1:  Train_Loss:0.6040467023849487, Valid_Loss:1.2003391981124878, Valid_ACC:0.6203999519348145
Epoch 823, CIFAR-10 Batch 2:  Train_Loss:0.5869377255439758, Valid_Loss:1.208159327507019, Valid_ACC:0.6085999011993408
Epoch 823, CIFAR-10 Batch 3:  Train_Loss:0.5899178385734558, Valid_Loss:1.1988943815231323, Valid_ACC:0.6205998659133911
Epoch 823, CIFAR-10 Batch 4:  Train_Loss:0.6036437153816223, Valid_Loss:1.217093586921692, Valid_ACC:0.6101999282836914
Epoch 823, CIFAR-10 Batch 5:  Train_Loss:0.6132718324661255, Valid_Loss:1.2182929515838623, Valid_ACC:0.612799882888794
Epoch 824, CIFAR-10 Batch 1:  Train_Loss:0.6015976667404175, Valid_Loss:1.2023097276687622, Valid_ACC:0.6173998713493347
Epoch 824, CIFAR-10 Batch 2:  Train_Loss:0.5742906928062439, Valid_Loss:1.1973462104797363, Valid_ACC:0.6173999309539795
Epoch 824, CIFAR-10 Batch 3:  Train_Loss:0.5894938111305237, Valid_Loss:1.2034194469451904, Valid_ACC:0.6157999038696289
Epoch 824, CIFAR-10 Batch 4:  Train_Loss:0.5874186754226685, Valid_Loss:1.206711769104004, Valid_ACC:0.6125999093055725
Epoch 824, CIFAR-10 Batch 5:  Train_Loss:0.6113350987434387, Valid_Loss:1.2147446870803833, Valid_ACC:0.6089999079704285
Epoch 825, CIFAR-10 Batch 1:  Train_Loss:0.5967438817024231, Valid_Loss:1.1983611583709717, Valid_ACC:0.6203999519348145
Epoch 825, CIFAR-10 Batch 2:  Train_Loss:0.5836421847343445, Valid_Loss:1.1930756568908691, Valid_ACC:0.6161999106407166
Epoch 825, CIFAR-10 Batch 3:  Train_Loss:0.5917240381240845, Valid_Loss:1.2121504545211792, Valid_ACC:0.6105998754501343
Epoch 825, CIFAR-10 Batch 4:  Train_Loss:0.5945411324501038, Valid_Loss:1.2032610177993774, Valid_ACC:0.6123999357223511
Epoch 825, CIFAR-10 Batch 5:  Train_Loss:0.6049404740333557, Valid_Loss:1.22182035446167, Valid_ACC:0.6121999025344849
Epoch 826, CIFAR-10 Batch 1:  Train_Loss:0.6028425693511963, Valid_Loss:1.1990690231323242, Valid_ACC:0.6185998916625977
Epoch 826, CIFAR-10 Batch 2:  Train_Loss:0.5790463089942932, Valid_Loss:1.1941955089569092, Valid_ACC:0.6159999370574951
Epoch 826, CIFAR-10 Batch 3:  Train_Loss:0.5798863768577576, Valid_Loss:1.2009180784225464, Valid_ACC:0.6185998320579529
Epoch 826, CIFAR-10 Batch 4:  Train_Loss:0.5807842016220093, Valid_Loss:1.2052421569824219, Valid_ACC:0.6157999038696289
Epoch 826, CIFAR-10 Batch 5:  Train_Loss:0.604730486869812, Valid_Loss:1.2057585716247559, Valid_ACC:0.6107999086380005
Epoch 827, CIFAR-10 Batch 1:  Train_Loss:0.599699079990387, Valid_Loss:1.212561845779419, Valid_ACC:0.6167999505996704
Epoch 827, CIFAR-10 Batch 2:  Train_Loss:0.5889608263969421, Valid_Loss:1.2091184854507446, Valid_ACC:0.6147999167442322
Epoch 827, CIFAR-10 Batch 3:  Train_Loss:0.5828912258148193, Valid_Loss:1.2076406478881836, Valid_ACC:0.6137998700141907
Epoch 827, CIFAR-10 Batch 4:  Train_Loss:0.585966944694519, Valid_Loss:1.198990821838379, Valid_ACC:0.612799882888794
Epoch 827, CIFAR-10 Batch 5:  Train_Loss:0.6006016135215759, Valid_Loss:1.2069867849349976, Valid_ACC:0.6123998761177063
Epoch 828, CIFAR-10 Batch 1:  Train_Loss:0.5997182130813599, Valid_Loss:1.2077518701553345, Valid_ACC:0.6183999180793762
Epoch 828, CIFAR-10 Batch 2:  Train_Loss:0.5965005159378052, Valid_Loss:1.2180612087249756, Valid_ACC:0.6053999066352844
Epoch 828, CIFAR-10 Batch 3:  Train_Loss:0.5759918689727783, Valid_Loss:1.2001078128814697, Valid_ACC:0.6153998970985413
Epoch 828, CIFAR-10 Batch 4:  Train_Loss:0.591623842716217, Valid_Loss:1.2021164894104004, Valid_ACC:0.6135998964309692
Epoch 828, CIFAR-10 Batch 5:  Train_Loss:0.6131759881973267, Valid_Loss:1.2003318071365356, Valid_ACC:0.6165999174118042
Epoch 829, CIFAR-10 Batch 1:  Train_Loss:0.6149560213088989, Valid_Loss:1.2076386213302612, Valid_ACC:0.6149998903274536
Epoch 829, CIFAR-10 Batch 2:  Train_Loss:0.5858055949211121, Valid_Loss:1.210052490234375, Valid_ACC:0.6097999215126038
Epoch 829, CIFAR-10 Batch 3:  Train_Loss:0.5938748121261597, Valid_Loss:1.207695722579956, Valid_ACC:0.6119999289512634
Epoch 829, CIFAR-10 Batch 4:  Train_Loss:0.6089194416999817, Valid_Loss:1.2196378707885742, Valid_ACC:0.606999933719635
Epoch 829, CIFAR-10 Batch 5:  Train_Loss:0.6091808080673218, Valid_Loss:1.2051105499267578, Valid_ACC:0.612799882888794
Epoch 830, CIFAR-10 Batch 1:  Train_Loss:0.6054936647415161, Valid_Loss:1.202529788017273, Valid_ACC:0.6187999248504639
Epoch 830, CIFAR-10 Batch 2:  Train_Loss:0.5893166661262512, Valid_Loss:1.207535982131958, Valid_ACC:0.6123999357223511
Epoch 830, CIFAR-10 Batch 3:  Train_Loss:0.5762078166007996, Valid_Loss:1.205222725868225, Valid_ACC:0.6125999093055725
Epoch 830, CIFAR-10 Batch 4:  Train_Loss:0.6144425272941589, Valid_Loss:1.2240835428237915, Valid_ACC:0.6081998348236084
Epoch 830, CIFAR-10 Batch 5:  Train_Loss:0.5949937105178833, Valid_Loss:1.205702781677246, Valid_ACC:0.6123999357223511
Epoch 831, CIFAR-10 Batch 1:  Train_Loss:0.5940744280815125, Valid_Loss:1.204804539680481, Valid_ACC:0.6185999512672424
Epoch 831, CIFAR-10 Batch 2:  Train_Loss:0.5999239683151245, Valid_Loss:1.2108277082443237, Valid_ACC:0.6107999682426453
Epoch 831, CIFAR-10 Batch 3:  Train_Loss:0.593835711479187, Valid_Loss:1.210442304611206, Valid_ACC:0.6119999289512634
Epoch 831, CIFAR-10 Batch 4:  Train_Loss:0.5957001447677612, Valid_Loss:1.21368408203125, Valid_ACC:0.613599956035614
Epoch 831, CIFAR-10 Batch 5:  Train_Loss:0.6015646457672119, Valid_Loss:1.2090281248092651, Valid_ACC:0.6111999750137329
Epoch 832, CIFAR-10 Batch 1:  Train_Loss:0.6020882725715637, Valid_Loss:1.1980215311050415, Valid_ACC:0.6167998909950256
Epoch 832, CIFAR-10 Batch 2:  Train_Loss:0.5875269174575806, Valid_Loss:1.1970711946487427, Valid_ACC:0.6123999357223511
Epoch 832, CIFAR-10 Batch 3:  Train_Loss:0.5852645039558411, Valid_Loss:1.216786503791809, Valid_ACC:0.6141999363899231
Epoch 832, CIFAR-10 Batch 4:  Train_Loss:0.5989077091217041, Valid_Loss:1.2061759233474731, Valid_ACC:0.6107999086380005
Epoch 832, CIFAR-10 Batch 5:  Train_Loss:0.5913882255554199, Valid_Loss:1.1974871158599854, Valid_ACC:0.6151999235153198
Epoch 833, CIFAR-10 Batch 1:  Train_Loss:0.612522542476654, Valid_Loss:1.2145482301712036, Valid_ACC:0.6201999187469482
Epoch 833, CIFAR-10 Batch 2:  Train_Loss:0.5869037508964539, Valid_Loss:1.210595965385437, Valid_ACC:0.6101999282836914
Epoch 833, CIFAR-10 Batch 3:  Train_Loss:0.5902025699615479, Valid_Loss:1.2215732336044312, Valid_ACC:0.6095998883247375
Epoch 833, CIFAR-10 Batch 4:  Train_Loss:0.5926764011383057, Valid_Loss:1.2065590620040894, Valid_ACC:0.6141998767852783
Epoch 833, CIFAR-10 Batch 5:  Train_Loss:0.6000638604164124, Valid_Loss:1.206061601638794, Valid_ACC:0.6083999872207642
Epoch 834, CIFAR-10 Batch 1:  Train_Loss:0.5949174165725708, Valid_Loss:1.192024827003479, Valid_ACC:0.6215999126434326
Epoch 834, CIFAR-10 Batch 2:  Train_Loss:0.5915219187736511, Valid_Loss:1.2100414037704468, Valid_ACC:0.6121998429298401
Epoch 834, CIFAR-10 Batch 3:  Train_Loss:0.5791081190109253, Valid_Loss:1.2124272584915161, Valid_ACC:0.6149998903274536
Epoch 834, CIFAR-10 Batch 4:  Train_Loss:0.5933281779289246, Valid_Loss:1.2046432495117188, Valid_ACC:0.6107999086380005
Epoch 834, CIFAR-10 Batch 5:  Train_Loss:0.6058034896850586, Valid_Loss:1.204490303993225, Valid_ACC:0.6153998374938965
Epoch 835, CIFAR-10 Batch 1:  Train_Loss:0.588708758354187, Valid_Loss:1.1992028951644897, Valid_ACC:0.6215999126434326
Epoch 835, CIFAR-10 Batch 2:  Train_Loss:0.58548903465271, Valid_Loss:1.2012420892715454, Valid_ACC:0.6137998700141907
Epoch 835, CIFAR-10 Batch 3:  Train_Loss:0.5820986032485962, Valid_Loss:1.2086589336395264, Valid_ACC:0.6155998706817627
Epoch 835, CIFAR-10 Batch 4:  Train_Loss:0.5908606052398682, Valid_Loss:1.2099785804748535, Valid_ACC:0.6101999282836914
Epoch 835, CIFAR-10 Batch 5:  Train_Loss:0.5954784154891968, Valid_Loss:1.2019126415252686, Valid_ACC:0.6191998720169067
Epoch 836, CIFAR-10 Batch 1:  Train_Loss:0.5917032957077026, Valid_Loss:1.2012054920196533, Valid_ACC:0.6179999113082886
Epoch 836, CIFAR-10 Batch 2:  Train_Loss:0.5728508234024048, Valid_Loss:1.1934038400650024, Valid_ACC:0.6193999648094177
Epoch 836, CIFAR-10 Batch 3:  Train_Loss:0.5795063972473145, Valid_Loss:1.2084324359893799, Valid_ACC:0.6185999512672424
Epoch 836, CIFAR-10 Batch 4:  Train_Loss:0.5848712921142578, Valid_Loss:1.1962342262268066, Valid_ACC:0.6139999628067017
Epoch 836, CIFAR-10 Batch 5:  Train_Loss:0.5957303047180176, Valid_Loss:1.206191897392273, Valid_ACC:0.616399884223938
Epoch 837, CIFAR-10 Batch 1:  Train_Loss:0.5935777425765991, Valid_Loss:1.210723638534546, Valid_ACC:0.6179999113082886
Epoch 837, CIFAR-10 Batch 2:  Train_Loss:0.592640221118927, Valid_Loss:1.2173854112625122, Valid_ACC:0.6075999140739441
Epoch 837, CIFAR-10 Batch 3:  Train_Loss:0.5664418935775757, Valid_Loss:1.20326828956604, Valid_ACC:0.6177998781204224
Epoch 837, CIFAR-10 Batch 4:  Train_Loss:0.5916733741760254, Valid_Loss:1.2049000263214111, Valid_ACC:0.6123999357223511
Epoch 837, CIFAR-10 Batch 5:  Train_Loss:0.6028889417648315, Valid_Loss:1.2053896188735962, Valid_ACC:0.6107999086380005
Epoch 838, CIFAR-10 Batch 1:  Train_Loss:0.590388834476471, Valid_Loss:1.1923187971115112, Valid_ACC:0.6225998997688293
Epoch 838, CIFAR-10 Batch 2:  Train_Loss:0.5802128314971924, Valid_Loss:1.2015687227249146, Valid_ACC:0.6143998503684998
Epoch 838, CIFAR-10 Batch 3:  Train_Loss:0.5746605396270752, Valid_Loss:1.212661623954773, Valid_ACC:0.6169998645782471
Epoch 838, CIFAR-10 Batch 4:  Train_Loss:0.595369279384613, Valid_Loss:1.2109683752059937, Valid_ACC:0.6147999167442322
Epoch 838, CIFAR-10 Batch 5:  Train_Loss:0.6027663350105286, Valid_Loss:1.2026052474975586, Valid_ACC:0.6185998916625977
Epoch 839, CIFAR-10 Batch 1:  Train_Loss:0.6011248230934143, Valid_Loss:1.202186942100525, Valid_ACC:0.6185998916625977
Epoch 839, CIFAR-10 Batch 2:  Train_Loss:0.602064311504364, Valid_Loss:1.2060737609863281, Valid_ACC:0.6155998706817627
Epoch 839, CIFAR-10 Batch 3:  Train_Loss:0.5934546589851379, Valid_Loss:1.2091896533966064, Valid_ACC:0.6143999099731445
Epoch 839, CIFAR-10 Batch 4:  Train_Loss:0.6005521416664124, Valid_Loss:1.201568841934204, Valid_ACC:0.6171998977661133
Epoch 839, CIFAR-10 Batch 5:  Train_Loss:0.6100965738296509, Valid_Loss:1.2074793577194214, Valid_ACC:0.6127999424934387
Epoch 840, CIFAR-10 Batch 1:  Train_Loss:0.5989658832550049, Valid_Loss:1.1963564157485962, Valid_ACC:0.619399905204773
Epoch 840, CIFAR-10 Batch 2:  Train_Loss:0.5940126180648804, Valid_Loss:1.2068392038345337, Valid_ACC:0.6113998889923096
Epoch 840, CIFAR-10 Batch 3:  Train_Loss:0.559248149394989, Valid_Loss:1.1992812156677246, Valid_ACC:0.61819988489151
Epoch 840, CIFAR-10 Batch 4:  Train_Loss:0.5979903936386108, Valid_Loss:1.2111873626708984, Valid_ACC:0.6109999418258667
Epoch 840, CIFAR-10 Batch 5:  Train_Loss:0.6224632859230042, Valid_Loss:1.2221554517745972, Valid_ACC:0.6135998964309692
Epoch 841, CIFAR-10 Batch 1:  Train_Loss:0.6138517260551453, Valid_Loss:1.208659291267395, Valid_ACC:0.6139998435974121
Epoch 841, CIFAR-10 Batch 2:  Train_Loss:0.5891695022583008, Valid_Loss:1.2041789293289185, Valid_ACC:0.619399905204773
Epoch 841, CIFAR-10 Batch 3:  Train_Loss:0.6093680262565613, Valid_Loss:1.2233490943908691, Valid_ACC:0.6113998889923096
Epoch 841, CIFAR-10 Batch 4:  Train_Loss:0.5924726128578186, Valid_Loss:1.2016419172286987, Valid_ACC:0.6151999831199646
Epoch 841, CIFAR-10 Batch 5:  Train_Loss:0.5955166220664978, Valid_Loss:1.1985654830932617, Valid_ACC:0.6167998909950256
Epoch 842, CIFAR-10 Batch 1:  Train_Loss:0.5978977680206299, Valid_Loss:1.2076683044433594, Valid_ACC:0.6165999174118042
Epoch 842, CIFAR-10 Batch 2:  Train_Loss:0.5846112370491028, Valid_Loss:1.2034125328063965, Valid_ACC:0.6159998774528503
Epoch 842, CIFAR-10 Batch 3:  Train_Loss:0.5722148418426514, Valid_Loss:1.2037698030471802, Valid_ACC:0.6169999241828918
Epoch 842, CIFAR-10 Batch 4:  Train_Loss:0.5933296084403992, Valid_Loss:1.2046257257461548, Valid_ACC:0.6077998876571655
Epoch 842, CIFAR-10 Batch 5:  Train_Loss:0.5979930758476257, Valid_Loss:1.2069848775863647, Valid_ACC:0.6155998706817627
Epoch 843, CIFAR-10 Batch 1:  Train_Loss:0.5928564667701721, Valid_Loss:1.1969070434570312, Valid_ACC:0.6241999268531799
Epoch 843, CIFAR-10 Batch 2:  Train_Loss:0.5779871940612793, Valid_Loss:1.1955487728118896, Valid_ACC:0.6189998984336853
Epoch 843, CIFAR-10 Batch 3:  Train_Loss:0.5898439288139343, Valid_Loss:1.2155054807662964, Valid_ACC:0.6151999235153198
Epoch 843, CIFAR-10 Batch 4:  Train_Loss:0.5940588712692261, Valid_Loss:1.2110674381256104, Valid_ACC:0.6143999099731445
Epoch 843, CIFAR-10 Batch 5:  Train_Loss:0.609241247177124, Valid_Loss:1.1997334957122803, Valid_ACC:0.611599862575531
Epoch 844, CIFAR-10 Batch 1:  Train_Loss:0.6029666066169739, Valid_Loss:1.2060041427612305, Valid_ACC:0.6145999431610107
Epoch 844, CIFAR-10 Batch 2:  Train_Loss:0.588148832321167, Valid_Loss:1.1962380409240723, Valid_ACC:0.6191998720169067
Epoch 844, CIFAR-10 Batch 3:  Train_Loss:0.6008540987968445, Valid_Loss:1.2167789936065674, Valid_ACC:0.6121998429298401
Epoch 844, CIFAR-10 Batch 4:  Train_Loss:0.5899018049240112, Valid_Loss:1.2128612995147705, Valid_ACC:0.6135998964309692
Epoch 844, CIFAR-10 Batch 5:  Train_Loss:0.604223906993866, Valid_Loss:1.2081445455551147, Valid_ACC:0.6183999180793762
Epoch 845, CIFAR-10 Batch 1:  Train_Loss:0.588564395904541, Valid_Loss:1.209263563156128, Valid_ACC:0.6189998984336853
Epoch 845, CIFAR-10 Batch 2:  Train_Loss:0.5690476298332214, Valid_Loss:1.193550944328308, Valid_ACC:0.6169998645782471
Epoch 845, CIFAR-10 Batch 3:  Train_Loss:0.5749796628952026, Valid_Loss:1.2003881931304932, Valid_ACC:0.6179998517036438
Epoch 845, CIFAR-10 Batch 4:  Train_Loss:0.5857349634170532, Valid_Loss:1.196401596069336, Valid_ACC:0.6119999289512634
Epoch 845, CIFAR-10 Batch 5:  Train_Loss:0.6019918322563171, Valid_Loss:1.2043923139572144, Valid_ACC:0.6167998909950256
Epoch 846, CIFAR-10 Batch 1:  Train_Loss:0.608974039554596, Valid_Loss:1.2113605737686157, Valid_ACC:0.6177998781204224
Epoch 846, CIFAR-10 Batch 2:  Train_Loss:0.5869506597518921, Valid_Loss:1.2019431591033936, Valid_ACC:0.610599935054779
Epoch 846, CIFAR-10 Batch 3:  Train_Loss:0.5982885360717773, Valid_Loss:1.2137477397918701, Valid_ACC:0.6135998964309692
Epoch 846, CIFAR-10 Batch 4:  Train_Loss:0.589123547077179, Valid_Loss:1.208701491355896, Valid_ACC:0.6147998571395874
Epoch 846, CIFAR-10 Batch 5:  Train_Loss:0.5911216139793396, Valid_Loss:1.193293571472168, Valid_ACC:0.6179999113082886
Epoch 847, CIFAR-10 Batch 1:  Train_Loss:0.6102861166000366, Valid_Loss:1.202418565750122, Valid_ACC:0.6157999634742737
Epoch 847, CIFAR-10 Batch 2:  Train_Loss:0.5843557715415955, Valid_Loss:1.2007508277893066, Valid_ACC:0.6169999241828918
Epoch 847, CIFAR-10 Batch 3:  Train_Loss:0.589363694190979, Valid_Loss:1.209539771080017, Valid_ACC:0.6143998503684998
Epoch 847, CIFAR-10 Batch 4:  Train_Loss:0.59486985206604, Valid_Loss:1.2085340023040771, Valid_ACC:0.612799882888794
Epoch 847, CIFAR-10 Batch 5:  Train_Loss:0.6076181530952454, Valid_Loss:1.2103983163833618, Valid_ACC:0.6109999418258667
Epoch 848, CIFAR-10 Batch 1:  Train_Loss:0.5992321372032166, Valid_Loss:1.198788046836853, Valid_ACC:0.6191998720169067
Epoch 848, CIFAR-10 Batch 2:  Train_Loss:0.5787777900695801, Valid_Loss:1.1966025829315186, Valid_ACC:0.6199998259544373
Epoch 848, CIFAR-10 Batch 3:  Train_Loss:0.5798827409744263, Valid_Loss:1.2082818746566772, Valid_ACC:0.6189998984336853
Epoch 848, CIFAR-10 Batch 4:  Train_Loss:0.5821110010147095, Valid_Loss:1.1964783668518066, Valid_ACC:0.6135998964309692
Epoch 848, CIFAR-10 Batch 5:  Train_Loss:0.6182896494865417, Valid_Loss:1.2237259149551392, Valid_ACC:0.6075999140739441
Epoch 849, CIFAR-10 Batch 1:  Train_Loss:0.6028300523757935, Valid_Loss:1.1972044706344604, Valid_ACC:0.6155999302864075
Epoch 849, CIFAR-10 Batch 2:  Train_Loss:0.5988262295722961, Valid_Loss:1.2118840217590332, Valid_ACC:0.6131998896598816
Epoch 849, CIFAR-10 Batch 3:  Train_Loss:0.57633376121521, Valid_Loss:1.2084895372390747, Valid_ACC:0.6175999045372009
Epoch 849, CIFAR-10 Batch 4:  Train_Loss:0.5836285352706909, Valid_Loss:1.2002792358398438, Valid_ACC:0.6125999093055725
Epoch 849, CIFAR-10 Batch 5:  Train_Loss:0.5927249789237976, Valid_Loss:1.1951963901519775, Valid_ACC:0.6197999119758606
Epoch 850, CIFAR-10 Batch 1:  Train_Loss:0.5926612019538879, Valid_Loss:1.1940733194351196, Valid_ACC:0.6185998916625977
Epoch 850, CIFAR-10 Batch 2:  Train_Loss:0.5867810845375061, Valid_Loss:1.2071077823638916, Valid_ACC:0.614599883556366
Epoch 850, CIFAR-10 Batch 3:  Train_Loss:0.606307864189148, Valid_Loss:1.2245771884918213, Valid_ACC:0.6117998361587524
Epoch 850, CIFAR-10 Batch 4:  Train_Loss:0.5853914022445679, Valid_Loss:1.2051583528518677, Valid_ACC:0.6133999228477478
Epoch 850, CIFAR-10 Batch 5:  Train_Loss:0.5919137597084045, Valid_Loss:1.1949142217636108, Valid_ACC:0.6187999248504639
Epoch 851, CIFAR-10 Batch 1:  Train_Loss:0.6049849987030029, Valid_Loss:1.2214853763580322, Valid_ACC:0.6131998896598816
Epoch 851, CIFAR-10 Batch 2:  Train_Loss:0.5838689208030701, Valid_Loss:1.207529067993164, Valid_ACC:0.6121999025344849
Epoch 851, CIFAR-10 Batch 3:  Train_Loss:0.5820126533508301, Valid_Loss:1.2019188404083252, Valid_ACC:0.6179999113082886
Epoch 851, CIFAR-10 Batch 4:  Train_Loss:0.587618350982666, Valid_Loss:1.196073293685913, Valid_ACC:0.6111999750137329
Epoch 851, CIFAR-10 Batch 5:  Train_Loss:0.5925054550170898, Valid_Loss:1.2026011943817139, Valid_ACC:0.6155999302864075
Epoch 852, CIFAR-10 Batch 1:  Train_Loss:0.5845980644226074, Valid_Loss:1.1973992586135864, Valid_ACC:0.6237999200820923
Epoch 852, CIFAR-10 Batch 2:  Train_Loss:0.5852322578430176, Valid_Loss:1.2083024978637695, Valid_ACC:0.6123999357223511
Epoch 852, CIFAR-10 Batch 3:  Train_Loss:0.5846524238586426, Valid_Loss:1.205178141593933, Valid_ACC:0.6109998822212219
Epoch 852, CIFAR-10 Batch 4:  Train_Loss:0.5816258788108826, Valid_Loss:1.203305959701538, Valid_ACC:0.6187998652458191
Epoch 852, CIFAR-10 Batch 5:  Train_Loss:0.6023064851760864, Valid_Loss:1.1969364881515503, Valid_ACC:0.6185998916625977
Epoch 853, CIFAR-10 Batch 1:  Train_Loss:0.5928676724433899, Valid_Loss:1.2069132328033447, Valid_ACC:0.6157999038696289
Epoch 853, CIFAR-10 Batch 2:  Train_Loss:0.577491819858551, Valid_Loss:1.2052885293960571, Valid_ACC:0.6137998700141907
Epoch 853, CIFAR-10 Batch 3:  Train_Loss:0.5801517963409424, Valid_Loss:1.211385726928711, Valid_ACC:0.6175999045372009
Epoch 853, CIFAR-10 Batch 4:  Train_Loss:0.5859748125076294, Valid_Loss:1.2024472951889038, Valid_ACC:0.6155998706817627
Epoch 853, CIFAR-10 Batch 5:  Train_Loss:0.5967400074005127, Valid_Loss:1.218633770942688, Valid_ACC:0.6123999953269958
Epoch 854, CIFAR-10 Batch 1:  Train_Loss:0.5909563899040222, Valid_Loss:1.203195333480835, Valid_ACC:0.6147998571395874
Epoch 854, CIFAR-10 Batch 2:  Train_Loss:0.5743436813354492, Valid_Loss:1.1973812580108643, Valid_ACC:0.6147999167442322
Epoch 854, CIFAR-10 Batch 3:  Train_Loss:0.595201313495636, Valid_Loss:1.219033122062683, Valid_ACC:0.6161999106407166
Epoch 854, CIFAR-10 Batch 4:  Train_Loss:0.6068360805511475, Valid_Loss:1.208594560623169, Valid_ACC:0.6093999147415161
Epoch 854, CIFAR-10 Batch 5:  Train_Loss:0.5856062769889832, Valid_Loss:1.2031373977661133, Valid_ACC:0.619399905204773
Epoch 855, CIFAR-10 Batch 1:  Train_Loss:0.6058075428009033, Valid_Loss:1.2024863958358765, Valid_ACC:0.6165999174118042
Epoch 855, CIFAR-10 Batch 2:  Train_Loss:0.5722429752349854, Valid_Loss:1.2041468620300293, Valid_ACC:0.6117998361587524
Epoch 855, CIFAR-10 Batch 3:  Train_Loss:0.5929498076438904, Valid_Loss:1.2157585620880127, Valid_ACC:0.6153998970985413
Epoch 855, CIFAR-10 Batch 4:  Train_Loss:0.5873536467552185, Valid_Loss:1.2097094058990479, Valid_ACC:0.6107999086380005
Epoch 855, CIFAR-10 Batch 5:  Train_Loss:0.5901294946670532, Valid_Loss:1.2131081819534302, Valid_ACC:0.6091998815536499
Epoch 856, CIFAR-10 Batch 1:  Train_Loss:0.5807645916938782, Valid_Loss:1.1932293176651, Valid_ACC:0.6183998584747314
Epoch 856, CIFAR-10 Batch 2:  Train_Loss:0.5712136626243591, Valid_Loss:1.201408863067627, Valid_ACC:0.614599883556366
Epoch 856, CIFAR-10 Batch 3:  Train_Loss:0.5823877453804016, Valid_Loss:1.2082778215408325, Valid_ACC:0.6155999898910522
Epoch 856, CIFAR-10 Batch 4:  Train_Loss:0.5822604298591614, Valid_Loss:1.2013484239578247, Valid_ACC:0.614599883556366
Epoch 856, CIFAR-10 Batch 5:  Train_Loss:0.5963276624679565, Valid_Loss:1.2178561687469482, Valid_ACC:0.6101999282836914
Epoch 857, CIFAR-10 Batch 1:  Train_Loss:0.5924521684646606, Valid_Loss:1.2102117538452148, Valid_ACC:0.6107999086380005
Epoch 857, CIFAR-10 Batch 2:  Train_Loss:0.5832338929176331, Valid_Loss:1.210504174232483, Valid_ACC:0.6155998706817627
Epoch 857, CIFAR-10 Batch 3:  Train_Loss:0.5739578604698181, Valid_Loss:1.2121474742889404, Valid_ACC:0.610599935054779
Epoch 857, CIFAR-10 Batch 4:  Train_Loss:0.5862728953361511, Valid_Loss:1.211814522743225, Valid_ACC:0.613599956035614
Epoch 857, CIFAR-10 Batch 5:  Train_Loss:0.6111299991607666, Valid_Loss:1.2154979705810547, Valid_ACC:0.6067999601364136
Epoch 858, CIFAR-10 Batch 1:  Train_Loss:0.5886639952659607, Valid_Loss:1.1937445402145386, Valid_ACC:0.6227998733520508
Epoch 858, CIFAR-10 Batch 2:  Train_Loss:0.5690556168556213, Valid_Loss:1.2053542137145996, Valid_ACC:0.6147999167442322
Epoch 858, CIFAR-10 Batch 3:  Train_Loss:0.6072617769241333, Valid_Loss:1.2260750532150269, Valid_ACC:0.6133999228477478
Epoch 858, CIFAR-10 Batch 4:  Train_Loss:0.5826526880264282, Valid_Loss:1.204995036125183, Valid_ACC:0.6131998896598816
Epoch 858, CIFAR-10 Batch 5:  Train_Loss:0.5928593277931213, Valid_Loss:1.2063907384872437, Valid_ACC:0.6117998361587524
Epoch 859, CIFAR-10 Batch 1:  Train_Loss:0.6044433116912842, Valid_Loss:1.2099329233169556, Valid_ACC:0.616399884223938
Epoch 859, CIFAR-10 Batch 2:  Train_Loss:0.5729626417160034, Valid_Loss:1.1967668533325195, Valid_ACC:0.6187999248504639
Epoch 859, CIFAR-10 Batch 3:  Train_Loss:0.6216305494308472, Valid_Loss:1.243489146232605, Valid_ACC:0.613399863243103
Epoch 859, CIFAR-10 Batch 4:  Train_Loss:0.5858842730522156, Valid_Loss:1.2131237983703613, Valid_ACC:0.615399956703186
Epoch 859, CIFAR-10 Batch 5:  Train_Loss:0.6090044975280762, Valid_Loss:1.2130749225616455, Valid_ACC:0.6129998564720154
Epoch 860, CIFAR-10 Batch 1:  Train_Loss:0.5852302312850952, Valid_Loss:1.1926095485687256, Valid_ACC:0.619399905204773
Epoch 860, CIFAR-10 Batch 2:  Train_Loss:0.5793333649635315, Valid_Loss:1.206129789352417, Valid_ACC:0.6139999032020569
Epoch 860, CIFAR-10 Batch 3:  Train_Loss:0.5957236289978027, Valid_Loss:1.2227338552474976, Valid_ACC:0.6149998903274536
Epoch 860, CIFAR-10 Batch 4:  Train_Loss:0.6067770719528198, Valid_Loss:1.2260419130325317, Valid_ACC:0.6081998348236084
Epoch 860, CIFAR-10 Batch 5:  Train_Loss:0.5966330170631409, Valid_Loss:1.1967281103134155, Valid_ACC:0.6157998442649841
Epoch 861, CIFAR-10 Batch 1:  Train_Loss:0.5874911546707153, Valid_Loss:1.203453540802002, Valid_ACC:0.619399905204773
Epoch 861, CIFAR-10 Batch 2:  Train_Loss:0.5732183456420898, Valid_Loss:1.1915316581726074, Valid_ACC:0.6161999106407166
Epoch 861, CIFAR-10 Batch 3:  Train_Loss:0.5774794816970825, Valid_Loss:1.207754373550415, Valid_ACC:0.6187999248504639
Epoch 861, CIFAR-10 Batch 4:  Train_Loss:0.5849170088768005, Valid_Loss:1.2039799690246582, Valid_ACC:0.6151999235153198
Epoch 861, CIFAR-10 Batch 5:  Train_Loss:0.5893875956535339, Valid_Loss:1.2058132886886597, Valid_ACC:0.6169998645782471
Epoch 862, CIFAR-10 Batch 1:  Train_Loss:0.6083267331123352, Valid_Loss:1.2168595790863037, Valid_ACC:0.6113998889923096
Epoch 862, CIFAR-10 Batch 2:  Train_Loss:0.5747264623641968, Valid_Loss:1.1957329511642456, Valid_ACC:0.6169999241828918
Epoch 862, CIFAR-10 Batch 3:  Train_Loss:0.5769774317741394, Valid_Loss:1.2116355895996094, Valid_ACC:0.6113998889923096
Epoch 862, CIFAR-10 Batch 4:  Train_Loss:0.5871604681015015, Valid_Loss:1.1948108673095703, Valid_ACC:0.6171998977661133
Epoch 862, CIFAR-10 Batch 5:  Train_Loss:0.5862211585044861, Valid_Loss:1.194320559501648, Valid_ACC:0.618399977684021
Epoch 863, CIFAR-10 Batch 1:  Train_Loss:0.5793123245239258, Valid_Loss:1.2027020454406738, Valid_ACC:0.619399905204773
Epoch 863, CIFAR-10 Batch 2:  Train_Loss:0.5808740258216858, Valid_Loss:1.201521635055542, Valid_ACC:0.6149999499320984
Epoch 863, CIFAR-10 Batch 3:  Train_Loss:0.5843895673751831, Valid_Loss:1.2184314727783203, Valid_ACC:0.619399905204773
Epoch 863, CIFAR-10 Batch 4:  Train_Loss:0.5840685367584229, Valid_Loss:1.2064504623413086, Valid_ACC:0.6119999289512634
Epoch 863, CIFAR-10 Batch 5:  Train_Loss:0.5930590629577637, Valid_Loss:1.20845365524292, Valid_ACC:0.6121999025344849
Epoch 864, CIFAR-10 Batch 1:  Train_Loss:0.5893320441246033, Valid_Loss:1.201102614402771, Valid_ACC:0.6137998700141907
Epoch 864, CIFAR-10 Batch 2:  Train_Loss:0.5821908712387085, Valid_Loss:1.1988502740859985, Valid_ACC:0.6179999113082886
Epoch 864, CIFAR-10 Batch 3:  Train_Loss:0.5952184796333313, Valid_Loss:1.2182531356811523, Valid_ACC:0.6167998909950256
Epoch 864, CIFAR-10 Batch 4:  Train_Loss:0.5812129974365234, Valid_Loss:1.2080466747283936, Valid_ACC:0.6109999418258667
Epoch 864, CIFAR-10 Batch 5:  Train_Loss:0.5960597991943359, Valid_Loss:1.2166484594345093, Valid_ACC:0.6113998889923096
Epoch 865, CIFAR-10 Batch 1:  Train_Loss:0.6008282899856567, Valid_Loss:1.2071921825408936, Valid_ACC:0.6157999038696289
Epoch 865, CIFAR-10 Batch 2:  Train_Loss:0.579149067401886, Valid_Loss:1.200221061706543, Valid_ACC:0.6167998909950256
Epoch 865, CIFAR-10 Batch 3:  Train_Loss:0.5864771604537964, Valid_Loss:1.2145395278930664, Valid_ACC:0.6185998916625977
Epoch 865, CIFAR-10 Batch 4:  Train_Loss:0.581613302230835, Valid_Loss:1.1957764625549316, Valid_ACC:0.6203998923301697
Epoch 865, CIFAR-10 Batch 5:  Train_Loss:0.600365936756134, Valid_Loss:1.1975622177124023, Valid_ACC:0.6151999235153198
Epoch 866, CIFAR-10 Batch 1:  Train_Loss:0.6005455851554871, Valid_Loss:1.1922725439071655, Valid_ACC:0.6235998868942261
Epoch 866, CIFAR-10 Batch 2:  Train_Loss:0.5683724284172058, Valid_Loss:1.1884034872055054, Valid_ACC:0.619399905204773
Epoch 866, CIFAR-10 Batch 3:  Train_Loss:0.5716963410377502, Valid_Loss:1.1983002424240112, Valid_ACC:0.621199905872345
Epoch 866, CIFAR-10 Batch 4:  Train_Loss:0.5852071046829224, Valid_Loss:1.2023528814315796, Valid_ACC:0.6171999573707581
Epoch 866, CIFAR-10 Batch 5:  Train_Loss:0.6016685366630554, Valid_Loss:1.2157200574874878, Valid_ACC:0.6111999154090881
Epoch 867, CIFAR-10 Batch 1:  Train_Loss:0.5918147563934326, Valid_Loss:1.1963399648666382, Valid_ACC:0.6221998929977417
Epoch 867, CIFAR-10 Batch 2:  Train_Loss:0.5934658050537109, Valid_Loss:1.2011034488677979, Valid_ACC:0.6149998903274536
Epoch 867, CIFAR-10 Batch 3:  Train_Loss:0.5663227438926697, Valid_Loss:1.200369119644165, Valid_ACC:0.6189998984336853
Epoch 867, CIFAR-10 Batch 4:  Train_Loss:0.594332754611969, Valid_Loss:1.2041831016540527, Valid_ACC:0.6161999106407166
Epoch 867, CIFAR-10 Batch 5:  Train_Loss:0.6065416932106018, Valid_Loss:1.2115188837051392, Valid_ACC:0.6125999093055725
Epoch 868, CIFAR-10 Batch 1:  Train_Loss:0.5980377197265625, Valid_Loss:1.193580985069275, Valid_ACC:0.6175999641418457
Epoch 868, CIFAR-10 Batch 2:  Train_Loss:0.5812548995018005, Valid_Loss:1.1957643032073975, Valid_ACC:0.6171998381614685
Epoch 868, CIFAR-10 Batch 3:  Train_Loss:0.5862054824829102, Valid_Loss:1.2030001878738403, Valid_ACC:0.6185998916625977
Epoch 868, CIFAR-10 Batch 4:  Train_Loss:0.5904527306556702, Valid_Loss:1.1912721395492554, Valid_ACC:0.619399905204773
Epoch 868, CIFAR-10 Batch 5:  Train_Loss:0.5978765487670898, Valid_Loss:1.2046598196029663, Valid_ACC:0.6185998916625977
Epoch 869, CIFAR-10 Batch 1:  Train_Loss:0.6023772954940796, Valid_Loss:1.1995729207992554, Valid_ACC:0.621799886226654
Epoch 869, CIFAR-10 Batch 2:  Train_Loss:0.6026349067687988, Valid_Loss:1.2140326499938965, Valid_ACC:0.6079999208450317
Epoch 869, CIFAR-10 Batch 3:  Train_Loss:0.6168510317802429, Valid_Loss:1.2338017225265503, Valid_ACC:0.6103999018669128
Epoch 869, CIFAR-10 Batch 4:  Train_Loss:0.6186587810516357, Valid_Loss:1.227503776550293, Valid_ACC:0.6055998802185059
Epoch 869, CIFAR-10 Batch 5:  Train_Loss:0.6047269105911255, Valid_Loss:1.2175662517547607, Valid_ACC:0.6137999296188354
Epoch 870, CIFAR-10 Batch 1:  Train_Loss:0.597788393497467, Valid_Loss:1.2075302600860596, Valid_ACC:0.6145999431610107
Epoch 870, CIFAR-10 Batch 2:  Train_Loss:0.5938255190849304, Valid_Loss:1.2060935497283936, Valid_ACC:0.6153998970985413
Epoch 870, CIFAR-10 Batch 3:  Train_Loss:0.6017269492149353, Valid_Loss:1.2200318574905396, Valid_ACC:0.6185999512672424
Epoch 870, CIFAR-10 Batch 4:  Train_Loss:0.630163311958313, Valid_Loss:1.2340154647827148, Valid_ACC:0.6035999059677124
Epoch 870, CIFAR-10 Batch 5:  Train_Loss:0.62403804063797, Valid_Loss:1.2301592826843262, Valid_ACC:0.608199954032898
Epoch 871, CIFAR-10 Batch 1:  Train_Loss:0.6075074672698975, Valid_Loss:1.1982002258300781, Valid_ACC:0.6209999322891235
Epoch 871, CIFAR-10 Batch 2:  Train_Loss:0.5871965885162354, Valid_Loss:1.2049388885498047, Valid_ACC:0.6121999025344849
Epoch 871, CIFAR-10 Batch 3:  Train_Loss:0.6037064790725708, Valid_Loss:1.234878659248352, Valid_ACC:0.6101999282836914
Epoch 871, CIFAR-10 Batch 4:  Train_Loss:0.6585697531700134, Valid_Loss:1.2473373413085938, Valid_ACC:0.6005999445915222
Epoch 871, CIFAR-10 Batch 5:  Train_Loss:0.6195285320281982, Valid_Loss:1.240424394607544, Valid_ACC:0.6065999269485474
Epoch 872, CIFAR-10 Batch 1:  Train_Loss:0.59898841381073, Valid_Loss:1.1968438625335693, Valid_ACC:0.6203998923301697
Epoch 872, CIFAR-10 Batch 2:  Train_Loss:0.5870957374572754, Valid_Loss:1.1946779489517212, Valid_ACC:0.6197999119758606
Epoch 872, CIFAR-10 Batch 3:  Train_Loss:0.5828304886817932, Valid_Loss:1.2054316997528076, Valid_ACC:0.6151999235153198
Epoch 872, CIFAR-10 Batch 4:  Train_Loss:0.6009443998336792, Valid_Loss:1.2176581621170044, Valid_ACC:0.6121999025344849
Epoch 872, CIFAR-10 Batch 5:  Train_Loss:0.605012059211731, Valid_Loss:1.2167935371398926, Valid_ACC:0.6113998889923096
Epoch 873, CIFAR-10 Batch 1:  Train_Loss:0.5922930836677551, Valid_Loss:1.1947112083435059, Valid_ACC:0.6175999045372009
Epoch 873, CIFAR-10 Batch 2:  Train_Loss:0.5849843621253967, Valid_Loss:1.2047549486160278, Valid_ACC:0.6171998977661133
Epoch 873, CIFAR-10 Batch 3:  Train_Loss:0.6368459463119507, Valid_Loss:1.2618447542190552, Valid_ACC:0.6007999181747437
Epoch 873, CIFAR-10 Batch 4:  Train_Loss:0.6468216180801392, Valid_Loss:1.2417004108428955, Valid_ACC:0.6005998849868774
Epoch 873, CIFAR-10 Batch 5:  Train_Loss:0.6020621657371521, Valid_Loss:1.2203930616378784, Valid_ACC:0.6101998686790466
Epoch 874, CIFAR-10 Batch 1:  Train_Loss:0.5994638204574585, Valid_Loss:1.201302409172058, Valid_ACC:0.6191998720169067
Epoch 874, CIFAR-10 Batch 2:  Train_Loss:0.5712221264839172, Valid_Loss:1.196653962135315, Valid_ACC:0.616399884223938
Epoch 874, CIFAR-10 Batch 3:  Train_Loss:0.5959072709083557, Valid_Loss:1.2232625484466553, Valid_ACC:0.6129999160766602
Epoch 874, CIFAR-10 Batch 4:  Train_Loss:0.6364750862121582, Valid_Loss:1.2417550086975098, Valid_ACC:0.602199912071228
Epoch 874, CIFAR-10 Batch 5:  Train_Loss:0.6009771227836609, Valid_Loss:1.2111895084381104, Valid_ACC:0.6125999093055725
Epoch 875, CIFAR-10 Batch 1:  Train_Loss:0.5961174368858337, Valid_Loss:1.1967226266860962, Valid_ACC:0.6207998991012573
Epoch 875, CIFAR-10 Batch 2:  Train_Loss:0.588494062423706, Valid_Loss:1.205162763595581, Valid_ACC:0.6159998774528503
Epoch 875, CIFAR-10 Batch 3:  Train_Loss:0.5844168066978455, Valid_Loss:1.2201228141784668, Valid_ACC:0.613399863243103
Epoch 875, CIFAR-10 Batch 4:  Train_Loss:0.6338424682617188, Valid_Loss:1.2374333143234253, Valid_ACC:0.6047999262809753
Epoch 875, CIFAR-10 Batch 5:  Train_Loss:0.6419014930725098, Valid_Loss:1.2575196027755737, Valid_ACC:0.6009998917579651
Epoch 876, CIFAR-10 Batch 1:  Train_Loss:0.6212843656539917, Valid_Loss:1.2092490196228027, Valid_ACC:0.6147999167442322
Epoch 876, CIFAR-10 Batch 2:  Train_Loss:0.5965911149978638, Valid_Loss:1.203847050666809, Valid_ACC:0.6173999309539795
Epoch 876, CIFAR-10 Batch 3:  Train_Loss:0.6295275092124939, Valid_Loss:1.2422618865966797, Valid_ACC:0.6035999059677124
Epoch 876, CIFAR-10 Batch 4:  Train_Loss:0.6158537864685059, Valid_Loss:1.2204307317733765, Valid_ACC:0.6101998686790466
Epoch 876, CIFAR-10 Batch 5:  Train_Loss:0.6230138540267944, Valid_Loss:1.2412047386169434, Valid_ACC:0.601599931716919
Epoch 877, CIFAR-10 Batch 1:  Train_Loss:0.6001424789428711, Valid_Loss:1.1943211555480957, Valid_ACC:0.619399905204773
Epoch 877, CIFAR-10 Batch 2:  Train_Loss:0.5968071222305298, Valid_Loss:1.2080926895141602, Valid_ACC:0.6113999485969543
Epoch 877, CIFAR-10 Batch 3:  Train_Loss:0.5947332978248596, Valid_Loss:1.210831642150879, Valid_ACC:0.6109998822212219
Epoch 877, CIFAR-10 Batch 4:  Train_Loss:0.625647783279419, Valid_Loss:1.229973316192627, Valid_ACC:0.6055998802185059
Epoch 877, CIFAR-10 Batch 5:  Train_Loss:0.6283199787139893, Valid_Loss:1.2424461841583252, Valid_ACC:0.6081998944282532
Epoch 878, CIFAR-10 Batch 1:  Train_Loss:0.6359332799911499, Valid_Loss:1.223468542098999, Valid_ACC:0.6141999959945679
Epoch 878, CIFAR-10 Batch 2:  Train_Loss:0.6116805076599121, Valid_Loss:1.2132773399353027, Valid_ACC:0.6131999492645264
Epoch 878, CIFAR-10 Batch 3:  Train_Loss:0.6491920351982117, Valid_Loss:1.2676217555999756, Valid_ACC:0.6001999378204346
Epoch 878, CIFAR-10 Batch 4:  Train_Loss:0.596075177192688, Valid_Loss:1.2078685760498047, Valid_ACC:0.6125998497009277
Epoch 878, CIFAR-10 Batch 5:  Train_Loss:0.6083834767341614, Valid_Loss:1.2228567600250244, Valid_ACC:0.6109998822212219
Epoch 879, CIFAR-10 Batch 1:  Train_Loss:0.618589460849762, Valid_Loss:1.2021350860595703, Valid_ACC:0.6177998781204224
Epoch 879, CIFAR-10 Batch 2:  Train_Loss:0.5886922478675842, Valid_Loss:1.2016258239746094, Valid_ACC:0.6185998916625977
Epoch 879, CIFAR-10 Batch 3:  Train_Loss:0.6099359393119812, Valid_Loss:1.2322862148284912, Valid_ACC:0.6093999147415161
Epoch 879, CIFAR-10 Batch 4:  Train_Loss:0.5950677394866943, Valid_Loss:1.2016310691833496, Valid_ACC:0.6141998767852783
Epoch 879, CIFAR-10 Batch 5:  Train_Loss:0.6003397703170776, Valid_Loss:1.2350170612335205, Valid_ACC:0.6079999208450317
Epoch 880, CIFAR-10 Batch 1:  Train_Loss:0.6021902561187744, Valid_Loss:1.2095530033111572, Valid_ACC:0.6175999045372009
Epoch 880, CIFAR-10 Batch 2:  Train_Loss:0.5900173783302307, Valid_Loss:1.2027394771575928, Valid_ACC:0.6115999221801758
Epoch 880, CIFAR-10 Batch 3:  Train_Loss:0.5861896872520447, Valid_Loss:1.2122604846954346, Valid_ACC:0.6103998422622681
Epoch 880, CIFAR-10 Batch 4:  Train_Loss:0.5965677499771118, Valid_Loss:1.2114871740341187, Valid_ACC:0.6149999499320984
Epoch 880, CIFAR-10 Batch 5:  Train_Loss:0.6397426724433899, Valid_Loss:1.262780785560608, Valid_ACC:0.6025999188423157
Epoch 881, CIFAR-10 Batch 1:  Train_Loss:0.6575058102607727, Valid_Loss:1.2408949136734009, Valid_ACC:0.6105998754501343
Epoch 881, CIFAR-10 Batch 2:  Train_Loss:0.6188071966171265, Valid_Loss:1.2201168537139893, Valid_ACC:0.6125999093055725
Epoch 881, CIFAR-10 Batch 3:  Train_Loss:0.6276887059211731, Valid_Loss:1.2343252897262573, Valid_ACC:0.6093999147415161
Epoch 881, CIFAR-10 Batch 4:  Train_Loss:0.6115807294845581, Valid_Loss:1.2123569250106812, Valid_ACC:0.6187998652458191
Epoch 881, CIFAR-10 Batch 5:  Train_Loss:0.6454491019248962, Valid_Loss:1.2587192058563232, Valid_ACC:0.602199912071228
Epoch 882, CIFAR-10 Batch 1:  Train_Loss:0.6508277654647827, Valid_Loss:1.2409906387329102, Valid_ACC:0.6045998930931091
Epoch 882, CIFAR-10 Batch 2:  Train_Loss:0.6066405177116394, Valid_Loss:1.2093698978424072, Valid_ACC:0.619999885559082
Epoch 882, CIFAR-10 Batch 3:  Train_Loss:0.6263626217842102, Valid_Loss:1.2413959503173828, Valid_ACC:0.6089999079704285
Epoch 882, CIFAR-10 Batch 4:  Train_Loss:0.6245865821838379, Valid_Loss:1.2263545989990234, Valid_ACC:0.613399863243103
Epoch 882, CIFAR-10 Batch 5:  Train_Loss:0.6645190119743347, Valid_Loss:1.2632465362548828, Valid_ACC:0.5993999242782593
Epoch 883, CIFAR-10 Batch 1:  Train_Loss:0.6560943722724915, Valid_Loss:1.2403515577316284, Valid_ACC:0.6073999404907227
Epoch 883, CIFAR-10 Batch 2:  Train_Loss:0.6177214980125427, Valid_Loss:1.2163710594177246, Valid_ACC:0.612799882888794
Epoch 883, CIFAR-10 Batch 3:  Train_Loss:0.6105812788009644, Valid_Loss:1.2232743501663208, Valid_ACC:0.6123998761177063
Epoch 883, CIFAR-10 Batch 4:  Train_Loss:0.6035274267196655, Valid_Loss:1.2138971090316772, Valid_ACC:0.6155999302864075
Epoch 883, CIFAR-10 Batch 5:  Train_Loss:0.6335339546203613, Valid_Loss:1.2391552925109863, Valid_ACC:0.6065999269485474
Epoch 884, CIFAR-10 Batch 1:  Train_Loss:0.6380958557128906, Valid_Loss:1.2282524108886719, Valid_ACC:0.6139999628067017
Epoch 884, CIFAR-10 Batch 2:  Train_Loss:0.5893641710281372, Valid_Loss:1.2050938606262207, Valid_ACC:0.6169999241828918
Epoch 884, CIFAR-10 Batch 3:  Train_Loss:0.6235727071762085, Valid_Loss:1.2400314807891846, Valid_ACC:0.6065999865531921
Epoch 884, CIFAR-10 Batch 4:  Train_Loss:0.6271675825119019, Valid_Loss:1.2250096797943115, Valid_ACC:0.6059998869895935
Epoch 884, CIFAR-10 Batch 5:  Train_Loss:0.6263735890388489, Valid_Loss:1.2428148984909058, Valid_ACC:0.605199933052063
Epoch 885, CIFAR-10 Batch 1:  Train_Loss:0.6290496587753296, Valid_Loss:1.2276153564453125, Valid_ACC:0.6081998944282532
Epoch 885, CIFAR-10 Batch 2:  Train_Loss:0.6027189493179321, Valid_Loss:1.2146271467208862, Valid_ACC:0.615199863910675
Epoch 885, CIFAR-10 Batch 3:  Train_Loss:0.6107168197631836, Valid_Loss:1.2308675050735474, Valid_ACC:0.6075999736785889
Epoch 885, CIFAR-10 Batch 4:  Train_Loss:0.6336699724197388, Valid_Loss:1.23320734500885, Valid_ACC:0.605199933052063
Epoch 885, CIFAR-10 Batch 5:  Train_Loss:0.6411409378051758, Valid_Loss:1.2297240495681763, Valid_ACC:0.6099998354911804
Epoch 886, CIFAR-10 Batch 1:  Train_Loss:0.6087244153022766, Valid_Loss:1.2117736339569092, Valid_ACC:0.6157999038696289
Epoch 886, CIFAR-10 Batch 2:  Train_Loss:0.5998964309692383, Valid_Loss:1.20609712600708, Valid_ACC:0.6167999505996704
Epoch 886, CIFAR-10 Batch 3:  Train_Loss:0.616856038570404, Valid_Loss:1.2317906618118286, Valid_ACC:0.6047999262809753
Epoch 886, CIFAR-10 Batch 4:  Train_Loss:0.6342945098876953, Valid_Loss:1.2236127853393555, Valid_ACC:0.6075999140739441
Epoch 886, CIFAR-10 Batch 5:  Train_Loss:0.6414300799369812, Valid_Loss:1.235131025314331, Valid_ACC:0.6083999276161194
Epoch 887, CIFAR-10 Batch 1:  Train_Loss:0.6183125972747803, Valid_Loss:1.2115405797958374, Valid_ACC:0.6149998903274536
Epoch 887, CIFAR-10 Batch 2:  Train_Loss:0.6165355443954468, Valid_Loss:1.221582293510437, Valid_ACC:0.6127999424934387
Epoch 887, CIFAR-10 Batch 3:  Train_Loss:0.6173761487007141, Valid_Loss:1.2252368927001953, Valid_ACC:0.6121999025344849
Epoch 887, CIFAR-10 Batch 4:  Train_Loss:0.6187736988067627, Valid_Loss:1.2233049869537354, Valid_ACC:0.6059998869895935
Epoch 887, CIFAR-10 Batch 5:  Train_Loss:0.6094587445259094, Valid_Loss:1.2096993923187256, Valid_ACC:0.6149999499320984
Epoch 888, CIFAR-10 Batch 1:  Train_Loss:0.6200586557388306, Valid_Loss:1.2038081884384155, Valid_ACC:0.6177998781204224
Epoch 888, CIFAR-10 Batch 2:  Train_Loss:0.6094903349876404, Valid_Loss:1.2191230058670044, Valid_ACC:0.6165999174118042
Epoch 888, CIFAR-10 Batch 3:  Train_Loss:0.6380524039268494, Valid_Loss:1.2449524402618408, Valid_ACC:0.6015998721122742
Epoch 888, CIFAR-10 Batch 4:  Train_Loss:0.6181621551513672, Valid_Loss:1.224086880683899, Valid_ACC:0.6121999621391296
Epoch 888, CIFAR-10 Batch 5:  Train_Loss:0.6393808126449585, Valid_Loss:1.2266123294830322, Valid_ACC:0.6157999038696289
Epoch 889, CIFAR-10 Batch 1:  Train_Loss:0.6206027865409851, Valid_Loss:1.2214399576187134, Valid_ACC:0.6153998374938965
Epoch 889, CIFAR-10 Batch 2:  Train_Loss:0.633543848991394, Valid_Loss:1.2272443771362305, Valid_ACC:0.6115999221801758
Epoch 889, CIFAR-10 Batch 3:  Train_Loss:0.6035162210464478, Valid_Loss:1.2194161415100098, Valid_ACC:0.6097999215126038
Epoch 889, CIFAR-10 Batch 4:  Train_Loss:0.6195547580718994, Valid_Loss:1.2166179418563843, Valid_ACC:0.6101999282836914
Epoch 889, CIFAR-10 Batch 5:  Train_Loss:0.6368376612663269, Valid_Loss:1.2451883554458618, Valid_ACC:0.6043999195098877
Epoch 890, CIFAR-10 Batch 1:  Train_Loss:0.6186622381210327, Valid_Loss:1.2140940427780151, Valid_ACC:0.611599862575531
Epoch 890, CIFAR-10 Batch 2:  Train_Loss:0.5974075794219971, Valid_Loss:1.2071964740753174, Valid_ACC:0.614599883556366
Epoch 890, CIFAR-10 Batch 3:  Train_Loss:0.608156144618988, Valid_Loss:1.2272876501083374, Valid_ACC:0.6115999221801758
Epoch 890, CIFAR-10 Batch 4:  Train_Loss:0.6038536429405212, Valid_Loss:1.2095837593078613, Valid_ACC:0.6145999431610107
Epoch 890, CIFAR-10 Batch 5:  Train_Loss:0.6044920086860657, Valid_Loss:1.2124755382537842, Valid_ACC:0.6085999011993408
Epoch 891, CIFAR-10 Batch 1:  Train_Loss:0.6139987111091614, Valid_Loss:1.2127989530563354, Valid_ACC:0.6149998903274536
Epoch 891, CIFAR-10 Batch 2:  Train_Loss:0.6136199235916138, Valid_Loss:1.207779049873352, Valid_ACC:0.6205998659133911
Epoch 891, CIFAR-10 Batch 3:  Train_Loss:0.6070911884307861, Valid_Loss:1.2216616868972778, Valid_ACC:0.611799955368042
Epoch 891, CIFAR-10 Batch 4:  Train_Loss:0.6133016347885132, Valid_Loss:1.21943998336792, Valid_ACC:0.6097999215126038
Epoch 891, CIFAR-10 Batch 5:  Train_Loss:0.6155806183815002, Valid_Loss:1.2202099561691284, Valid_ACC:0.6077998876571655
Epoch 892, CIFAR-10 Batch 1:  Train_Loss:0.6184359192848206, Valid_Loss:1.219688057899475, Valid_ACC:0.6117998957633972
Epoch 892, CIFAR-10 Batch 2:  Train_Loss:0.6132056713104248, Valid_Loss:1.2168904542922974, Valid_ACC:0.6179999113082886
Epoch 892, CIFAR-10 Batch 3:  Train_Loss:0.6018139123916626, Valid_Loss:1.2168922424316406, Valid_ACC:0.6093999147415161
Epoch 892, CIFAR-10 Batch 4:  Train_Loss:0.6127338409423828, Valid_Loss:1.219390869140625, Valid_ACC:0.6045999526977539
Epoch 892, CIFAR-10 Batch 5:  Train_Loss:0.6141980886459351, Valid_Loss:1.2173328399658203, Valid_ACC:0.613399863243103
Epoch 893, CIFAR-10 Batch 1:  Train_Loss:0.6066222190856934, Valid_Loss:1.2119593620300293, Valid_ACC:0.6139998435974121
Epoch 893, CIFAR-10 Batch 2:  Train_Loss:0.607805609703064, Valid_Loss:1.2068374156951904, Valid_ACC:0.6183998584747314
Epoch 893, CIFAR-10 Batch 3:  Train_Loss:0.5931804180145264, Valid_Loss:1.2143274545669556, Valid_ACC:0.6159999370574951
Epoch 893, CIFAR-10 Batch 4:  Train_Loss:0.6016057729721069, Valid_Loss:1.2101831436157227, Valid_ACC:0.6155999302864075
Epoch 893, CIFAR-10 Batch 5:  Train_Loss:0.6382821798324585, Valid_Loss:1.2373605966567993, Valid_ACC:0.6079999208450317
Epoch 894, CIFAR-10 Batch 1:  Train_Loss:0.6380511522293091, Valid_Loss:1.2180559635162354, Valid_ACC:0.6119998693466187
Epoch 894, CIFAR-10 Batch 2:  Train_Loss:0.6240534782409668, Valid_Loss:1.2205214500427246, Valid_ACC:0.6113998889923096
Epoch 894, CIFAR-10 Batch 3:  Train_Loss:0.6055136919021606, Valid_Loss:1.223241925239563, Valid_ACC:0.615199863910675
Epoch 894, CIFAR-10 Batch 4:  Train_Loss:0.6123760342597961, Valid_Loss:1.218542218208313, Valid_ACC:0.6079999208450317
Epoch 894, CIFAR-10 Batch 5:  Train_Loss:0.6182410717010498, Valid_Loss:1.2215311527252197, Valid_ACC:0.6091999411582947
Epoch 895, CIFAR-10 Batch 1:  Train_Loss:0.603386402130127, Valid_Loss:1.2126572132110596, Valid_ACC:0.6119998693466187
Epoch 895, CIFAR-10 Batch 2:  Train_Loss:0.5740170478820801, Valid_Loss:1.1921801567077637, Valid_ACC:0.6197998523712158
Epoch 895, CIFAR-10 Batch 3:  Train_Loss:0.5996267199516296, Valid_Loss:1.2216968536376953, Valid_ACC:0.6065999269485474
Epoch 895, CIFAR-10 Batch 4:  Train_Loss:0.5953360795974731, Valid_Loss:1.2143946886062622, Valid_ACC:0.6101998686790466
Epoch 895, CIFAR-10 Batch 5:  Train_Loss:0.5979859828948975, Valid_Loss:1.2218713760375977, Valid_ACC:0.6161998510360718
Epoch 896, CIFAR-10 Batch 1:  Train_Loss:0.6034188270568848, Valid_Loss:1.2092019319534302, Valid_ACC:0.6159999370574951
Epoch 896, CIFAR-10 Batch 2:  Train_Loss:0.6019471883773804, Valid_Loss:1.2059290409088135, Valid_ACC:0.616399884223938
Epoch 896, CIFAR-10 Batch 3:  Train_Loss:0.591586172580719, Valid_Loss:1.2216213941574097, Valid_ACC:0.6137999296188354
Epoch 896, CIFAR-10 Batch 4:  Train_Loss:0.6088172197341919, Valid_Loss:1.2176955938339233, Valid_ACC:0.6081998944282532
Epoch 896, CIFAR-10 Batch 5:  Train_Loss:0.6020684838294983, Valid_Loss:1.2149930000305176, Valid_ACC:0.6107999682426453
Epoch 897, CIFAR-10 Batch 1:  Train_Loss:0.588716447353363, Valid_Loss:1.1978321075439453, Valid_ACC:0.6231998801231384
Epoch 897, CIFAR-10 Batch 2:  Train_Loss:0.5712226629257202, Valid_Loss:1.1926988363265991, Valid_ACC:0.6129999756813049
Epoch 897, CIFAR-10 Batch 3:  Train_Loss:0.5682779550552368, Valid_Loss:1.2024706602096558, Valid_ACC:0.6157999038696289
Epoch 897, CIFAR-10 Batch 4:  Train_Loss:0.5906378626823425, Valid_Loss:1.2095471620559692, Valid_ACC:0.6153998970985413
Epoch 897, CIFAR-10 Batch 5:  Train_Loss:0.6020254492759705, Valid_Loss:1.226161003112793, Valid_ACC:0.610599935054779
Epoch 898, CIFAR-10 Batch 1:  Train_Loss:0.6029070019721985, Valid_Loss:1.201836347579956, Valid_ACC:0.6205998659133911
Epoch 898, CIFAR-10 Batch 2:  Train_Loss:0.6107099652290344, Valid_Loss:1.2093135118484497, Valid_ACC:0.6137999296188354
Epoch 898, CIFAR-10 Batch 3:  Train_Loss:0.5960184335708618, Valid_Loss:1.2223025560379028, Valid_ACC:0.6095998883247375
Epoch 898, CIFAR-10 Batch 4:  Train_Loss:0.5788448452949524, Valid_Loss:1.200742244720459, Valid_ACC:0.612799882888794
Epoch 898, CIFAR-10 Batch 5:  Train_Loss:0.5894699692726135, Valid_Loss:1.2045636177062988, Valid_ACC:0.6191998720169067
Epoch 899, CIFAR-10 Batch 1:  Train_Loss:0.6202750205993652, Valid_Loss:1.2157423496246338, Valid_ACC:0.6139999032020569
Epoch 899, CIFAR-10 Batch 2:  Train_Loss:0.5830168128013611, Valid_Loss:1.2041733264923096, Valid_ACC:0.6143999099731445
Epoch 899, CIFAR-10 Batch 3:  Train_Loss:0.5788578987121582, Valid_Loss:1.2147738933563232, Valid_ACC:0.612799882888794
Epoch 899, CIFAR-10 Batch 4:  Train_Loss:0.5954622626304626, Valid_Loss:1.2090420722961426, Valid_ACC:0.6099998950958252
Epoch 899, CIFAR-10 Batch 5:  Train_Loss:0.6047497987747192, Valid_Loss:1.2174217700958252, Valid_ACC:0.6149998903274536
Epoch 900, CIFAR-10 Batch 1:  Train_Loss:0.6015003323554993, Valid_Loss:1.208628535270691, Valid_ACC:0.6177998781204224
Epoch 900, CIFAR-10 Batch 2:  Train_Loss:0.5801608562469482, Valid_Loss:1.200561761856079, Valid_ACC:0.6177998781204224
Epoch 900, CIFAR-10 Batch 3:  Train_Loss:0.5884155631065369, Valid_Loss:1.2169640064239502, Valid_ACC:0.60999995470047
Epoch 900, CIFAR-10 Batch 4:  Train_Loss:0.5784176588058472, Valid_Loss:1.20368492603302, Valid_ACC:0.6107999086380005
Epoch 900, CIFAR-10 Batch 5:  Train_Loss:0.6021060943603516, Valid_Loss:1.212202548980713, Valid_ACC:0.613399863243103
Epoch 901, CIFAR-10 Batch 1:  Train_Loss:0.5950050354003906, Valid_Loss:1.2109692096710205, Valid_ACC:0.6115999221801758
Epoch 901, CIFAR-10 Batch 2:  Train_Loss:0.5805601477622986, Valid_Loss:1.1999255418777466, Valid_ACC:0.6139999032020569
Epoch 901, CIFAR-10 Batch 3:  Train_Loss:0.5788883566856384, Valid_Loss:1.211930751800537, Valid_ACC:0.6133999228477478
Epoch 901, CIFAR-10 Batch 4:  Train_Loss:0.5767697095870972, Valid_Loss:1.2025974988937378, Valid_ACC:0.6149999499320984
Epoch 901, CIFAR-10 Batch 5:  Train_Loss:0.5914667844772339, Valid_Loss:1.2210259437561035, Valid_ACC:0.6123998761177063
Epoch 902, CIFAR-10 Batch 1:  Train_Loss:0.6037139296531677, Valid_Loss:1.209282398223877, Valid_ACC:0.612799882888794
Epoch 902, CIFAR-10 Batch 2:  Train_Loss:0.5734438896179199, Valid_Loss:1.2019283771514893, Valid_ACC:0.6169999241828918
Epoch 902, CIFAR-10 Batch 3:  Train_Loss:0.5925641059875488, Valid_Loss:1.2244529724121094, Valid_ACC:0.6149998903274536
Epoch 902, CIFAR-10 Batch 4:  Train_Loss:0.5809356570243835, Valid_Loss:1.2021218538284302, Valid_ACC:0.6171998977661133
Epoch 902, CIFAR-10 Batch 5:  Train_Loss:0.6044297218322754, Valid_Loss:1.2294344902038574, Valid_ACC:0.6119998693466187
Epoch 903, CIFAR-10 Batch 1:  Train_Loss:0.6120809316635132, Valid_Loss:1.1992390155792236, Valid_ACC:0.6211998462677002
Epoch 903, CIFAR-10 Batch 2:  Train_Loss:0.5986929535865784, Valid_Loss:1.2146743535995483, Valid_ACC:0.6137999296188354
Epoch 903, CIFAR-10 Batch 3:  Train_Loss:0.6126002669334412, Valid_Loss:1.243277907371521, Valid_ACC:0.6067999601364136
Epoch 903, CIFAR-10 Batch 4:  Train_Loss:0.5973965525627136, Valid_Loss:1.212315320968628, Valid_ACC:0.6099998950958252
Epoch 903, CIFAR-10 Batch 5:  Train_Loss:0.6027799844741821, Valid_Loss:1.2105863094329834, Valid_ACC:0.6123999357223511
Epoch 904, CIFAR-10 Batch 1:  Train_Loss:0.6103407144546509, Valid_Loss:1.2201597690582275, Valid_ACC:0.6091999411582947
Epoch 904, CIFAR-10 Batch 2:  Train_Loss:0.5892442464828491, Valid_Loss:1.2016664743423462, Valid_ACC:0.6189998984336853
Epoch 904, CIFAR-10 Batch 3:  Train_Loss:0.6238288283348083, Valid_Loss:1.2467360496520996, Valid_ACC:0.6045999526977539
Epoch 904, CIFAR-10 Batch 4:  Train_Loss:0.6048778891563416, Valid_Loss:1.214022159576416, Valid_ACC:0.6085999011993408
Epoch 904, CIFAR-10 Batch 5:  Train_Loss:0.5889342427253723, Valid_Loss:1.2188752889633179, Valid_ACC:0.6087998747825623
Epoch 905, CIFAR-10 Batch 1:  Train_Loss:0.6156125068664551, Valid_Loss:1.2072802782058716, Valid_ACC:0.6195998787879944
Epoch 905, CIFAR-10 Batch 2:  Train_Loss:0.569629967212677, Valid_Loss:1.1920840740203857, Valid_ACC:0.619999885559082
Epoch 905, CIFAR-10 Batch 3:  Train_Loss:0.5775980353355408, Valid_Loss:1.2122849225997925, Valid_ACC:0.615399956703186
Epoch 905, CIFAR-10 Batch 4:  Train_Loss:0.598275899887085, Valid_Loss:1.2163681983947754, Valid_ACC:0.6129999160766602
Epoch 905, CIFAR-10 Batch 5:  Train_Loss:0.5865829586982727, Valid_Loss:1.2115122079849243, Valid_ACC:0.6113998889923096
Epoch 906, CIFAR-10 Batch 1:  Train_Loss:0.5964837074279785, Valid_Loss:1.205491542816162, Valid_ACC:0.6165999174118042
Epoch 906, CIFAR-10 Batch 2:  Train_Loss:0.5706521272659302, Valid_Loss:1.1944537162780762, Valid_ACC:0.6195999383926392
Epoch 906, CIFAR-10 Batch 3:  Train_Loss:0.5783411264419556, Valid_Loss:1.1998205184936523, Valid_ACC:0.6187999248504639
Epoch 906, CIFAR-10 Batch 4:  Train_Loss:0.5805627703666687, Valid_Loss:1.2008368968963623, Valid_ACC:0.6141998767852783
Epoch 906, CIFAR-10 Batch 5:  Train_Loss:0.5876477360725403, Valid_Loss:1.209059476852417, Valid_ACC:0.6131999492645264
Epoch 907, CIFAR-10 Batch 1:  Train_Loss:0.5806150436401367, Valid_Loss:1.1990227699279785, Valid_ACC:0.6179999113082886
Epoch 907, CIFAR-10 Batch 2:  Train_Loss:0.5646019577980042, Valid_Loss:1.1924867630004883, Valid_ACC:0.6151999235153198
Epoch 907, CIFAR-10 Batch 3:  Train_Loss:0.5600845813751221, Valid_Loss:1.1968955993652344, Valid_ACC:0.6221998929977417
Epoch 907, CIFAR-10 Batch 4:  Train_Loss:0.589759111404419, Valid_Loss:1.2038516998291016, Valid_ACC:0.6169999241828918
Epoch 907, CIFAR-10 Batch 5:  Train_Loss:0.6105371713638306, Valid_Loss:1.231054663658142, Valid_ACC:0.6149998903274536
Epoch 908, CIFAR-10 Batch 1:  Train_Loss:0.6053297519683838, Valid_Loss:1.2163114547729492, Valid_ACC:0.6147998571395874
Epoch 908, CIFAR-10 Batch 2:  Train_Loss:0.5910231471061707, Valid_Loss:1.21061110496521, Valid_ACC:0.612799882888794
Epoch 908, CIFAR-10 Batch 3:  Train_Loss:0.5961941480636597, Valid_Loss:1.2280863523483276, Valid_ACC:0.6131998896598816
Epoch 908, CIFAR-10 Batch 4:  Train_Loss:0.5904625058174133, Valid_Loss:1.2145612239837646, Valid_ACC:0.6103999018669128
Epoch 908, CIFAR-10 Batch 5:  Train_Loss:0.6010533571243286, Valid_Loss:1.2153578996658325, Valid_ACC:0.6125999093055725
Epoch 909, CIFAR-10 Batch 1:  Train_Loss:0.6131818890571594, Valid_Loss:1.2081170082092285, Valid_ACC:0.6165999174118042
Epoch 909, CIFAR-10 Batch 2:  Train_Loss:0.5656929016113281, Valid_Loss:1.196622371673584, Valid_ACC:0.6169999241828918
Epoch 909, CIFAR-10 Batch 3:  Train_Loss:0.5856395959854126, Valid_Loss:1.2175347805023193, Valid_ACC:0.6119999289512634
Epoch 909, CIFAR-10 Batch 4:  Train_Loss:0.5900724530220032, Valid_Loss:1.205920934677124, Valid_ACC:0.6125999093055725
Epoch 909, CIFAR-10 Batch 5:  Train_Loss:0.5894525647163391, Valid_Loss:1.1992794275283813, Valid_ACC:0.612799882888794
Epoch 910, CIFAR-10 Batch 1:  Train_Loss:0.5875452160835266, Valid_Loss:1.204939842224121, Valid_ACC:0.6171998381614685
Epoch 910, CIFAR-10 Batch 2:  Train_Loss:0.6009135246276855, Valid_Loss:1.214490532875061, Valid_ACC:0.6137998700141907
Epoch 910, CIFAR-10 Batch 3:  Train_Loss:0.5711977481842041, Valid_Loss:1.2114791870117188, Valid_ACC:0.6135998964309692
Epoch 910, CIFAR-10 Batch 4:  Train_Loss:0.5855778455734253, Valid_Loss:1.207082748413086, Valid_ACC:0.6119999289512634
Epoch 910, CIFAR-10 Batch 5:  Train_Loss:0.6024572253227234, Valid_Loss:1.2221100330352783, Valid_ACC:0.6113999485969543
Epoch 911, CIFAR-10 Batch 1:  Train_Loss:0.5900160074234009, Valid_Loss:1.2085262537002563, Valid_ACC:0.6167998909950256
Epoch 911, CIFAR-10 Batch 2:  Train_Loss:0.6023886203765869, Valid_Loss:1.2196484804153442, Valid_ACC:0.610599935054779
Epoch 911, CIFAR-10 Batch 3:  Train_Loss:0.5852767825126648, Valid_Loss:1.2160364389419556, Valid_ACC:0.6137999296188354
Epoch 911, CIFAR-10 Batch 4:  Train_Loss:0.6066731214523315, Valid_Loss:1.220568060874939, Valid_ACC:0.6079999208450317
Epoch 911, CIFAR-10 Batch 5:  Train_Loss:0.607962965965271, Valid_Loss:1.2031958103179932, Valid_ACC:0.6147998571395874
Epoch 912, CIFAR-10 Batch 1:  Train_Loss:0.5952791571617126, Valid_Loss:1.2059460878372192, Valid_ACC:0.6191999316215515
Epoch 912, CIFAR-10 Batch 2:  Train_Loss:0.604701578617096, Valid_Loss:1.2157065868377686, Valid_ACC:0.6123998165130615
Epoch 912, CIFAR-10 Batch 3:  Train_Loss:0.6074212789535522, Valid_Loss:1.232266902923584, Valid_ACC:0.613599956035614
Epoch 912, CIFAR-10 Batch 4:  Train_Loss:0.5775420665740967, Valid_Loss:1.2026523351669312, Valid_ACC:0.6139999628067017
Epoch 912, CIFAR-10 Batch 5:  Train_Loss:0.5926496386528015, Valid_Loss:1.2186903953552246, Valid_ACC:0.6135998368263245
Epoch 913, CIFAR-10 Batch 1:  Train_Loss:0.5966101288795471, Valid_Loss:1.2008012533187866, Valid_ACC:0.6161998510360718
Epoch 913, CIFAR-10 Batch 2:  Train_Loss:0.580663800239563, Valid_Loss:1.2002122402191162, Valid_ACC:0.6101999282836914
Epoch 913, CIFAR-10 Batch 3:  Train_Loss:0.577197253704071, Valid_Loss:1.2224985361099243, Valid_ACC:0.6129999160766602
Epoch 913, CIFAR-10 Batch 4:  Train_Loss:0.5876767039299011, Valid_Loss:1.2060941457748413, Valid_ACC:0.608799934387207
Epoch 913, CIFAR-10 Batch 5:  Train_Loss:0.597801685333252, Valid_Loss:1.2128900289535522, Valid_ACC:0.6183999180793762
Epoch 914, CIFAR-10 Batch 1:  Train_Loss:0.6012519598007202, Valid_Loss:1.2046359777450562, Valid_ACC:0.6189998388290405
Epoch 914, CIFAR-10 Batch 2:  Train_Loss:0.5965568423271179, Valid_Loss:1.2074482440948486, Valid_ACC:0.6131998896598816
Epoch 914, CIFAR-10 Batch 3:  Train_Loss:0.5659713745117188, Valid_Loss:1.1966116428375244, Valid_ACC:0.619999885559082
Epoch 914, CIFAR-10 Batch 4:  Train_Loss:0.6013866662979126, Valid_Loss:1.2223114967346191, Valid_ACC:0.6099998950958252
Epoch 914, CIFAR-10 Batch 5:  Train_Loss:0.6053520441055298, Valid_Loss:1.2189418077468872, Valid_ACC:0.6165999174118042
Epoch 915, CIFAR-10 Batch 1:  Train_Loss:0.5890716910362244, Valid_Loss:1.2024791240692139, Valid_ACC:0.6179999709129333
Epoch 915, CIFAR-10 Batch 2:  Train_Loss:0.5695826411247253, Valid_Loss:1.1945558786392212, Valid_ACC:0.6175999045372009
Epoch 915, CIFAR-10 Batch 3:  Train_Loss:0.5769208073616028, Valid_Loss:1.2031562328338623, Valid_ACC:0.6205998659133911
Epoch 915, CIFAR-10 Batch 4:  Train_Loss:0.582589864730835, Valid_Loss:1.2003953456878662, Valid_ACC:0.6179999113082886
Epoch 915, CIFAR-10 Batch 5:  Train_Loss:0.5975245237350464, Valid_Loss:1.2204618453979492, Valid_ACC:0.6137998700141907
Epoch 916, CIFAR-10 Batch 1:  Train_Loss:0.5923704504966736, Valid_Loss:1.2009854316711426, Valid_ACC:0.6185998916625977
Epoch 916, CIFAR-10 Batch 2:  Train_Loss:0.5682544708251953, Valid_Loss:1.1979796886444092, Valid_ACC:0.6193999648094177
Epoch 916, CIFAR-10 Batch 3:  Train_Loss:0.5652869343757629, Valid_Loss:1.2067348957061768, Valid_ACC:0.614599883556366
Epoch 916, CIFAR-10 Batch 4:  Train_Loss:0.5885671377182007, Valid_Loss:1.2125056982040405, Valid_ACC:0.6113998889923096
Epoch 916, CIFAR-10 Batch 5:  Train_Loss:0.5939591526985168, Valid_Loss:1.2278242111206055, Valid_ACC:0.6077998876571655
Epoch 917, CIFAR-10 Batch 1:  Train_Loss:0.6220558881759644, Valid_Loss:1.2151479721069336, Valid_ACC:0.6161999702453613
Epoch 917, CIFAR-10 Batch 2:  Train_Loss:0.5770891904830933, Valid_Loss:1.202675461769104, Valid_ACC:0.6145999431610107
Epoch 917, CIFAR-10 Batch 3:  Train_Loss:0.5718089938163757, Valid_Loss:1.2022243738174438, Valid_ACC:0.6179999113082886
Epoch 917, CIFAR-10 Batch 4:  Train_Loss:0.6047268509864807, Valid_Loss:1.216355323791504, Valid_ACC:0.608199954032898
Epoch 917, CIFAR-10 Batch 5:  Train_Loss:0.6124375462532043, Valid_Loss:1.229156494140625, Valid_ACC:0.6079999208450317
Epoch 918, CIFAR-10 Batch 1:  Train_Loss:0.5969895720481873, Valid_Loss:1.2047902345657349, Valid_ACC:0.6141998767852783
Epoch 918, CIFAR-10 Batch 2:  Train_Loss:0.5778045058250427, Valid_Loss:1.2024120092391968, Valid_ACC:0.619399905204773
Epoch 918, CIFAR-10 Batch 3:  Train_Loss:0.5908761024475098, Valid_Loss:1.216430902481079, Valid_ACC:0.612799882888794
Epoch 918, CIFAR-10 Batch 4:  Train_Loss:0.6105472445487976, Valid_Loss:1.2115199565887451, Valid_ACC:0.6119998693466187
Epoch 918, CIFAR-10 Batch 5:  Train_Loss:0.612608790397644, Valid_Loss:1.2138159275054932, Valid_ACC:0.6153998970985413
Epoch 919, CIFAR-10 Batch 1:  Train_Loss:0.6059350371360779, Valid_Loss:1.2196353673934937, Valid_ACC:0.6103999018669128
Epoch 919, CIFAR-10 Batch 2:  Train_Loss:0.5838802456855774, Valid_Loss:1.2044490575790405, Valid_ACC:0.6183999180793762
Epoch 919, CIFAR-10 Batch 3:  Train_Loss:0.5770247578620911, Valid_Loss:1.2093449831008911, Valid_ACC:0.6179999113082886
Epoch 919, CIFAR-10 Batch 4:  Train_Loss:0.5874391794204712, Valid_Loss:1.2059862613677979, Valid_ACC:0.6117998957633972
Epoch 919, CIFAR-10 Batch 5:  Train_Loss:0.5959950089454651, Valid_Loss:1.208864450454712, Valid_ACC:0.616399884223938
Epoch 920, CIFAR-10 Batch 1:  Train_Loss:0.5850615501403809, Valid_Loss:1.1981098651885986, Valid_ACC:0.6197999119758606
Epoch 920, CIFAR-10 Batch 2:  Train_Loss:0.5700589418411255, Valid_Loss:1.1944706439971924, Valid_ACC:0.6183999180793762
Epoch 920, CIFAR-10 Batch 3:  Train_Loss:0.5679520964622498, Valid_Loss:1.2010831832885742, Valid_ACC:0.6175999641418457
Epoch 920, CIFAR-10 Batch 4:  Train_Loss:0.5794401168823242, Valid_Loss:1.2064430713653564, Valid_ACC:0.6111998558044434
Epoch 920, CIFAR-10 Batch 5:  Train_Loss:0.5883240699768066, Valid_Loss:1.212988018989563, Valid_ACC:0.6159999370574951
Epoch 921, CIFAR-10 Batch 1:  Train_Loss:0.5841220617294312, Valid_Loss:1.2168306112289429, Valid_ACC:0.6117998957633972
Epoch 921, CIFAR-10 Batch 2:  Train_Loss:0.5884323716163635, Valid_Loss:1.210882306098938, Valid_ACC:0.6125999689102173
Epoch 921, CIFAR-10 Batch 3:  Train_Loss:0.6030875444412231, Valid_Loss:1.2340277433395386, Valid_ACC:0.6105998754501343
Epoch 921, CIFAR-10 Batch 4:  Train_Loss:0.6139076352119446, Valid_Loss:1.2269545793533325, Valid_ACC:0.6077998876571655
Epoch 921, CIFAR-10 Batch 5:  Train_Loss:0.6020164489746094, Valid_Loss:1.2186462879180908, Valid_ACC:0.6167998909950256
Epoch 922, CIFAR-10 Batch 1:  Train_Loss:0.6199379563331604, Valid_Loss:1.233917236328125, Valid_ACC:0.6033998727798462
Epoch 922, CIFAR-10 Batch 2:  Train_Loss:0.5863128900527954, Valid_Loss:1.2025680541992188, Valid_ACC:0.6205998659133911
Epoch 922, CIFAR-10 Batch 3:  Train_Loss:0.5732358694076538, Valid_Loss:1.2078027725219727, Valid_ACC:0.614799976348877
Epoch 922, CIFAR-10 Batch 4:  Train_Loss:0.5825110077857971, Valid_Loss:1.2034448385238647, Valid_ACC:0.615399956703186
Epoch 922, CIFAR-10 Batch 5:  Train_Loss:0.6149047613143921, Valid_Loss:1.2224596738815308, Valid_ACC:0.6123998761177063
Epoch 923, CIFAR-10 Batch 1:  Train_Loss:0.600633978843689, Valid_Loss:1.2179464101791382, Valid_ACC:0.6097999215126038
Epoch 923, CIFAR-10 Batch 2:  Train_Loss:0.580555260181427, Valid_Loss:1.2069091796875, Valid_ACC:0.6151999235153198
Epoch 923, CIFAR-10 Batch 3:  Train_Loss:0.5645081400871277, Valid_Loss:1.1948363780975342, Valid_ACC:0.6225999593734741
Epoch 923, CIFAR-10 Batch 4:  Train_Loss:0.5850260257720947, Valid_Loss:1.2061482667922974, Valid_ACC:0.6137998700141907
Epoch 923, CIFAR-10 Batch 5:  Train_Loss:0.5898212194442749, Valid_Loss:1.206160306930542, Valid_ACC:0.6185999512672424
Epoch 924, CIFAR-10 Batch 1:  Train_Loss:0.5888060927391052, Valid_Loss:1.1935303211212158, Valid_ACC:0.6241999268531799
Epoch 924, CIFAR-10 Batch 2:  Train_Loss:0.5680878162384033, Valid_Loss:1.1991195678710938, Valid_ACC:0.6209999322891235
Epoch 924, CIFAR-10 Batch 3:  Train_Loss:0.5547840595245361, Valid_Loss:1.1967334747314453, Valid_ACC:0.6209999322891235
Epoch 924, CIFAR-10 Batch 4:  Train_Loss:0.5918554663658142, Valid_Loss:1.2128547430038452, Valid_ACC:0.6075999140739441
Epoch 924, CIFAR-10 Batch 5:  Train_Loss:0.609616756439209, Valid_Loss:1.2351582050323486, Valid_ACC:0.6133999228477478
Epoch 925, CIFAR-10 Batch 1:  Train_Loss:0.6171095371246338, Valid_Loss:1.2202378511428833, Valid_ACC:0.6113998889923096
Epoch 925, CIFAR-10 Batch 2:  Train_Loss:0.5813071131706238, Valid_Loss:1.203147530555725, Valid_ACC:0.619399905204773
Epoch 925, CIFAR-10 Batch 3:  Train_Loss:0.5782634019851685, Valid_Loss:1.2150577306747437, Valid_ACC:0.6151999235153198
Epoch 925, CIFAR-10 Batch 4:  Train_Loss:0.5898008942604065, Valid_Loss:1.2123770713806152, Valid_ACC:0.6107999086380005
Epoch 925, CIFAR-10 Batch 5:  Train_Loss:0.6073384284973145, Valid_Loss:1.2127466201782227, Valid_ACC:0.6171998977661133
Epoch 926, CIFAR-10 Batch 1:  Train_Loss:0.6138548851013184, Valid_Loss:1.2084946632385254, Valid_ACC:0.6135998964309692
Epoch 926, CIFAR-10 Batch 2:  Train_Loss:0.5930007696151733, Valid_Loss:1.2097384929656982, Valid_ACC:0.6121998429298401
Epoch 926, CIFAR-10 Batch 3:  Train_Loss:0.5810304880142212, Valid_Loss:1.2089757919311523, Valid_ACC:0.621799886226654
Epoch 926, CIFAR-10 Batch 4:  Train_Loss:0.5926563739776611, Valid_Loss:1.2113680839538574, Valid_ACC:0.6111999154090881
Epoch 926, CIFAR-10 Batch 5:  Train_Loss:0.6106717586517334, Valid_Loss:1.2276804447174072, Valid_ACC:0.6095999479293823
Epoch 927, CIFAR-10 Batch 1:  Train_Loss:0.5963914394378662, Valid_Loss:1.2147494554519653, Valid_ACC:0.6107999086380005
Epoch 927, CIFAR-10 Batch 2:  Train_Loss:0.5753188729286194, Valid_Loss:1.2023212909698486, Valid_ACC:0.6173998713493347
Epoch 927, CIFAR-10 Batch 3:  Train_Loss:0.5731271505355835, Valid_Loss:1.206253170967102, Valid_ACC:0.6137999296188354
Epoch 927, CIFAR-10 Batch 4:  Train_Loss:0.5698989629745483, Valid_Loss:1.1976206302642822, Valid_ACC:0.6157999038696289
Epoch 927, CIFAR-10 Batch 5:  Train_Loss:0.5992617011070251, Valid_Loss:1.2261459827423096, Valid_ACC:0.6089999079704285
Epoch 928, CIFAR-10 Batch 1:  Train_Loss:0.591626763343811, Valid_Loss:1.2236144542694092, Valid_ACC:0.6115999221801758
Epoch 928, CIFAR-10 Batch 2:  Train_Loss:0.5751566886901855, Valid_Loss:1.204372525215149, Valid_ACC:0.6121998429298401
Epoch 928, CIFAR-10 Batch 3:  Train_Loss:0.5699697136878967, Valid_Loss:1.200819730758667, Valid_ACC:0.6137999296188354
Epoch 928, CIFAR-10 Batch 4:  Train_Loss:0.5725357532501221, Valid_Loss:1.2018797397613525, Valid_ACC:0.6137999296188354
Epoch 928, CIFAR-10 Batch 5:  Train_Loss:0.5945260524749756, Valid_Loss:1.216149926185608, Valid_ACC:0.6169999837875366
Epoch 929, CIFAR-10 Batch 1:  Train_Loss:0.5937691926956177, Valid_Loss:1.2065446376800537, Valid_ACC:0.6137999296188354
Epoch 929, CIFAR-10 Batch 2:  Train_Loss:0.5723748207092285, Valid_Loss:1.2032842636108398, Valid_ACC:0.6157998442649841
Epoch 929, CIFAR-10 Batch 3:  Train_Loss:0.5810239911079407, Valid_Loss:1.2151095867156982, Valid_ACC:0.6179999113082886
Epoch 929, CIFAR-10 Batch 4:  Train_Loss:0.5877123475074768, Valid_Loss:1.2040663957595825, Valid_ACC:0.6111999750137329
Epoch 929, CIFAR-10 Batch 5:  Train_Loss:0.5932935476303101, Valid_Loss:1.2092264890670776, Valid_ACC:0.6165998578071594
Epoch 930, CIFAR-10 Batch 1:  Train_Loss:0.5866430997848511, Valid_Loss:1.2128076553344727, Valid_ACC:0.6105998754501343
Epoch 930, CIFAR-10 Batch 2:  Train_Loss:0.5756692290306091, Valid_Loss:1.199214220046997, Valid_ACC:0.6201998591423035
Epoch 930, CIFAR-10 Batch 3:  Train_Loss:0.5829357504844666, Valid_Loss:1.2173848152160645, Valid_ACC:0.6201999187469482
Epoch 930, CIFAR-10 Batch 4:  Train_Loss:0.5944685339927673, Valid_Loss:1.2143577337265015, Valid_ACC:0.6121999025344849
Epoch 930, CIFAR-10 Batch 5:  Train_Loss:0.5940767526626587, Valid_Loss:1.2188571691513062, Valid_ACC:0.6181999444961548
Epoch 931, CIFAR-10 Batch 1:  Train_Loss:0.5872942209243774, Valid_Loss:1.2053085565567017, Valid_ACC:0.6149998903274536
Epoch 931, CIFAR-10 Batch 2:  Train_Loss:0.5751534700393677, Valid_Loss:1.1954057216644287, Valid_ACC:0.6169999241828918
Epoch 931, CIFAR-10 Batch 3:  Train_Loss:0.5670075416564941, Valid_Loss:1.2026044130325317, Valid_ACC:0.6193999648094177
Epoch 931, CIFAR-10 Batch 4:  Train_Loss:0.5964942574501038, Valid_Loss:1.2077385187149048, Valid_ACC:0.6103999614715576
Epoch 931, CIFAR-10 Batch 5:  Train_Loss:0.5980653166770935, Valid_Loss:1.2183873653411865, Valid_ACC:0.6149999499320984
Epoch 932, CIFAR-10 Batch 1:  Train_Loss:0.5939871668815613, Valid_Loss:1.2111501693725586, Valid_ACC:0.6153998970985413
Epoch 932, CIFAR-10 Batch 2:  Train_Loss:0.5711646676063538, Valid_Loss:1.201705813407898, Valid_ACC:0.61819988489151
Epoch 932, CIFAR-10 Batch 3:  Train_Loss:0.5840601921081543, Valid_Loss:1.2146286964416504, Valid_ACC:0.6123998761177063
Epoch 932, CIFAR-10 Batch 4:  Train_Loss:0.585120677947998, Valid_Loss:1.2020652294158936, Valid_ACC:0.6131999492645264
Epoch 932, CIFAR-10 Batch 5:  Train_Loss:0.612267255783081, Valid_Loss:1.2319488525390625, Valid_ACC:0.609799861907959
Epoch 933, CIFAR-10 Batch 1:  Train_Loss:0.5897297263145447, Valid_Loss:1.2033182382583618, Valid_ACC:0.6189998388290405
Epoch 933, CIFAR-10 Batch 2:  Train_Loss:0.5798532366752625, Valid_Loss:1.2001328468322754, Valid_ACC:0.6177999377250671
Epoch 933, CIFAR-10 Batch 3:  Train_Loss:0.578784704208374, Valid_Loss:1.2102041244506836, Valid_ACC:0.6145999431610107
Epoch 933, CIFAR-10 Batch 4:  Train_Loss:0.5811072587966919, Valid_Loss:1.2058237791061401, Valid_ACC:0.6121999025344849
Epoch 933, CIFAR-10 Batch 5:  Train_Loss:0.5822219848632812, Valid_Loss:1.2013919353485107, Valid_ACC:0.6215999126434326
Epoch 934, CIFAR-10 Batch 1:  Train_Loss:0.5870537757873535, Valid_Loss:1.2026115655899048, Valid_ACC:0.613399863243103
Epoch 934, CIFAR-10 Batch 2:  Train_Loss:0.6024166345596313, Valid_Loss:1.2242897748947144, Valid_ACC:0.6095998883247375
Epoch 934, CIFAR-10 Batch 3:  Train_Loss:0.6045147180557251, Valid_Loss:1.2265995740890503, Valid_ACC:0.610599935054779
Epoch 934, CIFAR-10 Batch 4:  Train_Loss:0.5796712040901184, Valid_Loss:1.1988739967346191, Valid_ACC:0.6129999160766602
Epoch 934, CIFAR-10 Batch 5:  Train_Loss:0.6016779541969299, Valid_Loss:1.226288914680481, Valid_ACC:0.6111999154090881
Epoch 935, CIFAR-10 Batch 1:  Train_Loss:0.6016185283660889, Valid_Loss:1.206679105758667, Valid_ACC:0.6109998822212219
Epoch 935, CIFAR-10 Batch 2:  Train_Loss:0.5961754322052002, Valid_Loss:1.204528570175171, Valid_ACC:0.6183999180793762
Epoch 935, CIFAR-10 Batch 3:  Train_Loss:0.5709131956100464, Valid_Loss:1.2067502737045288, Valid_ACC:0.6181999444961548
Epoch 935, CIFAR-10 Batch 4:  Train_Loss:0.5723253488540649, Valid_Loss:1.1943140029907227, Valid_ACC:0.6181999444961548
Epoch 935, CIFAR-10 Batch 5:  Train_Loss:0.5890041589736938, Valid_Loss:1.2147316932678223, Valid_ACC:0.6125998497009277
Epoch 936, CIFAR-10 Batch 1:  Train_Loss:0.5867360234260559, Valid_Loss:1.210274338722229, Valid_ACC:0.6123998761177063
Epoch 936, CIFAR-10 Batch 2:  Train_Loss:0.5763993859291077, Valid_Loss:1.206829309463501, Valid_ACC:0.6201999187469482
Epoch 936, CIFAR-10 Batch 3:  Train_Loss:0.5630602240562439, Valid_Loss:1.1974973678588867, Valid_ACC:0.6139998435974121
Epoch 936, CIFAR-10 Batch 4:  Train_Loss:0.5822305679321289, Valid_Loss:1.2080223560333252, Valid_ACC:0.6121999621391296
Epoch 936, CIFAR-10 Batch 5:  Train_Loss:0.6067299842834473, Valid_Loss:1.2160723209381104, Valid_ACC:0.6183999180793762
Epoch 937, CIFAR-10 Batch 1:  Train_Loss:0.5776782035827637, Valid_Loss:1.2096258401870728, Valid_ACC:0.6129999160766602
Epoch 937, CIFAR-10 Batch 2:  Train_Loss:0.576896071434021, Valid_Loss:1.2127659320831299, Valid_ACC:0.6131998896598816
Epoch 937, CIFAR-10 Batch 3:  Train_Loss:0.5687254071235657, Valid_Loss:1.2105677127838135, Valid_ACC:0.6117998361587524
Epoch 937, CIFAR-10 Batch 4:  Train_Loss:0.5669106245040894, Valid_Loss:1.196171522140503, Valid_ACC:0.6109999418258667
Epoch 937, CIFAR-10 Batch 5:  Train_Loss:0.6026007533073425, Valid_Loss:1.2176945209503174, Valid_ACC:0.6141998767852783
Epoch 938, CIFAR-10 Batch 1:  Train_Loss:0.5781134366989136, Valid_Loss:1.2043216228485107, Valid_ACC:0.6139999032020569
Epoch 938, CIFAR-10 Batch 2:  Train_Loss:0.5746850371360779, Valid_Loss:1.198570966720581, Valid_ACC:0.6191999316215515
Epoch 938, CIFAR-10 Batch 3:  Train_Loss:0.5815470218658447, Valid_Loss:1.217759370803833, Valid_ACC:0.6125998497009277
Epoch 938, CIFAR-10 Batch 4:  Train_Loss:0.5779650807380676, Valid_Loss:1.1973137855529785, Valid_ACC:0.6169999241828918
Epoch 938, CIFAR-10 Batch 5:  Train_Loss:0.5888459086418152, Valid_Loss:1.2170056104660034, Valid_ACC:0.6115999221801758
Epoch 939, CIFAR-10 Batch 1:  Train_Loss:0.5779070854187012, Valid_Loss:1.2066795825958252, Valid_ACC:0.6181999444961548
Epoch 939, CIFAR-10 Batch 2:  Train_Loss:0.6062004566192627, Valid_Loss:1.2262698411941528, Valid_ACC:0.6069998741149902
Epoch 939, CIFAR-10 Batch 3:  Train_Loss:0.5668947696685791, Valid_Loss:1.2027068138122559, Valid_ACC:0.6157999038696289
Epoch 939, CIFAR-10 Batch 4:  Train_Loss:0.5785683393478394, Valid_Loss:1.205343246459961, Valid_ACC:0.6159998774528503
Epoch 939, CIFAR-10 Batch 5:  Train_Loss:0.5942318439483643, Valid_Loss:1.2217786312103271, Valid_ACC:0.6113998889923096
Epoch 940, CIFAR-10 Batch 1:  Train_Loss:0.5725573897361755, Valid_Loss:1.2068278789520264, Valid_ACC:0.6207998991012573
Epoch 940, CIFAR-10 Batch 2:  Train_Loss:0.5599862337112427, Valid_Loss:1.19233238697052, Valid_ACC:0.6187999248504639
Epoch 940, CIFAR-10 Batch 3:  Train_Loss:0.5814161896705627, Valid_Loss:1.2123754024505615, Valid_ACC:0.6115999221801758
Epoch 940, CIFAR-10 Batch 4:  Train_Loss:0.5723246932029724, Valid_Loss:1.2094385623931885, Valid_ACC:0.6167999505996704
Epoch 940, CIFAR-10 Batch 5:  Train_Loss:0.5970339775085449, Valid_Loss:1.2155193090438843, Valid_ACC:0.6165999174118042
Epoch 941, CIFAR-10 Batch 1:  Train_Loss:0.5708812475204468, Valid_Loss:1.204784870147705, Valid_ACC:0.613599956035614
Epoch 941, CIFAR-10 Batch 2:  Train_Loss:0.5720968246459961, Valid_Loss:1.2001652717590332, Valid_ACC:0.6157999038696289
Epoch 941, CIFAR-10 Batch 3:  Train_Loss:0.5891920328140259, Valid_Loss:1.226090908050537, Valid_ACC:0.6101998686790466
Epoch 941, CIFAR-10 Batch 4:  Train_Loss:0.5839716792106628, Valid_Loss:1.213141918182373, Valid_ACC:0.619399905204773
Epoch 941, CIFAR-10 Batch 5:  Train_Loss:0.6016843318939209, Valid_Loss:1.2291898727416992, Valid_ACC:0.6049999594688416
Epoch 942, CIFAR-10 Batch 1:  Train_Loss:0.592401385307312, Valid_Loss:1.2006821632385254, Valid_ACC:0.6143999099731445
Epoch 942, CIFAR-10 Batch 2:  Train_Loss:0.5916547775268555, Valid_Loss:1.2223973274230957, Valid_ACC:0.6147999167442322
Epoch 942, CIFAR-10 Batch 3:  Train_Loss:0.5753272771835327, Valid_Loss:1.2104403972625732, Valid_ACC:0.6177999377250671
Epoch 942, CIFAR-10 Batch 4:  Train_Loss:0.5701113939285278, Valid_Loss:1.2035895586013794, Valid_ACC:0.6121999025344849
Epoch 942, CIFAR-10 Batch 5:  Train_Loss:0.6009426712989807, Valid_Loss:1.2322816848754883, Valid_ACC:0.6095998883247375
Epoch 943, CIFAR-10 Batch 1:  Train_Loss:0.6021068096160889, Valid_Loss:1.2197911739349365, Valid_ACC:0.6129998564720154
Epoch 943, CIFAR-10 Batch 2:  Train_Loss:0.5724006295204163, Valid_Loss:1.2084745168685913, Valid_ACC:0.6175999045372009
Epoch 943, CIFAR-10 Batch 3:  Train_Loss:0.56900954246521, Valid_Loss:1.218233585357666, Valid_ACC:0.612799882888794
Epoch 943, CIFAR-10 Batch 4:  Train_Loss:0.572425365447998, Valid_Loss:1.2026357650756836, Valid_ACC:0.6141998767852783
Epoch 943, CIFAR-10 Batch 5:  Train_Loss:0.5821317434310913, Valid_Loss:1.2129970788955688, Valid_ACC:0.6173999309539795
Epoch 944, CIFAR-10 Batch 1:  Train_Loss:0.5800219178199768, Valid_Loss:1.204354166984558, Valid_ACC:0.6173998713493347
Epoch 944, CIFAR-10 Batch 2:  Train_Loss:0.5689740180969238, Valid_Loss:1.2001302242279053, Valid_ACC:0.6203998923301697
Epoch 944, CIFAR-10 Batch 3:  Train_Loss:0.5676852464675903, Valid_Loss:1.2118301391601562, Valid_ACC:0.6117998957633972
Epoch 944, CIFAR-10 Batch 4:  Train_Loss:0.5715046525001526, Valid_Loss:1.2049460411071777, Valid_ACC:0.613399863243103
Epoch 944, CIFAR-10 Batch 5:  Train_Loss:0.59703528881073, Valid_Loss:1.2265541553497314, Valid_ACC:0.6131999492645264
Epoch 945, CIFAR-10 Batch 1:  Train_Loss:0.5724170207977295, Valid_Loss:1.2044425010681152, Valid_ACC:0.6179999113082886
Epoch 945, CIFAR-10 Batch 2:  Train_Loss:0.569530725479126, Valid_Loss:1.2030518054962158, Valid_ACC:0.6171999573707581
Epoch 945, CIFAR-10 Batch 3:  Train_Loss:0.5705418586730957, Valid_Loss:1.2083697319030762, Valid_ACC:0.615199863910675
Epoch 945, CIFAR-10 Batch 4:  Train_Loss:0.5681837797164917, Valid_Loss:1.197907567024231, Valid_ACC:0.6139998435974121
Epoch 945, CIFAR-10 Batch 5:  Train_Loss:0.585719108581543, Valid_Loss:1.2096878290176392, Valid_ACC:0.6169999241828918
Epoch 946, CIFAR-10 Batch 1:  Train_Loss:0.5885764360427856, Valid_Loss:1.2194035053253174, Valid_ACC:0.613599956035614
Epoch 946, CIFAR-10 Batch 2:  Train_Loss:0.5702723264694214, Valid_Loss:1.1992261409759521, Valid_ACC:0.6183999180793762
Epoch 946, CIFAR-10 Batch 3:  Train_Loss:0.5726457238197327, Valid_Loss:1.2113603353500366, Valid_ACC:0.6143999695777893
Epoch 946, CIFAR-10 Batch 4:  Train_Loss:0.6175580024719238, Valid_Loss:1.2257485389709473, Valid_ACC:0.6131999492645264
Epoch 946, CIFAR-10 Batch 5:  Train_Loss:0.5841683149337769, Valid_Loss:1.2159194946289062, Valid_ACC:0.614599883556366
Epoch 947, CIFAR-10 Batch 1:  Train_Loss:0.5654118061065674, Valid_Loss:1.2070097923278809, Valid_ACC:0.6167998313903809
Epoch 947, CIFAR-10 Batch 2:  Train_Loss:0.5723388195037842, Valid_Loss:1.2034648656845093, Valid_ACC:0.614599883556366
Epoch 947, CIFAR-10 Batch 3:  Train_Loss:0.5709394216537476, Valid_Loss:1.2135616540908813, Valid_ACC:0.6103999018669128
Epoch 947, CIFAR-10 Batch 4:  Train_Loss:0.5849612951278687, Valid_Loss:1.2161813974380493, Valid_ACC:0.6113998889923096
Epoch 947, CIFAR-10 Batch 5:  Train_Loss:0.5903743505477905, Valid_Loss:1.2034251689910889, Valid_ACC:0.6225999593734741
Epoch 948, CIFAR-10 Batch 1:  Train_Loss:0.5644651651382446, Valid_Loss:1.2004992961883545, Valid_ACC:0.6215999126434326
Epoch 948, CIFAR-10 Batch 2:  Train_Loss:0.5762016177177429, Valid_Loss:1.2078441381454468, Valid_ACC:0.6121999025344849
Epoch 948, CIFAR-10 Batch 3:  Train_Loss:0.5893614292144775, Valid_Loss:1.2247380018234253, Valid_ACC:0.6141999363899231
Epoch 948, CIFAR-10 Batch 4:  Train_Loss:0.5630812644958496, Valid_Loss:1.198074460029602, Valid_ACC:0.616399884223938
Epoch 948, CIFAR-10 Batch 5:  Train_Loss:0.5866702795028687, Valid_Loss:1.2125076055526733, Valid_ACC:0.6157999634742737
Epoch 949, CIFAR-10 Batch 1:  Train_Loss:0.5856670141220093, Valid_Loss:1.2067610025405884, Valid_ACC:0.6117998957633972
Epoch 949, CIFAR-10 Batch 2:  Train_Loss:0.5662065744400024, Valid_Loss:1.2008922100067139, Valid_ACC:0.6173998713493347
Epoch 949, CIFAR-10 Batch 3:  Train_Loss:0.5848679542541504, Valid_Loss:1.2175421714782715, Valid_ACC:0.6095998883247375
Epoch 949, CIFAR-10 Batch 4:  Train_Loss:0.5843936204910278, Valid_Loss:1.2081429958343506, Valid_ACC:0.6147999167442322
Epoch 949, CIFAR-10 Batch 5:  Train_Loss:0.5965390205383301, Valid_Loss:1.2244555950164795, Valid_ACC:0.6135998964309692
Epoch 950, CIFAR-10 Batch 1:  Train_Loss:0.5794138312339783, Valid_Loss:1.2216821908950806, Valid_ACC:0.6129998564720154
Epoch 950, CIFAR-10 Batch 2:  Train_Loss:0.5613139271736145, Valid_Loss:1.1996852159500122, Valid_ACC:0.6149998903274536
Epoch 950, CIFAR-10 Batch 3:  Train_Loss:0.5763067007064819, Valid_Loss:1.214695930480957, Valid_ACC:0.6139999032020569
Epoch 950, CIFAR-10 Batch 4:  Train_Loss:0.5693373680114746, Valid_Loss:1.200508713722229, Valid_ACC:0.614599883556366
Epoch 950, CIFAR-10 Batch 5:  Train_Loss:0.5811282992362976, Valid_Loss:1.2112388610839844, Valid_ACC:0.6113998293876648
Epoch 951, CIFAR-10 Batch 1:  Train_Loss:0.5715548396110535, Valid_Loss:1.1990082263946533, Valid_ACC:0.6147999167442322
Epoch 951, CIFAR-10 Batch 2:  Train_Loss:0.5690957307815552, Valid_Loss:1.2028225660324097, Valid_ACC:0.6153998970985413
Epoch 951, CIFAR-10 Batch 3:  Train_Loss:0.5657496452331543, Valid_Loss:1.20143723487854, Valid_ACC:0.6141998767852783
Epoch 951, CIFAR-10 Batch 4:  Train_Loss:0.5790073871612549, Valid_Loss:1.2072083950042725, Valid_ACC:0.6173999309539795
Epoch 951, CIFAR-10 Batch 5:  Train_Loss:0.5929878950119019, Valid_Loss:1.2228775024414062, Valid_ACC:0.6085999011993408
Epoch 952, CIFAR-10 Batch 1:  Train_Loss:0.5745171904563904, Valid_Loss:1.2101070880889893, Valid_ACC:0.6155999302864075
Epoch 952, CIFAR-10 Batch 2:  Train_Loss:0.5630815029144287, Valid_Loss:1.205946445465088, Valid_ACC:0.6169999837875366
Epoch 952, CIFAR-10 Batch 3:  Train_Loss:0.5678689479827881, Valid_Loss:1.207817554473877, Valid_ACC:0.6123999357223511
Epoch 952, CIFAR-10 Batch 4:  Train_Loss:0.5619285106658936, Valid_Loss:1.2052123546600342, Valid_ACC:0.6159999370574951
Epoch 952, CIFAR-10 Batch 5:  Train_Loss:0.5885589122772217, Valid_Loss:1.2310595512390137, Valid_ACC:0.6071999073028564
Epoch 953, CIFAR-10 Batch 1:  Train_Loss:0.5719261169433594, Valid_Loss:1.2167983055114746, Valid_ACC:0.6095998883247375
Epoch 953, CIFAR-10 Batch 2:  Train_Loss:0.5669259428977966, Valid_Loss:1.1947835683822632, Valid_ACC:0.6185998916625977
Epoch 953, CIFAR-10 Batch 3:  Train_Loss:0.5731760859489441, Valid_Loss:1.2107579708099365, Valid_ACC:0.6119999289512634
Epoch 953, CIFAR-10 Batch 4:  Train_Loss:0.5755116939544678, Valid_Loss:1.2121565341949463, Valid_ACC:0.6137998700141907
Epoch 953, CIFAR-10 Batch 5:  Train_Loss:0.5975208878517151, Valid_Loss:1.2245855331420898, Valid_ACC:0.6071998476982117
Epoch 954, CIFAR-10 Batch 1:  Train_Loss:0.5735557079315186, Valid_Loss:1.2072073221206665, Valid_ACC:0.614599883556366
Epoch 954, CIFAR-10 Batch 2:  Train_Loss:0.5671720504760742, Valid_Loss:1.2036285400390625, Valid_ACC:0.616399884223938
Epoch 954, CIFAR-10 Batch 3:  Train_Loss:0.5666102170944214, Valid_Loss:1.2119070291519165, Valid_ACC:0.612799882888794
Epoch 954, CIFAR-10 Batch 4:  Train_Loss:0.5744540691375732, Valid_Loss:1.2026225328445435, Valid_ACC:0.6183999180793762
Epoch 954, CIFAR-10 Batch 5:  Train_Loss:0.5860426425933838, Valid_Loss:1.203473687171936, Valid_ACC:0.6181999444961548
Epoch 955, CIFAR-10 Batch 1:  Train_Loss:0.5823934078216553, Valid_Loss:1.2125136852264404, Valid_ACC:0.6111998558044434
Epoch 955, CIFAR-10 Batch 2:  Train_Loss:0.5833486914634705, Valid_Loss:1.2124409675598145, Valid_ACC:0.612799882888794
Epoch 955, CIFAR-10 Batch 3:  Train_Loss:0.5706050992012024, Valid_Loss:1.215308666229248, Valid_ACC:0.6113998889923096
Epoch 955, CIFAR-10 Batch 4:  Train_Loss:0.5733044147491455, Valid_Loss:1.2017806768417358, Valid_ACC:0.6195999383926392
Epoch 955, CIFAR-10 Batch 5:  Train_Loss:0.5891798138618469, Valid_Loss:1.2306727170944214, Valid_ACC:0.6087998747825623
Epoch 956, CIFAR-10 Batch 1:  Train_Loss:0.5698904395103455, Valid_Loss:1.2124032974243164, Valid_ACC:0.6119998693466187
Epoch 956, CIFAR-10 Batch 2:  Train_Loss:0.5594937205314636, Valid_Loss:1.1992570161819458, Valid_ACC:0.6161998510360718
Epoch 956, CIFAR-10 Batch 3:  Train_Loss:0.559583306312561, Valid_Loss:1.215555191040039, Valid_ACC:0.6119998693466187
Epoch 956, CIFAR-10 Batch 4:  Train_Loss:0.569096028804779, Valid_Loss:1.2040352821350098, Valid_ACC:0.6147999167442322
Epoch 956, CIFAR-10 Batch 5:  Train_Loss:0.5818723440170288, Valid_Loss:1.2219903469085693, Valid_ACC:0.6099998950958252
Epoch 957, CIFAR-10 Batch 1:  Train_Loss:0.5822869539260864, Valid_Loss:1.2241885662078857, Valid_ACC:0.6121999025344849
Epoch 957, CIFAR-10 Batch 2:  Train_Loss:0.5557787418365479, Valid_Loss:1.2065389156341553, Valid_ACC:0.6159998774528503
Epoch 957, CIFAR-10 Batch 3:  Train_Loss:0.5844542384147644, Valid_Loss:1.230009913444519, Valid_ACC:0.6075999736785889
Epoch 957, CIFAR-10 Batch 4:  Train_Loss:0.5961445569992065, Valid_Loss:1.218244194984436, Valid_ACC:0.6185998916625977
Epoch 957, CIFAR-10 Batch 5:  Train_Loss:0.6052648425102234, Valid_Loss:1.2325570583343506, Valid_ACC:0.6113998889923096
Epoch 958, CIFAR-10 Batch 1:  Train_Loss:0.5710057616233826, Valid_Loss:1.2154375314712524, Valid_ACC:0.6131998896598816
Epoch 958, CIFAR-10 Batch 2:  Train_Loss:0.5914589762687683, Valid_Loss:1.2139465808868408, Valid_ACC:0.6165999174118042
Epoch 958, CIFAR-10 Batch 3:  Train_Loss:0.5751698613166809, Valid_Loss:1.2238093614578247, Valid_ACC:0.6123998761177063
Epoch 958, CIFAR-10 Batch 4:  Train_Loss:0.5818425416946411, Valid_Loss:1.2174959182739258, Valid_ACC:0.6121999025344849
Epoch 958, CIFAR-10 Batch 5:  Train_Loss:0.5860154032707214, Valid_Loss:1.2235956192016602, Valid_ACC:0.6087998747825623
Epoch 959, CIFAR-10 Batch 1:  Train_Loss:0.5830078125, Valid_Loss:1.2010406255722046, Valid_ACC:0.6219999194145203
Epoch 959, CIFAR-10 Batch 2:  Train_Loss:0.5555845499038696, Valid_Loss:1.1995493173599243, Valid_ACC:0.6207998991012573
Epoch 959, CIFAR-10 Batch 3:  Train_Loss:0.5759814977645874, Valid_Loss:1.2125474214553833, Valid_ACC:0.6079999208450317
Epoch 959, CIFAR-10 Batch 4:  Train_Loss:0.5682366490364075, Valid_Loss:1.2024693489074707, Valid_ACC:0.6143999099731445
Epoch 959, CIFAR-10 Batch 5:  Train_Loss:0.593600332736969, Valid_Loss:1.21847665309906, Valid_ACC:0.6155998706817627
Epoch 960, CIFAR-10 Batch 1:  Train_Loss:0.5710535049438477, Valid_Loss:1.1926624774932861, Valid_ACC:0.6195998787879944
Epoch 960, CIFAR-10 Batch 2:  Train_Loss:0.5708072185516357, Valid_Loss:1.198356032371521, Valid_ACC:0.619399905204773
Epoch 960, CIFAR-10 Batch 3:  Train_Loss:0.5565921664237976, Valid_Loss:1.21348237991333, Valid_ACC:0.6121999025344849
Epoch 960, CIFAR-10 Batch 4:  Train_Loss:0.6061486005783081, Valid_Loss:1.2175477743148804, Valid_ACC:0.6163999438285828
Epoch 960, CIFAR-10 Batch 5:  Train_Loss:0.614898681640625, Valid_Loss:1.2525975704193115, Valid_ACC:0.6039999127388
Epoch 961, CIFAR-10 Batch 1:  Train_Loss:0.5698803663253784, Valid_Loss:1.2000818252563477, Valid_ACC:0.6191999316215515
Epoch 961, CIFAR-10 Batch 2:  Train_Loss:0.5752636790275574, Valid_Loss:1.2134816646575928, Valid_ACC:0.6107999086380005
Epoch 961, CIFAR-10 Batch 3:  Train_Loss:0.5676849484443665, Valid_Loss:1.2166930437088013, Valid_ACC:0.6119999289512634
Epoch 961, CIFAR-10 Batch 4:  Train_Loss:0.5826164484024048, Valid_Loss:1.2102577686309814, Valid_ACC:0.6121999025344849
Epoch 961, CIFAR-10 Batch 5:  Train_Loss:0.6027435064315796, Valid_Loss:1.2449003458023071, Valid_ACC:0.6089999079704285
Epoch 962, CIFAR-10 Batch 1:  Train_Loss:0.5790659785270691, Valid_Loss:1.2005456686019897, Valid_ACC:0.6183998584747314
Epoch 962, CIFAR-10 Batch 2:  Train_Loss:0.5968648195266724, Valid_Loss:1.2189077138900757, Valid_ACC:0.6159999370574951
Epoch 962, CIFAR-10 Batch 3:  Train_Loss:0.5723388195037842, Valid_Loss:1.211925983428955, Valid_ACC:0.6139999032020569
Epoch 962, CIFAR-10 Batch 4:  Train_Loss:0.5750904679298401, Valid_Loss:1.2021664381027222, Valid_ACC:0.6191999316215515
Epoch 962, CIFAR-10 Batch 5:  Train_Loss:0.5853607654571533, Valid_Loss:1.2286313772201538, Valid_ACC:0.6103999018669128
Epoch 963, CIFAR-10 Batch 1:  Train_Loss:0.5795473456382751, Valid_Loss:1.2087990045547485, Valid_ACC:0.6147999167442322
Epoch 963, CIFAR-10 Batch 2:  Train_Loss:0.5676285624504089, Valid_Loss:1.204817295074463, Valid_ACC:0.6153998970985413
Epoch 963, CIFAR-10 Batch 3:  Train_Loss:0.5530708432197571, Valid_Loss:1.2098475694656372, Valid_ACC:0.6105998754501343
Epoch 963, CIFAR-10 Batch 4:  Train_Loss:0.5689894556999207, Valid_Loss:1.2041996717453003, Valid_ACC:0.6143999099731445
Epoch 963, CIFAR-10 Batch 5:  Train_Loss:0.5899535417556763, Valid_Loss:1.2309956550598145, Valid_ACC:0.6075998544692993
Epoch 964, CIFAR-10 Batch 1:  Train_Loss:0.5575575232505798, Valid_Loss:1.196981430053711, Valid_ACC:0.6141999363899231
Epoch 964, CIFAR-10 Batch 2:  Train_Loss:0.5618633031845093, Valid_Loss:1.195220947265625, Valid_ACC:0.6175999045372009
Epoch 964, CIFAR-10 Batch 3:  Train_Loss:0.56772780418396, Valid_Loss:1.2188655138015747, Valid_ACC:0.6107999086380005
Epoch 964, CIFAR-10 Batch 4:  Train_Loss:0.5794646143913269, Valid_Loss:1.2241971492767334, Valid_ACC:0.6065999269485474
Epoch 964, CIFAR-10 Batch 5:  Train_Loss:0.6077960729598999, Valid_Loss:1.2455284595489502, Valid_ACC:0.6029999256134033
Epoch 965, CIFAR-10 Batch 1:  Train_Loss:0.6040543913841248, Valid_Loss:1.240556240081787, Valid_ACC:0.6023998856544495
Epoch 965, CIFAR-10 Batch 2:  Train_Loss:0.5690288543701172, Valid_Loss:1.208805799484253, Valid_ACC:0.6161999106407166
Epoch 965, CIFAR-10 Batch 3:  Train_Loss:0.5761879682540894, Valid_Loss:1.2095073461532593, Valid_ACC:0.6129999160766602
Epoch 965, CIFAR-10 Batch 4:  Train_Loss:0.5939176082611084, Valid_Loss:1.2168102264404297, Valid_ACC:0.6097999215126038
Epoch 965, CIFAR-10 Batch 5:  Train_Loss:0.5889827013015747, Valid_Loss:1.2332004308700562, Valid_ACC:0.603399932384491
Epoch 966, CIFAR-10 Batch 1:  Train_Loss:0.5834866762161255, Valid_Loss:1.2137951850891113, Valid_ACC:0.6137999296188354
Epoch 966, CIFAR-10 Batch 2:  Train_Loss:0.5760575532913208, Valid_Loss:1.2012892961502075, Valid_ACC:0.6171998977661133
Epoch 966, CIFAR-10 Batch 3:  Train_Loss:0.5593603849411011, Valid_Loss:1.2077556848526, Valid_ACC:0.6113998889923096
Epoch 966, CIFAR-10 Batch 4:  Train_Loss:0.5790125131607056, Valid_Loss:1.2069261074066162, Valid_ACC:0.613599956035614
Epoch 966, CIFAR-10 Batch 5:  Train_Loss:0.5935528874397278, Valid_Loss:1.2237271070480347, Valid_ACC:0.609799861907959
Epoch 967, CIFAR-10 Batch 1:  Train_Loss:0.6117343306541443, Valid_Loss:1.2256958484649658, Valid_ACC:0.6075998544692993
Epoch 967, CIFAR-10 Batch 2:  Train_Loss:0.6140002608299255, Valid_Loss:1.230625033378601, Valid_ACC:0.6075999140739441
Epoch 967, CIFAR-10 Batch 3:  Train_Loss:0.6221485733985901, Valid_Loss:1.262862205505371, Valid_ACC:0.5963999629020691
Epoch 967, CIFAR-10 Batch 4:  Train_Loss:0.6121204495429993, Valid_Loss:1.2233068943023682, Valid_ACC:0.6021998524665833
Epoch 967, CIFAR-10 Batch 5:  Train_Loss:0.5822762250900269, Valid_Loss:1.2044440507888794, Valid_ACC:0.6127999424934387
Epoch 968, CIFAR-10 Batch 1:  Train_Loss:0.5900152921676636, Valid_Loss:1.200726866722107, Valid_ACC:0.6167998909950256
Epoch 968, CIFAR-10 Batch 2:  Train_Loss:0.5808731913566589, Valid_Loss:1.2042555809020996, Valid_ACC:0.6179999113082886
Epoch 968, CIFAR-10 Batch 3:  Train_Loss:0.5691714882850647, Valid_Loss:1.2019662857055664, Valid_ACC:0.6115999221801758
Epoch 968, CIFAR-10 Batch 4:  Train_Loss:0.5776848793029785, Valid_Loss:1.197782278060913, Valid_ACC:0.613599956035614
Epoch 968, CIFAR-10 Batch 5:  Train_Loss:0.5854914784431458, Valid_Loss:1.2031447887420654, Valid_ACC:0.6137998104095459
Epoch 969, CIFAR-10 Batch 1:  Train_Loss:0.5827069282531738, Valid_Loss:1.2110352516174316, Valid_ACC:0.6101999282836914
Epoch 969, CIFAR-10 Batch 2:  Train_Loss:0.573127031326294, Valid_Loss:1.205940842628479, Valid_ACC:0.6157999038696289
Epoch 969, CIFAR-10 Batch 3:  Train_Loss:0.5519700050354004, Valid_Loss:1.2001283168792725, Valid_ACC:0.6191999316215515
Epoch 969, CIFAR-10 Batch 4:  Train_Loss:0.5688305497169495, Valid_Loss:1.201252818107605, Valid_ACC:0.6153998374938965
Epoch 969, CIFAR-10 Batch 5:  Train_Loss:0.5956689119338989, Valid_Loss:1.2408454418182373, Valid_ACC:0.6055999398231506
Epoch 970, CIFAR-10 Batch 1:  Train_Loss:0.6169360280036926, Valid_Loss:1.2269477844238281, Valid_ACC:0.6085999011993408
Epoch 970, CIFAR-10 Batch 2:  Train_Loss:0.5726372003555298, Valid_Loss:1.2056623697280884, Valid_ACC:0.6117998957633972
Epoch 970, CIFAR-10 Batch 3:  Train_Loss:0.5665467381477356, Valid_Loss:1.2118470668792725, Valid_ACC:0.6161999106407166
Epoch 970, CIFAR-10 Batch 4:  Train_Loss:0.5577546954154968, Valid_Loss:1.2056454420089722, Valid_ACC:0.6105999946594238
Epoch 970, CIFAR-10 Batch 5:  Train_Loss:0.5898666977882385, Valid_Loss:1.203603982925415, Valid_ACC:0.6159998774528503
Epoch 971, CIFAR-10 Batch 1:  Train_Loss:0.5740594267845154, Valid_Loss:1.2016987800598145, Valid_ACC:0.6125999689102173
Epoch 971, CIFAR-10 Batch 2:  Train_Loss:0.5755425095558167, Valid_Loss:1.2118581533432007, Valid_ACC:0.6167999505996704
Epoch 971, CIFAR-10 Batch 3:  Train_Loss:0.5543385744094849, Valid_Loss:1.2060707807540894, Valid_ACC:0.619399905204773
Epoch 971, CIFAR-10 Batch 4:  Train_Loss:0.5714155435562134, Valid_Loss:1.2034120559692383, Valid_ACC:0.6095998883247375
Epoch 971, CIFAR-10 Batch 5:  Train_Loss:0.5867524743080139, Valid_Loss:1.2181202173233032, Valid_ACC:0.6123999357223511
Epoch 972, CIFAR-10 Batch 1:  Train_Loss:0.5852049589157104, Valid_Loss:1.2043486833572388, Valid_ACC:0.6143999099731445
Epoch 972, CIFAR-10 Batch 2:  Train_Loss:0.5776785612106323, Valid_Loss:1.2138521671295166, Valid_ACC:0.6159998774528503
Epoch 972, CIFAR-10 Batch 3:  Train_Loss:0.5577325820922852, Valid_Loss:1.2020015716552734, Valid_ACC:0.6127999424934387
Epoch 972, CIFAR-10 Batch 4:  Train_Loss:0.5619783997535706, Valid_Loss:1.2034225463867188, Valid_ACC:0.6161999106407166
Epoch 972, CIFAR-10 Batch 5:  Train_Loss:0.6048670411109924, Valid_Loss:1.24183189868927, Valid_ACC:0.6103999018669128
Epoch 973, CIFAR-10 Batch 1:  Train_Loss:0.5818405151367188, Valid_Loss:1.2124099731445312, Valid_ACC:0.6105998754501343
Epoch 973, CIFAR-10 Batch 2:  Train_Loss:0.5812427997589111, Valid_Loss:1.195634365081787, Valid_ACC:0.6165998578071594
Epoch 973, CIFAR-10 Batch 3:  Train_Loss:0.5537217259407043, Valid_Loss:1.206587791442871, Valid_ACC:0.6175999045372009
Epoch 973, CIFAR-10 Batch 4:  Train_Loss:0.5721625685691833, Valid_Loss:1.2170989513397217, Valid_ACC:0.6115999221801758
Epoch 973, CIFAR-10 Batch 5:  Train_Loss:0.585549533367157, Valid_Loss:1.214538812637329, Valid_ACC:0.6159998774528503
Epoch 974, CIFAR-10 Batch 1:  Train_Loss:0.573988139629364, Valid_Loss:1.2184489965438843, Valid_ACC:0.6133999228477478
Epoch 974, CIFAR-10 Batch 2:  Train_Loss:0.5606572031974792, Valid_Loss:1.2020397186279297, Valid_ACC:0.6163999438285828
Epoch 974, CIFAR-10 Batch 3:  Train_Loss:0.5718072652816772, Valid_Loss:1.2162113189697266, Valid_ACC:0.6109999418258667
Epoch 974, CIFAR-10 Batch 4:  Train_Loss:0.563328206539154, Valid_Loss:1.2038711309432983, Valid_ACC:0.6117998957633972
Epoch 974, CIFAR-10 Batch 5:  Train_Loss:0.5821048021316528, Valid_Loss:1.2219791412353516, Valid_ACC:0.6145999431610107
Epoch 975, CIFAR-10 Batch 1:  Train_Loss:0.602806806564331, Valid_Loss:1.2206131219863892, Valid_ACC:0.6105998754501343
Epoch 975, CIFAR-10 Batch 2:  Train_Loss:0.5670490264892578, Valid_Loss:1.2089464664459229, Valid_ACC:0.6157999038696289
Epoch 975, CIFAR-10 Batch 3:  Train_Loss:0.5678155422210693, Valid_Loss:1.222480297088623, Valid_ACC:0.6111999154090881
Epoch 975, CIFAR-10 Batch 4:  Train_Loss:0.5928296446800232, Valid_Loss:1.2320683002471924, Valid_ACC:0.6109999418258667
Epoch 975, CIFAR-10 Batch 5:  Train_Loss:0.5922718644142151, Valid_Loss:1.2190475463867188, Valid_ACC:0.6137999296188354
Epoch 976, CIFAR-10 Batch 1:  Train_Loss:0.5754711627960205, Valid_Loss:1.215710997581482, Valid_ACC:0.6093999147415161
Epoch 976, CIFAR-10 Batch 2:  Train_Loss:0.563541054725647, Valid_Loss:1.2034313678741455, Valid_ACC:0.6185998916625977
Epoch 976, CIFAR-10 Batch 3:  Train_Loss:0.5631778240203857, Valid_Loss:1.2143771648406982, Valid_ACC:0.6113998889923096
Epoch 976, CIFAR-10 Batch 4:  Train_Loss:0.56568443775177, Valid_Loss:1.2049349546432495, Valid_ACC:0.6151999235153198
Epoch 976, CIFAR-10 Batch 5:  Train_Loss:0.5801709294319153, Valid_Loss:1.219376564025879, Valid_ACC:0.6135998964309692
Epoch 977, CIFAR-10 Batch 1:  Train_Loss:0.5920766592025757, Valid_Loss:1.2230846881866455, Valid_ACC:0.611799955368042
Epoch 977, CIFAR-10 Batch 2:  Train_Loss:0.5612612962722778, Valid_Loss:1.1941876411437988, Valid_ACC:0.6209999322891235
Epoch 977, CIFAR-10 Batch 3:  Train_Loss:0.5517772436141968, Valid_Loss:1.2022455930709839, Valid_ACC:0.6171998977661133
Epoch 977, CIFAR-10 Batch 4:  Train_Loss:0.5721522569656372, Valid_Loss:1.2064595222473145, Valid_ACC:0.608799934387207
Epoch 977, CIFAR-10 Batch 5:  Train_Loss:0.5918973684310913, Valid_Loss:1.225520372390747, Valid_ACC:0.6127999424934387
Epoch 978, CIFAR-10 Batch 1:  Train_Loss:0.5985337495803833, Valid_Loss:1.2198243141174316, Valid_ACC:0.6135998964309692
Epoch 978, CIFAR-10 Batch 2:  Train_Loss:0.5560552477836609, Valid_Loss:1.1971853971481323, Valid_ACC:0.6173999309539795
Epoch 978, CIFAR-10 Batch 3:  Train_Loss:0.5631073713302612, Valid_Loss:1.2149066925048828, Valid_ACC:0.6127999424934387
Epoch 978, CIFAR-10 Batch 4:  Train_Loss:0.5960016250610352, Valid_Loss:1.2203693389892578, Valid_ACC:0.6167999505996704
Epoch 978, CIFAR-10 Batch 5:  Train_Loss:0.5756665468215942, Valid_Loss:1.224745512008667, Valid_ACC:0.6149999499320984
Epoch 979, CIFAR-10 Batch 1:  Train_Loss:0.5743213295936584, Valid_Loss:1.2151790857315063, Valid_ACC:0.6097999215126038
Epoch 979, CIFAR-10 Batch 2:  Train_Loss:0.5551146268844604, Valid_Loss:1.1972407102584839, Valid_ACC:0.6211998462677002
Epoch 979, CIFAR-10 Batch 3:  Train_Loss:0.5590999126434326, Valid_Loss:1.2065939903259277, Valid_ACC:0.616399884223938
Epoch 979, CIFAR-10 Batch 4:  Train_Loss:0.5648499727249146, Valid_Loss:1.208566427230835, Valid_ACC:0.612799882888794
Epoch 979, CIFAR-10 Batch 5:  Train_Loss:0.5741377472877502, Valid_Loss:1.2208417654037476, Valid_ACC:0.6157999038696289
Epoch 980, CIFAR-10 Batch 1:  Train_Loss:0.5735352635383606, Valid_Loss:1.2064651250839233, Valid_ACC:0.6127999424934387
Epoch 980, CIFAR-10 Batch 2:  Train_Loss:0.5575557947158813, Valid_Loss:1.1975579261779785, Valid_ACC:0.621199905872345
Epoch 980, CIFAR-10 Batch 3:  Train_Loss:0.580289900302887, Valid_Loss:1.2240092754364014, Valid_ACC:0.6129999756813049
Epoch 980, CIFAR-10 Batch 4:  Train_Loss:0.5687105655670166, Valid_Loss:1.2066874504089355, Valid_ACC:0.6135998964309692
Epoch 980, CIFAR-10 Batch 5:  Train_Loss:0.5851956009864807, Valid_Loss:1.2229728698730469, Valid_ACC:0.6109999418258667
Epoch 981, CIFAR-10 Batch 1:  Train_Loss:0.5758479237556458, Valid_Loss:1.2056682109832764, Valid_ACC:0.6149998903274536
Epoch 981, CIFAR-10 Batch 2:  Train_Loss:0.5771186351776123, Valid_Loss:1.2011924982070923, Valid_ACC:0.6175998449325562
Epoch 981, CIFAR-10 Batch 3:  Train_Loss:0.5525498986244202, Valid_Loss:1.2111915349960327, Valid_ACC:0.6113998889923096
Epoch 981, CIFAR-10 Batch 4:  Train_Loss:0.564750611782074, Valid_Loss:1.2055519819259644, Valid_ACC:0.6123999357223511
Epoch 981, CIFAR-10 Batch 5:  Train_Loss:0.5755506157875061, Valid_Loss:1.214788556098938, Valid_ACC:0.614599883556366
Epoch 982, CIFAR-10 Batch 1:  Train_Loss:0.566981315612793, Valid_Loss:1.2028777599334717, Valid_ACC:0.6195999383926392
Epoch 982, CIFAR-10 Batch 2:  Train_Loss:0.5563448071479797, Valid_Loss:1.19329035282135, Valid_ACC:0.6207998991012573
Epoch 982, CIFAR-10 Batch 3:  Train_Loss:0.5600717663764954, Valid_Loss:1.204880952835083, Valid_ACC:0.6157999038696289
Epoch 982, CIFAR-10 Batch 4:  Train_Loss:0.5665820240974426, Valid_Loss:1.2087284326553345, Valid_ACC:0.6121999025344849
Epoch 982, CIFAR-10 Batch 5:  Train_Loss:0.5722453594207764, Valid_Loss:1.2179003953933716, Valid_ACC:0.6155998706817627
Epoch 983, CIFAR-10 Batch 1:  Train_Loss:0.5761057138442993, Valid_Loss:1.2094502449035645, Valid_ACC:0.6117998957633972
Epoch 983, CIFAR-10 Batch 2:  Train_Loss:0.5546888113021851, Valid_Loss:1.19441819190979, Valid_ACC:0.6235998868942261
Epoch 983, CIFAR-10 Batch 3:  Train_Loss:0.5824573040008545, Valid_Loss:1.2215116024017334, Valid_ACC:0.6079999208450317
Epoch 983, CIFAR-10 Batch 4:  Train_Loss:0.5677268505096436, Valid_Loss:1.2041079998016357, Valid_ACC:0.6149998903274536
Epoch 983, CIFAR-10 Batch 5:  Train_Loss:0.5899753570556641, Valid_Loss:1.2201159000396729, Valid_ACC:0.6165999174118042
Epoch 984, CIFAR-10 Batch 1:  Train_Loss:0.5779784917831421, Valid_Loss:1.220388650894165, Valid_ACC:0.6113998889923096
Epoch 984, CIFAR-10 Batch 2:  Train_Loss:0.564362645149231, Valid_Loss:1.216353178024292, Valid_ACC:0.6123998761177063
Epoch 984, CIFAR-10 Batch 3:  Train_Loss:0.5636590123176575, Valid_Loss:1.2125366926193237, Valid_ACC:0.6103999018669128
Epoch 984, CIFAR-10 Batch 4:  Train_Loss:0.5777065753936768, Valid_Loss:1.2119091749191284, Valid_ACC:0.6089999079704285
Epoch 984, CIFAR-10 Batch 5:  Train_Loss:0.577325701713562, Valid_Loss:1.2229100465774536, Valid_ACC:0.6113998889923096
Epoch 985, CIFAR-10 Batch 1:  Train_Loss:0.5656945705413818, Valid_Loss:1.2066764831542969, Valid_ACC:0.6157999038696289
Epoch 985, CIFAR-10 Batch 2:  Train_Loss:0.5571933388710022, Valid_Loss:1.1924054622650146, Valid_ACC:0.6159999370574951
Epoch 985, CIFAR-10 Batch 3:  Train_Loss:0.5747477412223816, Valid_Loss:1.2185521125793457, Valid_ACC:0.6119998693466187
Epoch 985, CIFAR-10 Batch 4:  Train_Loss:0.5696014165878296, Valid_Loss:1.205828070640564, Valid_ACC:0.6115999221801758
Epoch 985, CIFAR-10 Batch 5:  Train_Loss:0.584863543510437, Valid_Loss:1.231157660484314, Valid_ACC:0.6119999289512634
Epoch 986, CIFAR-10 Batch 1:  Train_Loss:0.5907416343688965, Valid_Loss:1.2290172576904297, Valid_ACC:0.60999995470047
Epoch 986, CIFAR-10 Batch 2:  Train_Loss:0.5605384707450867, Valid_Loss:1.191827416419983, Valid_ACC:0.6157999038696289
Epoch 986, CIFAR-10 Batch 3:  Train_Loss:0.5556530952453613, Valid_Loss:1.2032322883605957, Valid_ACC:0.613599956035614
Epoch 986, CIFAR-10 Batch 4:  Train_Loss:0.5644782185554504, Valid_Loss:1.2014986276626587, Valid_ACC:0.6123999357223511
Epoch 986, CIFAR-10 Batch 5:  Train_Loss:0.5882296562194824, Valid_Loss:1.2247610092163086, Valid_ACC:0.6119998693466187
Epoch 987, CIFAR-10 Batch 1:  Train_Loss:0.5759688019752502, Valid_Loss:1.221951961517334, Valid_ACC:0.6109998822212219
Epoch 987, CIFAR-10 Batch 2:  Train_Loss:0.5626171231269836, Valid_Loss:1.203129768371582, Valid_ACC:0.6157999038696289
Epoch 987, CIFAR-10 Batch 3:  Train_Loss:0.5642150640487671, Valid_Loss:1.2102739810943604, Valid_ACC:0.6129999160766602
Epoch 987, CIFAR-10 Batch 4:  Train_Loss:0.5500103831291199, Valid_Loss:1.2001357078552246, Valid_ACC:0.6141999363899231
Epoch 987, CIFAR-10 Batch 5:  Train_Loss:0.5788376331329346, Valid_Loss:1.215184211730957, Valid_ACC:0.6151999235153198
Epoch 988, CIFAR-10 Batch 1:  Train_Loss:0.6005665063858032, Valid_Loss:1.2269015312194824, Valid_ACC:0.6095999479293823
Epoch 988, CIFAR-10 Batch 2:  Train_Loss:0.5802223086357117, Valid_Loss:1.2054829597473145, Valid_ACC:0.6159998774528503
Epoch 988, CIFAR-10 Batch 3:  Train_Loss:0.5588589310646057, Valid_Loss:1.2113773822784424, Valid_ACC:0.6159998774528503
Epoch 988, CIFAR-10 Batch 4:  Train_Loss:0.558310329914093, Valid_Loss:1.2019935846328735, Valid_ACC:0.6133999228477478
Epoch 988, CIFAR-10 Batch 5:  Train_Loss:0.592747688293457, Valid_Loss:1.208999752998352, Valid_ACC:0.6193998456001282
Epoch 989, CIFAR-10 Batch 1:  Train_Loss:0.5855807065963745, Valid_Loss:1.2138934135437012, Valid_ACC:0.6103999018669128
Epoch 989, CIFAR-10 Batch 2:  Train_Loss:0.5761075019836426, Valid_Loss:1.2171564102172852, Valid_ACC:0.6105998754501343
Epoch 989, CIFAR-10 Batch 3:  Train_Loss:0.549228310585022, Valid_Loss:1.2114242315292358, Valid_ACC:0.6157999038696289
Epoch 989, CIFAR-10 Batch 4:  Train_Loss:0.559317946434021, Valid_Loss:1.203848123550415, Valid_ACC:0.6125999093055725
Epoch 989, CIFAR-10 Batch 5:  Train_Loss:0.5772006511688232, Valid_Loss:1.205214023590088, Valid_ACC:0.6183999180793762
Epoch 990, CIFAR-10 Batch 1:  Train_Loss:0.578977108001709, Valid_Loss:1.2153396606445312, Valid_ACC:0.6131998896598816
Epoch 990, CIFAR-10 Batch 2:  Train_Loss:0.5784575939178467, Valid_Loss:1.2031738758087158, Valid_ACC:0.6187999248504639
Epoch 990, CIFAR-10 Batch 3:  Train_Loss:0.5477449297904968, Valid_Loss:1.195124626159668, Valid_ACC:0.6149998903274536
Epoch 990, CIFAR-10 Batch 4:  Train_Loss:0.5642712712287903, Valid_Loss:1.199368953704834, Valid_ACC:0.6128000020980835
Epoch 990, CIFAR-10 Batch 5:  Train_Loss:0.589278519153595, Valid_Loss:1.2141027450561523, Valid_ACC:0.6135998964309692
Epoch 991, CIFAR-10 Batch 1:  Train_Loss:0.5989198684692383, Valid_Loss:1.2327052354812622, Valid_ACC:0.6055999398231506
Epoch 991, CIFAR-10 Batch 2:  Train_Loss:0.5730732679367065, Valid_Loss:1.2163996696472168, Valid_ACC:0.6091999411582947
Epoch 991, CIFAR-10 Batch 3:  Train_Loss:0.5619924068450928, Valid_Loss:1.2111581563949585, Valid_ACC:0.6133999228477478
Epoch 991, CIFAR-10 Batch 4:  Train_Loss:0.5883014798164368, Valid_Loss:1.2220861911773682, Valid_ACC:0.6061999201774597
Epoch 991, CIFAR-10 Batch 5:  Train_Loss:0.6084994077682495, Valid_Loss:1.2295384407043457, Valid_ACC:0.6119999289512634
Epoch 992, CIFAR-10 Batch 1:  Train_Loss:0.5717222690582275, Valid_Loss:1.2032567262649536, Valid_ACC:0.6117998957633972
Epoch 992, CIFAR-10 Batch 2:  Train_Loss:0.5588951706886292, Valid_Loss:1.2043359279632568, Valid_ACC:0.6141998767852783
Epoch 992, CIFAR-10 Batch 3:  Train_Loss:0.5535073280334473, Valid_Loss:1.2019953727722168, Valid_ACC:0.6131998896598816
Epoch 992, CIFAR-10 Batch 4:  Train_Loss:0.595241904258728, Valid_Loss:1.2258739471435547, Valid_ACC:0.6069998741149902
Epoch 992, CIFAR-10 Batch 5:  Train_Loss:0.5756700038909912, Valid_Loss:1.2106788158416748, Valid_ACC:0.6161999106407166
Epoch 993, CIFAR-10 Batch 1:  Train_Loss:0.5697667002677917, Valid_Loss:1.206804871559143, Valid_ACC:0.6121999025344849
Epoch 993, CIFAR-10 Batch 2:  Train_Loss:0.5552444458007812, Valid_Loss:1.1972219944000244, Valid_ACC:0.6205998659133911
Epoch 993, CIFAR-10 Batch 3:  Train_Loss:0.5559707880020142, Valid_Loss:1.2012004852294922, Valid_ACC:0.6171998977661133
Epoch 993, CIFAR-10 Batch 4:  Train_Loss:0.560828447341919, Valid_Loss:1.2008658647537231, Valid_ACC:0.6123998761177063
Epoch 993, CIFAR-10 Batch 5:  Train_Loss:0.5959306359291077, Valid_Loss:1.2248308658599854, Valid_ACC:0.6081998944282532
Epoch 994, CIFAR-10 Batch 1:  Train_Loss:0.5836399793624878, Valid_Loss:1.214072585105896, Valid_ACC:0.6113998889923096
Epoch 994, CIFAR-10 Batch 2:  Train_Loss:0.5687541365623474, Valid_Loss:1.210270881652832, Valid_ACC:0.613399863243103
Epoch 994, CIFAR-10 Batch 3:  Train_Loss:0.5579039454460144, Valid_Loss:1.205452561378479, Valid_ACC:0.6131999492645264
Epoch 994, CIFAR-10 Batch 4:  Train_Loss:0.5562238693237305, Valid_Loss:1.2000954151153564, Valid_ACC:0.613399863243103
Epoch 994, CIFAR-10 Batch 5:  Train_Loss:0.5867575407028198, Valid_Loss:1.2225230932235718, Valid_ACC:0.6097999215126038
Epoch 995, CIFAR-10 Batch 1:  Train_Loss:0.5864357352256775, Valid_Loss:1.2145859003067017, Valid_ACC:0.614599883556366
Epoch 995, CIFAR-10 Batch 2:  Train_Loss:0.589786171913147, Valid_Loss:1.2256429195404053, Valid_ACC:0.6055998802185059
Epoch 995, CIFAR-10 Batch 3:  Train_Loss:0.5546073913574219, Valid_Loss:1.2077285051345825, Valid_ACC:0.6119999289512634
Epoch 995, CIFAR-10 Batch 4:  Train_Loss:0.5534567832946777, Valid_Loss:1.1934947967529297, Valid_ACC:0.6149998903274536
Epoch 995, CIFAR-10 Batch 5:  Train_Loss:0.5672957897186279, Valid_Loss:1.2016853094100952, Valid_ACC:0.6209999322891235
Epoch 996, CIFAR-10 Batch 1:  Train_Loss:0.5878874063491821, Valid_Loss:1.2123069763183594, Valid_ACC:0.612799882888794
Epoch 996, CIFAR-10 Batch 2:  Train_Loss:0.6034460067749023, Valid_Loss:1.235377311706543, Valid_ACC:0.6063998937606812
Epoch 996, CIFAR-10 Batch 3:  Train_Loss:0.5640957355499268, Valid_Loss:1.213568925857544, Valid_ACC:0.611599862575531
Epoch 996, CIFAR-10 Batch 4:  Train_Loss:0.5709149837493896, Valid_Loss:1.2120654582977295, Valid_ACC:0.6123999357223511
Epoch 996, CIFAR-10 Batch 5:  Train_Loss:0.5806182026863098, Valid_Loss:1.2154909372329712, Valid_ACC:0.6181999444961548
Epoch 997, CIFAR-10 Batch 1:  Train_Loss:0.6065478920936584, Valid_Loss:1.2281761169433594, Valid_ACC:0.6075998544692993
Epoch 997, CIFAR-10 Batch 2:  Train_Loss:0.575984001159668, Valid_Loss:1.2211965322494507, Valid_ACC:0.6117998957633972
Epoch 997, CIFAR-10 Batch 3:  Train_Loss:0.5494920611381531, Valid_Loss:1.1971155405044556, Valid_ACC:0.6213999390602112
Epoch 997, CIFAR-10 Batch 4:  Train_Loss:0.5724044442176819, Valid_Loss:1.2085033655166626, Valid_ACC:0.6119999289512634
Epoch 997, CIFAR-10 Batch 5:  Train_Loss:0.5711565017700195, Valid_Loss:1.216066837310791, Valid_ACC:0.6143999099731445
Epoch 998, CIFAR-10 Batch 1:  Train_Loss:0.5776127576828003, Valid_Loss:1.2026026248931885, Valid_ACC:0.6127999424934387
Epoch 998, CIFAR-10 Batch 2:  Train_Loss:0.5780267119407654, Valid_Loss:1.215045690536499, Valid_ACC:0.6123998761177063
Epoch 998, CIFAR-10 Batch 3:  Train_Loss:0.5498159527778625, Valid_Loss:1.1956368684768677, Valid_ACC:0.619399905204773
Epoch 998, CIFAR-10 Batch 4:  Train_Loss:0.5538732409477234, Valid_Loss:1.1967778205871582, Valid_ACC:0.6163999438285828
Epoch 998, CIFAR-10 Batch 5:  Train_Loss:0.5867708921432495, Valid_Loss:1.2021000385284424, Valid_ACC:0.6203998923301697
Epoch 999, CIFAR-10 Batch 1:  Train_Loss:0.5898041129112244, Valid_Loss:1.2167912721633911, Valid_ACC:0.6145999431610107
Epoch 999, CIFAR-10 Batch 2:  Train_Loss:0.6093196272850037, Valid_Loss:1.2467591762542725, Valid_ACC:0.6015998721122742
Epoch 999, CIFAR-10 Batch 3:  Train_Loss:0.5632667541503906, Valid_Loss:1.2172136306762695, Valid_ACC:0.6143999695777893
Epoch 999, CIFAR-10 Batch 4:  Train_Loss:0.5670855045318604, Valid_Loss:1.2141672372817993, Valid_ACC:0.6157999038696289
Epoch 999, CIFAR-10 Batch 5:  Train_Loss:0.5875425934791565, Valid_Loss:1.2156904935836792, Valid_ACC:0.6175999641418457
Epoch 1000, CIFAR-10 Batch 1:  Train_Loss:0.5655543804168701, Valid_Loss:1.2057818174362183, Valid_ACC:0.6157999038696289
Epoch 1000, CIFAR-10 Batch 2:  Train_Loss:0.5697718262672424, Valid_Loss:1.207259178161621, Valid_ACC:0.6203998923301697
Epoch 1000, CIFAR-10 Batch 3:  Train_Loss:0.5513326525688171, Valid_Loss:1.2000902891159058, Valid_ACC:0.6143999099731445
Epoch 1000, CIFAR-10 Batch 4:  Train_Loss:0.5558584928512573, Valid_Loss:1.2063511610031128, Valid_ACC:0.6119999885559082
Epoch 1000, CIFAR-10 Batch 5:  Train_Loss:0.5853994488716125, Valid_Loss:1.2142045497894287, Valid_ACC:0.6153998970985413
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1><p>The model has been saved to disk.</p>
<h2 id="Test-Model">Test Model<a class="anchor-link" href="#Test-Model">&#182;</a></h2><p>Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Set batch size if not already set</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">pass</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">top_n_predictions</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">test_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the saved model against the test dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_training.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
    <span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Load model</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_model_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>

        <span class="c1"># Get Tensors from loaded model</span>
        <span class="n">loaded_x</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;x:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_y</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;y:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_acc</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;accuracy:0&#39;</span><span class="p">)</span>
        
        <span class="c1"># Get accuracy in batches for memory limitations</span>
        <span class="n">test_batch_acc_total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">test_batch_count</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">train_feature_batch</span><span class="p">,</span> <span class="n">train_label_batch</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">batch_features_labels</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">test_batch_acc_total</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">loaded_acc</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">train_feature_batch</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">train_label_batch</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">test_batch_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Accuracy: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_batch_acc_total</span><span class="o">/</span><span class="n">test_batch_count</span><span class="p">))</span>

        <span class="c1"># Print Random Samples</span>
        <span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)),</span> <span class="n">n_samples</span><span class="p">)))</span>
        <span class="n">random_test_predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">loaded_logits</span><span class="p">),</span> <span class="n">top_n_predictions</span><span class="p">),</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">random_test_features</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
        <span class="n">helper</span><span class="o">.</span><span class="n">display_image_predictions</span><span class="p">(</span><span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">random_test_predictions</span><span class="p">)</span>


<span class="n">test_model</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Testing Accuracy: 0.6093590497970581

</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=355
height=319
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-50-80%-Accuracy?">Why 50-80% Accuracy?<a class="anchor-link" href="#Why-50-80%-Accuracy?">&#182;</a></h2><p>You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130">well above 80%</a>.  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as "dlnd_image_classification.ipynb" and save it as a HTML file under "File" -&gt; "Download as".  Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
